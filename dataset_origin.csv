REDAME_file,Heading,Contents,Codes with >= 2 votes
https://github.com/sethm/symon,# SYMON - A 6502 System Simulator," Version: 1.3.1 Last Updated: 12 October, 2019 See the file COPYING for license. ",14
https://github.com/sethm/symon,## 1.0 About,"  Symon is a general purpose simulator for systems based on the MOS
Technologies 6502 microprocessor and compatibles. Symon is implemented
in Java. Its core goals are accuracy, ease of development, clear
documentation, and extensive test suites for validating correctness. Symon simulates a complete system with a 1 MHz NMOS 6502 or CMOS
65C02, 32KB of RAM, 16KB of ROM, a MOS 6551 or Motorola 6850 ACIA, a
MOS 6522 VIA, and an experimental 6545 CRTC. Symon has extensive unit tests to verify correctness, and fully passes
Klaus Dormann's 6502 Functional Test Suite as of version 0.8.2
(See this thread on the 6502.org Forums
for more information about this functional test suite). Symon is under constant, active development. Feedback and patches
are always welcome.",1246
https://github.com/sethm/symon,## 2.0 Requirements,"  
Java 1.8 or higher
Maven 2.0.x or higher (for building from source)
JUnit 4 or higher (for testing)
",3
https://github.com/sethm/symon,## 3.0 Features,"  Symon can simulate multiple 6502 based architectures. At present, three
machines are implemented: Symon (the default), MULTICOMP, and a ""Simple""
machine useful for debugging.",1
https://github.com/sethm/symon,### 3.1 Memory Maps, ,1
https://github.com/sethm/symon,#### 3.1.1 Symon Memory Map,"  
$0000--$7FFF: 32KB RAM
$8000--$800F: 6522 VIA
$8800--$8803: MOS 6551 ACIA (Serial Console)
$9000--$9001: MOS 6545 CRTC
$C000--$FFFF: 16KB ROM
 The CRT Controller uses memory address $7000 as the start of Video
memory.",1
https://github.com/sethm/symon,#### 3.1.2 MULTICOMP Memory Map,"  
$0000--$DFFF: 56KB RAM
$E000--$FFFF: 8KB ROM
$FFD0--$FFD1: Motorola 6850 ACIA
$FFD8--$FFDF: Controller for SD cards
",1
https://github.com/sethm/symon,### 3.1.3 Simple Memory Map,"  
$0000--$FFFF: 64KB RAM
",1
https://github.com/sethm/symon,### 3.2 Serial Console and CPU Status,"   The main window of the simulator acts as the primary Input/Output
system through a virtual serial terminal. The terminal is attached to
a simulated ACIA, including a programmable baud rate generator that
tries to approximate the correct ""feel"" of the programmed baud rate.
(The sample Enhanced BASIC ROM image is programmed for 9600 baud) It also provides CPU status. Contents of the accumulator, index
registers, processor status flags, disassembly of the instruction
register, and stack pointer are all displayed.  The console supports font sizes from 10 to 20 points.",1
https://github.com/sethm/symon,### 3.3 ROM Loading,"   Symon can load any appropriately sized ROM image. The Symon
architecture expects as 16KB (16384 byte) ROM image, while the
MULTICOMP architecture expects an 8KB (8192 byte) ROM image. Images
are loaded via the ""Load ROM..."" action in the ""File"" menu. The
selected ROM file will be loaded into memory at the correct ROM base
address.",1
https://github.com/sethm/symon,### 3.4 Memory Window,   Memory contents can be viewed (and edited) one page at a time through the Memory Window.,1
https://github.com/sethm/symon,### 3.5 Trace Log,"   The last 20,000 execution steps are disassembled and logged to the Trace Log
Window.",1
https://github.com/sethm/symon,### 3.6 Simulator Speeds,   Simulated speeds may be set from 1MHz to 8MHz.,1
https://github.com/sethm/symon,### 3.7 Breakpoints,   Breakpoints can be set and removed through the Breakpoints window.,1
https://github.com/sethm/symon,### 3.8 Experimental 6545 CRTC Video,"   This feature is highly experimental. It's possible to open a video window
from the ""View"" menu.  This window simulates the output of a MOS 6545 CRT
Controller located at address $9000 and $9001. By default, the 40 x 25 character display uses video memory located at base
address $7000.  This means that the memory from address $7000 (28672
decimal) to $73E8 (29672 decimal) is directly mapped to video. 
Address Register (at address $9000)
R1: Horizontal Displayed Columns
R6: Vertical Displayed Rows
R9: Scan Lines per Row
R10: Cursor Start Scan Line and Cursor Control Mode
R11: Cursor End Scan Line
R12: Display Start Address (High Byte)
R13: Display Start Address (Low Byte)
R14: Cursor Position (High Byte)
R15: Cursor Position (Low Byte)
 Although the simulation is pretty good, there are a few key differences
between the simulated 6545 and a real 6545: 

The simulated 6545 supports only the straight binary addressing
mode of the real 6545, and not the Row/Column addressing mode.


The simulated 6545 has full 16 bit addressing, where the real 6545
has only a 14-bit address bus.


The simulation is done at a whole-frame level, meaning that lots
of 6545 programming tricks that were achieved by updating the
frame address during vertical and horizontal sync times are not
achievable.  There is no way (for example) to change the Display Start
Address (R12 and R13) while a frame is being drawn.

 For more information on the 6545 CRTC and its programming model, please see the following resources 
CRTC 6545/6845 Information (André Fachat)
CRTC Operation (André Fachat)
MOS 6545 Datasheet (PDF)
",16
https://github.com/sethm/symon,#### 3.8.1 Example BASIC Program to test Video,"  This program will fill the video screen with all printable characters. 10 J = 0
20 FOR I = 28672 TO 29672
30 POKE I,J
40 IF J < 255 THEN J = J + 1 ELSE J = 0
50 NEXT I
60 END
",1
https://github.com/sethm/symon,## 4.0 Usage, ,3
https://github.com/sethm/symon,### 4.1 Building,"  To build Symon with Apache Maven, just type: $ mvn package
 Maven will build Symon, run unit tests, and produce a jar file in the
target directory containing the compiled simulator. Symon is meant to be invoked directly from the jar file. To run with
Java 1.8 or greater, just type: $ java -jar symon-1.2.0.jar
 When Symon is running, you should be presented with a simple graphical
interface.",3
https://github.com/sethm/symon,### 4.2 ROM images,"  The simulator requires a ROM image loaded into memory to work
properly. Without a ROM in memory, the simulator will not be able to
reset, since the reset vector for the 6502 is located in the ROM
address space. By default, any file named rom.bin that exists in the same directory
where Symon is launched will be loaded as a ROM image. ROM images can
also be swapped out at run-time with the ""Load ROM Image..."" in the
File menu. The ""samples"" directory contains a ROM image for the Symon
architecture named 'ehbasic.rom', containing Lee Davison's Enhanced
6502 BASIC. This serves as a good starting point for exploration. Note: Presently, EhBASIC only works with the Symon machine
architecture, not with MULTICOMP.",3
https://github.com/sethm/symon,### 4.3 Loading A Program,"  In addition to ROM images, programs in the form of raw binary object files can
be loaded directly into memory from ""Load Program..."" in the File menu. Programs are loaded starting at addres $0300.  After loading the program, the
simulated CPU's reset vector is loaded with the values $00, $03, and the CPU is
reset. There are two very simple sample program in the ""samples"" directory,
for testing. 

'echo.prg' will echo back anything typed at the console.


'hello.prg' will continuously print ""Hello, 6502 World!"" to the console.

",3
https://github.com/sethm/symon,### 4.4 Running,"  After loading a program or ROM image, clicking ""Run"" will start the simulator
running.",3
https://github.com/sethm/symon,## 5.0 Revision History,"  

1.3.1: 12 October, 2019 - Add support for new command line
option -cpu <type> to specify one of 6502 or 65c02 on startup,
and new option -rom <file> to specify a ROM file to load.


1.3.0: 24 February, 2018 - Adds support for 65C02 opcodes.


1.2.1: 8 January, 2016 - Remove dependency on Java 8. Now
supports compiling and running under Java 1.7.


1.2.0: 3 January, 2016 - Add symbolic disassembly to breakpoints
window.


1.1.1: 2 January, 2016 - Minor enhancement: Allows breakpoints
to be added with the Enter key.


1.1.0: 31 December, 2015 - Fixed delay loop to better
simulate various clock speeds. Added ability to select clock
speed at runtime. Status display now shows the next instruction
to be executed, instead of the last instruction executed.
Added support for breakpoints.


1.0.0: 10 August, 2014 - Added ""Simple"" machine
implementation, pure RAM with no IO. Added Klaus Dormann's
6502 Functional Tests for further machine verification (these
tests must be run in the ""Simple"" machine).


0.9.9.1: 27 July, 2014 - Pressing 'Control' while clicking
'Reset' now performs a memory clear.


0.9.9: 26 July, 2014 - MULTICOMP and multi-machine support
contributed by Maik Merten <maikmerten@googlemail.com>


0.9.1: 26 January, 2014 - Support for IRQ and NMI handling.


0.9.0: 29 December, 2013 - First pass at a 6545 CRTC simulation.


0.8.5: 30 March, 2013 - ASCII display for memory window.
Allows user to select a step count from a drop-down box.


0.8.4: 4 March, 2013 - Fix for ZPX, ZPY display in the trace log
(change contributed by jsissom)


0.8.3: 12 January, 2013 - Added tool-tip text. Memory is no longer
cleared when resetting. Fixed swapped register labels.


0.8.2: 01 January, 2013 - Fully passes Klaus Dormann's 6502 Functional Test suite!


0.8.1: 30 December, 2012


0.8.0: 29 December, 2012


0.7.0: 9 December, 2012


0.6: 5 November, 2012


0.5: 21 October, 2012 - Able to run Enhanced BASIC for the first time.


0.3: 14 October, 2012


0.2: 22 April, 2012


0.1: 20 January, 2010

",4
https://github.com/sethm/symon,## 6.0 Roadmap,"  

1.2: Better breakpoint support. Symbolic debugging of breakpoints.


2.0: Complete rewrite of the UI in JavaFX instead of Swing. Complete
assembler and disassembler built in. Ability to attach source code for
symbolic debugging.

",4
https://github.com/sethm/symon,## 7.0 To Do,"  

Feedback (in the form of dialogs, status bar, etc).


Better debugging tools from the UI, including breakpoints
and disassembly.


UI needs a ton more polish.


More extensive testing.


Clean up JavaDoc.


Implement CMOS 65C02 instructions and NMOS / CMOS mode flag.


Allow displaying ACIA status and dumping ACIA buffers, for
debugging.


CRTC emulation is very naive. The whole frame is drawn in one
CPU step. This should be improved by drawing scan lines during
machine steps to approximate real NTSC/PAL refresh rates.


Symbolic debugging.

",4
https://github.com/sethm/symon,## 8.0 Copyright and Acknowledgements,"  Copyright (c) 2014 Seth J. Morabito <web@loomcom.com> Portions Copyright (c) 2014 Maik Merten <maikmerten@googlemail.com> Additional components used in this project are copyright their respective owners. 
Enhanced 6502 BASIC Copyright (c) Lee Davison
6502 Functional Tests Copyright (c) Klaus Dormann
JTerminal Copyright (c) Graham Edgecombe
 This project would not have been possible without the following resources: 

Andrew Jacobs' 6502 Pages, for
wonderfully detailed information about the 6502


Neil Parker's ""The 6502/65C02/65C816 Instruction Set Decoded"",
for information about how instructions are coded

",5
https://github.com/sethm/symon,## 9.0 Licensing,,5
https://github.com/lastromanticx/oo-inheritance-code-along-wdf-000,# Code Along: An Intro to Inheritance,,1
https://github.com/lastromanticx/oo-inheritance-code-along-wdf-000,## Objectives,"  
Learn about inheritance in object oriented Ruby.
Write classes that inherit from another class.
",12
https://github.com/lastromanticx/oo-inheritance-code-along-wdf-000,## Introduction: Why Inheritance?,"  In the real-world, different entities (people, animals, cars, you name it) are related in various ways. Within a single entity or group, there exist systems of classification. For example, the ""dogs"" entity or category includes pugs, corgis, labs, etc. All of these breeds share common features because they are all dogs. But they all have certain unique traits as well. Another example: you are writing a web application in which users are either admins, instructors or students. All of these entities are ""users"" and have common features, but they all have some unique traits as well. How can our code reflect that fact that these different categories of things all share some, or even many, characteristics but all have some unique attributes as well? Well, we could write separate admin, instructor and student class that each contain repetitious code to lend each of these classes shared attributes and behaviors. We know, however, that repetitious code is always something to be avoided. Not only is it time consuming but, what happens when we need to make a change to this shared behavior? We'd have to code the same change in three places. Instead, we can use inheritance. The use of inheritance allows us to create a family of classes with shared behavior, while still differentiating those classes. With inheritance, we could inherit the admin, instructor and student classes from a user class. Then, any changes made to the user class would apply to the other class. While you may not write your own classes that use inheritance very frequently, you will encounter it frequently as a Ruby on Rails web developer. Once we introduce the use of databases and the challenge of connecting our programs to our database, you'll encounter inheritance in nearly every program you write for the web. More on that (much) later.",12
https://github.com/lastromanticx/oo-inheritance-code-along-wdf-000,## What is Inheritance?,"  In Ruby, classes can inherit from one another. This means that they adopt all of the attributes and behaviors (i.e. all of the methods) of the parent, also called the super class. In this exercise, we'll be building our own chain of inheritance.",1
https://github.com/lastromanticx/oo-inheritance-code-along-wdf-000,## Code Along: Basic Inheritance,"  In this domain model, we have class Vehicle that will act as the parent, or super, class. We will create child classes, also known as subclasses for different types of Vehicles, such as car.",3
https://github.com/lastromanticx/oo-inheritance-code-along-wdf-000,### Step 1: Defining the Super Class,"  Open up lib/super_vehicle.rb. We're going to define some methods in this parent class so that our subclasses, when we make them, will have access to them. class Vehicle

  attr_accessor :wheel_size, :wheel_number
  
  def initialize(wheel_size, wheel_number)
    @wheel_size = wheel_size
    @wheel_number = wheel_number
  end
  
  def go
    ""vrrrrrrrooom!""
  end
  
  def fill_up_tank
    ""filling up!""
  end
    
end Instances of Vehicle initialize with a wheel size and number. We also have #go and #fill_up_tank instance methods that describe some common vehicle behavior. Go ahead and run the test suite and you'll see that you are passing all of the tests for the Vehicle class but none of the tests for the Car class.",3
https://github.com/lastromanticx/oo-inheritance-code-along-wdf-000,### Step 2: Defining the Subclass,"  Open up lib/sub_car.rb. Notice that we are requiring lib/super_vehicle.rb. That is because our Car class will need access to the Vehicle class and will therefore need access to the file that contains that class. Go ahead and define the class in the following way: class Car < Vehicle

end We use the < to inherit the Car class from Vehicle. Notice that there are no methods defined in the Car class. Run the test suite again and you'll see that you are passing a number of tests for the Car class. Wow! We didn't write anything in our Car class but instances of Car class inherit all of the Vehicle methods and therefore have access to them. We're still failing the #go test however. Looks like the test is expecting the #go method on an individual car to return the phrase: ""VRRROOOOOOOOOOOOOOOOOOOOOOOM!!!!!"". This is different than the return value of the #go method that we inherited from the Vehicle class. Let's overwrite the inherited go method with one specific to Car.",3
https://github.com/lastromanticx/oo-inheritance-code-along-wdf-000,### Step 3: Overwriting Inherited Methods,"  In lib/sub_car.rb, write the following method: class Car < Vehicle
  def go
    ""VRRROOOOOOOOOOOOOOOOOOOOOOOM!!!!!""
  end
end Now, run the tests again and you should be passing all of them.",3
https://github.com/lastromanticx/oo-inheritance-code-along-wdf-000,#### Method Look-Up in Ruby,"  How does our above example work? Well, when your program is being executed, at the point at which the #go method is invoked, the compiler will first look in the class to which the instance of car that we are calling the method on belongs. If it finds a #go method there, it will execute that method. If it doesn't find such a method there, it will move on to look in the parent class that this class inherits from. View this lesson on Learn.co View Intro to Inheritance on Learn.co and start learning to code for free.",3
https://github.com/microlv/prerender,# Prerender Service [![Stories in Ready](https://badge.waffle.io/prerender/prerender.png?label=ready&title=Ready)](https://waffle.io/prerender/prerender)," Google, Facebook, Twitter, Yahoo, and Bing are constantly trying to view your website... but they don't execute javascript. That's why we built Prerender. Prerender is perfect for AngularJS SEO, BackboneJS SEO, EmberJS SEO, and any other javascript framework. Behind the scenes, Prerender is a node server from prerender.io that uses phantomjs to create static HTML out of a javascript page. We host this as a service at prerender.io but we also open sourced it because we believe basic SEO is a right, not a privilege! It should be used in conjunction with these middleware libraries to serve the prerendered HTML to crawlers for SEO. Get started in two lines of code using Rails or Node. Prerender adheres to google's _escaped_fragment_ proposal, which we recommend you use. It's easy: 
Just add <meta name=""fragment"" content=""!""> to the <head> of all of your pages
If you use hash urls (#), change them to the hash-bang (#!)
That's it! Perfect SEO on javascript pages.
 Prerender includes lots of plugins, for example using Amazon S3 to cache your prerendered HTML.
Prerender also starts multiple phantomjs processes to maximize throughput.",123
https://github.com/microlv/prerender,### <a id='middleware'></a>,,-
https://github.com/microlv/prerender,## Middleware,  This is a list of middleware available to use with the prerender service:,6
https://github.com/microlv/prerender,#### Official middleware, ,3
https://github.com/microlv/prerender,###### Javascript,"  
prerender-node (Express)
",6
https://github.com/microlv/prerender,###### Ruby,"  
prerender_rails (Rails)
",6
https://github.com/microlv/prerender,###### Apache,"  
.htaccess
",6
https://github.com/microlv/prerender,###### Nginx,"  
nginx.conf
",6
https://github.com/microlv/prerender,#### Community middleware, ,6
https://github.com/microlv/prerender,###### PHP,"  
zfr-prerender (Zend Framework 2)
YuccaPrerenderBundle (Symfony 2)
Laravel Prerender (Laravel)
",6
https://github.com/microlv/prerender,###### Java,"  
prerender-java
",6
https://github.com/microlv/prerender,###### Grails,"  
grails-prerender
",6
https://github.com/microlv/prerender,###### Nginx,"  
Reverse Proxy Example
",6
https://github.com/microlv/prerender,###### Apache,"  
.htaccess
 Request more middleware for a different framework in this issue.",6
https://github.com/microlv/prerender,## How it works,  This is a simple service that only takes a url and returns the rendered HTML (with all script tags removed). Note: you should proxy the request through your server (using middleware) so that any relative links to CSS/images/etc still work. GET http://service.prerender.io/https://www.google.com GET http://service.prerender.io/https://www.google.com/search?q=angular,13
https://github.com/microlv/prerender,## Running locally,"  If you are trying to test Prerender with your website on localhost, you'll have to run the Prerender server locally so that Prerender can access your local dev website. If you are running the prerender service locally. Make sure you set your middleware to point to your local Prerender server with: export PRERENDER_SERVICE_URL=<your local url> $ npm install
$ node server.js
// also supports heroku style invocation using foreman
$ foreman start
",3
https://github.com/microlv/prerender,## Deploying your own on heroku,"  $ git clone https://github.com/prerender/prerender.git
$ cd prerender
$ heroku create
$ git push heroku master
 ",3
https://github.com/microlv/prerender,#Customization,"See prerender.io/server to see how to customize the server. You can clone this repo and run server.js
OR
use npm install prerender --save to create an express-like server with custom plugins",3
https://github.com/microlv/prerender,## Plugins,"  See prerender.io/server to see how to create plugins. We use a plugin system in the same way that Connect and Express use middleware. Our plugins are a little different and we don't want to confuse the prerender plugins with the prerender middleware, so we opted to call them ""plugins"". Plugins are in the lib/plugins directory, and add functionality to the prerender service. Each plugin can implement any of the plugin methods:",3
https://github.com/microlv/prerender,####`init()`,,3
https://github.com/microlv/prerender,"####`beforePhantomRequest(req, res, next)`",,3
https://github.com/microlv/prerender,"####`onPhantomPageCreate(phantom, req, res, next)`",,3
https://github.com/microlv/prerender,"####`afterPhantomRequest(req, res, next)`",,3
https://github.com/microlv/prerender,"####`beforeSend(req, res, next)`",,3
https://github.com/microlv/prerender,## Available plugins, ,3
https://github.com/microlv/prerender,### basicAuth,"  If you want to only allow access to your Prerender server from authorized parties, enable the basic auth plugin. You will need to add the BASIC_AUTH_USERNAME and BASIC_AUTH_PASSWORD environment variables. export BASIC_AUTH_USERNAME=prerender
export BASIC_AUTH_PASSWORD=test
 Then make sure to pass the basic authentication headers (password base64 encoded). curl -u prerender:wrong http://localhost:1337/http://example.com -> 401
curl -u prerender:test http://localhost:1337/http://example.com -> 200
",3
https://github.com/microlv/prerender,### removeScriptTags,"  We remove script tags because we don't want any framework specific routing/rendering to happen on the rendered HTML once it's executed by the crawler. The crawlers may not execute javascript, but we'd rather be safe than have something get screwed up. For example, if you rendered the HTML of an angular page but left the angular scripts in there, your browser would try to execute the angular routing and rendering on a page that no longer has any angular bindings.",3
https://github.com/microlv/prerender,### httpHeaders,"  If your Javascript routing has a catch-all for things like 404's, you can tell the prerender service to serve a 404 to google instead of a 200. This way, google won't index your 404's. Add these tags in the <head> of your page if you want to serve soft http headers. Note: Prerender will still send the HTML of the page. This just modifies the status code and headers being sent. Example: telling prerender to server this page as a 404 <meta name=""prerender-status-code"" content=""404""> Example: telling prerender to serve this page as a 302 redirect <meta name=""prerender-status-code"" content=""302"">
<meta name=""prerender-header"" content=""Location: http://www.google.com"">",3
https://github.com/microlv/prerender,### whitelist,"  If you only want to allow requests to a certain domain, use this plugin to cause a 404 for any other domains. You can add the whitelisted domains to the plugin itself, or use the ALLOWED_DOMAINS environment variable. export ALLOWED_DOMAINS=www.prerender.io,prerender.io",3
https://github.com/microlv/prerender,### blacklist,"  If you want to disallow requests to a certain domain, use this plugin to cause a 404 for the domains. You can add the blacklisted domains to the plugin itself, or use the BLACKLISTED_DOMAINS environment variable. export BLACKLISTED_DOMAINS=yahoo.com,www.google.com",3
https://github.com/microlv/prerender,### <a id='s3-html-cache'></a>, ,3
https://github.com/microlv/prerender,### s3HtmlCache,"  A GET request will check S3 for a cached copy. If a cached copy is found, it will return that. Otherwise, it will make the request to your server and then persist the HTML to the S3 cache. A POST request will skip the S3 cache. It will make a request to your server and then persist the HTML to the S3 cache. The POST is meant to update the cache. You'll need to sign up with Amazon Web Services and export these 3 environment variables. $ export AWS_ACCESS_KEY_ID=<aws access key>
$ export AWS_SECRET_ACCESS_KEY=<aws secret access key>
$ export S3_BUCKET_NAME=<bucket name>
 Warning! Your keys should be kept private and you'll be charged for all files uploaded to S3. 
If Prerender is hosted on a EC2 instance, you can also take advantage of IAM instance roles
so that you don't need to export your AWS credentials.
 
You can also export the S3_PREFIX_KEY variable so that the key (which is by default the complete requested URL) is
prefixed. This is useful if you want to organize the snapshots in the same bucket.
",3
https://github.com/microlv/prerender,#### Region support,"  By default, s3HtmlCache works with the US Standard region (East), if your bucket is localized in another region you can config it with an environment variable : AWS_REGION. $ export AWS_REGION=<region name>
 For example : $ export AWS_REGION=eu-west-1
",3
https://github.com/microlv/prerender,### inMemoryHtmlCache,"  The default is an in memory cache but you can easily change it to any caching system compatible with the cache-manager nodejs package. For example, with the request: GET http://service.prerender.io/https://www.facebook.com/ First time: Overall Elapsed:	00:00:03.3174661 With cache: Overall Elapsed:	00:00:00.0360119",3
https://github.com/microlv/prerender,### logger,  This will show console.log's from the phantomjs page in your local console. Great for debugging.,3
https://github.com/microlv/prerender,### mongodbCache,  Caches pages in a MongoDB database. Available at prerender-mongodb-cache by @lammertw,3
https://github.com/microlv/prerender,### memjsCache,  Caches pages in a memjs(memcache) service. Available at prerender-memjs-cache by @lammertw,3
https://github.com/microlv/prerender,## License,"  The MIT License (MIT) Copyright (c) 2013 Todd Hooper <todd@prerender.io> Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.",5
https://github.com/shrah/corert,# .NET Core Runtime (CoreRT),"This repo contains the .NET Core runtime optimized for AOT compilation

Platform Support
This is a work in progress. The current state of platform support:

Windows x64 w/ RyuJIT codegen: Simple ASP.NET apps compile and run with some workarounds
MacOS and Linux x64 w/ RyuJIT codegen: Same as Windows, the libraries are less complete.
Linux ARM w/ RyuJIT codegen: ""Hello world""
CppCodeGen (targets all platforms that support C++): Simple C# programs. The big missing features are reflection, garbage collection and exception handling.
WebAssembly: Early prototype that compiles and runs very trivial programs only. Many features are not yet implemented.",1
https://github.com/shrah/corert,"## How to Engage, Contribute and Provide Feedback","Some of the best ways to contribute are to try things out, file bugs, and join in design conversations.

Looking for something to work on? The up for grabs issues are a great place to start or take a look at our documentation.

This project follows the .NET Core Contribution Guidelines.

Join the chat at https://gitter.im/dotnet/corert",67
https://github.com/shrah/corert,### Reporting security issues and security bugs,"Security issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) secure@microsoft.com. You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the MSRC PGP key, can be found in the Security TechCenter.",67
https://github.com/shrah/corert,## License,The CoreRT Repo is licensed under the MIT license.,5
https://github.com/shrah/corert,## .NET Foundation,"CoreRT is a .NET Foundation project.

This project has adopted the code of conduct defined by the Contributor Covenant to clarify expected behavior in our community. For more information, see the .NET Foundation Code of Conduct.",156
https://github.com/shrah/corert,## Related Projects,"There are many .NET related projects on GitHub.

The .NET home repo links to 100s of .NET projects, from Microsoft and the community.
The ASP.NET home repo is the best place to start learning about ASP.NET Core.",6
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,# Hello World,,1
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,## Overview,"  We're going to make a file that will print ""Hello World!"" to your terminal.",1
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,## Objectives,"  
Create a new Ruby file.
Write syntactically valid code to produce ""Hello World!""
Run a Ruby file.
Run the Learn gem.
Submit a Learn lab.
",1
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,## Instructions,  Get started by clicking the Open button in Learn.,3
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,### Creating a File,"  You will need to create a text file called hello_world.rb within the lab's directory. The .rb file extension is a common convention for specifying the language of the file - in this case, Ruby. To create this, in the Learn IDE's terminal type touch hello_world.rb. If that worked as expected, you should now see the file appear in the file browser. You can open this file by double clicking on it in the file browser or by typing atom hello_world.rb. You should now see an empty file open in your text editor, ready to be edited.",3
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,### Writing Code,"  In the file hello_world.rb that you created, you need to write a single line of code that prints the string Hello World! to your terminal. To print in Ruby, you need to use the method puts which is short for ""output string."" And because Hello World! is a string, you need to surround your text with """". File: hello_world.rb puts ""Hello World!"" Anytime you make changes to a file, such as the one you've just made, you need to save it so these changes are preserved. If you forget to save it before you run your tests, it will be tested against an empty document! Always remember to save it every time you make changes by selecting Save from the File menu.",3
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,### Executing Your File,"  Execute this file by typing ruby hello_world.rb into your terminal and pressing enter. The ruby part of that command tells your computer to use the Ruby interpreter when reading and executing the code in your file. The second part of the command, hello_world.rb is the path to the file you want to run. Note: be sure to save your file before trying to print, otherwise it will not work. You should see: $ ruby hello_world.rb
Hello World!",3
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,### Running Learn,"  Confirm everything is working by running the learn command. You should see that all tests are passing (e.g. no red error text). Note: When you write code, the case (uppercase/lowercase) of characters matters, and so your test will not pass unless you print ""Hello World!"" exactly.",3
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,### Submitting Your Lab,"  Submit your solution by typing learn submit into your terminal, then click Next Lesson to move on. Your adventure in Ruby has only just begun.",3
https://github.com/LoMicah03/hello-world-ruby-ruby-intro-000,### Hello World History,"  A small piece of coding history—a handwritten version of Hello World in C (an early programming language).  Hello World! by Brian Kernighan, from Artsy's Algorythm Auction based on a 1974 Bell Laboratories internal memorandum by Brian Kernighan, Programming in C: A Tutorial, which contains the first known version. View Hello World on Learn.co and start learning to code for free.",4
https://github.com/gevans/chef-xdebug,# Description, Words go here. Currently tested only on 64-bit Ubuntu 10.04 (Lucid).,1
https://github.com/gevans/chef-xdebug,# Requirements, ,3
https://github.com/gevans/chef-xdebug,## Cookbooks:, ,3
https://github.com/gevans/chef-xdebug,# Attributes, ,3
https://github.com/gevans/chef-xdebug,# Usage, ,3
https://github.com/gevans/chef-xdebug,# TODO,"  
Placeholder
",4
https://github.com/gevans/chef-xdebug,# ISSUES,"  
Placeholder
",3
https://github.com/gevans/chef-xdebug,## Development,"  
Source hosted at GitHub
Report issues/Questions/Feature requests on GitHub Issues
 Pull requests are very welcome! Make sure your patches are well tested.
Ideally create a topic branch for every seperate change you make.",3
https://github.com/gevans/chef-xdebug,# LICENSE & AUTHOR:,"  


Author::
David King, xforty technologies (dking@xforty.com)




Contributors::
https://github.com/xforty/chef-xdebug/contributors


Copyright::
2012, xforty technologies


 Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.",5
https://github.com/h3biomed/lastpass-cli,# LastPass CLI,,1
https://github.com/h3biomed/lastpass-cli,#### (c) 2014 LastPass.,  C99 command line interface to LastPass.com.,5
https://github.com/h3biomed/lastpass-cli,## Operating System Support,"  lpass is designed to run on GNU/Linux, Cygwin and Mac OS X.",3
https://github.com/h3biomed/lastpass-cli,## Dependencies,"  
LibreSSL or OpenSSL
libcurl
libxml2
pinentry (optional)
AsciiDoc (build-time documentation generation only)
xclip, xsel, pbcopy, or putclip from cygutils-extra for clipboard support (optional)
",3
https://github.com/h3biomed/lastpass-cli,### Installing on Linux, ,3
https://github.com/h3biomed/lastpass-cli,#### Redhat/Centos,"  
Install the needed dependencies
 sudo yum install openssl libcurl libxml2 pinentry xclip openssl-devel libxml2-devel libcurl-devel
",3
https://github.com/h3biomed/lastpass-cli,##### Debian/Ubuntu,"  
Debian: Install the needed dependencies
 sudo apt-get install openssl libcurl3 libxml2 libssl-dev libxml2-dev libcurl4-openssl-dev pinentry-curses xclip
 
Ubuntu: Install the needed dependencies
 sudo apt-get install openssl libcurl4-openssl-dev libxml2 libssl-dev libxml2-dev pinentry-curses xclip
",3
https://github.com/h3biomed/lastpass-cli,#### Gentoo,"  
Install the package
 sudo emerge lastpass-cli
",3
https://github.com/h3biomed/lastpass-cli,##### Other Linux Distros,  Install the packages listed in the Dependencies section of this document.,3
https://github.com/h3biomed/lastpass-cli,### Installing on OS X,"  
Install homebrew following the instructions at http://brew.sh/
Install lastpass-cli using homebrew:
 brew install lastpass-cli --with-pinentry
 Optionally you can add --with-doc to install the documentation.",3
https://github.com/h3biomed/lastpass-cli,### Installing on FreeBSD,"  
Install the binary package
 sudo pkg install security/lastpass-cli
 
Or build the port yourself
 sudo make -C /usr/ports/security/lastpass-cli all install clean
",3
https://github.com/h3biomed/lastpass-cli,## Building,"  $ make
",3
https://github.com/h3biomed/lastpass-cli,## Installing,"  $ sudo make install
 These environment variables can be passed to make to do the right thing: PREFIX, DESTDIR, BINDIR, LIBDIR, MANDIR.",3
https://github.com/h3biomed/lastpass-cli,## Running,"  If you've installed it: $ lpass
 Otherwise, from the build directory: $ ./lpass
",3
https://github.com/h3biomed/lastpass-cli,## Documentation,"  The install-doc target builds and installs the documentation.
It requires AsciiDoc as a prerequisite. $ sudo make install-doc
 Once installed, $ man lpass
",36
https://github.com/anirut/TuentiTV,# Tuenti for Android TV [![Android Arsenal](https://img.shields.io/badge/Android%20Arsenal-TuentiTV-brightgreen.svg?style=flat)](https://android-arsenal.com/details/3/1465)," Sample project created to show some of the most important features related to Android TV projects. This little sample uses mocked data to simulate an application working with information from Tuenti servers. In this repository you are going to find some interesting samples to work with Android TV like: 
How to configure Android dependencies to create an Android TV application. Leanback is the most important dependency.
Hos to configure an Activity to work as Launcher Activity for Android TV projects.
How to extend from Leanback BrowseFragment to create the main view of this project.
How to extend from Leanback DetailsFragment to create the detail view of this project.
How to extend from Leanback SearchFragment to create the search view of this project.
How to show Android TV recommendations.
How to create a custom Activity/Fragment without Leanback library help for Android TV.
How to use View Focus to create custom Activities/Fragments for Android TV and different focus features added for Android TV like nextFocusDown.
How to use  xml tag inside your layouts.
How to use State List Animators to improve your application UI/UX.
How to change Activities/Fragments background to improve your views.
How to capture Android TV DPAD events.
How to create your own presenters to use with ArrayObjectAdapter.
",1
https://github.com/anirut/TuentiTV,## Implementation description,  Tuenti for Android TV - Blog Post Working with Android TV Slides - English,6
https://github.com/anirut/TuentiTV,## Video Demo,  [Tuenti TV Project - Video] 3,3
https://github.com/anirut/TuentiTV,## Screenshots,"  






",3
https://github.com/anirut/TuentiTV,## Libraries used on the sample project,"  
Dagger
Butterknife
Picasso
",6
https://github.com/anirut/TuentiTV,## Developed By,"  
Pedro Vicente Gómez Sánchez - pedrovicente.gomez@gmail.com
 

 

",5
https://github.com/anirut/TuentiTV,## License,"  Copyright 2014 Pedro Vicente Gómez Sánchez

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
",5
https://github.com/sineed/rails,# Welcome to Rails," Rails is a web-application framework that includes everything needed to
create database-backed web applications according to the
Model-View-Controller (MVC)
pattern. Understanding the MVC pattern is key to understanding Rails. MVC divides your
application into three layers, each with a specific responsibility. The Model layer represents your domain model (such as Account, Product,
Person, Post, etc.) and encapsulates the business logic that is specific to
your application. In Rails, database-backed model classes are derived from
ActiveRecord::Base. Active Record allows you to present the data from
database rows as objects and embellish these data objects with business logic
methods. You can read more about Active Record in its README.
Although most Rails models are backed by a database, models can also be ordinary
Ruby classes, or Ruby classes that implement a set of interfaces as provided by
the Active Model module. You can read more about Active Model in its README. The Controller layer is responsible for handling incoming HTTP requests and
providing a suitable response. Usually this means returning HTML, but Rails controllers
can also generate XML, JSON, PDFs, mobile-specific views, and more. Controllers load and
manipulate models, and render view templates in order to generate the appropriate HTTP response.
In Rails, incoming requests are routed by Action Dispatch to an appropriate controller, and
controller classes are derived from ActionController::Base. Action Dispatch and Action Controller
are bundled together in Action Pack. You can read more about Action Pack in its
README. The View layer is composed of ""templates"" that are responsible for providing
appropriate representations of your application's resources. Templates can
come in a variety of formats, but most view templates are HTML with embedded
Ruby code (ERB files). Views are typically rendered to generate a controller response,
or to generate the body of an email. In Rails, View generation is handled by Action View.
You can read more about Action View in its README. Active Record, Active Model, Action Pack, and Action View can each be used independently outside Rails.
In addition to that, Rails also comes with Action Mailer (README), a library
to generate and send emails; Active Job (README), a
framework for declaring jobs and making them run on a variety of queueing
backends; Action Cable (README), a framework to
integrate WebSockets with a Rails application;
and Active Support (README), a collection
of utility classes and standard library extensions that are useful for Rails,
and may also be used independently outside Rails.",1
https://github.com/sineed/rails,## Getting Started,"  

Install Rails at the command prompt if you haven't yet:
 $ gem install rails



At the command prompt, create a new Rails application:
 $ rails new myapp

where ""myapp"" is the application name.


Change directory to myapp and start the web server:
 $ cd myapp
 $ rails server

Run with --help or -h for options.


Using a browser, go to http://localhost:3000 and you'll see:
""Yay! You’re on Rails!""


Follow the guidelines to start developing your application. You may find
the following resources handy:

Getting Started with Rails
Ruby on Rails Guides
The API Documentation
Ruby on Rails Tutorial


",36
https://github.com/sineed/rails,## Contributing,"  We encourage you to contribute to Ruby on Rails! Please check out the
Contributing to Ruby on Rails guide for guidelines about how to proceed. Join us! Everyone interacting in Rails and its sub-projects' codebases, issue trackers, chat rooms, and mailing lists is expected to follow the Rails code of conduct.",7
https://github.com/sineed/rails,## Code Status,  ,4
https://github.com/sineed/rails,## License,  Ruby on Rails is released under the MIT License.,5
https://github.com/samuelbohler/apache2-chef-cookbook,# apache2 Cookbook,"This cookbook provides a complete Debian/Ubuntu style Apache HTTPD configuration. Non-Debian based distributions such as Red Hat/CentOS, ArchLinux and others supported by this cookbook will have a configuration that mimics Debian/Ubuntu style as it is easier to manage with Chef.

Debian-style Apache configuration uses scripts to manage modules and sites (vhosts). The scripts are:

a2ensite
a2dissite
a2enmod
a2dismod
a2enconf
a2disconf
This cookbook ships with templates of these scripts for non Debian/Ubuntu platforms. The scripts are used in the Definitions below.",12
https://github.com/samuelbohler/apache2-chef-cookbook,# Requirements,,3
https://github.com/samuelbohler/apache2-chef-cookbook,## Ohai and Chef:,"Ohai: 0.6.12+
Chef: 0.10.10+
As of v1.2.0, this cookbook makes use of node['platform_family'] to simplify platform selection logic. This attribute was introduced in Ohai v0.6.12. The recipe methods were introduced in Chef v0.10.10. If you must run an older version of Chef or Ohai, use version 1.1.16 of this cookbook.",3
https://github.com/samuelbohler/apache2-chef-cookbook,## Cookbooks:,"This cookbook doesn't have direct dependencies on other cookbooks, as none are needed for the default recipe or the general use cases.

Depending on your OS configuration and security policy, you may need additional recipes or cookbooks for this cookbook's recipes to converge on the node. In particular, the following Operating System settings may affect the behavior of this cookbook:

apt cache outdated
SELinux enabled
IPtables
Compile tools
3rd party repositories
On Ubuntu/Debian, use Opscode's apt cookbook to ensure the package cache is updated so Chef can install packages, or consider putting apt-get in your bootstrap process or knife bootstrap template.

On RHEL, SELinux is enabled by default. The selinux cookbook contains a permissive recipe that can be used to set SELinux to ""Permissive"" state. Otherwise, additional recipes need to be created by the user to address SELinux permissions.

The easiest but certainly not ideal way to deal with IPtables is to flush all rules. Opscode does provide an iptables cookbook but is migrating from the approach used there to a more robust solution utilizing a general ""firewall"" LWRP that would have an ""iptables"" provider. Alternately, you can use ufw, with Opscode's ufw and firewall cookbooks to set up rules. See those cookbooks' READMEs for documentation.

Build/compile tools may not be installed on the system by default. Some recipes (e.g., apache2::mod_auth_openid) build the module from source. Use Opscode's build-essential cookbook to get essential build packages installed.

On ArchLinux, if you are using the apache2::mod_auth_openid recipe, you also need the pacman cookbook for the pacman_aur LWRP. Put recipe[pacman] on the node's expanded run list (on the node or in a role). This is not an explicit dependency because it is only required for this single recipe and platform; the pacman default recipe performs pacman -Sy to keep pacman's package cache updated.

The apache2::god_monitor recipe uses a definition from the god cookbook. Include recipe[god] in the node's expanded run list to ensure that the cookbook is available to the node, and to set up god.",36
https://github.com/samuelbohler/apache2-chef-cookbook,## Platforms:,"The following platforms and versions are tested and supported using test-kitchen

Ubuntu 12.04, 14.04
Debian 7.6
CentOS 6.5, 7.0
The following platform families are supported in the code, and are assumed to work based on the successful testing on Ubuntu and CentOS.

Red Hat (rhel)
Fedora
Amazon Linux
The following platforms are also supported in the code, have been tested manually but are not tested under test-kitchen.

SUSE/OpenSUSE
ArchLinux
FreeBSD",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Notes for RHEL Family:,"On Red Hat Enterprise Linux and derivatives, the EPEL repository may be necessary to install packages used in certain recipes. The apache2::default recipe, however, does not require any additional repositories. Opscode's yum-epel cookbook can be used to add the EPEL repository. See Examples for more information.",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Notes for FreeBSD:,Version 2.0 has been had some basic testing against FreeBSD 10.0 using Chef 11.14.2 which has support for pkgng (CHEF-4637).,34
https://github.com/samuelbohler/apache2-chef-cookbook,# Tests,"This cookbook in the source repository contains chefspec, serverspec and cucumber tests. This is an initial proof of concept that will be fleshed out with more supporting infrastructure at a future time.

Please see the CONTRIBUTING file for information on how to add tests for your contributions.",7
https://github.com/samuelbohler/apache2-chef-cookbook,# Attributes,"This cookbook uses many attributes, broken up into a few different kinds.",3
https://github.com/samuelbohler/apache2-chef-cookbook,## Platform specific,"In order to support the broadest number of platforms, several attributes are determined based on the node's platform. See the attributes/default.rb file for default values in the case statement at the top of the file.

node['apache']['package'] - Package name for Apache2
node['apache']['perl_pkg'] - Package name for Perl
node['apache']['dir'] - Location for the Apache configuration
node['apache']['log_dir'] - Location for Apache logs
node['apache']['error_log'] - Location for the default error log
node['apache']['access_log'] - Location for the default access log
node['apache']['user'] - User Apache runs as
node['apache']['group'] - Group Apache runs as
node['apache']['binary'] - Apache httpd server daemon
node['apache']['conf_dir'] - Location for the main config file (e.g apache2.conf or httpd.conf)
node['apache']['docroot_dir'] - Location for docroot
node['apache']['cgibin_dir'] - Location for cgi-bin
node['apache']['icondir'] - Location for icons
node['apache']['cache_dir'] - Location for cached files used by Apache itself or recipes
node['apache']['pid_file'] - Location of the PID file for Apache httpd
node['apache']['lib_dir'] - Location for shared libraries
node['apache']['default_site_enabled'] - Default site enabled. Default is false.
node['apache']['ext_status'] - if true, enables ExtendedStatus for mod_status",6
https://github.com/samuelbohler/apache2-chef-cookbook,## General settings,"These are general settings used in recipes and templates. Default values are noted.

node['apache']['version'] - Specifing 2.4 triggers apache 2.4 support. If the platform is known during our test to install 2.4 by default, it will be set to 2.4 for you. Otherwise it falls back to 2.2.
node['apache']['listen_addresses'] - Addresses that httpd should listen on. Default is any (""*"").
node['apache']['listen_ports'] - Ports that httpd should listen on. Default is port 80.
node['apache']['contact'] - Value for ServerAdmin directive. Default ""ops@example.com"".
node['apache']['timeout'] - Value for the Timeout directive. Default is 300.
node['apache']['keepalive'] - Value for the KeepAlive directive. Default is On.
node['apache']['keepaliverequests'] - Value for MaxKeepAliveRequests. Default is 100.
node['apache']['keepalivetimeout'] - Value for the KeepAliveTimeout directive. Default is 5.
node['apache']['sysconfig_additional_params'] - Additionals variables set in sysconfig file. Default is empty.
node['apache']['default_modules'] - Array of module names. Can take ""mod_FOO"" or ""FOO"" as names, where FOO is the apache module, e.g. ""mod_status"" or ""status"".
node['apache']['mpm'] - With apache.version 2.4, specifies what Multi-Processing Module to enable. Default is ""prefork"".
The modules listed in default_modules will be included as recipes in recipe[apache::default].",36
https://github.com/samuelbohler/apache2-chef-cookbook,## Prefork attributes,"Prefork attributes are used for tuning the Apache HTTPD prefork MPM configuration.

node['apache']['prefork']['startservers'] - initial number of server processes to start. Default is 16.
node['apache']['prefork']['minspareservers'] - minimum number of spare server processes. Default 16.
node['apache']['prefork']['maxspareservers'] - maximum number of spare server processes. Default 32.
node['apache']['prefork']['serverlimit'] - upper limit on configurable server processes. Default 400.
node['apache']['prefork']['maxrequestworkers'] - Maximum number of connections that will be processed simultaneously
node['apache']['prefork']['maxconnectionsperchild'] - Maximum number of request a child process will handle. Default 10000.",36
https://github.com/samuelbohler/apache2-chef-cookbook,## Worker attributes,"  Worker attributes are used for tuning the Apache HTTPD worker MPM
configuration. 
node['apache']['worker']['startservers'] - Initial number of server processes to start. Default 4
node['apache']['worker']['serverlimit'] - Upper limit on configurable server processes. Default 16.
node['apache']['worker']['minsparethreads'] - Minimum number of spare worker threads. Default 64
node['apache']['worker']['maxsparethreads'] - Maximum number of spare worker threads. Default 192.
node['apache']['worker']['maxrequestworkers'] - Maximum number of simultaneous connections. Default 1024.
node['apache']['worker']['maxconnectionsperchild']  - Limit on the number of connections that an individual child server will handle during its life.
",36
https://github.com/samuelbohler/apache2-chef-cookbook,## Event attributes,"  Event attributes are used for tuning the Apache HTTPD event MPM
configuration. 
node['apache']['event']['startservers'] - Initial number of child server processes created at startup. Default 4.
node['apache']['event']['serverlimit'] - Upper limit on configurable number of processes. Default 16.
node['apache']['event']['minsparethreads'] - Minimum number of spare worker threads. Default 64
node['apache']['event']['maxsparethreads'] - Maximum number of spare worker threads. Default 192.
node['apache']['event']['threadlimit'] - Upper limit on the configurable number of threads per child process. Default 192.
node['apache']['event']['threadsperchild'] - Number of threads created by each child process. Default 64.
node['apache']['event']['maxrequestworkers'] - Maximum number of connections that will be processed simultaneously.
node['apache']['event']['maxconnectionsperchild']  - Limit on the number of connections that an individual child server will handle during its life.
",36
https://github.com/samuelbohler/apache2-chef-cookbook,## mod\_auth\_openid attributes,"  The following attributes are in the attributes/mod_auth_openid.rb
file. Like all Chef attributes files, they are loaded as well, but
they're logistically unrelated to the others, being specific to the
mod_auth_openid recipe. 
node['apache']['mod_auth_openid']['checksum'] - sha256sum of the tarball containing the source.
node['apache']['mod_auth_openid']['ref'] - Any sha, tag, or branch found from https://github.com/bmuller/mod_auth_openid
node['apache']['mod_auth_openid']['version'] - directory name version within the tarball
node['apache']['mod_auth_openid']['cache_dir'] - the cache directory is where the sqlite3 database is stored. It is separate so it can be managed as a directory resource.
node['apache']['mod_auth_openid']['dblocation'] - filename of the sqlite3 database used for directive AuthOpenIDDBLocation, stored in the cache_dir by default.
node['apache']['mod_auth_openid']['configure_flags'] - optional array of configure flags passed to the ./configure step in the compilation of the module.
",36
https://github.com/samuelbohler/apache2-chef-cookbook,## mod\_ssl attributes,"  
node['apache']['mod_ssl']['cipher_suite'] - sets the
SSLCiphersuite value to the specified string. The default is
considered ""sane"" but you may need to change it for your local
security policy, e.g. if you have PCI-DSS requirements. Additional
commentary on the
original pull request.
",36
https://github.com/samuelbohler/apache2-chef-cookbook,# Recipes,"  Most of the recipes in the cookbook are for enabling Apache modules.
Where additional configuration or behavior is used, it is documented
below in more detail. The following recipes merely enable the specified module: mod_alias,
mod_auth_basic, mod_auth_digest, mod_authn_file, mod_authnz_ldap,
mod_authz_default, mod_authz_groupfile, mod_authz_host,
mod_authz_user, mod_autoindex, mod_cgi, mod_dav_fs,
mod_dav_svn, mod_deflate, mod_dir, mod_env, mod_expires,
mod_headers, mod_ldap, mod_log_config, mod_mime,
mod_negotiation, mod_proxy, mod_proxy_ajp, mod_proxy_balancer,
mod_proxy_connect, mod_proxy_http, mod_python, mod_rewrite,
mod_setenvif, mod_status, mod_wsgi, mod_xsendfile. On RHEL Family distributions, certain modules ship with a config file
with the package. The recipes here may delete those configuration
files to ensure they don't conflict with the settings from the
cookbook, which will use per-module configuration in
/etc/httpd/mods-enabled.",36
https://github.com/samuelbohler/apache2-chef-cookbook,## default,"  The default recipe does a number of things to set up Apache HTTPd. It
also includes a number of modules based on the attribute
node['apache']['default_modules'] as recipes.",3
https://github.com/samuelbohler/apache2-chef-cookbook,## logrotate,"  Logrotate adds a logrotate entry for your apache2 logs. This recipe
requires the logrotate cookbook; ensure that recipe[logrotate] is
in the node's expanded run list.",3
https://github.com/samuelbohler/apache2-chef-cookbook,## mod\_auth\_cas,"  This recipe installs the proper package and enables the auth_cas
module. It can install from source or package. Package is the default,
set the attribute node['apache']['mod_auth_cas']['from_source'] to
true to enable source installation. Modify the version to install by
changing the attribute
node['apache']['mod_auth_cas']['source_revision']. It is a version
tag by default, but could be master, or another tag, or branch. The module configuration is written out with the CASCookiePath set,
otherwise an error loading the module may cause Apache to not start. Note: This recipe does not work on EL 6 platforms unless
epel-testing repository is enabled (outside the scope of this
cookbook), or the package version 1.0.8.1-3.el6 or higher is otherwise
available to the system due to this bug: https://bugzilla.redhat.com/show_bug.cgi?format=multiple&id=708550",36
https://github.com/samuelbohler/apache2-chef-cookbook,## mod\_auth\_openid,"  Changed via COOK-915 This recipe compiles the module from source. In addition to
build-essential, some other packages are included for installation
like the GNU C++ compiler and development headers. To use the module in your own cookbooks to authenticate systems using
OpenIDs, specify an array of OpenIDs that are allowed to authenticate
with the attribute node['apache']['allowed_openids']. Use the
following in a vhost to protect with OpenID authentication: AuthType OpenID require user <%= node['apache']['allowed_openids'].join(' ') %>
AuthOpenIDDBLocation <%= node['apache']['mod_auth_openid']['dblocation'] %>
 Change the DBLocation with the attribute as required; this file is in
a different location than previous versions, see below. It should be a
sane default for most platforms, though, see
attributes/mod_auth_openid.rb.",36
https://github.com/samuelbohler/apache2-chef-cookbook,### Changes from COOK-915:,"  
AuthType OpenID instead of AuthOpenIDEnabled On.
require user instead of AuthOpenIDUserProgram.
A bug(?) in mod_auth_openid causes it to segfault when attempting
to update the database file if the containing directory is not
writable by the HTTPD process owner (e.g., www-data), even if the
file is writable. In order to not interfere with other settings from
the default recipe in this cookbook, the db file is moved.
",3
https://github.com/samuelbohler/apache2-chef-cookbook,## mod\_fastcgi,  Install the fastcgi package and enable the module. Only work on Debian/Ubuntu,3
https://github.com/samuelbohler/apache2-chef-cookbook,## mod\_fcgid,"  Installs the fcgi package and enables the module. Requires EPEL on
RHEL family. On RHEL family, this recipe will delete the fcgid.conf and on version
6+, create the /var/run/httpd/mod_fcgid` directory, which prevents the
emergency error: [emerg] (2)No such file or directory: mod_fcgid: Can't create shared memory for size XX bytes
",3
https://github.com/samuelbohler/apache2-chef-cookbook,## mod\_php5,"  Simply installs the appropriate package on Debian, Ubuntu and
ArchLinux. On Red Hat family distributions including Fedora, the php.conf that
comes with the package is removed. On RHEL platforms less than v6, the
php53 package is used.",3
https://github.com/samuelbohler/apache2-chef-cookbook,## mod\_ssl,"  Besides installing and enabling mod_ssl, this recipe will append
port 443 to the node['apache']['listen_ports'] attribute array and
update the ports.conf.",3
https://github.com/samuelbohler/apache2-chef-cookbook,## god\_monitor,"  Sets up a god monitor for Apache. External requirements are the
god and runit cookbooks from Opscode. When using this recipe,
include recipe[god] in the node's expanded run list to ensure the
client downloads it; god depends on runit so that will also be
downloaded. Note This recipe is not tested under test-kitchen yet and is
pending fix in COOK-744.",36
https://github.com/samuelbohler/apache2-chef-cookbook,# Definitions,"  The cookbook provides a few definitions. At some point in the future
these definitions may be refactored into lightweight resources and
providers as suggested by
foodcritic rule FC015.",6
https://github.com/samuelbohler/apache2-chef-cookbook,## apache\_config,"  Sets up configuration file for Apache from a template. The
template should be in the same cookbook where the definition is used. This is used by the apache_conf definition and is not often used directly. It will use a2enconf and a2disconf to control the symlinking of configuration files between conf-available and conf-enabled. Enable or disable an Apache config file in
#{node['apache']['dir']}/conf-available by calling a2enmod or
a2dismod to manage the symbolic link in
#{node['apache']['dir']}/conf-enabled. These config files should be created in your cookbook, and placed on the system using apache_conf",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Parameters:,"  
name - Name of the config enabled or disabled with the a2enconf or a2disconf scripts.
source  - The location of a template file. The default name.erb.
cookbook - The cookbook in which the configuration template is located (if it is not located in the current cookbook). The default value is the current cookbook.
enable - Default true, which uses a2enconf to enable the config. If false, the config will be disabled with a2disconf.
",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Examples:,"  Enable the example config.     apache_config 'example' do
      enable true
    end
 Disable a module:     apache_config 'disabled_example' do
      enable false
    end
 See the recipes directory for many more examples of apache_config.",6
https://github.com/samuelbohler/apache2-chef-cookbook,## apache\_conf,"  Writes conf files to the conf-available folder, and passes enabled values to apache_config. This definition should generally be called over apache_config.",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Parameters:,"  
name - Name of the config placed and enabled or disabled with the a2enconf or a2disconf scripts.
enable - Default true, which uses a2enconf to enable the config. If false, the config will be disabled with a2disconf.
conf_path - path to put the config in if you need to override the default conf-available.
",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Examples:,"  Place and enable the example conf:     apache_conf 'example' do
      enable true
    end
 Place and disable (or never enable to begin with) the example conf:     apache_conf 'example' do
      enable false
    end
 Place the example conf, which has a different path than the default (conf-*):     apache_conf 'example' do
      conf_path '/random/example/path'
      enable false
    end
",3
https://github.com/samuelbohler/apache2-chef-cookbook,## apache\_mod,"  Sets up configuration file for an Apache module from a template. The
template should be in the same cookbook where the definition is used.
This is used by the apache_module definition and is not often used
directly. This will use a template resource to write the module's configuration
file in the mods-available under the Apache configuration directory
(node['apache']['dir']). This is a platform-dependent location. See
apache_module.",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Parameters:,"  
name - Name of the template. When used from the apache_module,
it will use the same name as the module.
",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Examples:,"  Create #{node['apache']['dir']}/mods-available/alias.conf.     apache_mod ""alias""
",3
https://github.com/samuelbohler/apache2-chef-cookbook,## apache\_module,"  Enable or disable an Apache module in
#{node['apache']['dir']}/mods-available by calling a2enmod or
a2dismod to manage the symbolic link in
#{node['apache']['dir']}/mods-enabled. If the module has a
configuration file, a template should be created in the cookbook where
the definition is used. See Examples.",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Parameters:,"  
name - Name of the module enabled or disabled with the a2enmod or a2dismod scripts.
identifier - String to identify the module for the LoadModule directive. Not typically needed, defaults to #{name}_module
enable - Default true, which uses a2enmod to enable the module. If false, the module will be disabled with a2dismod.
conf - Default false. Set to true if the module has a config file, which will use apache_mod for the file.
filename - specify the full name of the file, e.g.
",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Examples:,"  Enable the ssl module, which also has a configuration template in templates/default/mods/ssl.conf.erb.     apache_module ""ssl"" do
      conf true
    end
 Enable the php5 module, which has a different filename than the module default:     apache_module ""php5"" do
      filename ""libphp5.so""
    end
 Disable a module:     apache_module ""disabled_module"" do
      enable false
    end
 See the recipes directory for many more examples of apache_module.",6
https://github.com/samuelbohler/apache2-chef-cookbook,## apache\_site,"  Enable or disable a VirtualHost in
#{node['apache']['dir']}/sites-available by calling a2ensite or
a2dissite to manage the symbolic link in
#{node['apache']['dir']}/sites-enabled. The template for the site must be managed as a separate resource. To
combine the template with enabling a site, see web_app.",36
https://github.com/samuelbohler/apache2-chef-cookbook,### Parameters:,"  
name - Name of the site.
enable - Default true, which uses a2ensite to enable the site. If false, the site will be disabled with a2dissite.
",3
https://github.com/samuelbohler/apache2-chef-cookbook,## web\_app,"  Manage a template resource for a VirtualHost site, and enable it with
apache_site. This is commonly done for managing web applications
such as Ruby on Rails, PHP or Django, and the default behavior
reflects that. However it is flexible. This definition includes some recipes to make sure the system is
configured to have Apache and some sane default modules: 
apache2
apache2::mod_rewrite
apache2::mod_deflate
apache2::mod_headers
 It will then configure the template (see Parameters and
Examples below), and enable or disable the site per the enable
parameter.",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Parameters:,"  Current parameters used by the definition: 
name - The name of the site. The template will be written to
#{node['apache']['dir']}/sites-available/#{params['name']}.conf
cookbook - Optional. Cookbook where the source template is. If
this is not defined, Chef will use the named template in the
cookbook where the definition is used.
template - Default web_app.conf.erb, source template file.
enable - Default true. Passed to the apache_site definition.
 Additional parameters can be defined when the definition is called in
a recipe, see Examples.",3
https://github.com/samuelbohler/apache2-chef-cookbook,### Examples:,"  The recommended way to use the web_app definition is in a application specific cookbook named ""my_app"".
The following example would look for a template named 'web_app.conf.erb' in your cookbook containing
the apache httpd directives defining the VirtualHost that would serve up ""my_app"".     web_app ""my_app"" do
       template 'web_app.conf.erb'
       server_name node['my_app']['hostname']
    end
 All parameters are passed into the template. You can use whatever you
like. The apache2 cookbook comes with a web_app.conf.erb template as
an example. The following parameters are used in the template: 
server_name - ServerName directive.
server_aliases - ServerAlias directive. Must be an array of aliases.
docroot - DocumentRoot directive.
application_name - Used in RewriteLog directive. Will be set to the name parameter.
directory_index - Allow overriding the default DirectoryIndex setting, optional
directory_options - Override Options on the docroot, for example to add parameters like Includes or Indexes, optional.
allow_override - Modify the AllowOverride directive on the docroot to support apps that need .htaccess to modify configuration or require authentication.
 To use the default web_app, for example:     web_app ""my_site"" do
      server_name node['hostname']
      server_aliases [node['fqdn'], ""my-site.example.com""]
      docroot ""/srv/www/my_site""
      cookbook 'apache2'
    end
 The parameters specified will be used as: 
@params[:server_name]
@params[:server_aliases]
@params[:docroot]
 In the template. When you write your own, the @ is significant. For more information about Definitions and parameters, see the
Chef Wiki",36
https://github.com/samuelbohler/apache2-chef-cookbook,# Usage,"  Using this cookbook is relatively straightforward. Add the desired
recipes to the run list of a node, or create a role. Depending on your
environment, you may have multiple roles that use different recipes
from this cookbook. Adjust any attributes as desired. For example, to
create a basic role for web servers that provide both HTTP and HTTPS:     % cat roles/webserver.rb
    name ""webserver""
    description ""Systems that serve HTTP and HTTPS""
    run_list(
      ""recipe[apache2]"",
      ""recipe[apache2::mod_ssl]""
    )
    default_attributes(
      ""apache"" => {
        ""listen_ports"" => [""80"", ""443""]
      }
    )
 For examples of using the definitions in your own recipes, see their
respective sections above.",3
https://github.com/samuelbohler/apache2-chef-cookbook,# License and Authors,"  

Author:: Adam Jacob adam@opscode.com


Author:: Joshua Timberman joshua@opscode.com


Author:: Bryan McLellan bryanm@widemile.com


Author:: Dave Esposito esposito@espolinux.corpnet.local


Author:: David Abdemoulaie github@hobodave.com


Author:: Edmund Haselwanter edmund@haselwanter.com


Author:: Eric Rochester err8n@virginia.edu


Author:: Jim Browne jbrowne@42lines.net


Author:: Matthew Kent mkent@magoazul.com


Author:: Nathen Harvey nharvey@customink.com


Author:: Ringo De Smet ringo.de.smet@amplidata.com


Author:: Sean OMeara someara@opscode.com


Author:: Seth Chisamore schisamo@opscode.com


Author:: Gilles Devaux gilles@peerpong.com


Author:: Sander van Zoest sander.vanzoest@viverae.com


Author:: Taylor Price tprice@onehealth.com


Copyright:: 2009-2012, Opscode, Inc


Copyright:: 2011, Atriso


Copyright:: 2011, CustomInk, LLC.


Copyright:: 2013-2014, OneHealth Solutions, Inc.


Copyright:: 2014, Viverae, Inc.

 Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.",5
https://github.com/venturion/vue-resource,# vue-resource [![Version](https://img.shields.io/npm/v/vue-resource.svg)](https://www.npmjs.com/package/vue-resource) [![License](https://img.shields.io/npm/l/vue-resource.svg)](https://www.npmjs.com/package/vue-resource) [![Downloads](https://img.shields.io/npm/dt/vue-resource.svg)](https://www.npmjs.com/package/vue-resource), The plugin for Vue.js provides services for making web requests and handle responses using a XMLHttpRequest or JSONP.,1
https://github.com/venturion/vue-resource,## Features,"  
Supports the Promise API and URI Templates
Supports interceptors for request and response
Supports latest Firefox, Chrome, Safari, Opera and IE9+
Supports Vue 1.0 & Vue 2.0
Compact size 14KB (5.3KB gzipped)
",1
https://github.com/venturion/vue-resource,## Installation,"  You can install it via yarn or NPM. $ yarn add vue-resource
$ npm install vue-resource
",3
https://github.com/venturion/vue-resource,### CDN,"  Available on jsdelivr, unpkg or cdnjs. <script src=""https://cdn.jsdelivr.net/npm/vue-resource@1.3.3""></script>",3
https://github.com/venturion/vue-resource,## Example,"  {
  // GET /someUrl
  this.$http.get('/someUrl').then(response => {

    // get body data
    this.someData = response.body;

  }, response => {
    // error callback
  });
}",3
https://github.com/venturion/vue-resource,## Documentation,"  
Configuration
HTTP Requests/Response
Creating Resources
Code Recipes
API Reference
",6
https://github.com/venturion/vue-resource,## Changelog,  Details changes for each release are documented in the release notes.,4
https://github.com/venturion/vue-resource,## Contribution,"  If you find a bug or want to contribute to the code or documentation, you can help by submitting an issue or a pull request.",7
https://github.com/venturion/vue-resource,## License,  MIT,5
https://github.com/vocotnhan/quickdic-dictionary.actionbarsherlock,# ActionBarSherlock," ActionBarSherlock is an standalone library designed to facilitate the use of
the action bar design pattern across all versions of Android through a single
API. The library will automatically use the native ActionBar implementation on
Android 4.0 or later. For previous versions which do not include ActionBar, a
custom action bar implementation based on the sources of Ice Cream Sandwich
will automatically be wrapped around the layout. This allows you to easily
develop an application with an action bar for every version of Android from 2.x
and up. See http://actionbarsherlock.com for more information.  Try out the sample applications on the Android Market: Feature Demos,
Fragments, and RoboGuice. Continuous integration is provided by Travis CI.",126
https://github.com/vocotnhan/quickdic-dictionary.actionbarsherlock,# Developed By,"  
Jake Wharton - jakewharton@gmail.com
",5
https://github.com/vocotnhan/quickdic-dictionary.actionbarsherlock,# License,"  Copyright 2012 Jake Wharton

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
",5
https://github.com/kraziegent/go-bootstrap,## go-bootstrap, This is not a web framework. It generates a skeleton web project for you to kick-ass. Feel free to use or rip-out any of its parts.,1
https://github.com/kraziegent/go-bootstrap,## Prerequisites,"  

PostgreSQL


Go programming language, version 1.3.x or newer.

",3
https://github.com/kraziegent/go-bootstrap,## Installation,"  

go get github.com/go-bootstrap/go-bootstrap


$GOPATH/bin/go-bootstrap -dir github.com/{git-user}/{project-name}


Start using it: cd $GOPATH/src/github.com/{git-user}/{project-name} && go run main.go

",3
https://github.com/kraziegent/go-bootstrap,## PostgreSQL Environment Variables,"  If you have PGUSER, PGPASSWORD, PGHOST, PGPORT, PGSSLMODE environment variables set,
they will be used to generate and bootstrap the database.",3
https://github.com/kraziegent/go-bootstrap,## Decisions Made for You,"  This generator makes A LOT of decisions for you. Here's the list of things it uses for your project: 

PostgreSQL is chosen for the database.


bcrypt is chosen as the password hasher.


Bootstrap Flatly is chosen for the UI theme.


Session is stored inside encrypted cookie.


Static directory is located under /static.


Model directory is located under /dal (Database Access Layer).


It does not use ORM nor installs one.


Test database is automatically created under $GO_BOOTSTRAP_PROJECT_NAME-test.


A minimal Dockerfile is provided.


A minimal Vagrantfile is provided.


github.com/tools/godep is chosen to manage dependencies.


github.com/jmoiron/sqlx is chosen to connect to a database.


github.com/gorilla is chosen for a lot of the HTTP plumbings.


github.com/carbocation/interpose is chosen as the middleware library.


github.com/tylerb/graceful is chosen to enable graceful shutdown.


github.com/rnubel/pgmgr is chosen as the database migration and management tool.


github.com/Sirupsen/logrus is chosen as the logging library.

",1
https://github.com/owap/map-journal-storytelling-template-js,# Story Map Journal," The Story Map Journal is ideal when you want to combine narrative text with maps and other embedded content. A Map Journal contains entries, or sections, that users simply scroll through. Each section in a Map Journal has an associated map, image, video or web page. Actions can also be defined in journal sections so that, for example, clicking a word automatically zooms the section’s map to a particular location.  View it live |
Map Journal page on Esri Story Maps website |
Download Latest release is version 1.7.1, if you want to be informed of new releases, we recommend you to watch this repository (see GitHub help). See the release page for release notes. For more infomation about using and customizing Esri's Storytelling Apps follow the Story Maps Developers' Corner.",1
https://github.com/owap/map-journal-storytelling-template-js,## Help content,"  
BlackSky/AlertWhere notes
Introduction
Instructions
Feedback / support
FAQ
Configuration
Customize the look and feel
Developer guide
Issues
Contributing
Licensing
",6
https://github.com/owap/map-journal-storytelling-template-js,## Introduction,"  A Map Journal application can be created from ArcGIS Online, from the Esri Story Maps website or from a Portal for ArcGIS deployment. The Journal's data are stored in a Web Application Item (this includes the narrative content, reference to the webmap(s), pictures, videos and the settings).
This repository provides the application source code for developers that want to customize Map Journal. For more information about the Map Journal, including a gallery of examples and a step-by-step tutorial, please see the Map Journal page on the Esri Story Maps website.",1
https://github.com/owap/map-journal-storytelling-template-js,## Instructions,"  First create your Map Journal in ArcGIS Online using the step-by-step tutorial.
Once your story is ready, you have to find its ID in ArcGIS Online. The ID is a 32 character string that you will find in your web browser's address bar when you are viewing your journal.  
Download the application
Deploy the application on your webserver. See FAQ for details
Edit index.html, find the configuration section on line 38 and paste in your application ID
Navigate to index.html (e.g., http://127.0.0.1/MapJournal/index.html)
 Enjoy!
You can continue to use the builder in ArcGIS Online to modify your story.
See customize the look and feel section or developer guide if you want to modify the app. If you are using Portal for ArcGIS, please follow the instructions at the end of app/config.js to configure the application. Optionally you can also configure the application to use the ArcGIS API for JavaScript included on your Portal.",3
https://github.com/owap/map-journal-storytelling-template-js,## Feedback / support,"  We would love to hear from you! 
StoryMaps Website
Let us know about your application
Story Maps forum on GeoNet
@EsriStoryMaps
ArcGIS Blog
 When you contact us, don't hesitate to include a link to your application to make it easier for us to understand what you are working on.",6
https://github.com/owap/map-journal-storytelling-template-js,## FAQ, ,6
https://github.com/owap/map-journal-storytelling-template-js,### What should I check before publishing a Journal?,"  We recommend that you perform the following checks before sharing your Journal with your audience: 
Check that all your Journal's content is shared with your audience (webmaps, medias, ...). Typically you can use another computer than the one you have used to build your story to make sure everything is loading properly. Alternatively this article will show you how to configure your browser for an incognito session or you can just sign-out from ArcGIS Online and any service that you have used to host your Journal's resources.
Try the application on different browsers, screen resolutions and mobile devices. You can emulate mobile  devices inside your desktop browser.
",3
https://github.com/owap/map-journal-storytelling-template-js,### What are the supported browsers?,"  Map Journal is supported on Internet Explorer 9 and above, Chrome, Firefox, Safari and the most recent tablet and smartphone devices.
Map Journal authoring is supported on Internet Explorer 10 and above, on the most recent tablet but not on smartphone. We actively test the application in all major browsers but if you experience difficulties especially with the builder, we recommend that you use Chrome.",6
https://github.com/owap/map-journal-storytelling-template-js,### Tips for your content, ,6
https://github.com/owap/map-journal-storytelling-template-js,#### Link between sections,"  One popular request is to add the ability to navigate between Journal's sections using links in the panel or through map features popup. Until we implement that capability in the builder you can do it using HTML markup. To add links in a section content, use the Source button of the text editor (second from the right on the first line) and use the following markup: <p><a onclick=""require(['dojo/topic'], function(topic){ topic.publish('story-navigate-section', 0); });"">Navigate to home section</a></p>
<p><a onclick=""require(['dojo/topic'], function(topic){ topic.publish('story-navigate-section', 2); });"">Navigate to section 2</a></p>
<p><a onclick=""require(['dojo/topic'], function(topic){ topic.publish('story-navigate-section', 4); });"">Navigate to section 4</a></p>
 Note that the links navigate the Journal using an index that start at 0 for the Home Section. If you remove or reorder your sections, you will have to modify the links manually. You can also add that capability to map feature popups. This can for example allow the home section map to be the spatial index to your story. To do that you need to download the application and include a piece of code in index.html, look at the end of the file and modify it as below. Follow the instructions to configure the web map and the layer that will receive the click event. require([""dojo/topic""], function(topic) {
	/*
	 * Custom Javascript to be executed while the application is initializing goes here
	 */
	
	// The application is ready
	topic.subscribe(""tpl-ready"", function(){
		/*
		 * Custom Javascript to be executed when the application is ready goes here
		 */
	});
	
	/*
	 * Set up a click handler on the feature of the map to navigate the story
	 */
	
	//
	// *************************************
	// Configure the webmap id and layer id
	// *************************************
	//
	// First find the webmap id through the URL when you open the map in Map Viewer
	// To get the layer id, paste the webmap id below and open the application, 
	//   then open the developer console, all the layers ids will be listed,
	//   find the correct one and paste it below
	// After this setup, clicking the 3rd feature of your layer, will navigate to the third entry
	//
	var WEBMAP_ID = ""0bb11c0469f042b3afaf8b0d76572822"",
		LAYER_ID = ""csv_7673_0"";
	
	var clickHandlerIsSetup = false;
	
	topic.subscribe(""story-loaded-map"", function(result){
		if ( result.id == WEBMAP_ID && ! clickHandlerIsSetup ) {
			var map = app.maps[result.id].response.map,
				layer = map.getLayer(LAYER_ID);
			
			console.log(map.graphicsLayerIds);
			
			if ( layer ) {
				layer.on(""mouse-over"", function(e){
					map.setMapCursor(""pointer"");
					map.infoWindow.setContent(""<b>""+e.graphic.attributes.name.split("","")[0]+""</b><br/><i>Click to zoom</i>"");
					map.infoWindow.show(e.graphic.geometry);
				});
				
				layer.on(""mouse-out"", function(e){
					map.setMapCursor(""default"");
					map.infoWindow.hide();
				});
				
				layer.on(""click"", function(e){
					var index = e.graphic.attributes[""__OBJECTID""];
					topic.publish(""story-navigate-section"", index);
				});
			}
			
			clickHandlerIsSetup = true;
		}
	});
});
",6
https://github.com/owap/map-journal-storytelling-template-js,### Security, ,6
https://github.com/owap/map-journal-storytelling-template-js,#### Can I keep my Journal private?,"  Yes, the regular ArcGIS Online security model applies.
By default your Journal is private, you can share it through Map Journal builder or ArcGIS Online.
When you share your Journal, it is your responsibility to make sure that all the resources of your Journal (webmaps, images, videos) are accessible to your audience.",6
https://github.com/owap/map-journal-storytelling-template-js,#### Who can edit my Journal?,  A Journal can only be edited by its owner (the named account that initially created the Journal). Organization Administrator (does not apply for public account) can take or give the Journal's ownership to another user. In that case you won't anymore be able to edit the Journal. Changing the ownership is the only way to collaborate on a Journal creation without sharing the owner's credentials.,6
https://github.com/owap/map-journal-storytelling-template-js,#### Can I use private web map or layer?,"  Yes. When the Journal is hosted in ArcGIS Online or Portal for ArcGIS, users that don't have access to the Journal or a webmap used in the Journal will be redirected to the ArcGIS Online sign-in page. It is not possible to display an authentication dialog in the Map Journal when the Journal is hosted in ArcGIS Online. When the Journal is hosted on your web server, an authentication dialog will appear inside the application. Note that for that authentication to work on some older browser (Internet Explorer 9) you need to install a proxy server on your web server to make sure the login credentials can be passed securely to ArcGIS Online. For more information, see the Using the proxy in the ArcGIS API for JavaScript documentation. Because of that limitation, we recommend that you configure the application to use OAuth. OAuth 2.0 based authentication is available for ArcGIS Online and Portal for ArcGIS users with developer or organizational accounts. Follow the procedure to add an application and register an application to get an OAuth application ID. Once you have that application, open index.html, locate the configOptions section and fill the oAuthAppId property. If you are using secured services but don't want users to have to authenticate, you can use a proxy to store the username/password to be used, see Working with Proxy Services, and add a proxy rules to specify what services need to use the proxy by editing PROXY_RULES in app/config.js.",6
https://github.com/owap/map-journal-storytelling-template-js,### Deployment,  Deploying a Map Journal require to use ArcGIS Online or Portal for ArcGIS. The Journal content have to be created using the Map Journal builder and will live in a Web Application Item.,6
https://github.com/owap/map-journal-storytelling-template-js,#### Can I use the template without ArcGIS Online or Portal for ArcGIS?,"  This is not a supported use case at that time. Please let us know if you are interested by such a scenario.
Map Journal rely heavily on the Portal for ArcGIS API but it is doable to modify the application to support other scenarios.",6
https://github.com/owap/map-journal-storytelling-template-js,#### Where is the data stored?,"  The Journal's data are stored in a Web Application Item in ArcGIS Online or Portal for ArcGIS. This include the narrative content, reference to the webmap(s), reference to picture(s), video(s), web page(s) and the settings. The image and videos that you include in your Journal using the builder are not copied in ArcGIS Online. You have to make sure that those medias as well as the webmaps you are using are and will remain accessible to your audience.",6
https://github.com/owap/map-journal-storytelling-template-js,#### Can I deploy Map Journal on Portal for ArcGIS?,"  Yes, Map Journal is included with Portal for ArcGIS starting at version 10.3. If you are using Portal 10.3+ and want to update Map Journal, download the latest version. If you are using Portal 10.2.1 or 10.2.2, you can't deploy the latest version of Map Journal and have to deploy the following version Map Journal V1.0.2 - portal. Then: 
Find your Portal apps/MapJournal folder (depending on your installation and version of Portal, this is either C:\Program Files\ArcGIS\Portal\apps\MapSeries or C:\Program Files\ArcGIS\Portal\webapps\arcgis#home\webmap\templates\MapJournal).
Remove the content of that folder
Extract the archive so that index.html is located at MapJournal\index.html
 If Map Journal was already included in your Portal you are done (Portal for ArcGIS 10.3+). If Map Journal was not available in your Portal: 
Log into Portal for ArcGIS and open My Content > Add Item > Application > Web Mapping Application > Configurable. Configure the URL to https://portal.domain.com/arcgis/apps/MapJournal. More details in the following documentation publishing a new web application item.
Create a new group that will reference the template available in your Portal
Share the newly created item with that group
Open My Organization > Edit Settings > Map  and set the Web App Templates to the newly created group. More details in the following documentation configuring the web application gallery
Now when you share a web map, the template should be an option
 Note that the archive you downloaded is using the ArcGIS API for JavaScript hosted in ArcGIS Online. This can create some incompatibility with your Portal, if you run into issue, please see the next section to update it. Also note that the web application gallery preview feature redirects to the StoryMaps website, the target page can be modified in app/config.js > HELP_URL_PORTAL.",6
https://github.com/owap/map-journal-storytelling-template-js,#### Can the template be used offline?,"  Yes, by using Portal for ArcGIS and configuring the template to use the ArcGIS API for Javascript included with the Portal. To edit the ArcGIS API for JavaScript, edit index.html and locate pathJSAPI around line 64. The URL is //webadaptor.domain.com/arcgis/jsapi/jsapi where arcgis is the name of your Web Adaptor. When deployed on a Portal for ArcGIS instance, the application doesn't require any external service to function. But by default the template will still include the header social buttons and Journal author are able to import pictures and videos from the some online pictures hosting services. These options can be disabled individually through the configuration file app/config.js.",6
https://github.com/owap/map-journal-storytelling-template-js,#### Can I use the builder with the downloadable?,"  Yes, when the template is configured with an application ID, adding the URL parameter 'edit' will open the builder. You will be prompted for user authentication through the Identity Manager.",6
https://github.com/owap/map-journal-storytelling-template-js,#### How to deploy the application on a web server?,"  If you are not familiar with web servers here is three solutions: 
Use a free hosting service like Dropbox, you may have to configure Dropbox to enable webpage hosting
Use the web server that comes with your server Operating System. On Windows this is Internet Information Services (IIS), if you have a C:\inetpub\wwwroot folder on your computer, you should be able to access it's content using http://localhost
On Windows or Mac OS, use a simple web server like Mongoose (not recommended for production)
 If you are experiencing some rendering issues like improper symbol appearing instead of icons, you will have an extra configuration to perform. Some servers require to configure a new mime type to be able to serve Map Journal fonts correctly. See the following links for more information: 
IIS Mime types
Properly serve webfonts
",6
https://github.com/owap/map-journal-storytelling-template-js,#### Can I use a single deployment of Map Journal for multiple stories?,"  Yes.
If you have customized the application and deployed it on your server, you don't need to copy it multiple times, edit index.html and paste a different application ID for each story you want to publish. Instead edit index.html, locate the configOptions section and fill the authorizedOwners property with the ArcGIS Online or Portal for ArcGIS login of the owner(s) of the Journals you want to use. This make possible for the application to display  any of the Journal created by the specified user(s) through an URL parameter. Example of the same application displaying two stories: 
http://myserver.com/MapJournal/index.html?appid=c7ad1a55de0247a68454a76f251225a4
http://myserver.com/MapJournal/index.html?appid=c7ad1a55de0247a68454a76f251225a5
",6
https://github.com/owap/map-journal-storytelling-template-js,## Configuration,"  In addition to the configuration offered by the builder, the file app/config.js provide various additional settings. This is for example the place where you can override some settings like the list of Geocoder services to be used (changes override ArcGIS Online or your Organization default settings). See the documentation provided in that file for more details.",3
https://github.com/owap/map-journal-storytelling-template-js,## Customize the look and feel, ,3
https://github.com/owap/map-journal-storytelling-template-js,### Custom color theme,"  As Map Journal doesn't yet offer the ability to create a custom theme through the builder, customizing the various colors of the application require to download and configure them through app/config.js. For example if you are using a Side Panel layout and have kept the default theme, open app/config.js, locate the LAYOUT property and edit the following line with the desired colors. themes: [
  {name: ""side-default-1"", dotNav: ""#777777"", panel: ""#FFFFFF"", media: ""#EEEEEE"", text: ""#000000"", textLink: ""#555"", esriLogo: ""black""},
  ...
  ]
",3
https://github.com/owap/map-journal-storytelling-template-js,### Other customization,"  Most of the look and feel customization can be done using the regular Application Download and including the css/html overrides directly into index.html. As the application Javascript and CSS are minified, we don't recommend that you directely edit those files (e.g. app-viewer-min.css, app-viewer-min.js, ...). In addition to being hard to edit, this will make application update complex for you. If you want to change the behavior of one functionality or want to add new one, follow the developer guide below. The easiest way to find the id or path of a DOM element that you want to customize is to use your browser developer tool, read documentation for Chrome, Safari, Firefox. Here is some customization examples that can achieved through the style tag already present for you in index.html (search for /* CUSTOM CSS RULES */):",3
https://github.com/owap/map-journal-storytelling-template-js,#### Use an image as the background of the Side or Floating panel header,"  ...
<body class=""claro"">
  <style>
    /* CUSTOM CSS RULES */
    .sectionPanel .header {
      background: url('http://www.esri.com/~/media/banner-map1.jpg');
    }

    .sectionPanel .appTitle {
      background: url('http://www.esri.com/~/media/banner-map1.jpg');
      background-position: 0 -50px;
    }
  </style>
...
",3
https://github.com/owap/map-journal-storytelling-template-js,## Developer guide,"  This developer guide is intended for developers that wants to modify the behavior or add new functionalities to the Map Journal application.
It requires knowledge of HTML, Javascript and CSS languages.
If you only need to customize look and feel, you should be able to do so using the customize section above.",6
https://github.com/owap/map-journal-storytelling-template-js,### Application life cycle,"  Map Journal fires events that allow customization with lose integration. This mean that you don't need to understand the application internals to implement simple extension. To try those events, look for the Custom Javascript block at the far end of index.html. ...
require([""dojo/topic""], function(topic) {
  /*
   * Custom Javascript to be executed while the application is initializing goes here
   */
   
  console.log(""Map Journal is initializing"");
  
  // The application is ready
  topic.subscribe(""tpl-ready"", function(){
    /*
     * Custom Javascript to be executed when the application is ready goes here
     */
     
    console.log(""Map Journal is ready"");
  });
  
  // When a section is being loaded (don't wait for the Main Stage media to be loaded) 
  topic.subscribe(""story-load-section"", function(index){
    console.log(""The section"", index, ""is being loaded"");
  });
  
  // After a map is loaded (when the map starts to render)	
  topic.subscribe(""story-loaded-map"", function(result){
    if ( result.index !== null )
      console.log(""The map"", result.id, ""has been loaded from the section"", result.index);
    else
      console.log(""The map"", result.id, ""has been loaded from a Main Stage Action"");
  });
  
  // When a main stage action that load a new media or reconfigure the current media is performed
  // Note that this even is not fired for the ""Locate and address or a place action""
  topic.subscribe(""story-perform-action-media"", function(media){
    console.log(""A Main Stage action is performed:"", media);
  });
});
...
",3
https://github.com/owap/map-journal-storytelling-template-js,### Developer helpers,"  In addition to the events described above, the story data, configuration and useful helpers functions can be accessed through the global variable app. console.log(""Section"", app.data.getCurrentSectionIndex(), ""/"", app.data.getStoryLength());
console.log(""Current map"", app.map);
console.log(""IDs of all the webmaps used in the story"", app.data.getWebmaps());
console.log(""Current section's data"", app.data.getCurrentSection());
console.log(""All sections data"", app.data.getStorySections());
console.log(""Story layout configuration"", app.data.getWebAppData().get().values.settings.layoutOptions);
console.log(""Static ayout configuration values"", app.data.getCurrentLayoutStaticConfig());
 Some events are also available for you to navigate the Journal programmatically: require([""dojo/topic""], function(topic) { 
  // Navigate to a section
  topic.publish(""story-navigate-section"", 2);
  
  // Reload the content panel
  topic.publish(""story-update-sections"");
  
  // Update a specific section content panel
  topic.publish(""story-update-section"", 2);
});
",3
https://github.com/owap/map-journal-storytelling-template-js,### Environment setup,"  Clone the repository or download a copy of the repository as a zip file. To build a production version of the application from the source code, you first need to install Node.js. Then initialize the environment by running the following commands in the MapJournal folder: 
npm install
npm install –g grunt-cli
 This will create a new node-modules folder in your project root with all the tools required to build the application. If you have trouble running the second command, see this documentation on how to install grunt-cli locally.",3
https://github.com/owap/map-journal-storytelling-template-js,### How to use the application from the source code,"  
Make accessible the MapJournal folder on a web server. Use your favorite server or run one with grunt server, this will start a server on port 8080
If using a Portal for ArcGIS instance configure the sharing url app/config.js (last property)
Use the URL parameter appid to specify the web item to be loaded, e.g.: http://localhost:8080/?appid=ABCD (configuring index.html > configOptions.appid is not supported in development mode)
",3
https://github.com/owap/map-journal-storytelling-template-js,### How to build application from the source code,"  
Open a terminal and navigate to the MapJournal folder
Run the following command: grunt
 The deploy folder now contains the built application that you can deploy to your web server.",3
https://github.com/owap/map-journal-storytelling-template-js,### Issues building the application,"  The build script perform code validation through JSHint, you can disable those validations by editing Gruntfile.js and look for the following comments /* Comment out to disable code linting */.",3
https://github.com/owap/map-journal-storytelling-template-js,### Design,"  Map Journal relies on AMD and Dojo loader AMD for application structure. The application is structured as this: 


Path
Contains




Gruntfile.js
Build configuration


src/
Main source code folder with index.html and the Eclipse project configuration


src/app/
Javascript and CSS source code


src/app/config.js
App configuration file (loaded at execution time)


src/app/storymaps/common/
Modules common across storymaps templates (main module is Core.js)


src/app/storymaps/common/builder/
Builder modules (main module is Builder.js)


src/app/storymaps/common/mapcontrols/
Map UI components (Overview, Legend)


src/app/storymaps/common/ui/
UI components


src/app/storymaps/common/utils/
Utils, connector,...


src/app/storymaps/common/_resources
Static resources


src/app/storymaps/tpl/
Map Journal modules (build configuration files in the root)


src/app/storymaps/tpl/builder/
Builder modules (main module is BuilderView.js)


src/app/storymaps/tpl/core/
Core modules (main module is MainView.js)


src/app/storymaps/tpl/ui/
UI components of the viewer grouped by target device


src/lib-app/
Dependencies (included in the final app)


src/lib-build/
Dependencies used by the build (not included in final app)


src/resources/
Static resources


 The main dependencies are: 
jQuery
Bootstrap
CKEditor
iDangero.us Swiper
 The application Javascript and CSS are minified into four files: 


File





app/viewer-min.css
Compressed CSS loaded when accessing the Map Journal as a viewer


app/viewer-min.js
Compressed Javascript loaded when accessing the Map Journal as a viewer


app/builder-min.css
Compressed CSS loaded when accessing the Map Journal as an author


app/builder-min.js
Compressed Javascript loaded when accessing the Map Journal as an author


 Depending on the URL parameters, index.html will load the corresponding files.",3
https://github.com/owap/map-journal-storytelling-template-js,## Issues,  Find a bug or want to request a new feature?  Please let us know by submitting an issue.,7
https://github.com/owap/map-journal-storytelling-template-js,## Contributing,  Esri welcomes contributions from anyone and everyone. Please see our guidelines for contributing.,7
https://github.com/owap/map-journal-storytelling-template-js,## Licensing,"Copyright 2013 Esri

Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.

A copy of the license is available in the repository's LICENSE.txt file.

Some open-source components of this project are licensed under other License terms, see src/lib-app/ folder for respective licence files.

Library	License
Bootstrap	MIT
CKEditor	LGPL
jQuery	MIT
jQuery Colorbox	MIT
iDangero.us swiper	MIT
ZeroClipboard	MIT
History.js	BSD
jQuery UI	MIT
FastClick	MIT
Hammer.JS	MIT
jQuery mousewheel	MIT
jQuery UI Touch Punch	MIT
[](Esri Tags: Storytelling MapJournal ArcGIS-Online Template Map Journal) [](Esri Language: JavaScript)",5
https://github.com/Paseam/tensorlayer,# Why TensorLayer," TensorLayer grow out from a need to combine the power of TensorFlow with the right building modules for deep neural networks. According to our years of research and practical experiences of tackling real-world machine learning problems, we come up with three design goals for TensorLayer: 
Simplicity: We make TensorLayer easy to work with by providing mass tutorials that can be deployed and run through in minutes. A TensorFlow user may find it easier to bootstrap with the simple, high-level APIs provided by TensorLayer, and then deep dive into their implementation details if need.
Flexibility: Developing an effective DL algorithm for a specific domain typically requires careful tunings from many aspects. Without the loss of simplicity, TensorLayer allows users to customize their modules by manipulating the native APIs of TensorFlow (e.g., training parameters, iteration control and tensor components).
Performance: TensorLayer aims to provide zero-cost abstraction for TensorFlow. With its first-class support for TensorFlow, it can easily run on either heterogeneous platforms or multiple computation nodes without compromise in performance.
 A frequent question regarding TensorLayer is that why do we develop a new library instead of leveraging existing ones like Keras and Tflearn. TensorLayer differentiates with those with its pursuits for flexibility and performance. A DL user may find it comfortable to bootstrap with Keras and Tflearn. These libraries provide high-level abstractions and hide engine implementation details from users. Though good for using, it becomes hard to tune and modify from the bottom, which is necessary when addressing domain-specific problems (i.e., one model does not fit all). Nevertheless, flexibility does not always come with the loss of performance. TensorLayer allows seamless distributed and heterogeneous deployment with its first-class support for the TensorFlow runtime.",12
https://github.com/Paseam/tensorlayer,# Installation,"  TensorLayer has install prerequisites including TensorFlow, numpy and matplotlib. For GPU support, CUDA and cuDNN are required. Please check here for detailed instructions. If you already had the pre-requisites ready, the simplest way to install TensorLayer in your python program is: pip install tensorlayer
or
pip install git+https://github.com/zsdonghao/tensorlayer.git",3
https://github.com/Paseam/tensorlayer,# Documentation,"  The documentation [Online] [PDF] [Epub] [HTML] describes the usages of TensorLayer APIs. It is also a self-contained document that walks through different types of deep neural networks, reinforcement learning and their applications in Natural Language Processing (NLP) problems. We have included the corresponding modularized implementations of Google TensorFlow Deep Learning tutorial, so you can read the TensorFlow tutorial [en] [cn] along with our document. Chinese documentation is also available.",3
https://github.com/Paseam/tensorlayer,# Your First Program,The first program trains a multi-layer perception network to solve the MNIST problem. We use the well-known scikit-style functions such as fit() and test(). The program is self-explained.,3
https://github.com/Paseam/tensorlayer,# Prepare data,,3
https://github.com/Paseam/tensorlayer,# Define placeholder,,3
https://github.com/Paseam/tensorlayer,# Define the neural network structure,,3
https://github.com/Paseam/tensorlayer,"# The softmax is implemented internally in tl.cost.cross_entropy(y, y_) to",,-
https://github.com/Paseam/tensorlayer,"# speed up computation, so we use identity here.",,-
https://github.com/Paseam/tensorlayer,# see tf.nn.sparse_softmax_cross_entropy_with_logits(),,-
https://github.com/Paseam/tensorlayer,# Define cost function and metric.,,-
https://github.com/Paseam/tensorlayer,# Define the optimizer,,-
https://github.com/Paseam/tensorlayer,# Initialize all variables,,-
https://github.com/Paseam/tensorlayer,# Print network information,,-
https://github.com/Paseam/tensorlayer,"# Train the network, we recommend to use tl.iterate.minibatches()",,-
https://github.com/Paseam/tensorlayer,# Evaluation,,-
https://github.com/Paseam/tensorlayer,# Save the network to .npz file,,-
https://github.com/Paseam/tensorlayer,# Contribution Guideline,"TensorLayer is a major ongoing research project in Data Science Institute, Imperial College London. The goal of the project is to develop a compositional language while complex learning systems can be build through composition of neural network modules. The whole development is now participated by numerous contributors here.",7
https://github.com/Paseam/tensorlayer,# License,TensorLayer is releazed under the Apache 2.0 license.,5
https://github.com/tinco/ruru,# Ruru (Rust + Ruby),,1
https://github.com/tinco/ruru,## Native Ruby extensions in Rust,"  



 


Documentation

Website

 Have you ever considered rewriting some parts of your slow Ruby application? Just replace your Ruby application with Rust, method by method, class by class. It does not require you
to change the interface of your classes or to change any other Ruby code. As simple as Ruby, as efficient as Rust.",12
https://github.com/tinco/ruru,## Contents,"  
Examples

The famous String#blank? method
Simple Sidekiq-compatible server
Safe conversions
Wrapping Rust data to Ruby objects
True parallelism
Defining a new class
Replacing only several methods instead of the whole class
Class definition DSL
Calling Ruby code from Rust


... and why is FFI not enough?
How do I use it?
Contributors are welcome!
License
",3
https://github.com/tinco/ruru,## Examples, ,3
https://github.com/tinco/ruru,### The famous `String#blank?` method,"  The fast String#blank? implementation by Yehuda Katz #[macro_use]
extern crate ruru;

use ruru::{Boolean, Class, Object, RString};

methods!(
   RString,
   itself,

   fn string_is_blank() -> Boolean {
       Boolean::new(itself.to_string().chars().all(|c| c.is_whitespace()))
   }
);

#[no_mangle]
pub extern fn initialize_string() {
    Class::from_existing(""String"").define(|itself| {
        itself.def(""blank?"", string_is_blank);
    });
}",3
https://github.com/tinco/ruru,#[macro_use],,-
https://github.com/tinco/ruru,#[no_mangle],,-
https://github.com/tinco/ruru,### Simple Sidekiq-compatible server,  Link to the repository,6
https://github.com/tinco/ruru,### Safe conversions,"  Since 0.8.0 safe conversions are available for built-in Ruby types and for custom types. Let's imagine that we are writing an HTTP server. It should handle requests which are passed from
Ruby side. Any object which responds to #body method is considered as a valid request. #[macro_use]
extern crate ruru;

use std::error::Error;
use ruru::{Class, Object, RString, VerifiedObject, VM};

class!(Request);

impl VerifiedObject for Request {
    fn is_correct_type<T: Object>(object: &T) -> bool {
        object.respond_to(""body"")
    }

    fn error_message() -> &'static str {
        ""Not a valid request""
    }
}

class!(Server);

methods!(
    Server,
    itself,

    fn process_request(request: Request) -> RString {
        let body = request
            .and_then(|request| request.send(""body"", vec![]).try_convert_to::<RString>())
            .map(|body| body.to_string());

        // Either request does not respond to `body` or `body` is not a String
        if let Err(ref error) = body {
            VM::raise(error.to_exception(), error.description());
        }

        let formatted_body = format!(""[BODY] {}"", body.unwrap());

        RString::new(&formatted_body)
    }
);

#[no_mangle]
pub extern fn initialize_server() {
    Class::new(""Server"", None).define(|itself| {
        itself.def(""process_request"", process_request);
    });
}",3
https://github.com/tinco/ruru,#[macro_use],,-
https://github.com/tinco/ruru,#[no_mangle],,-
https://github.com/tinco/ruru,### Wrapping Rust data to Ruby objects,,3
https://github.com/tinco/ruru,#[macro_use] extern crate ruru;,,-
https://github.com/tinco/ruru,#[macro_use] extern crate lazy_static;,,-
https://github.com/tinco/ruru,### True parallelism,"  Ruru provides a way to enable true parallelism for Ruby threads by releasing GVL (GIL). It means that a thread with released GVL runs in parallel with other threads without
being interrupted by GVL. Current example demonstrates a ""heavy"" computation (2 * 2 for simplicity) run in parallel. #[macro_use] extern crate ruru;

use ruru::{Class, Fixnum, Object, VM};

class!(Calculator);

methods!(
    Calculator,
    itself,

    fn heavy_computation() -> Fixnum {
        let computation = || { 2 * 2 };
        let unblocking_function = || {};

        // release GVL for current thread until `computation` is completed
        let result = VM::thread_call_without_gvl(
            computation,
            Some(unblocking_function)
        );

        Fixnum::new(result)
    }
);

fn main() {
    Class::new(""Calculator"", None).define(|itself| {
        itself.def(""heavy_computation"", heavy_computation);
    });
}",3
https://github.com/tinco/ruru,#[macro_use] extern crate ruru;,,-
https://github.com/tinco/ruru,### Defining a new class,,3
https://github.com/tinco/ruru,# ... somewhere in the application code ...,,-
https://github.com/tinco/ruru,#[macro_use],,-
https://github.com/tinco/ruru,#[no_mangle],,-
https://github.com/tinco/ruru,# No Calculator class in Ruby anymore,,-
https://github.com/tinco/ruru,# ... somewhere in the application ...,,-
https://github.com/tinco/ruru,### Replacing only several methods instead of the whole class,,3
https://github.com/tinco/ruru,### Class definition DSL,,3
https://github.com/tinco/ruru,### Calling Ruby code from Rust,,36
https://github.com/tinco/ruru,#[macro_use],,-
https://github.com/tinco/ruru,## ... and why is **FFI** not enough?,"  

No support of native Ruby types;


No way to create a standalone application to run the Ruby VM separately;


No way to call your Ruby code from Rust;

",2
https://github.com/tinco/ruru,## How do I use it?,"  Warning! The crate is a WIP. It is recommended to use Thermite gem,
a Rake-based helper for building and distributing Rust-based Ruby extensions. To be able to use Ruru, make sure that your Ruby version is 2.3.0 or higher. 
Your local MRI copy has to be built with the --enable-shared option. For
example, using rbenv:
 CONFIGURE_OPTS=--enable-shared rbenv install 2.3.0 
Add Ruru to Cargo.toml
 [dependencies]
ruru = ""0.9.0"" 
Compile your library as a dylib
 [lib]
crate-type = [""dylib""] 
Create a function which will initialize the extension
 #[no_mangle]
pub extern fn initialize_my_app() {
    Class::new(""SomeClass"");

    // ... etc
} 
Build extension
 $ cargo build --release or using Thermite $ rake thermite:build 
On the ruby side, open the compiled dylib and call the function to initialize extension
 require 'fiddle'

library = Fiddle::dlopen('path_to_dylib/libmy_library.dylib')

Fiddle::Function.new(library['initialize_my_app'], [], Fiddle::TYPE_VOIDP).call 
Ruru is ready ❤️
",3
https://github.com/tinco/ruru,## Contributors are welcome!,"  If you have any questions, join Ruru on
Gitter",7
https://github.com/tinco/ruru,## License,"  MIT License Copyright (c) 2015-2016 Dmitry Gritsay Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE. Icon is designed by Github.",5
https://github.com/voxik/fog,## Dependency Notice," Currently all fog providers are getting separated into metagems to lower the
load time and dependency count. If there's a metagem available for your cloud provider, e.g. fog-aws,
you should be using it instead of requiring the full fog collection to avoid
unnecessary dependencies. 'fog' should be required explicitly only if: 
The provider you use doesn't yet have a metagem available.
You require Ruby 1.9.3 support.
",3
https://github.com/voxik/fog,## Getting Started,"  The easiest way to learn fog is to install the gem and use the interactive console.
Here is an example of wading through server creation for Amazon Elastic Compute Cloud: $ sudo gem install fog
[...]

$ fog

  Welcome to fog interactive!
  :default provides [...]

>> server = Compute[:aws].servers.create
ArgumentError: image_id is required for this operation

>> server = Compute[:aws].servers.create(:image_id => 'ami-5ee70037')
<Fog::AWS::EC2::Server [...]>

>> server.destroy # cleanup after yourself or regret it, trust me
true
",3
https://github.com/voxik/fog,## Ruby version,"  Fog requires Ruby 2.0.0 or later. Ruby 1.8 and 1.9 support was dropped in fog-v2.0.0 as a backwards incompatible
change. Please use the later fog 1.x versions if you require 1.8.7 or 1.9.x support.",34
https://github.com/voxik/fog,## Collections,"  A high level interface to each cloud is provided through collections, such as images and servers.
You can see a list of available collections by calling collections on the connection object.
You can try it out using the fog command: >> Compute[:aws].collections
[:addresses, :directories, ..., :volumes, :zones]
 Some collections are available across multiple providers: 
compute providers have flavors, images and servers
dns providers have zones and records
storage providers have directories and files
 Collections share basic CRUD type operations, such as: 
all - fetch every object of that type from the provider.
create - initialize a new record locally and a remote resource with the provider.
get - fetch a single object by its identity from the provider.
new - initialize a new record locally, but do not create a remote resource with the provider.
 As an example, we'll try initializing and persisting a Rackspace Cloud server: require 'fog'

compute = Fog::Compute.new(
  :provider           => 'Rackspace',
  :rackspace_api_key  => key,
  :rackspace_username => username
)

# boot a gentoo server (flavor 1 = 256, image 3 = gentoo 2008.0)
server = compute.servers.create(:flavor_id => 1, :image_id => 3, :name => 'my_server')
server.wait_for { ready? } # give server time to boot

# DO STUFF

server.destroy # cleanup after yourself or regret it, trust me",3
https://github.com/voxik/fog,"# boot a gentoo server (flavor 1 = 256, image 3 = gentoo 2008.0)",,-
https://github.com/voxik/fog,# DO STUFF,,-
https://github.com/voxik/fog,## Models,"  Many of the collection methods return individual objects, which also provide common methods: 
destroy - will destroy the persisted object from the provider
save - persist the object to the provider
wait_for - takes a block and waits for either the block to return true for the object or for a timeout (defaults to 10 minutes)
",3
https://github.com/voxik/fog,## Mocks,"  As you might imagine, testing code using Fog can be slow and expensive, constantly turning on and shutting down instances.
Mocking allows skipping this overhead by providing an in memory representation of resources as you make requests.
Enabling mocking is easy to use: before you run other commands, simply run: Fog.mock! Then proceed as usual, if you run into unimplemented mocks, fog will raise an error and as always contributions are welcome!",3
https://github.com/voxik/fog,## Requests,"  Requests allow you to dive deeper when the models just can't cut it.
You can see a list of available requests by calling #requests on the connection object. For instance, ec2 provides methods related to reserved instances that don't have any models (yet). Here is how you can lookup your reserved instances: $ fog
>> Compute[:aws].describe_reserved_instances
#<Excon::Response [...]>
 It will return an excon response, which has body, headers and status. Both return nice hashes.",3
https://github.com/voxik/fog,## Go forth and conquer,"  Play around and use the console to explore or check out fog.io and the provider documentation
for more details and examples. Once you are ready to start scripting fog, here is a quick hint on how to make connections without the command line thing to help you. # create a compute connection
compute = Fog::Compute.new(:provider => 'AWS', :aws_access_key_id => ACCESS_KEY_ID, :aws_secret_access_key => SECRET_ACCESS_KEY)
# compute operations go here

# create a storage connection
storage = Fog::Storage.new(:provider => 'AWS', :aws_access_key_id => ACCESS_KEY_ID, :aws_secret_access_key => SECRET_ACCESS_KEY)
# storage operations go here geemus says: ""That should give you everything you need to get started, but let me know if there is anything I can do to help!""",36
https://github.com/voxik/fog,# create a compute connection,,-
https://github.com/voxik/fog,# compute operations go here,,-
https://github.com/voxik/fog,# create a storage connection,,-
https://github.com/voxik/fog,# storage operations go here,,-
https://github.com/voxik/fog,## Versioning,"  Fog library aims to adhere to Semantic Versioning 2.0.0, although it does not
address challenges of multi-provider libraries. Semantic versioning is only guaranteed for
the common API, not any provider-specific extensions.  You may also need to update your
configuration from time to time (even between Fog releases) as providers update or deprecate
services. However, we still aim for forwards compatibility within Fog major versions.  As a result of this policy, you can (and
should) specify a dependency on this gem using the Pessimistic Version
Constraint with two digits of precision. For example: spec.add_dependency 'fog', '~> 1.0' This means your project is compatible with Fog 1.0 up until 2.0.  You can also set a higher minimum version: spec.add_dependency 'fog', '~> 1.16'",4
https://github.com/voxik/fog,## Getting Help,"  
General Documentation.
Provider Specific Documentation.
Ask specific questions on Stack Overflow
Report bugs and discuss potential features in Github issues.
",6
https://github.com/voxik/fog,## Contributing,  Please refer to CONTRIBUTING.md.,7
https://github.com/voxik/fog,## License,  Please refer to LICENSE.md.,5
https://github.com/brendanwb/factory_girl_rails,# factory_girl_rails [![Build Status][ci-image]][ci] [![Code Climate][grade-image]][grade]," factory_girl is a fixtures replacement with a straightforward definition
syntax, support for multiple build strategies (saved instances, unsaved
instances, attribute hashes, and stubbed objects), and support for multiple
factories for the same class (user, admin_user, and so on), including factory
inheritance.",1
https://github.com/brendanwb/factory_girl_rails,## Rails,"  factory_girl_rails provides Rails integration for factory_girl. Currently, automatic factory definition loading is the only Rails-specific feature. Supported Rails versions are listed in Appraisals. Supported
Ruby versions are listed in .travis.yml.",1
https://github.com/brendanwb/factory_girl_rails,## Download,"  Github: http://github.com/thoughtbot/factory_girl_rails Gem: gem install factory_girl_rails
",3
https://github.com/brendanwb/factory_girl_rails,## Configuration,"  Add factory_girl_rails to your Gemfile: gem 'factory_girl_rails' Generators for factories will automatically substitute fixture (and maybe any other
fixture_replacement you set). If you want to disable this feature, add the
following to your application.rb file: config.generators do |g|
  g.factory_girl false
end Default factories directory is test/factories, or spec/factories if
test_framework generator is set to :rspec; change this behavior with: config.generators do |g|
  g.factory_girl dir: 'custom/dir/for/factories'
end If you use factory_girl for fixture replacement, ensure that
factory_girl_rails is available in the development group. If it's not, Rails
will generate standard .yml files instead of factory files. factory_girl takes an option suffix: 'some_suffix' to generate factories as
modelname_some_suffix.rb. If you use factory_girl for fixture replacement and already have a
factories.rb file in the directory that contains your tests,
factory_girl_rails will insert new factory definitions at the top of
factories.rb.",3
https://github.com/brendanwb/factory_girl_rails,## Contributing,  Please see CONTRIBUTING.md.,7
https://github.com/brendanwb/factory_girl_rails,## Credits,"  factory_girl was originally written by Joe Ferris.  factory_girl is maintained and funded by thoughtbot, inc The names and logos for thoughtbot are trademarks of thoughtbot, inc.",5
https://github.com/brendanwb/factory_girl_rails,## License,"  factory_girl_rails is Copyright © 2008-2014 Joe Ferris and thoughtbot. It is free
software, and may be redistributed under the terms specified in the
LICENSE file.",5
https://github.com/sebald/grunt-dss,# Grunt-DSS [![Build Status](https://secure.travis-ci.org/darcyclarke/grunt-dss.png?branch=master)](http://travis-ci.org/darcyclarke/grunt-dss)," Grunt-DSS is a Grunt plugin that generates UI documentation from CSS, Less, Stylus, Sass files based on the DSS parser output.",1
https://github.com/sebald/grunt-dss,## Getting Started,"  This plugin requires Grunt ~0.4.0 If you haven't used Grunt before, be sure to check out the Getting Started guide, as it explains how to create a Gruntfile as well as install and use Grunt plugins. Once you're familiar with that process, you may install this plugin with this command: npm install grunt-dss --save-dev Once the plugin has been installed, it may be enabled inside your Gruntfile with this line of JavaScript: grunt.loadNpmTasks('grunt-dss'); In your project's Gruntfile, add a section named dss to the data object passed into grunt.initConfig().",3
https://github.com/sebald/grunt-dss,## Settings, ,3
https://github.com/sebald/grunt-dss,#### files,"  Type: Array or Object
Default value: [] Files to parse. Using Grunt default files syntax. More about that on Gruntjs wiki.",36
https://github.com/sebald/grunt-dss,#### options.template,"  Type: String
Default value: {task_path}/template/ A relative path to a mustache template to be used instead of the default.",3
https://github.com/sebald/grunt-dss,#### options.template_index,"  Type: String
Default value: index.handlebars The filename of the index of the template.",3
https://github.com/sebald/grunt-dss,#### options.output_index,"  Type: String
Default value: index.html The filename of the index for the output file.",3
https://github.com/sebald/grunt-dss,#### options.parsers,"  Type: Object
Default value: {} An object filled with key value pairs of functions to be used when parsing comment blocks. See the example below for more context about how to use these.",36
https://github.com/sebald/grunt-dss,#### options.include_empty_files,"  Type: Boolean
Default value: true Include files without DSS annotations.",3
https://github.com/sebald/grunt-dss,#### options-handlebar_helpers,"  Type: Object
Default value: {} An object filled with key value pairs of handlebars helpers. The key is the helber name and the value is the callback function. See the Handlebar documentation for more information.",36
https://github.com/sebald/grunt-dss,### Example initConfig,"  grunt.initConfig({
  dss: {
    docs: {
      files: {
        'api/': 'css/**/*.{css,scss,sass,less,styl}'
      },
      options: {
        template: '/dark_theme/',
        parsers: {
          // Finds @link in comment blocks
          link: function(i, line, block){

            // Replace link with HTML wrapped version
            var exp = /(b(https?|ftp|file)://[-A-Z0-9+&@#/%?=~_|!:,.;]*[-A-Z0-9+&@#/%=~_|])/ig;
            line.replace(exp, ""<a href='$1'>$1</a>"");
            return line;
          }
        }
      }
    }
  }
});",3
https://github.com/sebald/grunt-dss,## DSS Sublime Text Plugin,  You can now auto-complete DSS-style comment blocks using @sc8696's Auto-Comments Sublime Text Plugin,6
https://github.com/aborunski/android-fragment-swapper,# FragmentSwapper," FragmentSwapper is an Open Source Android library that allows easy fragment's management. It is somewhat similar to Activities management model.
For instance, new fragment can be launched from another one with action's request (using request code) and then recieve the result. FragmentSwapper works with Android Support Library. In order to manage multiple fragments, FragmentSwapper object is required. Each fragment must implement FragmentDescriptor interface. Its example implementation is provided in BaseFragment class. BaseFragment can be also used as a base class in your application. Currently, it is possible to manage fragments within one container, using SingleContainerFragmentSwapper class. For information how to initialize the SingleContainerFragmentSwapper, and how to implement fragment swapping please check sample application and the library code.",1
https://github.com/aborunski/android-fragment-swapper,### Project integration,"  Add repository reference in your build.gradle file: repositories {
...
maven {
url 'http://dev.open-rnd.net:30844/content/groups/public/'
}
...
} Add library dependence: dependencies {
compile group: ""pl.openrnd.android"", name: ""fragmentsswapper"", version: ""1.0.1""
}",3
https://github.com/aborunski/android-fragment-swapper,### License,"  2015 (C) Copyright Open-RnD Sp. z o.o. Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.",5
https://github.com/anyexxx/iCreator,# iCreator, A command-line tool for creating all icons and launch-screen images of iOS App. ,1
https://github.com/anyexxx/iCreator,##,,-
https://github.com/anyexxx/iCreator,### Getting started,"  First, download and install ImageMagick. In Mac OS X, you can simply use Homebrew and do: brew install imagemagick
 Second, install Node.js. brew install node
 Then make sure A Icon Image (for creating icons) and A logo Image(for launch-screen) are prepared. Notice:  A launch-screen image == your logo over a solid-colored background.",3
https://github.com/anyexxx/iCreator,### Examples,"  
generate all icons
 node icreator.js  -icon:YourBigIcon.png
 
generate all launch-screen images.  -color:backgorund-color
 node icreator.js  -logo:YourLogo.png -color:#ffffff
 
-l means the App is running in Landscape
 node icreator.js -logo:logo.png -color:#ffffff -l
 
-output:xxxx is output dir (relative to cwd)
 node icreator.js  -icon:icon.png   -output:../icons
",3
https://github.com/anyexxx/iCreator,### About the size of logo image,"  iCreator will draw your logo image on a solid-colored launch-screen image ( center alignment ). The output image's size is between 320x480 to 1536x2048. If screen-image's long side < 500 , iCreator will resize logo image to 50%. If screen-image's long side > 1500 , iCreator will resize logo image to 200%. So, it's recommended that let the size of your logo image be between 300x300 to 500x500.",3
https://github.com/cwohlman/delta,# Delta [![Build Status](https://travis-ci.org/quilljs/delta.svg?branch=master)](http://travis-ci.org/quilljs/delta) [![Coverage Status](https://img.shields.io/coveralls/quilljs/delta.svg)](https://coveralls.io/r/quilljs/delta)," Deltas are a simple, yet expressive format that can be used to describe contents and changes. The format is JSON based, and is human readable, yet easily parsible by machines. Deltas can describe any rich text document, includes all text and formatting information, without the ambiguity and complexity of HTML. A Delta is made up of an Array of Operations, which describe changes to a document. They can be an insert, delete or retain. Note operations do not take an index. They always describe the change at the current index. Use retains to ""keep"" or ""skip"" certain parts of the document. Don’t be confused by its name Delta—Deltas represents both documents and changes to documents. If you think of Deltas as the instructions from going from one document to another, the way Deltas represent a document is by expressing the instructions starting from an empty document.",1
https://github.com/cwohlman/delta,## Quick Example,"  // Document with text ""Gandalf the Grey""
// with ""Gandalf"" bolded, and ""Grey"" in grey
var delta = new Delta([
  { insert: 'Gandalf', attributes: { bold: true } },
  { insert: ' the ' },
  { insert: 'Grey', attributes: { color: '#ccc' } }
]);

// Change intended to be applied to above:
// Keep the first 12 characters, delete the next 4,
// and insert a white 'White'
var death = new Delta().retain(12)
                       .delete(4)
                       .insert('White', { color: '#fff' });
// {
//   ops: [
//     { retain: 12 },
//     { delete: 4 },
//     { insert: 'White', attributes: { color: '#fff' } }
//   ]
// }

// Applying the above:
var restored = delta.compose(death);
// {
//   ops: [
//     { insert: 'Gandalf ', attributes: { bold: true } },
//     { insert: 'the ' },
//     { insert: 'White', attributes: { color: '#fff' } }
//   ]
// } This README describes Deltas in its general form and API functionality. Additional information on the way Quill specifically uses Deltas can be found on its own Delta docs. A walkthough of the motivation and design thinking behind Deltas are on Designing the Delta Format. This format is suitable for Operational Transform and defines several functions to support this use case.",36
https://github.com/cwohlman/delta,## Contents, ,6
https://github.com/cwohlman/delta,#### Operations,"  
insert
delete
retain
",3
https://github.com/cwohlman/delta,#### Construction,"  
constructor
insert
delete
retain
",3
https://github.com/cwohlman/delta,#### Documents,"  These methods called on or with non-document Deltas will result in undefined behavior. 
concat
diff
eachLine
",3
https://github.com/cwohlman/delta,#### Utility,"  
filter
forEach
length
map
partition
reduce
slice
",3
https://github.com/cwohlman/delta,#### Operational Transform,"  
compose
transform
transformPosition
",3
https://github.com/cwohlman/delta,## Operations, ,3
https://github.com/cwohlman/delta,### Insert Operation,"  Insert operations have an insert key defined. A String value represents inserting text. Any other type represents inserting an embed (however only one level of object comparison will be performed for equality). In both cases of text and embeds, an optional attributes key can be defined with an Object to describe additonal formatting information. Formats can be changed by the retain operation. // Insert a bolded ""Text""
{ insert: ""Text"", attributes: { bold: true } }

// Insert a link
{ insert: ""Google"", attributes: { href: 'https://www.google.com' } }

// Insert an embed
{
  insert: { image: 'https://octodex.github.com/images/labtocat.png' },
  attributes: { alt: ""Lab Octocat"" }
}

// Insert another embed
{
  insert: { video: 'https://www.youtube.com/watch?v=dMH0bHeiRNg' },
  attributes: {
    width: 420,
    height: 315
  }
}",3
https://github.com/cwohlman/delta,### Delete Operation,"  Delete operations have a Number delete key defined representing the number of characters to delete. All embeds have a length of 1. // Delete the next 10 characters
{ delete: 10 }",3
https://github.com/cwohlman/delta,### Retain Operation,"  Retain operations have a Number retain key defined representing the number of characters to keep (other libraries might use the name keep or skip). An optional attributes key can be defined with an Object to describe formatting changes to the character range. A value of null in the attributes Object represents removal of that key. Note: It is not necessary to retain the last characters of a document as this is implied. // Keep the next 5 characters
{ retain: 5 }

// Keep and bold the next 5 characters
{ retain: 5, attributes: { bold: true } }

// Keep and unbold the next 5 characters
// More specifically, remove the bold key in the attributes Object
// in the next 5 characters
{ retain: 5, attributes: { bold: null } }",3
https://github.com/cwohlman/delta,## Construction, ,3
https://github.com/cwohlman/delta,### constructor,  Creates a new Delta object.,3
https://github.com/cwohlman/delta,#### Methods,"  
new Delta()
new Delta(ops)
new Delta(delta)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
ops - Array of operations
delta - Object with an ops key set to an array of operations
 Note: No validity/sanity check is performed when constructed with ops or delta. The new delta's internal ops array will also be assigned to ops or delta.ops without deep copying.",3
https://github.com/cwohlman/delta,#### Example,"  var delta = new Delta([
  { insert: 'Hello World' },
  { insert: '!', attributes: { bold: true }}
]);

var packet = JSON.stringify(delta);

var other = new Delta(JSON.parse(packet));

var chained = new Delta().insert('Hello World').insert('!', { bold: true }); ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### insert(),  Appends an insert operation. Returns this for chainability.,3
https://github.com/cwohlman/delta,#### Methods,"  
insert(text, attributes)
insert(embed, attributes)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
text - String representing text to insert
embed - Number representing embed type to insert
attributes - Optional attributes to apply
",3
https://github.com/cwohlman/delta,#### Example,"  delta.insert('Text', { bold: true, color: '#ccc' });
delta.insert(1, { src: 'https://octodex.github.com/images/labtocat.png' }); ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### delete(),  Appends a delete operation. Returns this for chainability.,3
https://github.com/cwohlman/delta,#### Methods,"  
delete(length)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
length - Number of characters to delete
",3
https://github.com/cwohlman/delta,#### Example,  delta.delete(5); ,3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### retain(),  Appends a retain operation. Returns this for chainability.,3
https://github.com/cwohlman/delta,#### Methods,"  
retain(length, attributes)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
length - Number of characters to retain
attributes - Optional attributes to apply
",3
https://github.com/cwohlman/delta,#### Example,"  delta.retain(4).retain(5, { color: '#0c6' });",3
https://github.com/cwohlman/delta,## Documents, ,3
https://github.com/cwohlman/delta,### concat(),  Returns a new Delta representing the concatenation of this and another document Delta's operations.,3
https://github.com/cwohlman/delta,#### Methods,"  
concat(other)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
other - Document Delta to concatenate
",3
https://github.com/cwohlman/delta,#### Returns,"  
Delta - Concatenated document Delta
",3
https://github.com/cwohlman/delta,#### Example,"  var a = new Delta().insert('Hello');
var b = new Delta().insert('!', { bold: true });


// {
//   ops: [
//     { insert: 'Hello' },
//     { insert: '!', attributes: { bold: true } }
//   ]
// }
var concat = a.concat(b); ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### diff(),"  Returns a Delta representing the difference between two documents. Optionally, accepts a suggested index where change took place, often representing a cursor position before change.",3
https://github.com/cwohlman/delta,#### Methods,"  
diff(other)
diff(other, index)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
other - Document Delta to diff against
index - Suggested index where change took place
",3
https://github.com/cwohlman/delta,#### Returns,"  
Delta - difference between the two documents
",3
https://github.com/cwohlman/delta,#### Example,"  var a = new Delta().insert('Hello');
var b = new Delta().insert('Hello!');

var diff = a.diff(b);  // { ops: [{ retain: 5 }, { insert: '!' }] }
                       // a.compose(diff) == b ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### eachLine(),"  Iterates through document Delta, calling a given function with a Delta and attributes object, representing the line segment.",3
https://github.com/cwohlman/delta,#### Methods,"  
eachLine(predicate, newline)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
predicate - function to call on each line group
newline - newline character, defaults to \n
",3
https://github.com/cwohlman/delta,#### Example,"  var delta = new Delta().insert('Hello\n\n')
                       .insert('World')
                       .insert({ image: 'octocat.png' })
                       .insert('\n', { align: 'right' })
                       .insert('!');

delta.eachline(function(line, attributes) {
  console.log(line, attributes);
});
// Should log:
// { ops: [{ insert: 'Hello' }] }, {}
// { ops: [] }, {}
// { ops: [{ insert: 'World' }, { insert: { image: 'octocat.png' } }] }, { align: 'right' }
// { ops: [{ insert: '!' }] }, {}",3
https://github.com/cwohlman/delta,## Utility, ,3
https://github.com/cwohlman/delta,### filter(),  Returns an array of operations that passes a given function.,3
https://github.com/cwohlman/delta,#### Methods,"  
filter(predicate)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
predicate - Function to test each operation against. Return true to keep the operation, false otherwise.
",3
https://github.com/cwohlman/delta,#### Returns,"  
Array - Filtered resulting array
",3
https://github.com/cwohlman/delta,#### Example,"  var delta = new Delta().insert('Hello', { bold: true })
                       .insert({ image: 'https://octodex.github.com/images/labtocat.png' })
                       .insert('World!');

var text = delta.filter(function(op) {
  return typeof op.insert === 'string';
}).map(function(op) {
  return op.insert;
}).join(''); ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### forEach(),"  Iterates through operations, calling the provided function for each operation.",3
https://github.com/cwohlman/delta,#### Methods,"  
forEach(predicate)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
predicate - Function to call during iteration, passing in the current operation.
",3
https://github.com/cwohlman/delta,#### Example,"  delta.forEach(function(op) {
  console.log(op);
}); ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### length(),"  Returns length of a Delta, which is the sum of the lengths of its operations.",3
https://github.com/cwohlman/delta,#### Methods,"  
length()
",3
https://github.com/cwohlman/delta,#### Example,"  new Delta().insert('Hello').length();  // Returns 5

new Delta().insert('A').retain(2).delete(1) // Returns 4 ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### map(),  Returns a new array with the results of calling provided function on each operation.,3
https://github.com/cwohlman/delta,#### Methods,"  
map(predicate)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
predicate - Function to call, passing in the current operation, returning an element of the new array to be returned
",3
https://github.com/cwohlman/delta,#### Returns,"  
Array - A new array with each element being the result of the given function.
",3
https://github.com/cwohlman/delta,#### Example,"  var delta = new Delta().insert('Hello', { bold: true })
                       .insert({ image: 'https://octodex.github.com/images/labtocat.png' })
                       .insert('World!');

var text = delta.map(function(op) {
  if (typeof op.insert === 'string') {
    return op.insert;
  } else {
    return '';
  }
}).join(''); ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### partition(),"  Create an array of two arrays, the first with operations that pass the given function, the other that failed.",3
https://github.com/cwohlman/delta,#### Methods,"  
partition(predicate)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
predicate - Function to call, passing in the current operation, returning whether that operation passed
",3
https://github.com/cwohlman/delta,#### Returns,"  
Array - A new array of two Arrays, the first with passed operations, the other with failed operations
",3
https://github.com/cwohlman/delta,#### Example,"  var delta = new Delta().insert('Hello', { bold: true })
                       .insert({ image: 'https://octodex.github.com/images/labtocat.png' })
                       .insert('World!');

var results = delta.partition(function(op) {
  return typeof op.insert === 'string';
});
var passed = results[0];  // [{ insert: 'Hello', attributes: { bold: true }},
                              { insert: 'World'}]
var failed = results[1];  // [{ insert: { image: 'https://octodex.github.com/images/labtocat.png' }}] ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### reduce(),  Applies given function against an accumulator and each operation to reduce to a single value.,3
https://github.com/cwohlman/delta,#### Methods,"  
reduce(predicate, initialValue)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
predicate - Function to call per iteration, returning an accumulated value
initialValue - Initial value to pass to first call to predicate
",3
https://github.com/cwohlman/delta,#### Returns,"  
any - the accumulated value
",3
https://github.com/cwohlman/delta,#### Example,"  var delta = new Delta().insert('Hello', { bold: true })
                       .insert({ image: 'https://octodex.github.com/images/labtocat.png' })
                       .insert('World!');

var length = delta.reduce(function(length, op) {
  return length + (op.insert.length || 1);
}, 0); ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### slice(),  Returns copy of delta with subset of operations.,3
https://github.com/cwohlman/delta,#### Methods,"  
slice()
slice(start)
slice(start, end)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
start - Start index of subset, defaults to 0
end - End index of subset, defaults to rest of operations
",3
https://github.com/cwohlman/delta,#### Example,"  var delta = new Delta().insert('Hello', { bold: true }).insert(' World');

// {
//   ops: [
//     { insert: 'Hello', attributes: { bold: true } },
//     { insert: ' World' }
//   ]
// }
var copy = delta.slice();

// { ops: [{ insert: 'World' }] }
var world = delta.slice(6);

// { ops: [{ insert: ' ' }] }
var space = delta.slice(5, 6);",3
https://github.com/cwohlman/delta,## Operational Transform, ,3
https://github.com/cwohlman/delta,### compose(),"  Returns a Delta that is equivalent to applying the operations of own Delta, followed by another Delta.",3
https://github.com/cwohlman/delta,#### Methods,"  
compose(other)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
other - Delta to compose
",3
https://github.com/cwohlman/delta,#### Example,"  var a = new Delta().insert('abc');
var b = new Delta().retain(1).delete(1);

var composed = a.compose(b);  // composed == new Delta().insert('ac'); ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### transform(),  Transform given Delta against own operations.,3
https://github.com/cwohlman/delta,#### Methods,"  
transform(other, priority)
transform(index) - Alias for transformPosition
",3
https://github.com/cwohlman/delta,#### Parameters,"  
other - Delta to transform
priority - Boolean used to break ties. If true, then this takes priority
over other, that is, its actions are considered to happen ""first.""
",3
https://github.com/cwohlman/delta,#### Returns,"  
Delta - transformed Delta
",3
https://github.com/cwohlman/delta,#### Example,"  var a = new Delta().insert('a');
var b = new Delta().insert('b').retain(5).insert('c');

a.transform(b, true);  // new Delta().retain(1).insert('b').retain(5).insert('c');
a.transform(b, false); // new Delta().insert('b').retain(6).insert('c'); ",3
https://github.com/cwohlman/delta,##,,-
https://github.com/cwohlman/delta,### transformPosition(),  Transform an index against the delta. Useful for representing cursor/selection positions.,3
https://github.com/cwohlman/delta,#### Methods,"  
transformPosition(index)
",3
https://github.com/cwohlman/delta,#### Parameters,"  
index - index to transform
",3
https://github.com/cwohlman/delta,#### Returns,"  
Number - transformed index
",3
https://github.com/cwohlman/delta,#### Example,"  var delta = new Delta().retain(5).insert('a');
delta.transformPosition(4); // 4
delta.transformPosition(5); // 6",3
https://github.com/adamswann/WPD-.NET-Wrapper,# WPD-.NET-Wrapper, Windows Portable Device .Net Wrapper,1
https://github.com/adamswann/WPD-.NET-Wrapper,## Current State,"  Hi, to all the users that wish to use this library please feel free.
Unfortunately it has been a while since I've looked at this and I can't really remember how it all works.
I might get back to it someday but for now I'm not really keeping it up to date.",4
https://github.com/adamswann/WPD-.NET-Wrapper,## Copyright,"  Copyright (c) 2013 Gavin Chin (slowmonkey - https://github.com/slowmonkey) Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
""Software""), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions: The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  ADDITIONAL INFORMATION BEFORE I FORGET: 
Apparently there is a device simulator now for ""Windows 7 Portable Device Enabling Kit for MTP, Verions 7R2"", http://msdn.microsoft.com/en-us/library/windows/hardware/Dn614016(v=vs.85).aspx
",5
https://github.com/adamswann/WPD-.NET-Wrapper,##,,-
https://github.com/edsonmgoz/restaurante,# CakePHP," 


  CakePHP is a rapid development framework for PHP which uses commonly known design patterns like Active Record, Association Data Mapping, Front Controller and MVC.
Our primary goal is to provide a structured framework that enables PHP users at all levels to rapidly develop robust web applications, without any loss to flexibility.",12
https://github.com/edsonmgoz/restaurante,## Some Handy Links,"  CakePHP - The rapid development PHP framework CookBook - THE CakePHP user documentation; start learning here! API - A reference to CakePHP's classes Plugins - A repository of extensions to the framework The Bakery - Tips, tutorials and articles Community Center - A source for everything community related Training - Join a live session and get skilled with the framework CakeFest - Don't miss our annual CakePHP conference Cake Software Foundation - Promoting development related to CakePHP",6
https://github.com/edsonmgoz/restaurante,## Get Support!,"  #cakephp on irc.freenode.net - Come chat with us, we have cake Google Group - Community mailing list and forum GitHub Issues - Got issues? Please tell us! Roadmaps - Want to contribute? Get involved!",56
https://github.com/edsonmgoz/restaurante,## Contributing,"  CONTRIBUTING.md - Quick pointers for contributing to the CakePHP project CookBook ""Contributing"" Section (2.x) (3.0) - Version-specific details about contributing to the project",7
https://github.com/scollison/huginn,##," Huginn is a system for building agents that perform automated tasks for you online.  They can read the web, watch for events, and take actions on your behalf.  Huginn's Agents create and consume events, propagating them along a directed graph.  Think of it as a hackable Yahoo! Pipes plus IFTTT on your own server.  You always know who has your data.  You do. ",-
https://github.com/scollison/huginn,## What is Huginn?,"Huginn is a system for building agents that perform automated tasks for you online. They can read the web, watch for events, and take actions on your behalf. Huginn's Agents create and consume events, propagating them along a directed graph. Think of it as a hackable Yahoo! Pipes plus IFTTT on your own server. You always know who has your data. You do.",1
https://github.com/scollison/huginn,#### Here are some of the things that you can do with Huginn:,"Track the weather and get an email when it's going to rain (or snow) tomorrow (""Don't forget your umbrella!"")
List terms that you care about and receive emails when their occurrence on Twitter changes. (For example, want to know when something interesting has happened in the world of Machine Learning? Huginn will watch the term ""machine learning"" on Twitter and tell you when there is a spike in discussion.)
Watch for air travel or shopping deals
Follow your project names on Twitter and get updates when people mention them
Scrape websites and receive emails when they change
Connect to Adioso, HipChat, Basecamp, Growl, FTP, IMAP, Jabber, JIRA, MQTT, nextbus, Pushbullet, Pushover, RSS, Bash, Slack, StubHub, translation APIs, Twilio, Twitter, Wunderground, and Weibo, to name a few.
Send digest emails with things that you care about at specific times during the day
Track counts of high frequency events and send an SMS within moments when they spike, such as the term ""san francisco emergency""
Send and receive WebHooks
Run custom JavaScript or CoffeeScript functions
Track your location over time
Create Amazon Mechanical Turk workflows as the inputs, or outputs, of agents (the Amazon Turk Agent is called the ""HumanTaskAgent""). For example: ""Once a day, ask 5 people for a funny cat photo; send the results to 5 more people to be rated; send the top-rated photo to 5 people for a funny caption; send to 5 final people to rate for funniest caption; finally, post the best captioned photo on my blog.""",2
https://github.com/scollison/huginn,### Join us!,"  Want to help with Huginn?  All contributions are encouraged!  You could make UI improvements, add new Agents, write documentation and tutorials, or try tackling issues tagged with #help-wanted.  Please fork, add specs, and send pull requests! Really want a fix or feature? Want to solve some community issues and earn some extra coffee money? Take a look at the current bounties on Bountysource. Have an awesome idea but not feeling quite up to contributing yet? Head over to our Official 'suggest an agent' thread  and tell us!",57
https://github.com/scollison/huginn,## Examples,"  Please checkout the Huginn Introductory Screencast! And now, some example screenshots.  Below them are instructions to get you started.     ",3
https://github.com/scollison/huginn,## Getting Started, ,3
https://github.com/scollison/huginn,### Docker,  The quickest and easiest way to check out Huginn is to use the offical Docker image. Have a look at the documentation.,6
https://github.com/scollison/huginn,### Local Installation,"  If you just want to play around, you can simply fork this repository, then perform the following steps: 
Run git remote add upstream https://github.com/cantino/huginn.git to add the main repository as a remote for your fork.
Copy .env.example to .env (cp .env.example .env) and edit .env, at least updating the APP_SECRET_TOKEN variable.
Run bundle to install dependencies
Run bundle exec rake db:create, bundle exec rake db:migrate, and then bundle exec rake db:seed to create a development MySQL database with some example Agents.
Run bundle exec foreman start, visit http://localhost:3000/, and login with the username of admin and the password of password.
Setup some Agents!
Read the wiki for usage examples and to get started making new Agents.
Periodically run git fetch upstream and then git checkout master && git merge upstream/master to merge in the newest version of Huginn.
 Note: By default, emails are intercepted in the development Rails environment, which is what you just setup.  You can view
them at http://localhost:3000/letter_opener. If you'd like to send real emails via SMTP when playing
with Huginn locally, set SEND_EMAIL_IN_DEVELOPMENT to true in your .env file. If you need more detailed instructions, see the Novice setup guide.",36
https://github.com/scollison/huginn,### Develop,"  All agents have specs! Test all specs with bundle exec rspec, or test a specific spec with bundle exec rspec path/to/specific/spec.rb. Read more about rspec for rails here.",36
https://github.com/scollison/huginn,## Deployment, ,3
https://github.com/scollison/huginn,### Heroku,"  Try Huginn on Heroku:  (Takes a few minutes to setup. Read the documentation while you are waiting and be sure to click 'View it' after launch!) Huginn works on the free version of Heroku with significant limitations. For non-experimental use, we strongly recommend Heroku's cheapest paid plan or our Docker container. Please see the Huginn Wiki for detailed deployment strategies for different providers.",36
https://github.com/scollison/huginn,### Manual installation on any server,  Have a look at the installation guide.,36
https://github.com/scollison/huginn,### Optional Setup, ,3
https://github.com/scollison/huginn,#### Setup for private development,  See private development instructions on the wiki.,6
https://github.com/scollison/huginn,#### Enable the WeatherAgent,  In order to use the WeatherAgent you need an API key with Wunderground. Signup for one and then change the value of api_key: your-key in your seeded WeatherAgent.,3
https://github.com/scollison/huginn,#### Disable SSL,"  We assume your deployment will run over SSL. This is a very good idea! However, if you wish to turn this off, you'll probably need to edit config/initializers/devise.rb and modify the line containing config.rememberable_options = { :secure => true }.  You will also need to edit config/environments/production.rb and modify the value of config.force_ssl.",3
https://github.com/scollison/huginn,## License,  Huginn is provided under the MIT License.     ,5
https://github.com/g3collector/spring-best-practices,# SpringMVC - Best Practices," A full-blown, functional, tested Spring 3.2 reference application with JPA persistence, REST Level-3 resources, asynchronous processing, jobs, security, unit, mock, integration, functional, rest client stubs, and performance tests, and many best practices I gathered over several years working in mvc / spring / grails web apps.",1
https://github.com/g3collector/spring-best-practices,## How to run,"  mvn clean package
mvn jetty:run
",3
https://github.com/g3collector/spring-best-practices,## Best Practices, ,6
https://github.com/g3collector/spring-best-practices,### Domain Modeling,"  
Immutable Domain Model with Builder Pattern
Jackson JSON Annotations
JPA Annotations
Unit Tests
",6
https://github.com/g3collector/spring-best-practices,### REST,"  
REST Errors and Exception Resolver
HATEOAS (REST Level 3)
",6
https://github.com/g3collector/spring-best-practices,### Persistence,"  
Transaction Management & Connection Pooling
JPA / Hibernate
",6
https://github.com/g3collector/spring-best-practices,### AOP,"  
Http ETag management, HTTP Caching & Resource optimistic locking
",6
https://github.com/g3collector/spring-best-practices,### Async,"  
Asynchronous processing: Request-Acknowledge-Poll Pattern (Fork-Join/Future implemention on REST)
Jobs
",6
https://github.com/g3collector/spring-best-practices,### Caching,"  
Simplified caching using Spring’s new @Cacheable / Eh-Cache
",6
https://github.com/g3collector/spring-best-practices,### Spring,"  
Streamlined configuration for web, persistence, rest, spring, and properties
",6
https://github.com/g3collector/spring-best-practices,### Testing,"  
Unit Testing (JUnit, Mockito)
Integration Testing (Spring Test, MVC Test)
",6
https://github.com/g3collector/spring-best-practices,## Libraries Used,"  
Spring 3.2, JPA 2, Hibernate 4.1
JSP, JQuery, Twitter Bootstrap 2.2
H2 db (soon, MongoDb?)
JUnit, Mockito, Spring Test, Hamcrest, JsonPath,
Google Guava, Joda DateTime, Logback/Slf4j, Jackson Json
",3
https://github.com/dondre/angular-cli,## Angular-CLI,"  


 Prototype of a CLI for Angular applications based on the ember-cli project.",1
https://github.com/dondre/angular-cli,## Note,"  This project is very much still a work in progress. The CLI is now in beta.
If you wish to collaborate while the project is still young, check out our issue list. Before submitting new issues, have a look at issues marked with the type: faq label.",47
https://github.com/dondre/angular-cli,## Webpack update,"  We changed the build system between beta.10 and beta.14, from SystemJS to Webpack.
And with it comes a lot of benefits.
To take advantage of these, your app built with the old beta will need to migrate. You can update your beta.10 projects to beta.14 by following these instructions.",46
https://github.com/dondre/angular-cli,## Prerequisites,"  Both the CLI and generated project have dependencies that require Node 4 or higher, together
with NPM 3 or higher.",3
https://github.com/dondre/angular-cli,## Table of Contents,"  
Installation
Usage
Generating a New Project
Generating Components, Directives, Pipes and Services
Generating a Route
Creating a Build
Build Targets and Environment Files
Base tag handling in index.html
Bundling
Running Unit Tests
Running End-to-End Tests
Proxy To Backend
Deploying the App via GitHub Pages
Linting and formatting code
Commands autocompletion
Project assets
Global styles
CSS preprocessor integration
3rd Party Library Installation
Global Library Installation
Updating angular-cli
Development Hints for hacking on angular-cli
",6
https://github.com/dondre/angular-cli,## Installation,  BEFORE YOU INSTALL: please read the prerequisites npm install -g angular-cli,3
https://github.com/dondre/angular-cli,## Usage,  ng help,3
https://github.com/dondre/angular-cli,### Generating and serving an Angular2 project via a development server,"  ng new PROJECT_NAME
cd PROJECT_NAME
ng serve Navigate to http://localhost:4200/. The app will automatically reload if you change any of the source files. You can configure the default HTTP port and the one used by the LiveReload server with two command-line options : ng serve --host 0.0.0.0 --port 4201 --live-reload-port 49153",3
https://github.com/dondre/angular-cli,"### Generating Components, Directives, Pipes and Services",You can use the ng generate (or just ng g) command to generate Angular components:,3
https://github.com/dondre/angular-cli,# components support relative path generation,,-
https://github.com/dondre/angular-cli,# if in the directory src/app/feature/ and you run,,-
https://github.com/dondre/angular-cli,# your component will be generated in src/app/feature/new-cmp,,-
https://github.com/dondre/angular-cli,# but if you were to run,,-
https://github.com/dondre/angular-cli,# your component will be generated in src/app/newer-cmp,,-
https://github.com/dondre/angular-cli,### Generating a route,"  The CLI supports routing in several ways: 

We include the @angular/router NPM package when creating or initializing a project.


When you generate a module, you can use the --routing option like ng g module my-module --routing  to create a separate file my-module-routing.module.ts to store the module routes.
The file includes an empty Routes object that you can fill with routes to different components and/or modules.
The --routing option also generates a default component with the same name as the module.


You can use the --routing option with ng new or ng init to create a app-routing.module.ts file when you create or initialize a project.

",3
https://github.com/dondre/angular-cli,### Creating a build,  ng build The build artifacts will be stored in the dist/ directory.,3
https://github.com/dondre/angular-cli,### Build Targets and Environment Files,"  ng build can specify both a build target (--target=production or --target=development) and an
environment file to be used with that build (--environment=dev or --environment=prod).
By default, the development build target and environment are used. The mapping used to determine which environment file is used can be found in angular-cli.json: ""environments"": {
  ""source"": ""environments/environment.ts"",
  ""dev"": ""environments/environment.ts"",
  ""prod"": ""environments/environment.prod.ts""
} These options also apply to the serve command. If you do not pass a value for environment,
it will default to dev for development and prod for production. # these are equivalent
ng build --target=production --environment=prod
ng build --prod --env=prod
ng build --prod
# and so are these
ng build --target=development --environment=dev
ng build --dev --e=dev
ng build --dev
ng build You can also add your own env files other than dev and prod by doing the following: 
create a src/environments/environment.NAME.ts
add { ""NAME"": 'src/environments/environment.NAME.ts' } to the apps[0].environments object in angular-cli.json
use them via the --env=NAME flag on the build/serve commands.
",3
https://github.com/dondre/angular-cli,# these are equivalent,"  When building you can modify base tag (<base href=""/"">) in your index.html with --base-href your-url option. # Sets base tag href to /myUrl/ in your index.html
ng build --base-href /myUrl/
ng build --bh /myUrl/",-
https://github.com/dondre/angular-cli,# and so are these,,-
https://github.com/dondre/angular-cli,### Base tag handling in index.html,,3
https://github.com/dondre/angular-cli,# Sets base tag href to /myUrl/ in your index.html,,-
https://github.com/dondre/angular-cli,### Bundling,"  All builds make use of bundling, and using the --prod flag in  ng build --prod
or ng serve --prod will also make use of uglifying and tree-shaking functionality.",3
https://github.com/dondre/angular-cli,### Running unit tests,"  ng test Tests will execute after a build is executed via Karma, and it will automatically watch your files for changes. You can run tests a single time via --watch=false or --single-run. You can run tests with coverage via --code-coverage. The coverage report will be in the coverage/ directory. Linting during tests is also available via the --lint flag. See Linting and formatting code chapter for more informations.",3
https://github.com/dondre/angular-cli,### Running end-to-end tests,  ng e2e Before running the tests make sure you are serving the app via ng serve. End-to-end tests are run via Protractor.,3
https://github.com/dondre/angular-cli,### Proxy To Backend,"  Using the proxying support in webpack's dev server we can highjack certain urls and send them to a backend server.
We do this by passing a file to --proxy-config Say we have a server running on http://localhost:3000/api and we want all calls to http://localhost:4200/api to go to that server. We create a file next to projects package.json called proxy.conf.json
with the content {
  ""/api"": {
    ""target"": ""http://localhost:3000"",
    ""secure"": false
  }
} You can read more about what options are available here webpack-dev-server proxy settings and then we edit the package.json file's start script to be ""start"": ""ng serve --proxy-config proxy.conf.json"", now run it with npm start",3
https://github.com/dondre/angular-cli,### Deploying the app via GitHub Pages,"  You can deploy your apps quickly via: ng github-pages:deploy --message ""Optional commit message"" This will do the following: 
creates GitHub repo for the current project if one doesn't exist
rebuilds the app in production mode at the current HEAD
creates a local gh-pages branch if one doesn't exist
moves your app to the gh-pages branch and creates a commit
edit the base tag in index.html to support GitHub Pages
pushes the gh-pages branch to GitHub
returns back to the original HEAD
 Creating the repo requires a token from GitHub, and the remaining functionality
relies on ssh authentication for all git operations that communicate with github.com.
To simplify the authentication, be sure to setup your ssh keys. If you are deploying a user or organization page, you can instead use the following command: ng github-pages:deploy --user-page --message ""Optional commit message"" This command pushes the app to the master branch on the GitHub repo instead
of pushing to gh-pages, since user and organization pages require this.",3
https://github.com/dondre/angular-cli,### Linting and formatting code,"  You can lint your app code by running ng lint.
This will use the lint npm script that in generated projects uses tslint. You can modify the these scripts in package.json to run whatever tool you prefer.",3
https://github.com/dondre/angular-cli,### Commands autocompletion,"  To turn on auto completion use the following commands: For bash: ng completion 1>> ~/.bashrc 2>>&1
source ~/.bashrc For zsh: ng completion 1>> ~/.zshrc 2>>&1
source ~/.zshrc Windows users using gitbash: ng completion 1>> ~/.bash_profile 2>>&1
source ~/.bash_profile",3
https://github.com/dondre/angular-cli,### Project assets,"  You use the assets array in angular-cli.json to list files or folders you want to copy as-is when building your project: ""assets"": [
  ""assets"",
  ""favicon.ico""
]",3
https://github.com/dondre/angular-cli,### Global styles,"  The styles.css file allows users to add global styles and supports
CSS imports. If the project is created with the --style=sass option, this will be a .sass
file instead, and the same applies to scss/less/styl. You can add more global styles via the apps[0].styles property in angular-cli.json.",3
https://github.com/dondre/angular-cli,### CSS Preprocessor integration,"  Angular-CLI supports all major CSS preprocessors: 
sass/scss (http://sass-lang.com/)
less (http://lesscss.org/)
stylus (http://stylus-lang.com/)
 To use these preprocessors simply add the file to your component's styleUrls: @Component({
  selector: 'app-root',
  templateUrl: './app.component.html',
  styleUrls: ['./app.component.scss']
})
export class AppComponent {
  title = 'app works!';
} When generating a new project you can also define which extension you want for
style files: ng new sassy-project --style=sass Or set the default style on an existing project: ng set defaults.styleExt scss",36
https://github.com/dondre/angular-cli,### 3rd Party Library Installation,"  Simply install your library via npm install lib-name --save and import it in your code. If the library does not include typings, you can install them using npm: npm install d3 --save
npm install @types/d3 --save-dev If the library doesn't have typings available at @types/, you can still use it by
manually adding typings for it: 

First, create a typings.d.ts file in your src/ folder. This file will be automatically included as global type definition.


Then, in src/typings.d.ts, add the following code:

 declare module 'typeless-package'; 
Finally, in the component or file that uses the library, add the following code:
 import * as typelessPackage from 'typeless-package';
typelessPackage.method(); Done. Note: you might need or find useful to define more typings for the library that you're trying to use.",3
https://github.com/dondre/angular-cli,### Global Library Installation,"  Some javascript libraries need to be added to the global scope, and loaded as if
they were in a script tag. We can do this using the apps[0].scripts and
apps[0].styles properties of angular-cli.json. As an example, to use Bootstrap 4 this is
what you need to do: First install Bootstrap from npm: npm install bootstrap@next Then add the needed script files to apps[0].scripts: ""scripts"": [
  ""../node_modules/jquery/dist/jquery.js"",
  ""../node_modules/tether/dist/js/tether.js"",
  ""../node_modules/bootstrap/dist/js/bootstrap.js""
], Finally add the Bootstrap CSS to the apps[0].styles array: ""styles"": [
  ""../node_modules/bootstrap/dist/css/bootstrap.css"",
  ""styles.css""
], Restart ng serve if you're running it, and Bootstrap 4 should be working on
your app.",3
https://github.com/dondre/angular-cli,### Updating angular-cli,"  To update angular-cli to a new version, you must update both the global package and your project's local package. Global package: npm uninstall -g angular-cli
npm cache clean
npm install -g angular-cli@latest Local project package: rm -rf node_modules dist # use rmdir on Windows
npm install --save-dev angular-cli@latest
npm install
ng init Running ng init will check for changes in all the auto-generated files created by ng new and allow you to update yours. You are offered four choices for each changed file: y (overwrite), n (don't overwrite), d (show diff between your file and the updated file) and h (help). Carefully read the diffs for each code file, and either accept the changes or incorporate them manually after ng init finishes. The main cause of errors after an update is failing to incorporate these updates into your code. You can find more details about changes between versions in CHANGELOG.md.",36
https://github.com/dondre/angular-cli,## Development Hints for hacking on angular-cli, ,3
https://github.com/dondre/angular-cli,### Working with master,"  git clone https://github.com/angular/angular-cli.git
cd angular-cli
npm link npm link is very similar to npm install -g except that instead of downloading the package
from the repo, the just cloned angular-cli/ folder becomes the global package.
Any changes to the files in the angular-cli/ folder will immediately affect the global angular-cli package,
allowing you to quickly test any changes you make to the cli project. Now you can use angular-cli via the command line: ng new foo
cd foo
npm link angular-cli
ng serve npm link angular-cli is needed because by default the globally installed angular-cli just loads
the local angular-cli from the project which was fetched remotely from npm.
npm link angular-cli symlinks the global angular-cli package to the local angular-cli package.
Now the angular-cli you cloned before is in three places:
The folder you cloned it into, npm's folder where it stores global packages and the angular-cli project you just created. You can also use ng new foo --link-cli to automatically link the angular-cli package. Please read the official npm-link documentation
and the npm-link cheatsheet for more information.",36
https://github.com/dondre/angular-cli,## License,  MIT,5
https://github.com/BrunoBozza/CNTK,# CNTK,,1
https://github.com/BrunoBozza/CNTK,## Latest news,"  2016-03-24. New Text Reader (CNTKTextFormatReader) is available
Read description here https://github.com/Microsoft/CNTK/wiki/CNTKTextFormat-Reader 2016-02-29. Added ZIP files support to the ImageReader
Examples: https://github.com/Microsoft/CNTK/wiki/Image-reader
Updated build steps at https://github.com/Microsoft/CNTK/wiki/Setup-CNTK-on-your-machine See all news.",46
https://github.com/BrunoBozza/CNTK,## What is CNTK,"  CNTK (http://www.cntk.ai/), the Computational Network Toolkit by Microsoft Research, is a unified deep-learning toolkit that describes neural networks as a series of computational steps via a directed graph. In this directed graph, leaf nodes represent input values or network parameters, while other nodes represent matrix operations upon their inputs. CNTK allows to easily realize and combine popular model types such as feed-forward DNNs, convolutional nets (CNNs), and recurrent networks (RNNs/LSTMs). It implements stochastic gradient descent (SGD, error backpropagation) learning with automatic differentiation and parallelization across multiple GPUs and servers. CNTK has been available under an open-source license since April 2015. It is our hope that the community will take advantage of CNTK to share ideas more quickly through the exchange of open source working code. Wiki: Go to the CNTK Wiki for all information on CNTK including setup, examples, etc. License: See LICENSE.md in the root of this repository for the full license information. Tutorial: Microsoft Computational Network Toolkit (CNTK) @ NIPS 2015 Workshops Blogs: 
Microsoft Computational Network Toolkit offers most efficient distributed deep learning computational performance
Microsoft researchers win ImageNet computer vision challenge (December 2015)
",12
https://github.com/BrunoBozza/CNTK,## Performance,"  The figure below compares processing speed (frames processed per second) of CNTK to that of four other well-known toolkits. The configuration uses a fully connected 4-layer neural network (see our benchmark scripts) and an effective mini batch size (8192). All results were obtained on the same hardware with the respective latest public software versions as of Dec 3, 2015. ",1
https://github.com/BrunoBozza/CNTK,## Citation,"  If you used this toolkit or part of it to do your research, please cite the work as: Amit Agarwal, Eldar Akchurin, Chris Basoglu, Guoguo Chen, Scott Cyphers, Jasha Droppo, Adam Eversole, Brian Guenter, Mark Hillebrand, T. Ryan Hoens, Xuedong Huang, Zhiheng Huang, Vladimir Ivanov, Alexey Kamenev, Philipp Kranen, Oleksii Kuchaiev, Wolfgang Manousek, Avner May, Bhaskar Mitra, Olivier Nano, Gaizka Navarro, Alexey Orlov, Hari Parthasarathi, Baolin Peng, Marko Radmilac, Alexey Reznichenko, Frank Seide, Michael L. Seltzer, Malcolm Slaney, Andreas Stolcke, Huaming Wang, Yongqiang Wang, Kaisheng Yao, Dong Yu, Yu Zhang, Geoffrey Zweig (in alphabetical order), ""An Introduction to Computational Networks and the Computational Network Toolkit"", Microsoft Technical Report MSR-TR-2014-112, 2014.",5
https://github.com/BrunoBozza/CNTK,## Disclaimer,  CNTK is in active use at Microsoft and constantly evolving. There will be bugs.,3
https://github.com/pombredanne/cassle,# Introduction," The aim of this work is to try validate each TLS-connection with different techniques that exist nowadays. We are living in a world that everything is connected through internet and to provide security on this connections the majority of them use TLS. But we have seen how some governments use different aproach to circumvent them. Some of this vulnerabilities can be due to bugs in the implementations, bad deployments ... etc, but one of the vulnerability that this work try to resolve is the bad or poor validation of certificates. Before to send our private data to the other entity, usually in TLS, we have to validate the authenticity of the server with the goal to know that it is who claim it is. We have seen how apple failed in this due to the famous goto fail bug  https://www.imperialviolet.org/2014/02/22/applebug.html. Although is true that this vulnerability is because of a bad implementation is true that if apple had provided other techniques this situation could be discovered before. Our goal will be to validate each connection with different techniques because maybe an approach says that our connection is secure but perhaps there is another one that says the opposite providing a better solution.",12
https://github.com/pombredanne/cassle,# Techniques,"  A continuation the list of different techniques that the project is using: 
RFC -standard way- to validate it we are using the library NSS
SSLBlacklist - https://sslbl.abuse.ch/blacklist/
Revoke status - OCSP
DANE
ICSI-NOTARY - http://notary.icsi.berkeley.edu/
Certificate-transparency - http://www.certificate-transparency.org/
Pinning
",1
https://github.com/pombredanne/cassle,# Installation, ,3
https://github.com/pombredanne/cassle,#### Prerequisites,"Python >= 2.7 (www.python.org)
libpcap-python - http://sourceforge.net/projects/pylibpcap/
$ pip install -r requirements.txt
Once installed all packages and before to launch the program we have to set our root certificates. First we have to configure the directory that hold them.

$ mkdir -p ~/.pki/nssdb
$ cd ~/.pki/nssdb
$ certutil -N -d .
I use this but any directory is fine. If you change the directory you have to change the config file and set NSS_DB_DIR. By the default is ""~/.pki/nssdb"". Also we have to set the variable CERTS_DIRin the config file to say where reside our certificates. This project provide the root Mozilla's certificates in the certs folder. Also you should set the log directory LOG_DIR.

$ cd {project}
$ cd utils
$ python nssdb.py --add
In case that you want to remove it from the database

$ python nssdb.py --delete",3
https://github.com/pombredanne/cassle,##,,-
https://github.com/pombredanne/cassle,##,,-
https://github.com/pombredanne/cassle,###### OPTIONAL,"To configure for example a pin, to be protected against attacks to Facebook. The information provide may be fake since by now there is no way to extract such information securely.

$ cd utils
$ python gatherinfo.py -s www.facebook.com -p
[+] PIN
         _id: *.facebook.com
         issuer : DigiCert High Assurance CA-3
                 Base64 of SPKI with sha256: N2E2YWQ4ODI5OGNiYTY1YjE3NmJhM2E3YWIyNWVlOGY5MDYwNDAzM2RhNmE5OGFjMDc5NTlmNTY2ZmEzYWM1NA==
Do you want to include it in the DB (y/n): y
Database updated
Once that everything is ready execute.

$ ./cassle.py -i <interface> -p <port>",3
https://github.com/pombredanne/cassle,# TODO,"  

Add DNSSEC support since by now we do not provide DANE verification


Verify SCT from CT. There is no way to extract the log's public key


We are thinking to write it in golang since is more easy to write concurrent programs thanks to goroutines and channels. We want real time detection. The packages that golang provides offer the majority of all functionality. The application would have less dependencies.

",4
https://github.com/pombredanne/cassle,# State, ,4
https://github.com/pombredanne/cassle,#### WIP,  The project try to study some techniques that exist nowadays to validate the certificate. Some of them are not mature enough and have some limitations. Try your own methodology and change whatever you think.,4
https://github.com/blairanderson/amazon-autocomplete,#Amazon Autocomplete JS Plugin,,13
https://github.com/blairanderson/amazon-autocomplete,##Installation,,3
https://github.com/blairanderson/amazon-autocomplete,##Usage,,3
https://github.com/blairanderson/amazon-autocomplete,##Styling,,3
https://github.com/blairanderson/amazon-autocomplete,##Advanced Usage,,3
https://github.com/blairanderson/amazon-autocomplete,###Configuration,,3
https://github.com/blairanderson/amazon-autocomplete,####`new AmazonAutocomplete([paramsObject])`,,3
https://github.com/blairanderson/amazon-autocomplete,###Events,,3
https://github.com/blairanderson/amazon-autocomplete,###Advanced usage example,,3
https://github.com/blairanderson/amazon-autocomplete,##Features,,1
https://github.com/blairanderson/amazon-autocomplete,##Licence,,5
https://github.com/villanella/hikari-for-Jekyll,# hikari," Hikari is an open-source Jekyll theme perfect for dev-savvy bloggers who wants to get started with Jekyll in a very minimal way. 
SCSS!
Responsive
Lightweight (no JS library has been abused here)
    View demo",12
https://github.com/villanella/hikari-for-Jekyll,### How to install,"  
Clone this repo
Customize _config.yml and replace all dummy posts by yours
Change your profile picture in ~/assets/img/avatar.jpg
Publish (I recommend GitHub Pages, it's free)
",3
https://github.com/villanella/hikari-for-Jekyll,### Development,"  
master for development and pull requests.
gh-pages for the demo page; don't bother.
",3
https://github.com/villanella/hikari-for-Jekyll,#### Running locally,"  

Clone this repo


Install required dependencies with Bundler
 bundle install



Run the site with Jekyll
 bundle exec jekyll serve --watch



Visit the site at http://localhost:4000

",3
https://github.com/villanella/hikari-for-Jekyll,### Author,"  Mathieu Mayer-Mazzoli 
http://m3xm.github.io
http://twitter.com/mx3m
http://www.dribbble.com/m3xm
",5
https://github.com/villanella/hikari-for-Jekyll,### Main Contributors,"  Ross Allen 
https://github.com/ssorallen
 Julien Rousseau 
https://github.com/evarouss
",5
https://github.com/villanella/hikari-for-Jekyll,### License,  Open source. MIT license.,5
https://github.com/RLC22/butter-desktop,# [Butter](https://github.com/butterproject/butter-desktop)," 

 Allow any user to easily watch movies through torrent streaming, without any prerequisites. Visit the project's website at http://butterproject.org. ",16
https://github.com/RLC22/butter-desktop,## Getting Involved,"  Want to report a bug, request a feature, contribute to or translate Butter? Check out our in-depth guide to Contributing to Butter. We need all the help we can get! You can also join our community to keep up-to-date and meet other Butterrs.",7
https://github.com/RLC22/butter-desktop,## Getting Started,"  If you're comfortable getting up and running from a git clone, this method is for you. If you clone the GitHub repository, you will need to build a number of assets using grunt. The master branch which contains the latest release.",3
https://github.com/RLC22/butter-desktop,#### Quickstart:,"  
npm install -g grunt-cli bower
npm install
grunt build
grunt start
 If you encounter trouble with the above method, you can try: 
npm install -g bower grunt-cli (Linux: you may need to run with sudo)
cd desktop
npm install
bower install
grunt lang
grunt nwjs
grunt css
grunt start
 Optionally, you may simply run ./make_butter.sh if you are on a linux or mac based operating system. Full instructions & troubleshooting tips can be found in the Contributing Guide ",3
https://github.com/RLC22/butter-desktop,## Community,"  Keep track of Butter development and community activity. 
Follow Butter on [Twitter] (https://twitter.com/butterproject), [Facebook] (https://www.facebook.com/ButterProjectOrg/) and Google+.
Read and subscribe to The Official Butter Blog.
Join in discussions on the Butter Forum
Connect with us on IRC at #butterproject on freenode (web access)
 ##Screenshots

",5
https://github.com/RLC22/butter-desktop,##Screenshots,,-
https://github.com/RLC22/butter-desktop,## Versioning,"  For transparency and insight into our release cycle, and for striving to maintain backward compatibility, Butter will be maintained according to the Semantic Versioning guidelines as much as possible. Releases will be numbered with the following format: <major>.<minor>.<patch>-<build> Constructed with the following guidelines: 
A new major release indicates a large change where backward compatibility is broken.
A new minor release indicates a normal change that maintains backward compatibility.
A new patch release indicates a bugfix or small change which does not affect compatibility.
A new build release indicates this is a pre-release of the version.
  If you distribute a copy or make a fork of the project, you have to credit this project as the source. This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program.  If not, see http://www.gnu.org/licenses/ .  Copyright (c) 2015 Butter Project - Released under the
GPL v3 license.",4
https://github.com/kevinboudot/silex-cache-service-provider,# Silex Cache Service Provider, The Silex Cache service provider allows you to use several PHP opcode cache in your Silex application.,1
https://github.com/kevinboudot/silex-cache-service-provider,## Installation,"  To enable it, add this dependency to your composer.json file: {
    ""require"": {
        ""moust/silex-cache"": ""~2.0""
    }
}",3
https://github.com/kevinboudot/silex-cache-service-provider,## Parameters,"  
cache.options: Array of cache options.

driver: The cache driver to use. Can be any of: apc, array, file, memcache, memcached, xcache, redis, wincache.
cache_dir: Only relevant for file cache driver, specifies the path to the cache directory
memcache: Only relevant for memcache cache driver, provide the Memcache instance to use. If not defined, a default Memcache object will be instanciated. See the Memcache documentation for additional informations : PHP: Memcache - Manual
memcached: Only relevant for memcached cache driver, provide the Memcached instance to use. If not defined, a default Memcached object will be instanciated. See the Memcached documentation for additional informations : PHP: Memcached - Manual
redis: Only relevant for redis cache driver, provide the Redis instance to use. If not defined, a default Redis object will be instanciated. See the PhpRedis documentation for additional informations : PhpRedis


",3
https://github.com/kevinboudot/silex-cache-service-provider,## Registering,"  $app->register(new Moust\Silex\Provider\CacheServiceProvider(), array(
    'cache.options' => array(
        'driver' => 'apc'
    )
));",3
https://github.com/kevinboudot/silex-cache-service-provider,## Usage,"  The Cache provider provides a cache service. Here is a usage example: // stores a variable
$app['cache']->store('foo', 'bar');
// stores a variable with a 1 minute lifetime
$app['cache']->store('foo', 'bar', 60);
// fetch variable
echo $app['cache']->fetch('foo');
// delete variable
$app['cache']->delete('foo');
// clear all cached variables
$app['cache']->clear();",3
https://github.com/kevinboudot/silex-cache-service-provider,## Using multiple caches,"  The Cache provider can allow access to multiple caches. In order to configure the cache drivers, replace the cache.options with caches.options. caches.options is an array of configurations where keys are cache names and values are options: $app->register(new Moust\Silex\Provider\CacheServiceProvider(), array(
    'caches.options' => array(
        'apc' => array(
            'driver' => 'apc'
        ),
        'filesystem' => array(
            'driver' => 'file',
            'cache_dir' => './temp'
        ),
        'memory' => array(
            'driver' => 'array'
        ),
        'memcache' => array(
            'driver' => 'memcache',
            'memcache' => function () {
                $memcache = new \Memcache;
                $memcache->connect('localhost', 11211);
                return $memcache;
            }
        )
    )
)); The first registered cache is the default and can simply be accessed as you would if there was only one. Given the above configuration, these two lines are equivalent: $app['cache']->store('foo', 'bar');

$app['caches']['apc']->store('foo', 'bar');",3
https://github.com/kevinboudot/silex-cache-service-provider,# Licence,"  Copyright (c) 2014 Quentin Aupetit Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.",5
https://github.com/IvyGongoogle/SeetaFaceLib,## SeetaFaceLib - A Face Image Retrieval System,,1
https://github.com/IvyGongoogle/SeetaFaceLib,### [中文简介](doc/README_Chinese.md),1,1
https://github.com/IvyGongoogle/SeetaFaceLib,## Introduction,  SeetaFaceLib is a face image retrieval system based on SeetaFaceEngine. The GUI of the QT project is designed as follows: ,1
https://github.com/IvyGongoogle/SeetaFaceLib,## Installation,"  The package of the SeetaFaceLib requires SeetaFaceEngine, Falconn and Boost, and it has been tested on Mac OSX. SeetaFaceEngine and Falconn are included in the SeetaFaceLib, so you just need to install Boost. Besides, you need a QT environment to run the QT project.",3
https://github.com/IvyGongoogle/SeetaFaceLib,## Technical,"  
LSH to make fast search
reranking
",2
https://github.com/IvyGongoogle/SeetaFaceLib,## Demo,"  I have made a video demo. If you inerested in this project and want to know the performace of face image retrieval, you can access to the video: Video Demo",3
https://github.com/mcansh/simple-partials-reading-v-000,# Simple Partials,,1
https://github.com/mcansh/simple-partials-reading-v-000,## Objectives,"  
Explain why partials are used
Use Rails's render method to render a partial
Describe how the name of a partial turns into its filename
Reference partials located in an external folder
",1
https://github.com/mcansh/simple-partials-reading-v-000,## Introduction,"  As you know, while coding we are generally trying to not repeat our code. If we see a repeated chunk of code in different methods, we sometimes extract that chunk of code into its own method, which we can then reference in multiple places. We can apply a similar tool to reduce repetition in HTML. Partials are view-level files that only form one part of an HTML page. By using a partial, we can remove repeated pieces of HTML and add better organization to the code in our views. Let's look at an example to see what this means.",1
https://github.com/mcansh/simple-partials-reading-v-000,## Example,"  Before we get started, make sure that you run rake db:seed to seed the database. This will give us some posts and authors. Because we want to focus on partials, you'll notice some hard-coding in the controller. In the posts#create action, we've hard-coded that every new post created is linked to the very first author in the database. OK, let's dive in! This is the code in the posts#new form: <!-- app/views/posts/new.html.erb -->

<%= form_tag posts_path do %>
  <label>Post title:</label><br>
  <%= text_field_tag :title %><br>

  <label>Post Description</label><br>
  <%= text_area_tag :description %><br>

  <%= submit_tag ""Submit Post"" %>
<% end %> And this is the code in the posts#edit form: <!-- app/views/posts/edit.html.erb -->

<h3>Post Form</h3>

<%= form_tag post_path(@post), method: ""put"" do %>
  <label>Post title:</label><br>
  <%= text_field_tag :title %><br>

  <label>Post Description</label><br>
  <%= text_area_tag :description %><br>

  <%= submit_tag ""Submit Post"" %>
<% end %> Except for the first line of the form, the code is pretty much the same! The labels and field tags are the same. All of that duplication is not good in code. Duplication means twice the amount of code to maintain, twice the opportunity for bugs, and two slightly different forms when our interface should be consistent. Instead of duplicating all of that code, we just want to write it once in our partial and call it from both our edit and show views. Here's how: First, let's create a new file in app/views/posts/ called _form.html.erb. To indicate that this file is a partial (and only part of a larger view), an underscore is prefixed to the filename. Second, let's remove the repeated code in app/views/posts/edit.html.erb. The file should look like this: <h3>Post Form</h3>

<%= form_tag post_path(@post), method: ""put"" do %>
<% end %> Note that we left in the non-duplicated code. Now, let's also remove the duplicated code in the app/views/posts/new.html.erb file. The file should look like this: <%= form_tag posts_path do %>
<% end %> We left the code that is unique to each view and removed the duplicated code inside the form_tag blocks. So, now what? It looks like we are missing a bunch of code in our posts/new and posts/edit files. Not to worry –?that's where our partial comes in handy. First, we'll place the duplicated code in a new file called app/views/posts/_form.html.erb. The file should look as follows: <label>Post title:</label><br>
<%= text_field_tag :title %><br>

<label>Post Description</label><br>
<%= text_area_tag :description %><br>

<%= submit_tag ""Submit Post"" %> Next, we need to render the code into the posts/edit and posts/new pages by placing <%= render ""form"" %> where we want the code in the partial to be rendered. Notice that, while the file name of our partial starts with an underscore, when we reference it there is no underscore. Our posts/new file should now look like this: <!-- app/views/posts/new.html.erb -->

<%= form_tag posts_path do %>
 <%= render 'form' %>
<% end %> And our posts/edit file like this: <!-- app/views/posts/edit.html.erb -->

<h3>Post Form</h3>

<%= form_tag post_path(@post), method: ""put"" do %>
  <%= render 'form' %>
<% end %> And that's it –?we're all done! A couple of things to note: 

Notice that, even though the last line of the form (the <% end %> tag) is duplicated code, we didn't move it into the partial. This is because it closes the beginning of the form_tag block, which DOES differ from form to form. We don't want to open our form_tag block in one file and close it in a different file. This is a stylistic point that you will get a feel for over time.


We could have named the partial whatever we wanted to. The only requirements are that it start with an underscore and that references to the partial are made without the underscore. But, just like method names, it's good to make the names of our partials as commonsensical as possible.


We were able to reference the partial by just calling <%= render 'form' %>.  Notice that we didn't specify the folder that the partial lives in, such as <%= render 'posts/form' %>. The reason we didn't need this (even though it would have worked if we had included it) is that both the posts/new and posts/edit files are referencing a partial housed in the same folder in which they reside, app/views/posts. When referencing a partial from a different folder, we must include the folder name as well (e.g., <%= render 'posts/form' %> as opposed to <%= render 'form' %>).

",3
https://github.com/mcansh/simple-partials-reading-v-000,## Rendering a partial from a different folder,"  Let's take a look at our authors/show.html.erb file: <%= @author.name %>
<%= @author.hometown %> And now look at the code in posts/show.html.erb: <%= @post.author.name %>
<%= @post.author.hometown %>

<h1><%= @post.title %></h1>
<p><%= @post.description %></p> See the repetition? In both places, we are using the Author object to call the .name and .hometown methods. The first thing we have to fix is the slight difference between the templates. Let's make the beginning portion of the posts/show template match the authors/show template. <!-- app/views/posts/show.html.erb -->

<%= @author.name %>
<%= @author.hometown %>

<h1><%= @post.title %></h1>
<p><%= @post.description %></p> Then, let's make a new partial called app/views/authors/_author.html.erb and place the repeated code in the file. It should look like the following: <!-- app/views/authors/_author.html.erb -->

<%= @author.name %>
<%= @author.hometown %> Now we can just render this partial in our authors/show page by doing the following: <!-- app/views/authors/show.html.erb -->

<%= render 'author' %> Let's try making the same change to our posts/show page: <!-- app/views/posts/show.html.erb -->

<%= render 'author' %>

<h1><%= @post.title %></h1>
<p><%= @post.description %></p> Uh oh, something went wrong. This won't work because, if we don't specify the partial's parent folder, Rails assumes that the partial lives in the same folder as the view that's calling it. In this case, it looks for a file in the posts directory called _author.html.erb and doesn't find it. We need to tell Rails to go outside the folder by being explicit about the folder and file name that it should render. We can do that by changing the above code to the following: <!-- app/views/posts/show.html.erb -->

<%= render 'authors/author' %>

<h1><%= @post.title %></h1>
<p><%= @post.description %></p> We're almost there! One more problem is that our partial assumes it has access to an instance variable called @author. The partial won't function without it! We'll need to modify the PostsController to have it set that instance variable. Change the posts#show action in the controller to look like the following: # app/controllers/posts_controller.rb

def show
  @post = Post.find(params[:id])
  @author = @post.author
end And now we are done! Great job! View Simple Partials on Learn.co and start learning to code for free.",3
https://github.com/mcansh/simple-partials-reading-v-000,# app/controllers/posts_controller.rb,,3
https://github.com/kentmacdonald2/slack-history-export,# slack-history-export," Command line module to allow you download your slack history.
Supports IM/DM, channels and private groups now, support for multiparty direct message coming soon.",1
https://github.com/kentmacdonald2/slack-history-export,## Installation,"  npm install slack-history-export -g
",3
https://github.com/kentmacdonald2/slack-history-export,## Options,"  Usage: slack-history-export [options]
Options:

  -h, --help               output usage information
  -V, --version            output the version number
  -t, --token <value>      [REQUIRED] Enter your slack token API, you can generate it from here https://api.slack.com/web
  -u, --username [value]   Enter username of the person whose chat history with you you will like to download
  -c, --channel [value]    Enter the name of the channel you will like to download
  -g, --group [value]      Enter the name of the group you will like to download
  -d, --directory [value]  Directory to save generated file
  -f, --filename [value]   Name of generated file. Default is ""<current timestamp><username || channel || group>-slack-history"" e.g '1443378584156-abimbola-slack-history.json'
  -F, --format [value]     Format you want to download the data, supported format is [csv, json], default is 'json'
",3
https://github.com/kentmacdonald2/slack-history-export,## Usage,"  slack-history-export -t ""slack-token-123456abcde"" -u abimbola -F csv
",3
https://github.com/kentmacdonald2/slack-history-export,## Contributing,  Fork and submit pull requests to improve this tool,7
https://github.com/kentmacdonald2/slack-history-export,## Issues/Features requests,"  Yes, there would be bugs or feature requests. Please open an issue here and I would try to reply as soon as possible",6
https://github.com/Scott-O-Brian/docker-node,# Node.js,"  
 The official Node.js docker image, made with love by the node community.",1
https://github.com/Scott-O-Brian/docker-node,## What is Node.js?,"  Node.js is a platform built on Chrome's JavaScript runtime for easily building
fast, scalable network applications. Node.js uses an event-driven, non-blocking
I/O model that makes it lightweight and efficient, perfect for data-intensive
real-time applications that run across distributed devices. See: http://nodejs.org",1
https://github.com/Scott-O-Brian/docker-node,## Usage, ,3
https://github.com/Scott-O-Brian/docker-node,# How to use this image, ,3
https://github.com/Scott-O-Brian/docker-node,## Create a `Dockerfile` in your Node.js app project,"  FROM node:4-onbuild
# replace this with your application's default port
EXPOSE 8888 You can then build and run the Docker image: $ docker build -t my-nodejs-app .
$ docker run -it --rm --name my-running-app my-nodejs-app",3
https://github.com/Scott-O-Brian/docker-node,# replace this with your application's default port,,3
https://github.com/Scott-O-Brian/docker-node,### Notes,"  The image assumes that your application has a file named
package.json listing its
dependencies and defining its start
script. It also assumes that you have a file named .dockerignore otherwise it will copy your local npm modules: node_modules
 We have assembled a Best Practices Guide for those using these images on a daily basis.",3
https://github.com/Scott-O-Brian/docker-node,## Run a single Node.js script,"  For many simple, single file projects, you may find it inconvenient to write a
complete Dockerfile. In such cases, you can run a Node.js script by using the
Node.js Docker image directly: $ docker run -it --rm --name my-running-script -v ""$PWD"":/usr/src/app -w
/usr/src/app node:4 node your-daemon-or-script.js",3
https://github.com/Scott-O-Brian/docker-node,## Verbosity,"  By default the Node.js Docker Image has npm log verbosity set to info instead
of the default warn. This is because of the way Docker is isolated from the
host operating system and you are not guaranteed to be able to retrieve the
npm-debug.log file when npm fails. When npm fails, it writes it's verbose log to a log file inside the container.
If npm fails during an install when building a Docker Image with the docker build command, this log file will become inaccessible when Docker exits. The Docker Working Group have chosen to be overly verbose during a build to
provide an easy audit trail when install fails. If you prefer npm to be less
verbose you can easily reset the verbosity of npm using the following
techniques:",3
https://github.com/Scott-O-Brian/docker-node,### Dockerfile,"  If you create your own Dockerfile which inherits from the node image you can
simply use ENV to override NPM_CONFIG_LOGLEVEL. FROM node
ENV NPM_CONFIG_LOGLEVEL warn
...
",3
https://github.com/Scott-O-Brian/docker-node,### Docker Run,"  If you run the node image using docker run you can use the -e flag to
override NPM_CONFIG_LOGLEVEL. $ docker run -e NPM_CONFIG_LOGLEVEL=warn node ...
",3
https://github.com/Scott-O-Brian/docker-node,### NPM run,"  If you are running npm commands you can use --loglevel to control the
verbosity of the output. $ docker run node npm --loglevel=warn ...
",3
https://github.com/Scott-O-Brian/docker-node,# Image Variants,"  The node images come in many flavors, each designed for a specific use case.",3
https://github.com/Scott-O-Brian/docker-node,## `node:<version>`,"  This is the defacto image. If you are unsure about what your needs are, you
probably want to use this one. It is designed to be used both as a throw away
container (mount your source code and start the container to start your app), as
well as the base to build other images off of. This tag is based off of
buildpack-deps.
buildpack-deps is designed for the average user of docker who has many images
on their system. It, by design, has a large number of extremely common Debian
packages. This reduces the number of packages that images that derive from it
need to install, thus reducing the overall size of all images on your system.",3
https://github.com/Scott-O-Brian/docker-node,## `node:alpine`,"  This image is based on the popular
Alpine Linux project, available in
the alpine official image. Alpine Linux is
much smaller than most distribution base images (~5MB), and thus leads to much
slimmer images in general. This variant is highly recommended when final image size being as small as
possible is desired. The main caveat to note is that it does use
musl libc instead of
glibc and friends, so certain
software might run into issues depending on the depth of their libc
requirements. However, most software doesn't have an issue with this, so this
variant is usually a very safe choice. See
this Hacker News comment thread
for more discussion of the issues that might arise and some pro/con comparisons
of using Alpine-based images. To minimize image size, it's uncommon for additional related tools
(such as git or bash) to be included in Alpine-based images. Using this
image as a base, add the things you need in your own Dockerfile
(see the alpine image description for
examples of how to install packages if you are unfamiliar).",36
https://github.com/Scott-O-Brian/docker-node,## `node:onbuild`,"  This image makes building derivative images easier. For most use cases, creating
a Dockerfile in the base of your project directory with the line FROM node:onbuild will be enough to create a stand-alone image for your project. While the onbuild variant is really useful for ""getting off the ground
running"" (zero to Dockerized in a short period of time), it's not recommended
for long-term usage within a project due to the lack of control over when the
ONBUILD triggers fire (see also
docker/docker#5714,
docker/docker#8240,
docker/docker#11917). Once you've got a handle on how your project functions within Docker, you'll
probably want to adjust your Dockerfile to inherit from a non-onbuild
variant and copy the commands from the onbuild variant Dockerfile (moving
the ONBUILD lines to the end and removing the ONBUILD keywords) into your
own file so that you have tighter control over them and more transparency for
yourself and others looking at your Dockerfile as to what it does. This also
makes it easier to add additional requirements as time goes on (such as
installing more packages before performing the previously-ONBUILD steps). This onbuild variant will only install npm packages according to the
package.json and does not adhere to the npm-shrinkwrap.json (see full
discussion in
nodejs/docker-node#65. Note that npm installs devDependencies by default, which is undesirable if
you're building a production image. To avoid this pass NODE_ENV as a build
argument i.e. docker build --build-arg NODE_ENV=production ?",36
https://github.com/Scott-O-Brian/docker-node,## `node:slim`,"  This image does not contain the common packages contained in the default tag and
only contains the minimal packages needed to run node. Unless you are working
in an environment where only the Node.js image will be deployed and you have
space constraints, we highly recommend using the default image of this
repository.",3
https://github.com/Scott-O-Brian/docker-node,# License,"  License information for
the software contained in this image. License
information for the
Node.js Docker project.",5
https://github.com/Scott-O-Brian/docker-node,# Supported Docker versions,"  This image is officially supported on Docker version 1.9.1. Support for older versions (down to 1.6) is provided on a best-effort basis. Please see the Docker installation
documentation for details on how to
upgrade your Docker daemon.",46
https://github.com/Scott-O-Brian/docker-node,# Governance and Current Members,"  The Node.js Docker Image is governed by the Docker Working Group. See
GOVERNANCE.md
to learn more about the group's structure and CONTRIBUTING.md for guidance
about the expectations for all contributors to this project.",57
https://github.com/Scott-O-Brian/docker-node,## Docker Working Group Members,"  
Christopher Horrell (chorrell)
Hans Kristian Flaatten (starefossen)
Hugues Malphettes (hmalphettes)
John Mitchell (jlmitch5)
Peter Petrov (pesho)
William Blankenship (retrohacker)
",5
https://github.com/Scott-O-Brian/docker-node,## Docker Working Group Collaborators,"  
Mikeal Rogers (mikeal)
Laurent Goderre (LaurentGoderre)
",5
https://github.com/nilaydc/Exploratory-Data-Analysis,## Introduction," This assignment uses data from
the UC Irvine Machine
Learning Repository, a popular repository for machine learning
datasets. In particular, we will be using the ""Individual household
electric power consumption Data Set"" which I have made available on
the course web site: 

Dataset: Electric power consumption [20Mb]


Description: Measurements of electric power consumption in
one household with a one-minute sampling rate over a period of almost
4 years. Different electrical quantities and some sub-metering values
are available.

 The following descriptions of the 9 variables in the dataset are taken
from
the UCI
web site: 
Date: Date in format dd/mm/yyyy 
Time: time in format hh:mm:ss 
Global_active_power: household global minute-averaged active power (in kilowatt) 
Global_reactive_power: household global minute-averaged reactive power (in kilowatt) 
Voltage: minute-averaged voltage (in volt) 
Global_intensity: household global minute-averaged current intensity (in ampere) 
Sub_metering_1: energy sub-metering No. 1 (in watt-hour of active energy). It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered). 
Sub_metering_2: energy sub-metering No. 2 (in watt-hour of active energy). It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light. 
Sub_metering_3: energy sub-metering No. 3 (in watt-hour of active energy). It corresponds to an electric water-heater and an air-conditioner.
",1
https://github.com/nilaydc/Exploratory-Data-Analysis,## Loading the data,"  When loading the dataset into R, please consider the following: 

The dataset has 2,075,259 rows and 9 columns. First
calculate a rough estimate of how much memory the dataset will require
in memory before reading into R. Make sure your computer has enough
memory (most modern computers should be fine).


We will only be using data from the dates 2007-02-01 and
2007-02-02. One alternative is to read the data from just those dates
rather than reading in the entire dataset and subsetting to those
dates.


You may find it useful to convert the Date and Time variables to
Date/Time classes in R using the strptime() and as.Date()
functions.


Note that in this dataset missing values are coded as ?.

",3
https://github.com/nilaydc/Exploratory-Data-Analysis,## Making Plots,"  Our overall goal here is simply to examine how household energy usage
varies over a 2-day period in February, 2007. Your task is to
reconstruct the following plots below, all of which were constructed
using the base plotting system. First you will need to fork and clone the following GitHub repository:
https://github.com/rdpeng/ExData_Plotting1 For each plot you should 

Construct the plot and save it to a PNG file with a width of 480
pixels and a height of 480 pixels.


Name each of the plot files as plot1.png, plot2.png, etc.


Create a separate R code file (plot1.R, plot2.R, etc.) that
constructs the corresponding plot, i.e. code in plot1.R constructs
the plot1.png plot. Your code file should include code for reading
the data so that the plot can be fully reproduced. You should also
include the code that creates the PNG file.


Add the PNG file and R code file to your git repository

 When you are finished with the assignment, push your git repository to
GitHub so that the GitHub version of your repository is up to
date. There should be four PNG files and four R code files. The four plots that you will need to construct are shown below.",3
https://github.com/nilaydc/Exploratory-Data-Analysis,### Plot 1,  ,3
https://github.com/nilaydc/Exploratory-Data-Analysis,### Plot 2,  ,3
https://github.com/nilaydc/Exploratory-Data-Analysis,### Plot 3,  ,3
https://github.com/nilaydc/Exploratory-Data-Analysis,### Plot 4,  ,3
https://github.com/brismuth/fms-endpoint,# FixMyStreet-endpoint," FMS-Endpoint is a simple open source web application for storing problem
reports created by mySociety's FixMyStreet
platform. In fact, as it's an Open311
server, it should be happy accepting any reports submitted over the Open311
API.",1
https://github.com/brismuth/fms-endpoint,## Who needs an FMS-endpoint?,"  
if you're running a FixMyStreet deployment already, you don't necessarily
need a FixMyStreet endpoint!
 FixMyStreet sends reports to the relevant authority/department/council. This
is often accomplished by sending an email, but it's usually best if the report
can be injected directly into the back-end system. These systems can be large
and complex and FixMyStreet can integrate with a growing number of them. The
Open311 standard is used by some third parties to simplify this integration
process. However, if you're using FixMyStreet in an environment where the recipient of
reports has no established back-end database for collecting reports,
FMS-endpoint is a quick solution if you need to get something simple up and
running.",1
https://github.com/brismuth/fms-endpoint,## Installation,"  FixMyStreet-endpoint is written in PHP using the CodeIgniter framework. You
should find it easy to install provided you have access to a webserver and a
database. The code generally expects to be running under an Apache webserver with a
mySQL database. It may be possible change these things if your system
is different -- see the installation documentation: Installation instructions: see documentation/INSTALL.md",3
https://github.com/brismuth/fms-endpoint,## Quickstart,"  If you're familiar with PHP CodePoint (or possibly just PHP!) you might be
able to get things going just by dropping the repository somewhere under your
server root. (In fact, for a super quickstart, set up your webserver so that
web/ is the server root). The FMS-endpoint root page will provide diagnostics even if you've not got the
database running, so try hitting that as soon as you get going. Remember to see documentation/INSTALL.md for details. If the home page seems
OK, try clicking on Main site and logging in as the default out-of-the-box
administrator: 
username: admin@example.com
password: password
 You must to change these values as soon as you're logged in! The root page
will tell you how (until you've done it).",3
https://github.com/brismuth/fms-endpoint,## Licensing,"  The Open311 implementation is nearly all from Philip Ashlock's raw
implementation of Open311 GeoReport v2. See LICENSE.txt but also check in documentation/ for component-specific
licenses.",5
https://github.com/brismuth/fms-endpoint,## About mySociety,"  FMS-endpoint is a mySociety project. This particular project has been made possible with funding from
AusAid, through the
World Bank. Oct-2012__ FMS-endpoint is currently a work-in-progress!
Check https://github.com/mysociety/fms-endpoint for changes.",14
https://github.com/squareteam/yodatra,# Yodatra,      Backend development you shall do. And yodatra you shall use. A minimalistic framework built on top of Sinatra it is. The power of ActiveRecord it gives you and the simplicity of a Sinatra app. And all sort of small helpers.,12
https://github.com/squareteam/yodatra,## Instantly deploy your API,"  Based on your ActiveRecord models an API will be exposed very simply.
For every resource you want to expose, you will need to create a controller that inherits from the Yodatra::ModelsController. For example, given a User model class User < ActiveRecord::Base
# Your model definition
end Creating a controller as simple as class UsersController < Yodatra::ModelsController
  # limit read_scope
  def read_scope
    { only: [:id, :name] }
  end

  # whitelist assignable attributes
  def user_params
    params.permit(:name)
  end
end will expose all these routes: GET /users
 
retrieves all users (attributes exposed are limited by the read_scope method defined in the controller)
 GET /users/:id
 
retrieves a user (attributes exposed are limited by the read_scope method defined in the controller)
 POST /users
 
creates a user (attributes assignable are limited by the user_params method defined in the controller as advised here http://guides.rubyonrails.org/action_controller_overview.html#strong-parameters)
 PUT /users/:id
 
updates a user (attributes assignable are limited by the user_params method defined in the controller as advised here http://guides.rubyonrails.org/action_controller_overview.html#strong-parameters)
 DELETE /users/:id
 
deletes a user
 If your model is referenced by another model (with a has_many, has_one or belongs_to relationship), nested routes are also created for you. And you don't need to worry about the references/joins, they are done automaticaly! For example, imagine a Team model that has many Users class Team < ActiveRecord::Base
  has_many :users
end the following routes will be exposed by the UsersController controller: GET /team/:team_id/users
 GET /team/:team_id/users/:id
 POST /team/:team_id/users
 PUT /team/:team_id/users/:id
 DESTROY /team/:team_id/users/:id
",3
https://github.com/squareteam/yodatra,# Your model definition,,-
https://github.com/squareteam/yodatra,### Note,"  You can disable any of these actions by using the ::disable class method and providing the list of actions you want to disable class UsersController < Yodatra::ModelsController
  disable :read, :update, :delete, :nested_read_all, :nested_delete
end",3
https://github.com/squareteam/yodatra,### Extra,"  You can enable a special ""search"" action by using the ::enable_search_on class method class UsersController < Yodatra::ModelsController
  enable_search_on :name
end",3
https://github.com/squareteam/yodatra,## What it also provides for free,"  
Logger: Logs inside <your_project>/log in an environment named file env.err.log for all errors and env.log only for access logs.
Boot: loads automaticaly all <your_project>/app/models/**/*.rb files and <your_project>/app/controllers/**/*.rb files. Establish a connection with a database by reading the <your_project>/config/database.yml file
 For that create a sinatra app that inherits from Yodatra::Base instead of Sinatra::Base.",2
https://github.com/squareteam/yodatra,## Other useful modules,"  
Throttling: To fight against the dark side, an API throttling you will need. Example: allow only 10 requests/minute per IP:
 use Yodatra::Throttle, {:redis_conf => {}, :rpm => 10} warning: this module requires redis 
ApiFormatter:  this middleware will help you to format all your replies. Example: wrap all you replies within a {data: <...>} object:
 use Yodatra::ApiFormatter do |status, headers, response|
  body = response.empty? ? '' : response.first
  response = [{:data => body}]
  [status, headers, response]
end",3
https://github.com/elsdrium/neural_artistic_style,## Neural Artistic Style in Python,,1
https://github.com/elsdrium/neural_artistic_style,### Requirements, Implementation of A Neural Algorithm of Artistic Style. A method to transfer the style of one image to the subject of another image.,3
https://github.com/elsdrium/neural_artistic_style,### Examples,"  
DeepPy, Deep learning in Python.
CUDArray with cuDNN, CUDA-accelerated NumPy.
Pretrained VGG 19 model, choose imagenet-vgg-verydeep-19.
",3
https://github.com/elsdrium/neural_artistic_style,### Help,"  List command line options with python neural_artistic_style.py --help
",3
https://github.com/Unicamp-OpenPower/alice,# Alice," Alice is a command-line interface for managing Openstack user accounts. It creates a project, user and network configuration which just one line.",1
https://github.com/Unicamp-OpenPower/alice,## Getting Started,  This guide assumes that you have a full running Openstack installation on your server. Alice's stable version runs on Openstack Liberty release under Ubuntu 14.04.,3
https://github.com/Unicamp-OpenPower/alice,### Prerequisities,"  Your server must support Keystone v3, Neutron Client v2 authentication methods, and you should also be able to create a new Postqresql or MariaDB table, since it will be needed to store user data. You can use the same database used by Openstack, but if you run more than 2000 simultaneous connections on MariaDB, it might be safer to use a separate database.",3
https://github.com/Unicamp-OpenPower/alice,### Create database,"  Connect to the database server as the root user: $ mysql -u root -p
 Create alice database: CREATE DATABASE alice;
 Grant access to alice database: GRANT ALL PRIVILEGES ON alice.* TO 'alice'@'localhost' \
  IDENTIFIED BY 'ALICE_DBPASS';
GRANT ALL PRIVILEGES ON alice.* TO 'alice'@'%' \
  IDENTIFIED BY 'ALICE_DBPASS';
 Replacing ALICE_DBPASS with a suitable password.",3
https://github.com/Unicamp-OpenPower/alice,## Install,"  Clone the repository: $ git clone git@github.com:jwnx/alice.git
 Go inside the new folder and run the install script $ cd alice && python setup.py install 
",3
https://github.com/Unicamp-OpenPower/alice,### Configuration,"  First, add DATABASE_URL variable to your admin-openrc.sh. DATABASE_URL=mysql://alice:ALICE_DBPASS@controller/alice 
 In order create user's network configuration, you'll also need to add your external network ID. OS_EXT_NET=<your_ext_network_id>
 Inside the config file, you'll find the standart network, subnet and quota configurations. You can customize it to fit your cloud needs.",3
https://github.com/Unicamp-OpenPower/alice,## Usage,  Bellow we have a list of a few common usages of alice with explanations:,3
https://github.com/Unicamp-OpenPower/alice,### Add new user,"  $ alice add [OPTIONS] NAME EMAIL
 OPTIONS: 
--enable/--disable: Enables or disables user account. This user will not be allowed to login in her/his horizon account.
--expire: Set expiration date
--yes: Disables confirmation
",3
https://github.com/Unicamp-OpenPower/alice,#### Example:,"  $ alice add maria maria@email.com --expire ""12 jan 2017 --yes"" 
",3
https://github.com/Unicamp-OpenPower/alice,### List,"  $ alice list [OPTIONS] [FILTER]
 OPTIONS: 
--hightlight: Hightlights [expired] or [on hold] user accounts.
 FILTERS: {enabled, disabled, active, hold, expired}",3
https://github.com/Unicamp-OpenPower/alice,#### Example:,"   $ alice list enabled --highlight
",3
https://github.com/Unicamp-OpenPower/alice,### Modify,"  $ alice modify ID [ATTRIBUTES]
 Where ID can be name, email or db's ID. Attributes: {name, email, password, project_name, description, enabled, expiration}",3
https://github.com/Unicamp-OpenPower/alice,#### Examples:,"   $ alice modify amanda@mail.com expiration:'in 30d'
 $ alice modify amanda email:amanda@mail.com
 $ alice modify 1 name:amanda enabled:false
",3
https://github.com/Unicamp-OpenPower/alice,### Show,"  $ alice show ID
 Where ID can be name, email or db's ID.",3
https://github.com/Unicamp-OpenPower/alice,#### Examples:,"   $ alice show maria
",3
https://github.com/Unicamp-OpenPower/alice,### Migrate,"  $ alice migrate
 Copies user entries from Openstack to Alice database in order to be managable by Alice. Ignores services, admin and duplicates.",3
https://github.com/Unicamp-OpenPower/alice,## TODO:,"  
Implement full deletion method: includes deleting all user Openstack data.
Integrate mail notification
Add tests
",4
https://github.com/Unicamp-OpenPower/alice,## License,  This project is licensed under the GPL3.0 License.,5
https://github.com/lulupop/sweep,# sweep.js, A JavaScript library for smoother color transitions. Project page lives here.,16
https://github.com/lulupop/sweep,## About,  sweep.js is a small JavaScript library (5kb zipped) that enables proper color transitions through the HSL and HUSL spaces. Ordinary CSS transitions or existing frameworks convert HSL colors to RGB before transitioning. sweep.js addresses this by letting you transition through the color spectrum. I've written an in-depth post about the need for HSL transitions here.,16
https://github.com/lulupop/sweep,## Install,"  bower install -S sweep ...or just download it from here. Sweep's dependencies are bundled; all you have to do is include the script. <script src=""path/to/sweep.js""></script> Sweep is wrapped with UMD, so it'll also work as a module in your system of choice.",3
https://github.com/lulupop/sweep,## Usage,"  Using sweep.js to transition an element's color is easy. Whenever you want to trigger an HSL sweep, call: sweep(target, properties, fromColor, toColor[, options]) 
target - element that you wish to animate
properties - CSS properties that you wish to animate (string or array of strings)
fromColor - initial color before the transition
toColor - final color after the transition
options (optional) - an object that can set the following:

callback - function to be called once the animation finishes
direction - clockwise (1) or counterclockwise (-1)
duration - time (in ms) to complete the animation
space - 'HSL', 'HUSL', or 'RGB'


",3
https://github.com/lulupop/sweep,## Examples,"  Trigger a full color cycle on click: //click

var ex1 = document.querySelector('#ex1');
ex1.addEventListener('click', function() {
  sweep(ex1, 'backgroundColor', '#a8f', '#a8f', {direction: -1, duration: 2000});
}, false); Animate from purple to green on hover: //hover

var ex2 = document.querySelector('#ex2');

ex2.addEventListener('mouseenter', function() {
  sweep(ex2, 'backgroundColor', getStyle(ex2, 'background-color'), '#0fa');
}, false);

ex2.addEventListener('mouseleave', function() {
  sweep(ex2, 'backgroundColor', getStyle(ex2, 'background-color'), '#a8f');
}, false); Licensed under MIT. Created by rileyjshaw.",35
https://github.com/blair34854/AndroidN-ify,# AndroidN-ify, A Xposed module which allows you to use features introduced in Android N on devices running Lollipop and Marshmallow!,1
https://github.com/blair34854/AndroidN-ify,## Important,  Read here to learn about the future of this module!,6
https://github.com/blair34854/AndroidN-ify,### Translating,   You can translate this project on Crowdin: https://crowdin.com/project/android-n-ify,6
https://github.com/blair34854/AndroidN-ify,### Builds,  If you always want to be up to date with the latest code changes: You can find automated builds here: https://ci.paphonb.xyz/jenkins/job/AndroidN-ify/. Note that they may be buggy or crash as they are built every time a commit gets pushed. If you are currently using a stable version from the Xposed repository yon'll have to disable that version before installing a snapshot.,3
https://github.com/blair34854/AndroidN-ify,### Links,  Support thread: http://forum.xda-developers.com/xposed/modules/xposed-android-n-ify-features-t3345091 Module repository: http://repo.xposed.info/module/tk.wasdennnoch.androidn_ify,6
https://github.com/blair34854/AndroidN-ify,### License,"  Copyright 2016 MrWasdennnoch@xda

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
",5
https://github.com/BluesBaka/apples-and-holidays-v-000,# Iterating Over Hashes,,1
https://github.com/BluesBaka/apples-and-holidays-v-000,## Objectives,"  
Iterate over nested, or multidimensional, hashes.
",1
https://github.com/BluesBaka/apples-and-holidays-v-000,## The Holiday Suppliers, ,3
https://github.com/BluesBaka/apples-and-holidays-v-000,### Instructions,"  You have a bunch of decorations for various holidays organized by season. holiday_supplies = {
  :winter => {
    :christmas => [""Lights"", ""Wreath""],
    :new_years => [""Party Hats""]
  },
  :summer => {
    :fourth_of_july => [""Fireworks"", ""BBQ""]
  },
  :fall => {
    :thanksgiving => [""Turkey""]
  },
  :spring => {
    :memorial_day => [""BBQ""]
  }
} Write your methods in lib/holiday.rb; use the comments in each method as guides. 
Write a method that returns the second supply for the Fourth of July. For eg:
 def second_supply_for_fourth_of_july(holiday_supplies)
  holiday_supplies[:summer][:fourth_of_july][1]
end 

Write a method that adds a supply to both Winter holidays.


Write a method that adds a supply to Memorial Day.


Write a method that adds a new holiday and its associated supplies to any season.


Write a method to collect all Winter supplies from all the winter holidays. For eg:

 winter_supplies(holiday_supplies) #=> [""Lights"", ""Wreath"", etc] 

Write a method that uses a loop to list out all the supplies you have for each holiday and the season. Use string manipulation to get your output to match what the test is expecting.


Here are a few helpful tips:

Our hash keys are symbols. We need to convert them into strings. Use the .to_s method on a symbol to convert it into a string.
Look closely at the output string that the test is expecting. You'll notice that it expects holiday names, like ""New Years"", to have both words capitalized. Ruby has a .capitalize method that you can call on a string. But, note:

.capitalize returns the capitalized string but doesn't change the original string. So, when you call on that same string in the future, it isn't capitalized! You can capitalize a string for now and evermore by using the bang operator (!).
You'll need to capitalize both words in a given holiday's name. If you call ""new years"".capitalize!, it will return ""New years"". In order to capitalize both words, you'll need to .split the string into an array and iterate over that array to .capitalize! each word in it. Then, you'll need to .join the array back into a string.
If you're unfamiliar with the methods mentioned above, look them up in the Ruby documentation.




 Example of expected output: Winter:
  Christmas: Lights, Wreath
  New Years: Party Hats
 
Write a method to collect all holidays with ""BBQ"" in the supply array. The method should behave as seen below:
 holidays_with_bbqs(holiday_supplies)
#=> [:fourth_of_july, :memorial_day] Reminder: This is a challenging lab, so remember to use Pry, Google, and the Learn community to help you get the tests passing.",3
https://github.com/BluesBaka/apples-and-holidays-v-000,"#=> [:fourth_of_july, :memorial_day]",,3
https://github.com/BluesBaka/apples-and-holidays-v-000,## Resources,"  
StackOverflow: Accessing Elements of Nested Hashes in Ruby
honeybadger - Advanced Ruby Hash Techniques
 View Iterating Over Hashes on Learn.co and start learning to code for free.",6
https://github.com/umbobabo/component-typography,# component-typography, Provides typography postCSS variables for other components to use.,1
https://github.com/umbobabo/component-typography,# Variables we have around here, ,3
https://github.com/umbobabo/component-typography,## `--fontfamily-display` and `--fontfamily-body`,"  By using var(--fontfamily-display) and var(--fontfamily-body), respectively, you will get a serif (Milo), or a sans-serif font (Halifax), and their respective fallback fonts. By standardizing this we enable future changes to the main sans-serif and serif fonts of the website to be much simpler to perform, besides making it easier to provide font fallbacks.",3
https://github.com/umbobabo/component-typography,## `text-size-step-X`,"  (Where X is a number from -2 to 7) These variables contain a font-size in  ems, incrementing in a modular scale (a Major Second scale, or 1.125). Use these to calculate values for font-size. For example, var(--text-size-step-2) is the value in ems for the font size in the second step of the modular scale.",3
https://github.com/umbobabo/component-typography,## `--text-line-height-Y-on-step-X`,"  (Where X is a number from -2 to 7, and Y is one or two words separated-by-dashes) These variables represent the line height for a combination of font weight, style and size. Values for Y: 
body - Body text
body-bold - Body text, in bold
body-light - Body text, light
display - Display text
display-italic - Display text, italic
 for example, var(--text-line-height-body-bold-on-step-4) is the correct line-height value for body text in bold and in the 4th step of the modular scale.",3
https://github.com/Croydon/restart-my-fox,# Restart My Fox, Download this addon from [addons.mozilla.org] (https://addons.mozilla.org/en-US/firefox/addon/restart-my-fox) Source Code Repository For Restart My Fox Source code released under [MPL 2.0] (https://www.mozilla.org/MPL/2.0/),56
https://github.com/Croydon/restart-my-fox,#### What it does:,"  Adds to appMenu (Legacy) or ToolsMenu or Tool-bar, The Restart Browser menu item or Button that allows
users to easily restart the web browser without losing current open pages.",1
https://github.com/Croydon/restart-my-fox,### About this Add-on:,"  
Allows users to easily restart the web browser.
Keep all open pages.
Great if a plugin has stopped working and a restart is required to re-enable it.
Good when a script on a page causes multiple errors in the browser.
Excellent for when browser ram usage is really high.
 Allows you to clear the browsers fast restart cache.",2
https://github.com/Croydon/restart-my-fox,###  To build (Platform):,"  
Windows: CTRL + SHIFT + B
Linux: CTRL + SHIFT + B
Mac: CMD + SHIFT + B
",3
https://github.com/Croydon/restart-my-fox,#### Task Runner (Visual Studio Code):,"  
Windows: CTRL + SHIFT + P
Linux: CTRL + SHIFT + P
Mac: CMD + SHIFT + P
 


Task
Command
Result




Build
task build
Builds addon *.xpi


",3
https://github.com/Croydon/restart-my-fox,##### You must set the version number in the arguments field of tasks.json when bumping the XPI package version., ,3
https://github.com/Croydon/restart-my-fox,#### Build Notes (Visual Studio Code) (Platform):,"  
Windows: You must have python 2.7 or higher installed to run the build script.
Linux: You must on the build.py set in its properties permissions tab, To allow execution or EACCESS error will ensue.
",3
https://github.com/HPxpat/rdpy,# RDPY [![Build Status](https://travis-ci.org/citronneur/rdpy.svg?branch=dev)](https://travis-ci.org/citronneur/rdpy) [![PyPI version](https://badge.fury.io/py/rdpy.png)](http://badge.fury.io/py/rdpy)," Remote Desktop Protocol in twisted python. RDPY is a pure Python implementation of the Microsoft RDP (Remote Desktop Protocol) protocol (client and server side). RDPY is built over the event driven network engine Twisted. RDPY support standard RDP security layer, RDP over SSL and NLA authentication (through ntlmv2 authentication protocol). RDPY provides the following RDP and VNC binaries : 
RDP Man In The Middle proxy which record session
RDP Honeypot
RDP screenshoter
RDP client
VNC client
VNC screenshoter
RSS Player
",1
https://github.com/HPxpat/rdpy,## Build,"  RDPY is fully implemented in python, except the bitmap decompression algorithm which is implemented in C for performance purposes.",3
https://github.com/HPxpat/rdpy,### Dependencies,"  Dependencies are only needed for pyqt4 binaries : 
rdpy-rdpclient
rdpy-rdpscreenshot
rdpy-vncclient
rdpy-vncscreenshot
rdpy-rssplayer
",3
https://github.com/HPxpat/rdpy,#### Linux,"  Example for Debian based systems : sudo apt-get install python-qt4
",3
https://github.com/HPxpat/rdpy,#### OS X,"  Example for OS X to install PyQt with homebrew $ brew install qt sip pyqt
",3
https://github.com/HPxpat/rdpy,#### Windows,"  


x86
x86_64




PyQt4
PyQt4


PyWin32
PyWin32


",3
https://github.com/HPxpat/rdpy,### Build,"  $ git clone https://github.com/citronneur/rdpy.git rdpy
$ pip install twisted pyopenssl qt4reactor service_identity rsa pyasn1
$ python rdpy/setup.py install
 Or use PIP: $ pip install rdpy
 For virtualenv, you will need to link the qt4 library to it: $ ln -s /usr/lib/python2.7/dist-packages/PyQt4/ $VIRTUAL_ENV/lib/python2.7/site-packages/
$ ln -s /usr/lib/python2.7/dist-packages/sip.so $VIRTUAL_ENV/lib/python2.7/site-packages/
",3
https://github.com/HPxpat/rdpy,## RDPY Binaries,  RDPY comes with some very useful binaries. These binaries are linux and windows compatible.,3
https://github.com/HPxpat/rdpy,### rdpy-rdpclient,"  rdpy-rdpclient is a simple RDP Qt4 client. $ rdpy-rdpclient.py [-u username] [-p password] [-d domain] [-r rss_ouput_file] [...] XXX.XXX.XXX.XXX[:3389]
 You can use rdpy-rdpclient in a Recorder Session Scenario, used in rdpy-rdphoneypot.",3
https://github.com/HPxpat/rdpy,### rdpy-vncclient,"  rdpy-vncclient is a simple VNC Qt4 client . $ rdpy-vncclient.py [-p password] XXX.XXX.XXX.XXX[:5900]
",3
https://github.com/HPxpat/rdpy,### rdpy-rdpscreenshot,"  rdpy-rdpscreenshot saves login screen in file. $ rdpy-rdpscreenshot.py [-w width] [-l height] [-o output_file_path] XXX.XXX.XXX.XXX[:3389]
",3
https://github.com/HPxpat/rdpy,### rdpy-vncscreenshot,"  rdpy-vncscreenshot saves the first screen update in file. $ rdpy-vncscreenshot.py [-p password] [-o output_file_path] XXX.XXX.XXX.XXX[:5900]
",3
https://github.com/HPxpat/rdpy,### rdpy-rdpmitm,"  rdpy-rdpmitm is a RDP proxy allows you to do a Man In The Middle attack on RDP protocol.
Record Session Scenario into rss file which can be replayed by rdpy-rssplayer. $ rdpy-rdpmitm.py -o output_dir [-l listen_port] [-k private_key_file_path] [-c certificate_file_path] [-r (for XP or server 2003 client)] target_host[:target_port]
 Output directory is used to save the rss file with following format (YYYYMMDDHHMMSS_ip_index.rss)
The private key file and the certificate file are classic cryptographic files for SSL connections. The RDP protocol can negotiate its own security layer If one of both parameters are omitted, the server use standard RDP as security layer.",3
https://github.com/HPxpat/rdpy,### rdpy-rdphoneypot,"  rdpy-rdphoneypot is an RDP honey Pot. Use Recorded Session Scenario to replay scenario through RDP Protocol. $ rdpy-rdphoneypot.py [-l listen_port] [-k private_key_file_path] [-c certificate_file_path] rss_file_path_1 ... rss_file_path_N
 The private key file and the certificate file are classic cryptographic files for SSL connections. The RDP protocol can negotiate its own security layer. If one of both parameters are omitted, the server use standard RDP as security layer.
You can specify more than one files to match more common screen size.",3
https://github.com/HPxpat/rdpy,### rdpy-rssplayer,"  rdpy-rssplayer is use to replay Record Session Scenario (rss) files generates by either rdpy-rdpmitm or rdpy-rdpclient binaries. $ rdpy-rssplayer.py rss_file_path
",3
https://github.com/HPxpat/rdpy,## RDPY Qt Widget,"  RDPY can also be used as Qt widget through rdpy.ui.qt4.QRemoteDesktop class. It can be embedded in your own Qt application. qt4reactor must be used in your app for Twisted and Qt to work together. For more details, see sources of rdpy-rdpclient.",3
https://github.com/HPxpat/rdpy,## RDPY library,  In a nutshell RDPY can be used as a protocol library with a twisted engine.,3
https://github.com/HPxpat/rdpy,### Simple RDP Client,"  from rdpy.protocol.rdp import rdp

class MyRDPFactory(rdp.ClientFactory):

    def clientConnectionLost(self, connector, reason):
        reactor.stop()

    def clientConnectionFailed(self, connector, reason):
        reactor.stop()

    def buildObserver(self, controller, addr):

        class MyObserver(rdp.RDPClientObserver):

            def onReady(self):
                """"""
                @summary: Call when stack is ready
                """"""
                #send 'r' key
                self._controller.sendKeyEventUnicode(ord(unicode(""r"".toUtf8(), encoding=""UTF-8"")), True)
                #mouse move and click at pixel 200x200
                self._controller.sendPointerEvent(200, 200, 1, true)

            def onUpdate(self, destLeft, destTop, destRight, destBottom, width, height, bitsPerPixel, isCompress, data):
                """"""
                @summary: Notify bitmap update
                @param destLeft: xmin position
                @param destTop: ymin position
                @param destRight: xmax position because RDP can send bitmap with padding
                @param destBottom: ymax position because RDP can send bitmap with padding
                @param width: width of bitmap
                @param height: height of bitmap
                @param bitsPerPixel: number of bit per pixel
                @param isCompress: use RLE compression
                @param data: bitmap data
                """"""
                
            def onSessionReady(self):
		        """"""
		        @summary: Windows session is ready
		        """"""

            def onClose(self):
                """"""
                @summary: Call when stack is close
                """"""

        return MyObserver(controller)

from twisted.internet import reactor
reactor.connectTCP(""XXX.XXX.XXX.XXX"", 3389, MyRDPFactory())
reactor.run()",3
https://github.com/HPxpat/rdpy,### Simple RDP Server,"  from rdpy.protocol.rdp import rdp

class MyRDPFactory(rdp.ServerFactory):

    def buildObserver(self, controller, addr):

        class MyObserver(rdp.RDPServerObserver):

            def onReady(self):
                """"""
                @summary: Call when server is ready
                to send and receive messages
                """"""

            def onKeyEventScancode(self, code, isPressed):
                """"""
                @summary: Event call when a keyboard event is catch in scan code format
                @param code: scan code of key
                @param isPressed: True if key is down
                @see: rdp.RDPServerObserver.onKeyEventScancode
                """"""

            def onKeyEventUnicode(self, code, isPressed):
                """"""
                @summary: Event call when a keyboard event is catch in unicode format
                @param code: unicode of key
                @param isPressed: True if key is down
                @see: rdp.RDPServerObserver.onKeyEventUnicode
                """"""

            def onPointerEvent(self, x, y, button, isPressed):
                """"""
                @summary: Event call on mouse event
                @param x: x position
                @param y: y position
                @param button: 1, 2 or 3 button
                @param isPressed: True if mouse button is pressed
                @see: rdp.RDPServerObserver.onPointerEvent
                """"""

            def onClose(self):
                """"""
                @summary: Call when human client close connection
                @see: rdp.RDPServerObserver.onClose
                """"""

        return MyObserver(controller)

from twisted.internet import reactor
reactor.listenTCP(3389, MyRDPFactory())
reactor.run()",3
https://github.com/HPxpat/rdpy,### Simple VNC Client,"  from rdpy.protocol.rfb import rfb

class MyRFBFactory(rfb.ClientFactory):

    def clientConnectionLost(self, connector, reason):
        reactor.stop()

    def clientConnectionFailed(self, connector, reason):
        reactor.stop()

    def buildObserver(self, controller, addr):
        class MyObserver(rfb.RFBClientObserver):

            def onReady(self):
                """"""
                @summary: Event when network stack is ready to receive or send event
                """"""

            def onUpdate(self, width, height, x, y, pixelFormat, encoding, data):
                """"""
                @summary: Implement RFBClientObserver interface
                @param width: width of new image
                @param height: height of new image
                @param x: x position of new image
                @param y: y position of new image
                @param pixelFormat: pixefFormat structure in rfb.message.PixelFormat
                @param encoding: encoding type rfb.message.Encoding
                @param data: image data in accordance with pixel format and encoding
                """"""

            def onCutText(self, text):
                """"""
                @summary: event when server send cut text event
                @param text: text received
                """"""

            def onBell(self):
                """"""
                @summary: event when server send biiip
                """"""

            def onClose(self):
                """"""
                @summary: Call when stack is close
                """"""

        return MyObserver(controller)

from twisted.internet import reactor
reactor.connectTCP(""XXX.XXX.XXX.XXX"", 3389, MyRFBFactory())
reactor.run()",3
https://github.com/xwipeoutx/EnumGenie,# EnumGenie,  Master  CI Generate enums matching your C# enums. Comes with generators for TypeScript.,1
https://github.com/xwipeoutx/EnumGenie,## Installation,"  EnumGenie is a nuget! Crazy, I know.     dotnet add package EnumGenie.TypeScript",3
https://github.com/xwipeoutx/EnumGenie,## Documentation,  See the wiki,6
https://github.com/xwipeoutx/EnumGenie,## Usage,"  See EnumGenie.Sample project for a ...umm... sample. Crazy. using EnumGenie.Filters;
using EnumGenie.Sample.Enums;
using EnumGenie.Sources;
using EnumGenie.Transforms;
using EnumGenie.TypeScript;
using EnumGenie.Writers;

namespace EnumGenie.Sample
{
    public static class Program
    {
        public static void Main()
        {
            var genie = new EnumGenie()
                .SourceFrom.Assembly(typeof(Program).Assembly)
                .FilterBy.Predicate(t => t != typeof(Ignored))
                .TransformBy.RenamingEnum(def => def.Name.Replace(""StripThisOut"", """"))
                .WriteTo.Console(cfg => cfg.TypeScript(ts => ts.Declaration().Description().Descriptor()))
                .WriteTo.File(""./TypeScript/enums.ts"", cfg => cfg.TypeScript(ts => ts.Declaration().Description().Descriptor()));

            genie.Write();
        }
    }
}",36
https://github.com/xwipeoutx/EnumGenie,## Common Mistakes, ,3
https://github.com/xwipeoutx/EnumGenie,### Nothing is being output!,"  Ensure you are calling .Write() at the end.  This is where the work is done, the rest is just configuration.",6
https://github.com/kuyun-zhangyang/caffe,# Caffe," Caffe is a deep learning framework made with expression, speed, and modularity in mind.
It is developed by the Berkeley Vision and Learning Center (BVLC) and community contributors. Check out the project site for all the details like 
DIY Deep Learning for Vision with Caffe
Tutorial Documentation
BVLC reference models and the community model zoo
Installation instructions
 and step-by-step examples.  Please join the caffe-users group or gitter chat to ask questions and talk about methods and models.
Framework development discussions and thorough bug reports are collected on Issues. Happy brewing!",16
https://github.com/kuyun-zhangyang/caffe,## License and Citation,"  Caffe is released under the BSD 2-Clause license.
The BVLC reference models are released for unrestricted use. Please cite Caffe in your publications if it helps your research: @article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}
",5
https://github.com/ufirstgroup/jquery-handsontable,# Handsontable [![Build Status](https://travis-ci.org/handsontable/jquery-handsontable.png?branch=master)](https://travis-ci.org/handsontable/jquery-handsontable)," Handsontable is a minimal approach to Excel-like table editor in HTML & jQuery. Requires jQuery 1.9+ or 2.0+ (may work with 1.7+ too, but there are known issues with IE10). Runs in IE 8-11, Firefox, Chrome, Safari and Opera. See the demos at http://handsontable.com/ or fork the example on JSFiddle.",136
https://github.com/ufirstgroup/jquery-handsontable,## Usage,"  First, include all the dependencies. All the files that you need (apart from jQuery) are in the dist\ directory: <script src=""../lib/jquery.min.js""></script>
<script src=""dist/jquery.handsontable.full.js""></script>
<link rel=""stylesheet"" media=""screen"" href=""dist/jquery.handsontable.full.css""> Then, run handsontable() constructor on an empty div. After that, load some data if you wish: <div id=""dataTable""></div>
<script>
  var data = [
    ["""", ""Kia"", ""Nissan"", ""Toyota"", ""Honda""],
    [""2008"", 10, 11, 12, 13],
    [""2009"", 20, 11, 14, 13],
    [""2010"", 30, 15, 12, 13]
  ];
  $(""#dataTable"").handsontable({
    data: data,
    startRows: 6,
    startCols: 8
  });
</script>",3
https://github.com/ufirstgroup/jquery-handsontable,## API Reference,"  Check out the new wiki pages: Options, Methods and Events",6
https://github.com/ufirstgroup/jquery-handsontable,## Changelog,"  To see the list of recent changes, see Releases.",4
https://github.com/ufirstgroup/jquery-handsontable,## Questions,  Please use the 🆕 Handsontable Google Group for posting general Questions. Make sure the question was not answered before in FAQ or GitHub Issues,56
https://github.com/ufirstgroup/jquery-handsontable,## Reporting bugs and feature requests,"  Please follow this guidelines when reporting bugs and feature requests: 
Use GitHub Issues board to report bugs and feature requests (not my email address)
Please always write steps to reporoduce the error. That way we can focus on fixing the bug, not scratching our heads trying to reproduce it.
If possible, please add a JSFiddle link that shows the problem (start by forking this fiddle). It saves me much time.
If you can't reproduce it on JSFiddle, please add a screenshot that shows the problem. JSFiddle is much more appreciated because it lets me start fixing straight away.
 Thanks for understanding!",6
https://github.com/ufirstgroup/jquery-handsontable,## Contributing,  Please see CONTRIBUTING.md,7
https://github.com/ufirstgroup/jquery-handsontable,## Similar projects,"  I want to stay motivated to keep Handsontable the best possible editable datagrid on the Web. Therefore, I invite you to check out alternative projects. I would love to receive feedback if you would like to import some of their features to Handsontable. 
DataTables
SlickGrid
jqGrid
jTable
jui_datagrid
ParamQuery
Ember Table
Backgrid.js
dgrid
",6
https://github.com/ufirstgroup/jquery-handsontable,## License,  The MIT License (see the LICENSE file for the full text),5
https://github.com/grandamp/locust-swarm,# Swarm for Locust.io, This is a clone of https://github.com/gleicon/locust-swarm/ Ansible AWS Provisioning for Locust.io Distributed load testing. There will be one Master VM and a number of slave VMs,1
https://github.com/grandamp/locust-swarm,## AWS,"  - Depends on Ansible and boto
	$ sudo pip install ansible
	$ sudo pip install boto
- Ships with ec2.py and ec2.ini from ansible. you probably want to check [this doc and update](http://docs.ansible.com/intro_dynamic_inventory.html)
- Export credentials
	$ export AWS_ACCESS_KEY_ID=<aws access key id>
	$ export AWS_SECRET_ACCESS_KEY=<aws secret access key>
- Disable host key checking 
	$ export ANSIBLE_HOST_KEY_CHECKING=False

- At AWS, take note of your VPC id, subnet id, IP block assigned to this subnet and the key name you will be using.
- Each region may have distinct AMI ids for Ubuntu 14.04 64 bits (trusty)
- Configure group_vars/all with your data
- slave_count is the number of slave VMs
- test_host is the target host you will be testing (base host, not full URL)
	ssh_key_name: aws_devel
	aws_region: us-east-1
	ami_id: ami-9eaa1cf6
	instance_type: t2.micro
	vpc_id: vpc-ffffffff
	subnet_id: subnet-ffffffff
	slave_count: 3
	cidr_ip: 10.0.0.0/16
		test_host: ""https://google.com""

$ ansible-playbook -i aws_hosts.ini locust.yml --private-key ~/.ssh/aws_devel.pem
- aws_devel.pem is your public key, the same referred in the file above
- aws_hosts.ini file containing
	[local]
	localhost

- use EC2 panel to remove servers or $ ansible-playbook -i ./ec2.py remove_servers.yml
",3
https://github.com/grandamp/locust-swarm,## Testing agent,"  The testing agent is agent.py, copied into templates/ dir of locust role. If you use run.sh it will do it for you",3
https://github.com/grandamp/locust-swarm,## Target host,  The target host is configured at locust.yml variable test_host,3
https://github.com/grandamp/locust-swarm,## Master,  Access the master VM using http://ip:8089,3
https://github.com/wieweb/CountingView,# CountingView,"Inspired by UICountingLabel this is a swift version of an animated counting label.
",1
https://github.com/wieweb/CountingView,##Usage,"To start the counting animation just call startCounting

label.startCounting(destinationValue: 100)

// with all available properties
label.startCounting(0,
		destinationValue: 1000,
      	duration: 3,
          method: .Linear,
	       progress: { value in
   		   	print(value)
      	},
      	completion: {
      		print(""complete"")
    	})",3
https://github.com/wieweb/CountingView,### Format,"  By setting format you can also add a text. label.format = ""%@ Value""
 Alternatively you can provide a NSNumberFormatter to define the format of the animated number.     let formatter = NSNumberFormatter()
    formatter.minimumIntegerDigits = 5
    formatter.maximumFractionDigits = 0;
    formatter.numberStyle = .DecimalStyle
    formatter.groupingSeparator = "".""
    
    linealLabel.numberFormatter = formatter
",3
https://github.com/wieweb/CountingView,### Custom AnimatedView,"  If you want to create your own animated views use the CountAnimatorclass. let animator = CountAnimator(startValue: startValue, destinationValue: destinationValue, duration: duration, method: method)

animator.startCount({ value in
	if let formatedValue = self.numberFormatter.stringFromNumber(value) {
		self.text = String.localizedStringWithFormat(self.format, formatedValue)
		if let progress = progress {
			progress(value: value)
		}
	}
}, completion: {
	if let completion = completion {
		completion()
	}
})
 This class also provide startCount with a progressand completionclosure.",3
https://github.com/wieweb/CountingView,## Installation, ,3
https://github.com/wieweb/CountingView,#### Carthage,"  Add the following line to your Cartfile. ####Swift 2.3 github ""wieweb/CountingView"" ~> 1.1
 ####Swift 3.0 github ""wieweb/CountingView"" ""swift3.0""
 Then run carthage update.",3
https://github.com/wieweb/CountingView,####Swift 2.3,,3
https://github.com/wieweb/CountingView,####Swift 3.0,,3
https://github.com/wieweb/CountingView,#### Manually,  Just drag and drop the two .swift files in the CountingView folder into your project.,3
https://github.com/wieweb/CountingView,## Todo,"  
Counting Button
",4
https://github.com/mhm956/gala,## GALA,,1
https://github.com/mhm956/gala,#### Google Automated Language Assistant,  Goal: To build a voice controlled personal assistant using API.AI,1
https://github.com/mhm956/gala,#### Setup Automated,"  cd $PROJECT_DIR
./install.sh (you will need root permissions)",3
https://github.com/mhm956/gala,#### Setup Manual,"  Pre-build -- TODO: Make instruction on setting up user accounts for amazon and google 
Install API.AI
 $ sudo apt install python-pyaudio python-numpy
$ sudo pip install apiai

TODO: Add step to place client key
 
Install phue
 $ sudo pip install phue
 
Install Google Cloud client library
 $ sudo pip install --upgrade google-cloud-speech
 
Install Sonus
 $ sudo apt install sox libsox-fmt-all
$ curl -sL https://deb.nodesource.com/setup_6.x | sudo -E bash -
$ sudo apt install nodejs
$ sudo npm install npm --global
$ npm install --save sonus
 
Install Google Cloud SDK
 $ export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)""
$ echo ""deb https://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
$ curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
$ sudo apt-get update && sudo apt-get install google-cloud-sdk
$ sudo apt-get install google-cloud-sdk-app-engine-python google-cloud-sdk-app-engine-java
$ gcloud init
 
Install Amazon Polly
Replace USER_NAME with your own.
 sudo pip install awscli --upgrade --user USER_NAME
sudo pip install boto
 

Edit ~/.aconfig
TODO


Install Google Maps

 pip install googlemaps
pip install --upgrade google-api-python-client
 
Google Calendar
 pip install pytz
 
Download the OAUTH Key from Google's credential page.
Save the JSON to your working directory.
Run the calandar_example in the same directory as the JSON file
-- This only has to be done once on a new machine because the security is saved.
",3
https://github.com/agomezf/ProgrammingAssignment2,### Introduction," This second programming assignment will require you to write an R
function that is able to cache potentially time-consuming computations.
For example, taking the mean of a numeric vector is typically a fast
operation. However, for a very long vector, it may take too long to
compute the mean, especially if it has to be computed repeatedly (e.g.
in a loop). If the contents of a vector are not changing, it may make
sense to cache the value of the mean so that when we need it again, it
can be looked up in the cache rather than recomputed. In this
Programming Assignment you will take advantage of the scoping rules of
the R language and how they can be manipulated to preserve state inside
of an R object.",12
https://github.com/agomezf/ProgrammingAssignment2,### Example: Caching the Mean of a Vector,"  In this example we introduce the <<- operator which can be used to
assign a value to an object in an environment that is different from the
current environment. Below are two functions that are used to create a
special object that stores a numeric vector and caches its mean. The first function, makeVector creates a special ""vector"", which is
really a list containing a function to 
set the value of the vector
get the value of the vector
set the value of the mean
get the value of the mean
 makeVector <- function(x = numeric()) {
        m <- NULL
        set <- function(y) {
                x <<- y
                m <<- NULL
        }
        get <- function() x
        setmean <- function(mean) m <<- mean
        getmean <- function() m
        list(set = set, get = get,
             setmean = setmean,
             getmean = getmean)
}
 The following function calculates the mean of the special ""vector""
created with the above function. However, it first checks to see if the
mean has already been calculated. If so, it gets the mean from the
cache and skips the computation. Otherwise, it calculates the mean of
the data and sets the value of the mean in the cache via the setmean
function. cachemean <- function(x, ...) {
        m <- x$getmean()
        if(!is.null(m)) {
                message(""getting cached data"")
                return(m)
        }
        data <- x$get()
        m <- mean(data, ...)
        x$setmean(m)
        m
}
",3
https://github.com/agomezf/ProgrammingAssignment2,### Assignment: Caching the Inverse of a Matrix,"  Matrix inversion is usually a costly computation and there may be some
benefit to caching the inverse of a matrix rather than computing it
repeatedly (there are also alternatives to matrix inversion that we will
not discuss here). Your assignment is to write a pair of functions that
cache the inverse of a matrix. Write the following functions: 
makeCacheMatrix: This function creates a special ""matrix"" object
that can cache its inverse.
cacheSolve: This function computes the inverse of the special
""matrix"" returned by makeCacheMatrix above. If the inverse has
already been calculated (and the matrix has not changed), then
cacheSolve should retrieve the inverse from the cache.
 Computing the inverse of a square matrix can be done with the solve
function in R. For example, if X is a square invertible matrix, then
solve(X) returns its inverse. For this assignment, assume that the matrix supplied is always
invertible. In order to complete this assignment, you must do the following: 
Fork the GitHub repository containing the stub R files at
https://github.com/rdpeng/ProgrammingAssignment2
to create a copy under your own account.
Clone your forked GitHub repository to your computer so that you can
edit the files locally on your own machine.
Edit the R file contained in the git repository and place your
solution in that file (please do not rename the file).
Commit your completed R file into YOUR git repository and push your
git branch to the GitHub repository under your account.
Submit to Coursera the URL to your GitHub repository that contains
the completed R code for the assignment.
",3
https://github.com/agomezf/ProgrammingAssignment2,### Grading,  This assignment will be graded via peer assessment.,3
https://github.com/k0mrade/buntdb-optimization,# buntdb-optimization," search optimal key:value structure for buntdb IndexString improvement IndexString time is reduced from 32.485058468s to 26.732144865s.
The index is based on 1628953 rows. Before commit 823e2ea1467b2a65f30f8f8469f00c7c29317dd3 bash-3.2$ go run bunt-optimization.go
Reading Bunt database --> 10.118220838s
String index AD000007 creation time --> 32.485058468s
String index AD000008 creation time --> 4.319463065s
Indexes list --> [AD000007 AD000008]
Reading 1843230 rows from BuntDB was --> 1.968400782s
Reading 1628953 rows from index AD000007 was --> 1.270601993s
Reading 214277 rows from index AD000008 was --> 141.407204ms After commit 823e2ea1467b2a65f30f8f8469f00c7c29317dd3 bash-3.2$ go run bunt-optimization.go
Reading Bunt database --> 8.927277245s
String index AD000007 creation time --> 26.732144865s
String index AD000008 creation time --> 4.213542682s
Indexes list --> [AD000007 AD000008]
Reading 1843230 rows from BuntDB was --> 1.68400849s
Reading 1628953 rows from index AD000007 was --> 1.343550111s
Reading 214277 rows from index AD000008 was --> 217.864232ms",1
https://github.com/UniversityProjects/FEM1,# FEM I," Finite Element Methods For Elliptic Problems Uses the Matlab languages for the finite element implementation. Uses the C library triangle https://www.cs.cmu.edu/~quake/triangle.html for 2D mesh generation.  Lab Session 1 
Starting with the triangle library in Matlab.
Mesh Creation.
Mesh Acquisition In Matlab.
Mesh Drawing In Matlab.
Triangles Count In Plot.
Vertex Count In Plot.
  Lab Session 2 -div(grad u) = f 	on omega u = g 			    on omega's border First Order Elements 
KhTs Matrices Computation.
General Kh Matrix Computation (Memorized as a sparse matrix).
fhT Elements With Trapezoid And Barycenter Methods.
Fh Array Computation.
Border Condition Implementation.
Solution Computation.
Solution Plot.
Example with f = 1 and g = 0.
  Lab Session 3 -div(c grad u) = f 	on omega u = g 	on omega's border First Order Elements 
Added General Diffusion Term c(x,y)
c = 1
c = 2 + x + sin(3y)
Added Neumann Conditions.
Discontinuous c(x,y) Example (With Mesh That Follows The Discontinuity).
Added Exact Solution Confront.
Added An Order 2 Formula For Numerical Integration.
 -div(c grad u) + alpha*u = f 	on omega u = g 	on omega's border 
Added general reaction term alpha.
  Lab Session 4 -div(c grad u) = f 	on omega Second Order Elements PART I 
Added mesh details for finite elements of order K = 2.
(See http://arxiv.org/abs/math/0501496v2 for quadrature formula)
Added KE partial coefficients matrix computation.
 PART II 
Added Full Kh matrix Computation
Added FE partial coeficients array computation.
Added full Fh coeficients array computation.
Added NonHomogeneous Dirichlet conditions.
Added uh approximated solution computation.
Uh plot using only vertices info.
  Lab Session 5 -div(c grad u) = f 	on omega Second Order Elements 
Plot using edge info.
Added uniform mesh generator.
Added exact solution plot.
L2 error.
Added makeue.
Added quadrature formula for degree=3.
  Exam Project -div(c grad u) + beta grad u + alpha u = f 	on omega Second Order Elements 
Added transport term: beta grad u.
Added reaction term: alpha u.
",1
https://github.com/rramona2/JavaScript-Templates,# JavaScript Templates,,1
https://github.com/rramona2/JavaScript-Templates,## Demo,  JavaScript Templates Demo,3
https://github.com/rramona2/JavaScript-Templates,## Description,"  1KB lightweight, fast & powerful JavaScript templating engine with zero
dependencies. Compatible with server-side environments like Node.js, module
loaders like RequireJS, Browserify or webpack and all web browsers.",1
https://github.com/rramona2/JavaScript-Templates,## Usage, ,3
https://github.com/rramona2/JavaScript-Templates,### Client-side,"  Include the (minified) JavaScript Templates script in your HTML markup: <script src=""js/tmpl.min.js""></script> Add a script section with type ""text/x-tmpl"", a unique id property and
your template definition as content: <script type=""text/x-tmpl"" id=""tmpl-demo"">
<h3>{%=o.title%}</h3>
<p>Released under the
<a href=""{%=o.license.url%}"">{%=o.license.name%}</a>.</p>
<h4>Features</h4>
<ul>
{% for (var i=0; i<o.features.length; i++) { %}
    <li>{%=o.features[i]%}</li>
{% } %}
</ul>
</script> ""o"" (the lowercase letter) is a reference to the data parameter of the
template function (see the API section on how to modify this identifier). In your application code, create a JavaScript object to use as data for the
template: var data = {
    ""title"": ""JavaScript Templates"",
    ""license"": {
        ""name"": ""MIT license"",
        ""url"": ""http://www.opensource.org/licenses/MIT""
    },
    ""features"": [
        ""lightweight & fast"",
        ""powerful"",
        ""zero dependencies""
    ]
}; In a real application, this data could be the result of retrieving a
JSON resource. Render the result by calling the tmpl() method with the id of the template
and the data object as arguments: document.getElementById(""result"").innerHTML = tmpl(""tmpl-demo"", data);",3
https://github.com/rramona2/JavaScript-Templates,### Server-side,"  The following is an example how to use the JavaScript Templates engine on the
server-side with node.js. Create a new directory and add the tmpl.js file. Or alternatively, install
the blueimp-tmpl package with npm: npm install blueimp-tmpl Add a file template.html with the following content: <!DOCTYPE HTML>
<title>{%=o.title%}</title>
<h3><a href=""{%=o.url%}"">{%=o.title%}</a></h3>
<h4>Features</h4>
<ul>
{% for (var i=0; i<o.features.length; i++) { %}
    <li>{%=o.features[i]%}</li>
{% } %}
</ul> Add a file server.js with the following content: require(""http"").createServer(function (req, res) {
    var fs = require(""fs""),
        // The tmpl module exports the tmpl() function:
        tmpl = require(""./tmpl""),
        // Use the following version if you installed the package with npm:
        // tmpl = require(""blueimp-tmpl""),
        // Sample data:
        data = {
            ""title"": ""JavaScript Templates"",
            ""url"": ""https://github.com/blueimp/JavaScript-Templates"",
            ""features"": [
                ""lightweight & fast"",
                ""powerful"",
                ""zero dependencies""
            ]
        };
    // Override the template loading method:
    tmpl.load = function (id) {
        var filename = id + "".html"";
        console.log(""Loading "" + filename);
        return fs.readFileSync(filename, ""utf8"");
    };
    res.writeHead(200, {""Content-Type"": ""text/x-tmpl""});
    // Render the content:
    res.end(tmpl(""template"", data));
}).listen(8080, ""localhost"");
console.log(""Server running at http://localhost:8080/""); Run the application with the following command: node server.js",3
https://github.com/rramona2/JavaScript-Templates,## Requirements,  The JavaScript Templates script has zero dependencies.,3
https://github.com/rramona2/JavaScript-Templates,## API, ,36
https://github.com/rramona2/JavaScript-Templates,### tmpl() function,"  The tmpl() function is added to the global window object and can be
called as global function: var result = tmpl(""tmpl-demo"", data); The tmpl() function can be called with the id of a template, or with a
template string: var result = tmpl(""<h3>{%=o.title%}</h3>"", data); If called without second argument, tmpl() returns a reusable template
function: var func = tmpl(""<h3>{%=o.title%}</h3>"");
document.getElementById(""result"").innerHTML = func(data);",36
https://github.com/rramona2/JavaScript-Templates,### Templates cache,"  Templates loaded by id are cached in the map tmpl.cache: var func = tmpl(""tmpl-demo""), // Loads and parses the template
    cached = typeof tmpl.cache[""tmpl-demo""] === ""function"", // true
    result = tmpl(""tmpl-demo"", data); // Uses cached template function

tmpl.cache[""tmpl-demo""] = null;
result = tmpl(""tmpl-demo"", data); // Loads and parses the template again",36
https://github.com/rramona2/JavaScript-Templates,### Output encoding,"  The method tmpl.encode is used to escape HTML special characters in the
template output: var output = tmpl.encode(""<>&\""'\x00""); // Renders ""&lt;&gt;&amp;&quot;&#39;"" tmpl.encode makes use of the regular expression tmpl.encReg and the
encoding map tmpl.encMap to match and replace special characters, which can
be modified to change the behavior of the output encoding.
Strings matched by the regular expression, but not found in the encoding map are
removed from the output. This allows for example to automatically trim input
values (removing whitespace from the start and end of the string): tmpl.encReg = /(^\s+)|(\s+$)|[<>&""'\x00]/g;
var output = tmpl.encode(""    Banana!    ""); // Renders ""Banana"" (without whitespace)",36
https://github.com/rramona2/JavaScript-Templates,### Local helper variables,"  The local variables available inside the templates are the following: 
o: The data object given as parameter to the template function
(see the next section on how to modify the parameter name).
tmpl: A reference to the tmpl function object.
_s: The string for the rendered result content.
_e: A reference to the tmpl.encode method.
print: Helper function to add content to the rendered result string.
include: Helper function to include the return value of a different
template in the result.
 To introduce additional local helper variables, the string tmpl.helper can
be extended. The following adds a convenience function for console.log and a
streaming function, that streams the template rendering result back to the
callback argument
(note the comma at the beginning of each variable declaration): tmpl.helper += "",log=function(){console.log.apply(console, arguments)}"" +
    "",st='',stream=function(cb){var l=st.length;st=_s;cb( _s.slice(l));}""; Those new helper functions could be used to stream the template contents to the
console output: <script type=""text/x-tmpl"" id=""tmpl-demo"">
<h3>{%=o.title%}</h3>
{% stream(log); %}
<p>Released under the
<a href=""{%=o.license.url%}"">{%=o.license.name%}</a>.</p>
{% stream(log); %}
<h4>Features</h4>
<ul>
{% stream(log); %}
{% for (var i=0; i<o.features.length; i++) { %}
    <li>{%=o.features[i]%}</li>
    {% stream(log); %}
{% } %}
</ul>
{% stream(log); %}
</script>",36
https://github.com/rramona2/JavaScript-Templates,### Template function argument,"  The generated template functions accept one argument, which is the data object
given to the tmpl(id, data) function. This argument is available inside the
template definitions as parameter o (the lowercase letter). The argument name can be modified by overriding tmpl.arg: tmpl.arg = ""p"";

// Renders ""<h3>JavaScript Templates</h3>"":
var result = tmpl(""<h3>{%=p.title%}</h3>"", {title: ""JavaScript Templates""});",36
https://github.com/rramona2/JavaScript-Templates,### Template parsing,"  The template contents are matched and replaced using the regular expression
tmpl.regexp and the replacement function tmpl.func.
The replacement function operates based on the
parenthesized submatch strings. To use different tags for the template syntax, override tmpl.regexp with a
modified regular expression, by exchanging all occurrences of ""{%"" and ""%}"",
e.g. with ""[%"" and ""%]"": tmpl.regexp = /([\s'\\])(?!(?:[^[]|\[(?!%))*%\])|(?:\[%(=|#)([\s\S]+?)%\])|(\[%)|(%\])/g; By default, the plugin preserves whitespace
(newlines, carriage returns, tabs and spaces).
To strip unnecessary whitespace, you can override the tmpl.func function,
e.g. with the following code: var originalFunc = tmpl.func;
tmpl.func = function (s, p1, p2, p3, p4, p5, offset, str) {
    if (p1 && /\s/.test(p1)) {
        if (!offset || /\s/.test(str.charAt(offset - 1)) ||
                /^\s+$/g.test(str.slice(offset))) {
            return '';
        }
        return ' ';
    }
    return originalFunc.apply(tmpl, arguments);
};",36
https://github.com/rramona2/JavaScript-Templates,## Templates syntax, ,3
https://github.com/rramona2/JavaScript-Templates,### Interpolation,"  Print variable with HTML special characters escaped: <h3>{%=o.title%}</h3> Print variable without escaping: <h3>{%#o.user_id%}</h3> Print output of function calls: <a href=""{%=encodeURI(o.url)%}"">Website</a> Use dot notation to print nested properties: <strong>{%=o.author.name%}</strong>",3
https://github.com/rramona2/JavaScript-Templates,### Evaluation,"  Use print(str) to add escaped content to the output: <span>Year: {% var d=new Date(); print(d.getFullYear()); %}</span> Use print(str, true) to add unescaped content to the output: <span>{% print(""Fast &amp; powerful"", true); %}</span> Use include(str, obj) to include content from a different template: <div>
{% include('tmpl-link', {name: ""Website"", url: ""https://example.org""}); %}
</div> If else condition: {% if (o.author.url) { %}
    <a href=""{%=encodeURI(o.author.url)%}"">{%=o.author.name%}</a>
{% } else { %}
    <em>No author url.</em>
{% } %} For loop: <ul>
{% for (var i=0; i<o.features.length; i++) { %}
    <li>{%=o.features[i]%}</li>
{% } %}
</ul>",3
https://github.com/rramona2/JavaScript-Templates,## Compiled templates,"  The JavaScript Templates project comes with a compilation script, that allows
you to compile your templates into JavaScript code and combine them with a
minimal Templates runtime into one combined JavaScript file. The compilation script is built for node.js.
To use it, first install the JavaScript Templates project via
npm: npm install blueimp-tmpl This will put the executable tmpl.js into the folder node_modules/.bin.
It will also make it available on your PATH if you install the package globally
(by adding the -g flag to the install command). The tmpl.js executable accepts the paths to one or multiple template files
as command line arguments and prints the generated JavaScript code to the
console output. The following command line shows you how to store the generated
code in a new JavaScript file that can be included in your project: tmpl.js index.html > tmpl.js The files given as command line arguments to tmpl.js can either be pure
template files or HTML documents with embedded template script sections.
For the pure template files, the file names (without extension) serve as
template ids.
The generated file can be included in your project as a replacement for the
original tmpl.js runtime. It provides you with the same API and provides a
tmpl(id, data) function that accepts the id of one of your templates as
first and a data object as optional second parameter.",3
https://github.com/rramona2/JavaScript-Templates,## Tests,"  The JavaScript Templates project comes with
Unit Tests.
There are two different ways to run the tests: 
Open test/index.html in your browser or
run npm test in the Terminal in the root path of the repository package.
 The first one tests the browser integration,
the second one the node.js integration.",3
https://github.com/rramona2/JavaScript-Templates,## License,"  The JavaScript Templates script is released under the
MIT license.",5
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,## JavaScript Logging Lab,,1
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,## Objectives,"  
Practice using console.log()
Practice using console.error()
Practice using console.warn()
",12
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,## Introduction,"  Welcome to your first JavaScript lab! You'll notice a few new things in this lesson that we haven't encountered before. Don't worry, we'll walk you through them.",1
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,### Tests...,"  The first new thing you'll notice is tests.  When we want to run an experiment, we need to develop a hypothesis and we need to test it. So if we want to experiment with whether adding salt to ice water makes it hotter or colder, we need to design an experiment that controls for all of the other variables: we need to isolate our experiment from parts of its environment that aren't relevant to what we hope to test. In programming, tests place the scientific method into computer science. We run tests to verify that our programs behave the way we think they do. Tests help us identify bugs, and they give us a sense of the health of our applications. On Learn, we use tests as teaching tools. Just like in a normal coding environment, we use tests to describe the program's behavior. Unlike in a normal coding environment, you, not we, are in charge of getting the tests to pass ?that is, making the app behave like we expect it to.",3
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,### Structure,"  The structure of this lab ?where its files and folders are located ?looks roughly like the following: ├── CONTRIBUTING.md
├── LICENSE.md
├── README.md
├── index.js
├── node_modules/
├── package.json
└── test
    └── index-test.js All labs will more or less have the same structure. (And READMEs, for that matter, will still have CONTRIBUTING.md, LICENSE.md, and README.md files.) index.js might be called something else (something more descriptive) in other labs, and so test/index-test.js would be renamed accordingly. But index.js is also descriptive in its own right, defining something of an entry point for finding one's way around the app. This is often the file where you will write your code. (Later on, we'll introduce index.html and index.css ?you'll have to update or refer to these files sometimes, too!)",3
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,### Code-along,"  For now, open up index.js in your text editor. If you're using the Learn IDE, click the ""Open"" button on this lesson  your IDE should open up. You'll see a sidebar like this:  If you open up that ""javascript-logging-lab..."" folder, you'll see a list of files (along with a test/ directory). Click index.js, and it will open in the editor. In index.js, you should see, well, nothing. We'll fix that soon. Now open up test/index-test.js. Hey, there's something! What's all of this stuff doing? At the very top of the file, you'll see const expect = require('expect')
const fs = require('fs')
const jsdom = require('mocha-jsdom')
const path = require('path') This might be a bit bewildering, but at this point, we don't need to be able to write any of this code, or even understand every line perfectly.  All we need is to understand enough so that we can get a sense of what the test is asking us to accomplish, so that we can make the test pass.  Let's go through it. In these first lines, all we're doing is referencing different libraries that help us run your tests. A library is code that someone else (usually multiple someone elses) wrote for our use. Note that require won't work out of the box in the browser. We're actually running our tests in a different environment. (Remember the sandbox analogy from earlier? It's just like that.) A little farther down the page, you'll see describe('index', () => {
  // there's stuff in here, too
}) describe is a function provided by our test runner (in this case, we're using Mocha) ?it's basically a container for our tests. Then we have a few chunks like it('calls console.error()', () => {
  // this is where the tests are!
}) Each of these chunks describes a behavior that we expect the main program to implement. As you can see, they describe that behavior pretty carefully ?in this example, we know that our main file should call console.error() ?pretty simple, right? Don't worry too much yet about what's happening inside these chunks. Sometimes we'll need to do some pretty fancy footwork to test some pretty basic things; other times, and as time goes on, you'll be able to read and understand basically what our tests are expecting. And that'll be great! These aren't like tests that we all took in school: they're testing behavior, not information. Tests are meant to be as transparent as possible about what they're doing, and as you grow as a programmer, it's important to understand more and more what the aims of tests are. In some of our tests, you'll see lines like the following: jsdom({
  src: fs.readFileSync(path.resolve(__dirname, '..', 'index.js'), 'utf-8')
}) This line reads index.js (remember how we said we'd modify that?) and adds its code to the execution environment. The ""execution environment"" is simply where our code runs.",3
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,## Running the Tests,"  To run the tests, simply type learn test in the terminal part of the Learn IDE. (The terminal is the part below where you've been coding.) You should see something like  For the moment, all of the tests fail. Let's figure out how to get one of them passing! (The rest will be up to you.) Let's take the first one. The test description says, ""index calls console.error()"". So it sounds like, pretty straight-forwardly, like we should call console.error() somewhere in index.js. ""Calling"" a function means invoking it, causing it to act. We call functions with parentheses: console.error is a function, but console.error() is a call to the function. In index.js, add a call to console.error() ?you can call it with anything you like (as long as the syntax is valid). We're going to go with console.error(""HALP!"") Because it seems sufficiently dire. Remember to save your file. Anyway, let's run the tests again. In the Learn IDE's terminal, run learn test We should now see:  Nice! We got the first one to pass!",3
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,## A note about spies,"  You might often see errors like the ones above: ""Uncaught error: spy was not called"". Spies are little bits of code that keep track of whether or not they
were called. We use them to make sure that a function is called when we expect
it to be called. We'll try to rewrite these error messages when possible to be more descriptive
about what kinds of calls we expected; but know that sometimes, especially later
on, we leave the errors intentionally ambiguous for you to work out.",3
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,## Your turn,"  Now it's your turn ?can you follow a flow similar to the one we followed
together above to get the remaining to tests to pass? Imagine that you're building the user interface for a fancy ATM machine.
Because the developers are hip with the latest trends, they're using
JavaScript for the user-facing parts. We need a way to send messages to the user: some messages are just updates,
some are warnings (the user should not continue doing what they just did),
and some are errors (something broke, and we need to recover). Your job is to identify a way of sending each kind of message. Hint: in
JavaScript, you'll probably find ways of telling users things with console. And again, remember to save your files before you re-run your tests. When all of your tests pass, be sure to run learn submit to move on to the
next lesson.",3
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,## Feeling stuck?,"  In the above, when we ran our tests and saw the message ""index calls
console.error()"", we wrote, console.error(""HALP!"") Now when we run the tests again and see ""index calls console.log()"", we should
look at what is the same and what is different between this message and the
previous one. It looks like they're basically the same except for one tells
us to call console.error() and the other tells us to call console.log().
So if we got back to index.js and write something like, console.log(""I would be a logger."") // get it? we're now calling console.log() with a different string. Similarly, when we
see the message ""index calls console.warn()"", we know that we can go back to our
code and write something with console.warn(). You've got this!",3
https://github.com/JWood02/javascript-logging-lab-bootcamp-prep-000,## Resources,"  
npm
 View JavaScript Logging Lab on Learn.co and start learning to code for free.",6
https://github.com/trentmwillis/ember.js,# Contribution, See CONTRIBUTING.md,7
https://github.com/Songmu/p5-DBIx-FixtureLoader,# NAME, DBIx::FixtureLoader - Loading fixtures and inserting to your database,1
https://github.com/Songmu/p5-DBIx-FixtureLoader,# SYNOPSIS,"  use DBI;
use DBIx::FixtureLoader;

my $dbh = DBI->connect(...);
my $loader = DBIx::FixtureLoader->new(dbh => $dbh);
$loader->load_fixture('item.csv');
",3
https://github.com/Songmu/p5-DBIx-FixtureLoader,# DESCRIPTION,  DBIx::FixtureLoader is to load fixture data and insert to your database.,1
https://github.com/Songmu/p5-DBIx-FixtureLoader,# INTEFACE, ,3
https://github.com/Songmu/p5-DBIx-FixtureLoader,## Constructor,"  $loader = DBIx::FixtureLoader->new(%option)
 new is Constructor method. Various options may be set in %option, which affect
the behaviour of the object (Type and defaults in parentheses):",3
https://github.com/Songmu/p5-DBIx-FixtureLoader,### `dbh (DBI::db)`,  Required. Database handler.,3
https://github.com/Songmu/p5-DBIx-FixtureLoader,### `bulk_insert (Bool)`,  Using bulk_insert or not. Default value depends on your database.,3
https://github.com/Songmu/p5-DBIx-FixtureLoader,"### `update (Bool, Default: false)`",  Using INSERT ON DUPLICATE or not. It only works on MySQL.,3
https://github.com/Songmu/p5-DBIx-FixtureLoader,"### `ignore (Bool, Default: false)`",  Using INSERT IGNORE or not. This option is exclusive with update.,3
https://github.com/Songmu/p5-DBIx-FixtureLoader,"### `delete (Bool, Default: false)`",  DELETE all data from table before inserting or not.,3
https://github.com/Songmu/p5-DBIx-FixtureLoader,"### `csv_option (HashRef, Default: +{})`","  Specifying Text::CSV's option. binary and blank_is_undef
are automatically set.",3
https://github.com/Songmu/p5-DBIx-FixtureLoader,"### `skip_null_column (Bool, Default: false)`","  If true, null data is not to be inserted or updated explicitly. It it for using default value. NOTE: If this option is true, data can't be overwritten by null value.",3
https://github.com/Songmu/p5-DBIx-FixtureLoader,## Methods, ,3
https://github.com/Songmu/p5-DBIx-FixtureLoader,"### `$loader->load_fixture($file_or_data:(Str|HashRef|ArrayRef), [%option])`","  Loading fixture and inserting to your database. Table name and file format is guessed from
file name. For example, ""item.csv"" contains data of ""item"" table and format is ""CSV"". In most cases %option is not needed. Available keys of %option are as follows. 

table:Str
table name of database.


format:Str
data format. ""CSV"", ""YAML"" and ""JSON"" are available.


update:Bool
Using ON DUPLICATE KEY UPDATE or not. Default value depends on object setting.


ignore:Bool
Using INSERT IGNORE or not.


delete:Bool
DELETE all data from table before inserting or not.

",3
https://github.com/Songmu/p5-DBIx-FixtureLoader,## File Name and Data Format, ,3
https://github.com/Songmu/p5-DBIx-FixtureLoader,### file name,"  Data format is guessed from extension. Table name is guessed from basename. Leading alphabets,
underscores and numbers are considered table name. So, ""user_item-2.csv"" is considered CSV format
and containing data of ""user_item"" table.",3
https://github.com/Songmu/p5-DBIx-FixtureLoader,### data format,"  ""CSV"", ""YAML"" and ""JSON"" are parsable. CSV file must have header line for determining column names. Datas in ""YAML"" or ""JSON"" must be ArrayRef or HashRef containing HashRefs. Each HashRef is the data
of database record and keys of HashRef is matching to column names of the table.",3
https://github.com/Songmu/p5-DBIx-FixtureLoader,# LICENSE,"  Copyright (C) Masayuki Matsuki. This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself.",5
https://github.com/Songmu/p5-DBIx-FixtureLoader,# AUTHOR,  Masayuki Matsuki y.songmu@gmail.com,5
https://github.com/CraigLiaoBJ/ADClusterMapView,# ADClusterMapView - MKMapView with clustering, ADClusterMapView is a drop-in subclass of MKMapView that displays and animates clusters of annotations. This is very useful in cases where you have to display many annotations on the map. Concept and implementation were described on Applidium's website.,1
https://github.com/CraigLiaoBJ/ADClusterMapView,## Quick start,"  
Add the content of the ADClusterMapView folder to your iOS project
Link against the MapKit and CoreLocation frameworks if you don't already
Turn your MKMapView instance into a subclass of ADClusterMapView
Set your annotations by calling setAnnotations:. Do not use addAnnotation: or addAnnotations: as they are not supported yet.
",3
https://github.com/CraigLiaoBJ/ADClusterMapView,### ARC,"  If you are not using ARC in your project, add the -fobjc-arc flag to the files of the library in the Build Phases > Compile Sources section in Xcode.",3
https://github.com/CraigLiaoBJ/ADClusterMapView,## Displaying custom MKAnnotationView instances,"  In the mapView:viewForAnnotation: and mapView:viewForClusterAnnotation: implementations of your map view's delegate, you are given an instance of ADClusterAnnotation. You can call [annotation originalAnnotations] to retrieve your original id<MKAnnotation> instances and customize your MKAnnotationView instance like you would do with Map Kit.
This is especially useful in the case of a leaf annotation, whose originalAnnotations array obviously contains one and only one object.",3
https://github.com/CraigLiaoBJ/ADClusterMapView,### Example code:,"  - (MKAnnotationView *)mapView:(MKMapView *)mapView viewForAnnotation:(id<MKAnnotation>)annotation {
    MyAnnotationView * pinView = (MyAnnotationView *)[mapView dequeueReusableAnnotationViewWithIdentifier:@""ADClusterableAnnotation""];
    if (!pinView) {
        pinView = [[[MyAnnotationView alloc] initWithAnnotation:annotation
                                                reuseIdentifier:@""ADClusterableAnnotation""]
                   autorelease];
    }
    MyModel * model = [annotation originalAnnotations][0];
    pinView.image = model.image;
    return pinView;
}",3
https://github.com/CraigLiaoBJ/ADClusterMapView,## Optional delegate methods,  We provide you with a few optional methods that you may want to add to your ADClusterMapViewDelegate implementation:,6
https://github.com/CraigLiaoBJ/ADClusterMapView,### Setting the maximum number of clusters that you want to display at the same time,  - (NSInteger)numberOfClustersInMapView:(ADClusterMapView *)mapView; // default: 32,6
https://github.com/CraigLiaoBJ/ADClusterMapView,### Custom MKAnnotationView instance for clusters,  - (MKAnnotationView *)mapView:(ADClusterMapView *)mapView viewForClusterAnnotation:(id <MKAnnotation>)annotation; // default: same as returned by mapView:viewForAnnotation:,6
https://github.com/CraigLiaoBJ/ADClusterMapView,### Custom title for clusters,"  - (NSString *)clusterTitleForMapView:(ADClusterMapView *)mapView; // default : @""%d elements""",6
https://github.com/CraigLiaoBJ/ADClusterMapView,### Set visibility for cluster annotation's subtitle,  - (BOOL)shouldShowSubtitleForClusterAnnotationsInMapView:(ADClusterMapView *)mapView; // default: YES,6
https://github.com/CraigLiaoBJ/ADClusterMapView,### Disminish outliers weight,  - (double)clusterDiscriminationPowerForMapView:(ADClusterMapView *)mapView; // This parameter emphasize the discrimination of annotations which are far away from the center of mass. default: 1.0 (no discrimination applied),6
https://github.com/CraigLiaoBJ/ADClusterMapView,### Animation callback,  - (void)clusterAnimationDidStopForMapView:(ADClusterMapView *)mapView;,6
https://github.com/CraigLiaoBJ/ADClusterMapView,## Future Work,"  There are a couple of improvements that could be done. Feel free to send us pull requests if you want to contribute! 
Add support for annotations addition and removal.
Add support for multiple independant trees
More?
",47
https://github.com/Leelow/sinopia,## Use cases," 

Use private packages.
If you want to use all benefits of npm package system in your company without sending all code to the public, and use your private packages just as easy as public ones.
See using private packages section for details.


Cache npmjs.org registry.
If you have more than one server you want to install packages on, you might want to use this to decrease latency
(presumably ""slow"" npmjs.org will be connected to only once per package/version) and provide limited failover (if npmjs.org is down, we might still find something useful in the cache).
See using public packages section for details.


Override public packages.
If you want to use a modified version of some 3rd-party package (for example, you found a bug, but maintainer didn't accept pull request yet), you can publish your version locally under the same name.
See override public packages section for details.

",6
https://github.com/Leelow/sinopia,## Installation,"  # installation and starting (application will create default
# config in config.yaml you can edit later)
$ npm install -g sinopia
$ sinopia

# npm configuration
$ npm set registry http://localhost:4873/

# if you use HTTPS, add an appropriate CA information
# (""null"" means get CA list from OS)
$ npm set ca null Now you can navigate to http://localhost:4873/ where your local packages will be listed and can be searched.",3
https://github.com/Leelow/sinopia,# installation and starting (application will create default,,3
https://github.com/Leelow/sinopia,# config in config.yaml you can edit later),,3
https://github.com/Leelow/sinopia,# npm configuration,,3
https://github.com/Leelow/sinopia,"# if you use HTTPS, add an appropriate CA information",,-
https://github.com/Leelow/sinopia,"# (""null"" means get CA list from OS)",,-
https://github.com/Leelow/sinopia,### Docker,  A Sinopia docker image is available,6
https://github.com/Leelow/sinopia,### Chef,  A Sinopia Chef cookbook is available at Opscode community source: https://github.com/BarthV/sinopia-cookbook,6
https://github.com/Leelow/sinopia,### Puppet,  A Sinopia puppet module is available at puppet forge source: https://github.com/saheba/puppet-sinopia,6
https://github.com/Leelow/sinopia,## Configuration,"  When you start a server, it auto-creates a config file.",3
https://github.com/Leelow/sinopia,## Adding a new user,  npm adduser --registry http://localhost:4873/ This will prompt you for user credentials which will be saved on the Sinopia server.,3
https://github.com/Leelow/sinopia,## Using private packages,"  You can add users and manage which users can access which packages. It is recommended that you define a prefix for your private packages, for example ""local"", so all your private things will look like this: local-foo. This way you can clearly separate public packages from private ones.",3
https://github.com/Leelow/sinopia,## Using public packages from npmjs.org,"  If some package doesn't exist in the storage, server will try to fetch it from npmjs.org. If npmjs.org is down, it serves packages from cache pretending that no other packages exist. Sinopia will download only what's needed (= requested by clients), and this information will be cached, so if client will ask the same thing second time, it can be served without asking npmjs.org for it. Example: if you successfully request express@3.0.1 from this server once, you'll able to do that again (with all it's dependencies) anytime even if npmjs.org is down. But say express@3.0.0 will not be downloaded until it's actually needed by somebody. And if npmjs.org is offline, this server would say that only express@3.0.1 (= only what's in the cache) is published, but nothing else.",3
https://github.com/Leelow/sinopia,## Override public packages,"  If you want to use a modified version of some public package foo, you can just publish it to your local server, so when your type npm install foo, it'll consider installing your version. There's two options here: 

You want to create a separate fork and stop synchronizing with public version.
If you want to do that, you should modify your configuration file so sinopia won't make requests regarding this package to npmjs anymore. Add a separate entry for this package to config.yaml and remove npmjs from proxy_access list and restart the server.
When you publish your package locally, you should probably start with version string higher than existing one, so it won't conflict with existing package in the cache.


You want to temporarily use your version, but return to public one as soon as it's updated.
In order to avoid version conflicts, you should use a custom pre-release suffix of the next patch version. For example, if a public package has version 0.1.2, you can upload 0.1.3-my-temp-fix. This way your package will be used until its original maintainer updates his public package to 0.1.3.

",3
https://github.com/Leelow/sinopia,## Compatibility,"  Sinopia aims to support all features of a standard npm client that make sense to support in private repository. Unfortunately, it isn't always possible. Basic features: 
Installing packages (npm install, npm upgrade, etc.) - supported
Publishing packages (npm publish) - supported
 Advanced package control: 
Unpublishing packages (npm unpublish) - supported
Tagging (npm tag) - not yet supported, should be soon
Deprecation (npm deprecate) - not supported
 User management: 
Registering new users (npm adduser {newuser}) - supported
Transferring ownership (npm owner add {user} {pkg}) - not supported, sinopia uses its own acl management system
 Misc stuff: 
Searching (npm search) - supported in the browser client but not command line
Starring (npm star, npm unstar) - not supported, doesn't make sense in private registry
",1
https://github.com/Leelow/sinopia,## Storage,"  No CouchDB here. This application is supposed to work with zero configuration, so filesystem is used as a storage. If you want to use a database instead, ask for it, we'll come up with some kind of a plugin system.",3
https://github.com/Leelow/sinopia,## Similar existing things,"  
npm + git (I mean, using git+ssh:// dependencies) - most people seem to use this, but it's a terrible idea... npm update doesn't work, can't use git subdirectories this way, etc.
reggie - this looks very interesting indeed... I might borrow some code there.
shadow-npm, public service - it uses the same code as npmjs.org + service is dead
gemfury and others - those are closed-source cloud services, and I'm not in a mood to trust my private code to somebody (security through obscurity yeah!)
npm-registry-proxy, npm-delegate, npm-proxy - those are just proxies...
Is there something else?
",6
https://github.com/ganeshraju/bigtop,# [Apache Bigtop](http://bigtop.apache.org/)," ...is a project for the development of packaging and tests of the Apache Hadoop ecosystem. The primary goal of Apache Bigtop is to build a community around the packaging and interoperability testing of Apache Hadoop-related projects. This includes testing at various levels (packaging, platform, runtime, upgrade, etc...) developed by a community with a focus on the system as a whole, rather than individual projects.",1
https://github.com/ganeshraju/bigtop,# Immediately Get Started with Deployment and Smoke Testing of BigTop,"  The simplest way to get a feel for how bigtop works, is to just cd into bigtop-deploy/vm and try out the recipes under vagrant-puppet-vm, vagrant-puppet-docker, and so on.  Each one rapidly spins up, and runs the bigtop smoke tests on, a local bigtop based big data distribution.  Once you get the gist, you can hack around with the recipes to learn how the puppet/rpm/smoke-tests all work together, going deeper into the components you are interested in as described below.",3
https://github.com/ganeshraju/bigtop,# Quick overview of source code directories,"  
bigtop-deploy : deployment scripts, puppet stuff, VM utilities for Apache Bigtop.
bigtop-packages : RPM/DEB specifications for Apache Bigtop subcomponents
bigtop-test-framework : The source code for the iTest utilities (framework used by smoke tests).
bigtop-tests :
test-artifacts : source for tests.
test-execution : maven pom drivers for running the integration tests found in test-artifacts.
bigtop-toolchain : puppet scripts for setting up an instance which can build Apache Bigtop, sets up utils like jdk/maven/protobufs/...
 Also, there is a new project underway, Apache Bigtop blueprints, which aims to create templates/examples that demonstrate/compare various Apache Hadoop ecosystem components with one another.",36
https://github.com/ganeshraju/bigtop,# Contributing,"  There are lots of ways to contribute.  People with different expertise can help with various subprojects: 
puppet : Much of the Apache Bigtop deploy and pacakging tools use puppet to bootstrap and set up a cluster. But recipes for other tools are also welcome (ie. Chef, Ansible, etc.)
groovy : Primary language used to write the Apache Bigtop smokes and itest framework.
maven : Used to build Apache Bigtop smokes and also to define the high level Apache Bigtop project.
RPM/DEB : Used to package Apache Hadoop ecosystem related projects into GNU/Linux installable packages for most popular GNU/Linux distributions. So one could add a new project or improve existing packages.
hadoop : Apache Hadoop users can also contribute by using the Apache Bigtop smokes, improving them, and evaluating their breadth.
contributing your workloads : Contributing your workloads enable us to tests projects against real use cases and enable you to have people verifying the use cases you care about are always working.
documentation : We are always in need of a better documentation!
giving feedback : Tell us how you use Apache Bigtop, what was great and what was not so great. Also, what are you expecting from it and what would you like to see in the future?
 Also, opening JIRA's and getting started by posting on the mailing list is helpful.",7
https://github.com/ganeshraju/bigtop,# CTR model,"  Bigtop supports Commit-Then-Review model of development. The following
rules will be used for the CTR process: 
a committer can go ahead and commit the patch without mandatory review if
felt confident in its quality (e.g. reasonable testing has been done
locally; all compilations pass; RAT check is passed; the patch follows
coding guidelines)
a committer is encouraged to seek peer-review and/or advice before hand if
there're doubts in the approach taken, design decision, or implementation
details
a committer should keep an eye on the official CI builds at
http://ci.bigtop.apache.org/job/Bigtop-trunk/ (Bigtop-trunk-packages builds)
to make sure that committed changes haven't break anything. In
which case the committer should take a timely effort to resolve the issues
and unblock the others in the community
any non-document patch is required to be opened for at least 24 hours for
community feedback before it gets committed unless it has an explicit +1
from another committer
any non-document patch needs to address all the comment and reach consensus
before it gets committed without a +1 from other committers
there's no changes in the JIRA process, except as specified above
",7
https://github.com/ganeshraju/bigtop,# What do people use Apache Bigtop for?,"  You can go to the Apache Bigtop website for notes on how to do ""common"" tasks like: 
Apache Hadoop App developers: Download an Apache Bigtop built Apache Hadoop 2.0 VM from the website, so you can have a running psuedodistributed Apache Hadoop cluster to test your code on.
Cluster administers or deployment gurus: Run the Apache Bigtop smoke tests to ensure that your cluster is working.
Vendors: Build your own Apache Hadoop distribution, customized from Apache Bigtop bits.
",2
https://github.com/ganeshraju/bigtop,# Getting Started,"  Below are some recipes for getting started with using Apache Bigtop. As Apache Bigtop has different subprojects, these recipes will continue to evolve.
For specific questions it's always a good idea to ping the mailing list at dev-subscribe@bigtop.apache.org to get some immediate feedback, or open a JIRA.",3
https://github.com/ganeshraju/bigtop,## For Users: Running the smoke tests.,"  The simplest way to test bigtop is described in bigtop-tests/smoke-tests/README file For integration (API level) testing with maven, read on.",3
https://github.com/ganeshraju/bigtop,## For Users: Running the integration tests.,"  WARNING: since testing packages requires installing them on a live system it is highly recommended to use VMs for that. Testing Apache Bigtop is done using iTest framework. The tests are organized in maven submodules, with one submodule per Apache Bigtop component.  The bigtop-tests/test-execution/smokes/pom.xml defines all submodules to be tested, and each submodule is in its own directory under smokes/, for example: smokes/hadoop/pom.xml
smokes/hive/pom.xml
... and so on. 

New way (with Gradle build in place)


Step 1: install smoke tests for one or more components


Example 1:
gradle installTestArtifacts


Example 2: Installing just Hadoop-specific smoke tests
gradle install-hadoop




Step 2: Run the the smoke tests on your cluster (see Step 3 and/or Step 4 below)


We are on the route of migrating subprojects under top-level gradle build. Currently
converted projects could be listed by running
  gradle projects

To see the list of tasks in a subproject, ie itest-common, you can run
  gradle itest-common:tasks



Old Way


Step 1: Build the smokes with snapshots.  This ensures that all transitive dependencies etc.. are in your repo
mvn clean install -DskipTests -DskipITs -DperformRelease -f ./bigtop-test-framework/pom.xml
mvn clean install -DskipTests -DskipITs -DperformRelease -f ./test-artifacts/pom.xml



Step 2: Now, rebuild in ""offline"" mode.  This will make sure that your local changes to bigtop are embeded in the changes.
mvn clean install -DskipTests -DskipITs -DperformRelease -o -nsu -f ./bigtop-test-framework/pom.xml
mvn clean install -DskipTests -DskipITs -DperformRelease -o -nsu -f ./bigtop-tests/test-artifacts/pom.xml



Step 3: Now, you can run the smoke tests on your cluster.


Example 1: Running all the smoke tests with TRACE level logging (shows std out from each mr job).
  mvn clean verify -Dorg.apache.bigtop.itest.log4j.level=TRACE -f ./bigtop/bigtop-tests/test-execution/smokes/pom.xml 



Just running hadoop examples, nothing else.
  mvn clean verify -D'org.apache.maven-failsafe-plugin.testInclude=**/*TestHadoopExamples*' -f bigtop-tests/test-execution/smokes/hadoop/pom.xml



Note: A minor bug/issue: you need the ""testInclude"" regular expression above, even if you don't want to customize the tests,
since existing test names don't follow the maven integration test naming convention of IT*, but instead, follow the surefire (unit test) convention of Test*.



",3
https://github.com/ganeshraju/bigtop,## For Users: Creating Your Own Apache Hadoop Environment,"  Another common use case for Apache Bigtop is creating / setting up your own Apache Hadoop distribution.
For details on this, check out the bigtop-deploy/README.md file, which describes how to use the puppet repos
to create and setup your VMs.
There is a current effort underway to create vagrant/docker recipes as well, which will be contained in the
bigtop-deploy/ package.",3
https://github.com/ganeshraju/bigtop,## For Developers: Building the entire distribution from scratch,"  Packages have been built for CentOS/RHEL 5 and 6, Fedora 18, SuSE Linux Enterprise 11, OpenSUSE12.2, Ubuntu LTS Lucid and Precise, and Ubuntu Quantal. They can probably be built for other platforms as well. Some of the binary artifacts might be compatible with other closely related distributions. On all systems, Building Apache Bigtop requires certain set of tools To bootstrap the development environment from scratch execute ./gradlew toolchain
 This build task expected Puppet 3.x to be installed; user has to have sudo permissions. The task will pull down and install
all development dependencies, frameworks and SDKs, required to build the stack on your platform. 

Building packages : gradle [component-name]-[rpm|deb]
If -Dbuildwithdeps=true is set, the Gradle will follow the order of the build specified in
the ""dependencies"" section of bigtop.bom file. Otherwise just a single component will get build (original behavior).
To use an alternative definition of a stack composition (aka BOM), specify its
name with -Dbomfile= system property in the build time.
You can visualize all tasks dependencies by running gradle tasks --all


Building local YUM/APT repositories : gradle [component-name]-[yum|apt]


Recommended build environments
Bigtop provides ""development in the can"" environments, using Docker containers.
These have the build tools set by the toolchain, as well as the user and build
environment configured and cached. All currently supported OSes could be pulled
from official Bigtop repository at https://hub.docker.com/r/bigtop/slaves/tags/
To build a component (bigtop-groovy) for a particular OS (ubuntu-14.04) you can
run the following from a clone of Bigtop workspace (assuming your system has
Docker engine setup and working)
docker run --rm -u jenkins:jenkins -v `pwd`:/ws --workdir /ws bigtop/slaves:trunk-ubuntu-14.04 bash -l -c './gradlew allclean ; ./gradlew bigtop-groovy-pkg'

",3
https://github.com/ganeshraju/bigtop,## For Developers: Building and modifying the web site,"  The website can be built by running mvn site:site from the root directory of the
project.  The main page can be accessed from ""project_root/target/site/index.html"". The source for the website is located in ""project_root/src/site/"".",3
https://github.com/ganeshraju/bigtop,## For Developers: Building a component from Git repository,"  To fetch source from a Git repository you need to modify bigtop.mk and add the
following fields to your package: 
_GIT_REPO - SSH, HTTP or local path to Git repo.
_GIT_REF - branch, tag or commit hash to check out.
 Some packages have different names for source directory and source tarball
(hbase-0.98.5-src.tar.gz contains hbase-0.98.5 directory).
By default source will be fetched in a directory named _TARBALL_SRC
without .t* extension.
To explicitly set directory name use the _GIT_DIR option. Example for HBase: HBASE_GIT_REPO=https://github.com/apache/hbase.git
HBASE_GIT_REF=$(HBASE_PKG_VERSION)
HBASE_GIT_DIR=hbase-$(HBASE_PKG_VERSION)",3
https://github.com/ganeshraju/bigtop,## Contact us,  You can get in touch with us on the Apache Bigtop mailing lists.,5
https://github.com/wenjingjie/XXPagingScrollView,# XXPagingScrollView," 

 Paged scrollView with custom paging width ",1
https://github.com/wenjingjie/XXPagingScrollView,# Installation,"  The preferred way of installation is via CocoaPods. Just add pod 'XXPagingScrollView' and run pod install. It will install the most recent version of XXPagingScrollView. If you would like to use the latest code of XXPagingScrollView use: pod 'XXPagingScrollView', :head",3
https://github.com/wenjingjie/XXPagingScrollView,# Usage,"  simply, you can indicate the specific paging width & height, or set to 0 if you want a fulfill paging size public var pagingWidth:CGFloat
public var pagingHeight:CGFloat then use internal scrollview to show your content public var scrollView:UIScrollView check more detail in the demonstration",3
https://github.com/jmilleralpine/ParallelGit,# ParallelGit," A high performance Java JDK 7 nio in-memory filesystem for Git. 

",1
https://github.com/jmilleralpine/ParallelGit,## Quick start,"  Maven: <dependency>
  <groupId>com.beijunyi</groupId>
  <artifactId>parallelgit-filesystem</artifactId>
  <version>2.0.0</version>
</dependency> Gradle: 'com.beijunyi:parallelgit-filesystem:2.0.0'",3
https://github.com/jmilleralpine/ParallelGit,## Basic usages,"  Copy a file from repository to hard drive: public void loadSettings() throws IOException {
  try(GitFileSystem gfs = Gfs.newFileSystem(""my_branch"", ""/project/repository"")) {
    Path source = gfs.getPath(""/settings.xml"");
    Path target = Paths.get(""/app/config/settings.xml"");
    Files.copy(source, target);
  }
} Copy a file to repository and commit: public void backupSettings() throws IOException {
  try(GitFileSystem gfs = Gfs.newFileSystem(""my_branch"", ""/project/repository"")) {
    Path source = Paths.get(""/app/config/settings.xml"");
    Path target = gfs.getPath(""/settings.xml"");
    Files.copy(source, target);
    Gfs.commit(gfs).message(""Update settings"").execute();
  }
}",3
https://github.com/jmilleralpine/ParallelGit,## Project purpose explained,"  Git is an awesome data storage. Its special data structure offers many useful features such as: 
Keeping history snapshots at a very low cost
Automatic duplication detection
Remote backup
Merging and conflict resolution
 Git is well known and widely used as a VCS, yet few software application uses Git as a internal data storage. One of the reasons is the lack of high level API to efficiently communicate with a Git repository. Consider the workflow in software development, the standard steps to make changes to Git repository are: Checkout (branch/commit) ==> Write file ==> Add file to index ==> Commit
 While this model works sufficiently well with developers, it does not fit in the architecture diagram of a server role application. Reasons are: 
Only one branch can be checked out at a time
Checking out a branch is a heavy I/O task as files need to be deleted and re-created on hard drive
Every context switching needs a check out
 There are ways around these problems, but they usually involve manual blob and tree creations, which are verbose and error prone. ParallelGit is a layer between application logic and Git. It abstracts away Git's low level object manipulation details and provides a friendly interface which extends the Java 7 NIO filesystem API. The filesystem itself operates in memory with data pulled from hard drive on demand. With ParallelGit an application can control a Git repository as it were a normal filesystem. Arbitrary branch and commit can be checked out at the minimal CPU and I/O cost. Multiple filesystem instances can be hosted simultaneously with no interference.",2
https://github.com/jmilleralpine/ParallelGit,## Performance explained,"  Git is best at storing changes in many small batches. It is very rare to have a commit that updates all files in a repository. The size of I/O per request is usually very small compared to the size of the repository. Pre-loading everything into memory is usually an overkill for most tasks. To minimise I/O and memory usage, ParallelGit loads the minimum necessary data to complete a request. Consider a scenario where a branch has the file tree below: ├──app-core
?  └──src
?      ├──main
?      ?  ├──MyFactory.java
?      ?  └──MyProduct.java
?      └──test
?          └──ProductionTest.java
└──app-web
    ├──index.html
    └──style.css
 When this branch is checked out. The information of its head commit is loaded into memory. That includes the author and committer details, the commit message and the reference to the root node of this file tree. This reference is a 40-char hash, which can be used to find the tree object representing the root directory. Assuming the task requires the content of /app-core/src/main/MyFactory.java, before this file can be reached, its parent directories (including the root directory) need to be resolved i.e: 1) /
2) /app-core
3) /app-core/src
4) /app-core/src/main
 The last directory (/app-core/src/main) represented by a Git tree object has the reference to the blob of MyFactory.java. This reference is another 40-char hash value that can be used to find the byte array data of this file in constant time. Now let's say you want to read the file /app-core/src/main/MyProduct.java. This file is in the same directory as the previous one. There is no need to read the directories again as they are already in memory. This time we simply read the blob reference from /app-core/src/main and use it to retrieve the content of the file. Saving files to repository follows a similar pattern. Assuming you have made a change to MyFactory.java and you want to commit this change. ParallelGit saves the file as a blob and creates the new tree objects from bottom-up i.e: 1) /app-core/src/main
2) /app-core/src
3) /app-core
4) /
 The whole process above involved 2 out of the total 5 files in the branch, and ParallelGit only focuses on reaching the 2 files. The existence of the other 3 files causes (nearly) zero impact to the performance. Your repository can keep on growing and your request handling time remains constant.",13
https://github.com/jmilleralpine/ParallelGit,## Advanced features, ,16
https://github.com/jmilleralpine/ParallelGit,#### Merge,"  public void mergeFeatureBranch() throws IOException {
  try(GitFileSystem gfs = Gfs.newFileSystem(""master"", ""/project/repository"")) {
    GfsMerge.Result result = Gfs.merge(gfs).source(""feature_branch"").execute();
    assert result.isSuccessful();
  }
}",1
https://github.com/jmilleralpine/ParallelGit,#### Conflict resolution,"  // a magical method that can resolve any conflicts
public abstract void resolveConflicts(GitFileSystem gfs, Map<String, MergeConflict> conflicts);

public void mergeFeatureBranch() throws IOException {
  try(GitFileSystem gfs = Gfs.newFileSystem(""master"", ""/project/repository"")) {
    GfsMerge.Result result = Gfs.merge(gfs).source(""feature_branch"").execute();
    assert result.getStatus() == GfsMerge.Status.CONFLICTING;
      
    resolveConflicts(gfs, result.getConflicts());
    Gfs.commit(gfs).execute();
  }
}",1
https://github.com/jmilleralpine/ParallelGit,#### Create stash,"  // a magical method that does very interesting work
public abstract void doSomeWork(GitFileSystem gfs);

public void stashIncompleteWork() throws IOException {
  try(GitFileSystem gfs = Gfs.newFileSystem(""master"", ""/project/repository"")) {
    doSomeWork(gfs);
    Gfs.createStash(gfs).execute();
  }
}",1
https://github.com/jmilleralpine/ParallelGit,#### Apply stash,"  // a magical method that does very interesting work
public abstract void doSomeMoreWork(GitFileSystem gfs);

public void continuePreviousWork() throws IOException {
  try(GitFileSystem gfs = Gfs.newFileSystem(""master"", ""/project/repository"")) {
    Gfs.applyStash(gfs)
       .stash(0)  // (optional) to specify the index of the stash to apply 
       .execute();
    doSomeMoreWork(gfs);
  }
}",1
https://github.com/jmilleralpine/ParallelGit,#### Reset,"  // a magical method that always makes bad changes the first time
public abstract void doSomeWork(GitFileSystem gfs);

public void doSomeGoodWork() throws IOException {
  try(GitFileSystem gfs = Gfs.newFileSystem(""master"", ""/project/repository"")) {
    doSomeWork(gfs);
    Gfs.reset(gfs).execute();
    doSomeWork(gfs);
  }
}",1
https://github.com/jmilleralpine/ParallelGit,## Handy Utils,"  Package com.beijunyi.parallelgit.utils has a collection of utility classes to perform common Git tasks. 
BlobUtils - Blob insertion, byte array retrieval
BranchUtils - Branch creation, branch head reference update
CacheUtils - Index cache manipulation
CommitUtils - Commit creation, commit history retrieval
GitFileUtils - Shortcuts for readonly file accesses
RefUtils - Ref name normalisation, Ref-log retrieval
RepositoryUtils - Repository creation, repository settings
StashUtils - Stash manipulation
TagUtils - Tag manipulation
TreeUtils - Tree insertion, tree/subtree retrieval
",3
https://github.com/jmilleralpine/ParallelGit,## License,"  This project is licensed under Apache License, Version 2.0.",5
https://github.com/17352913480/1002,## Welcome to GitHub Pages," You can use the editor on GitHub to maintain and preview the content for your website in Markdown files. Whenever you commit to this repository, GitHub Pages will run Jekyll to rebuild the pages in your site, from the content in your Markdown files.",1
https://github.com/17352913480/1002,### Markdown,"  Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for Syntax highlighted code block

# Header 1
## Header 2
### Header 3

- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src) For more details see GitHub Flavored Markdown.",36
https://github.com/17352913480/1002,# Header 1,,-
https://github.com/17352913480/1002,## Header 2,,-
https://github.com/17352913480/1002,### Header 3,,-
https://github.com/17352913480/1002,### Jekyll Themes,  Your Pages site will use the layout and styles from the Jekyll theme you have selected in your repository settings. The name of this theme is saved in the Jekyll _config.yml configuration file.,3
https://github.com/17352913480/1002,### Support or Contact,  Having trouble with Pages? Check out our documentation or contact support and we’ll help you sort it out.,56
https://github.com/AzureByte/csharp_tutorials,# C Sharp ( C# ) Tutorials,,1
https://github.com/AzureByte/csharp_tutorials,#### Code samples demonstrating how to code in the c# programming language.,,3
https://github.com/AzureByte/csharp_tutorials,#### Points to Note:,"  

These code samples should only be used as a reference and for practise while learning the language. They dont follow any coding standards or best practises and are only meant to demonstrate coding in the language.


Please do not consider or treat them as a detailed programming guide.

  
Introduction
A program that prints the immortal saying 'Hello World!'
Variables
Introduction to Variables
Data Types
Introduction to Data Types
'byte' data type
'sbyte' data type
'short' data type
'ushort' data type
'int' data type
'uint' data type
'long' data type
'ulong' data type
'float' data type
'decimal' data type
'char' data type
'bool' data type
Output Formatting
Console output formatting options
Loops
The 'for' loop
Control Statements
The 'if' statement
File Handling
The 'Path' class
The 'FileInfo' class
The 'DirectoryInfo' class
",3
https://github.com/AzureByte/csharp_tutorials,##,,-
https://github.com/mmcgahan/io-slider,# Intro,"Many interactive sites use slider input, both on desktop and mobile, but the jQuery-UI slider that we typically rely on has a number of limitations that could be overcome with further development. Our projects increasingly require sliders to be touch-friendly, have clear value displays, provide adjustable min/max 'stops', use higher-order output transformations (e.g. exponential curves), and format their value in different ways (e.g. as %, $, or other units).",12
https://github.com/mmcgahan/io-slider,#Functional requirements,"Inherits all properites/methods/events from jQuery-UI slider

responds to touch events
keep track of internal stops - a min and max value that the slider cannot move beyond
has an HTML label that is dynamically updated with the value ($.fn.html)
default to an element generated internally
optional: set to any provided selector
optional: can be supplied with output formatting function (currency, %, etc.)
optional: can be supplied with a function that will be used in place of the raw slider value (e.g. exponential input)",1
https://github.com/mmcgahan/io-slider,#Technical spec,,3
https://github.com/mmcgahan/io-slider,## Properties,"$.fn.io-slider = $.fn.slider + extras

As for jQuery-UI slider, plus:

min-stop = false;
int value < max-stop
max-stop = false;
int value > min-stop
$label = $();
can pass in any jQuery selector to make that jQuery set the label
trans_value = this.value_transform(this.value)
this probably wont work right.
this.value might not return anything
this also optimizes for setting the value (not actually re-calculated onslide)
calculating onslide would optimize for getting the value",3
https://github.com/mmcgahan/io-slider,#Methods,"label_format = function() { return this.trans_value; }
can be set to any alternative function that returns the formatted value
value_transform = function(raw_value) { return raw_value; }
can be set to any alternative function that returns a number (not a string)",3
https://github.com/darg0001/J2EEScan,# J2EEScan - J2EE Security Scanner Burp Suite Plugin,  ,1
https://github.com/darg0001/J2EEScan,## What is J2EEScan,"  J2EEScan is a plugin for Burp Suite Proxy.
The goal of this plugin is to improve the test coverage during
web application penetration tests on J2EE applications.",12
https://github.com/darg0001/J2EEScan,## How does it works?,"  The plugin is fully integrated into the Burp Suite Scanner; it adds some new test
cases and new strategies to discover different kind of J2EE vulnerabilities.  Jetty Version Detection and Remote Leak Shared Buffers vulnerability (CVE-2015-2080)  Apache Wicket Arbitrary Resource Access (CVE-2015-2080) ",3
https://github.com/darg0001/J2EEScan,## Test cases:,"  Misc 
Expression Language Injection (CVE-2011-2730)
Apache Roller OGNL Injection (CVE-2013-4212)
Local File include - /WEB-INF/web.xml Retrieved
Local File Include - Spring Application Context Retrieved
Local File Include - struts.xml Retrieved
Local File Include - weblogic.xml Retrieved
Local File Include - ibm-ws-bnd.xml Retrieved
Local File Include - ibm-web-ext.xmi Retrieved
Local File Include - ibm-web-ext.xml Retrieved
Local File Include - /etc/shadow Retrieved
Local File Include - /etc/passwd Retrieved
HTTP Auth Weak Password
WEB-INF Application Configuration Files Retrieved
Status Servlet (CVE-2008-3273)
Snoop Servlet (CVE-2012-2170)
Extended Path Traversal Scan
AJP Service Detection - thanks to @ikki
Spring Boot Actuator console
UTF8 Response Splitting
JK Management Endpoints
Pivotal Spring Traversal (CVE-2014-3625)
 Apache Struts 
Apache Struts 2 S2-023 - thanks to @h3xstream
Apache Struts 2 S2-016
Apache Struts 2 S2-017
Apache Struts 2 S2-020
Apache Struts 2 S2-021
Apache Struts 2 S2-032
Apache Struts DevMode Enabled
Apache Struts OGNL Console
 Grails 
Grails Path Traversal (CVE-2014-0053)
 Apache Wicket 
Apache Wicket Arbitrary Resource Access (CVE-2015-2080)
 Java Server Faces 
Java Server Faces Local File Include (CVE-2013-3827 CVE-2011-4367)
 JBoss SEAM 
JBoss SEAM Remote Command Execution (CVE-2010-1871)
 Incorrect Error Handling 
JSF
Apache Struts
Apache Tapestry
Grails
GWT
Java
 XML Security 
XInclude Support
XML External Entity
 Information Disclosure Issues 
Remote JVM version
Apache Tomcat version
Jetty version
Oracle Application Server version
Oracle Glassfish version
Oracle Weblogic version
 Compliance Checks 
web.xml - HTTP Verb Tampering
web.xml - URL Parameters for Session Tracking
web.xml - Incomplete Error Handling
web.xml - Invoker Servlet
 JBoss 
JBoss Web Service Enumeration
JBoss Admin Console Weak Password
JBoss JMX/Web Console Not Password Protected
JBoss JMX Invoker Remote Command Execution
JBoss Undertow Directory Traversal (CVE-2014-7816)
JBoss jBPM Admin Console
 Tomcat 
Tomcat Manager Console Weak Password
Tomcat Host Manager Console Weak Password
End Of Life Software - Tomcat
 Weblogic 
Weblogic UDDI Explorer Detection
Weblogic UDDI Explorer SSRF Vulnerability (CVE-2014-4210)
Weblogic Admin Console Weak Password
 Oracle Application Server 
Added check for Oracle Log Database Accessible
Added check for Multiple Oracle Application Server Default Resources (CVE-2002-0565, CVE-2002-0568, CVE-2002-0569)
End Of Life Software - Oracle Application Server
 Jetty 
Jetty Remote Leak Shared Buffers (CVE-2015-2080) found by @gdssecurity
End Of Life Software - Jetty
 Apache Axis 
Apache Axis2 - Web Service Enumeration
Apache Axis2 - Admin Console Weak Password
Apache Axis2 - Local File Include Vulnerability (OSVDB 59001)
Apache Axis2 - Happy Axis
 NodeJS 
NodeJS HTTP Redirect (CVE-2015-1164)
NodeJS HTTP Response Splitting (CVE-2016-2216)
",3
https://github.com/darg0001/J2EEScan,## How to install ?,"  
From ""Cookie jar"" section in ""Options"" -> ""Sessions"" enable the Scanner field
Load the J2EEscan jar in the Burp Extender tab
The plugin requires at least Java 1.7
",3
https://github.com/darg0001/J2EEScan,## Contributors:,"  Special thanks to 
@h3xstream
@ikki
@Caligin35
",5
https://github.com/darg0001/J2EEScan,## Release Notes, ,4
https://github.com/darg0001/J2EEScan,"### Version 1.2.5 (29 May, 2016):","  
Added check for UTF8 Response Splitting
Added check for JBoss Undertow Directory Traversal (CVE-2014-7816)
Added check for NodeJS HTTP Redirect (CVE-2015-1164)
Added check for NodeJS HTTP Response Splitting (CVE-2016-2216)
Added check for JK Management Endpoints
Added check for Pivotal Spring Traversal (CVE-2014-3625)
Added check for JBoss jBPM Admin Consoles
Adedd check for Apache Struts 2 S2-032 (CVE-2016-3081)
Improved LFI payloads
Improved EL Injection tests
Improved WS Axis security checks
",4
https://github.com/darg0001/J2EEScan,"### Version 1.2.4 (26 Nov, 2015):","  
Added check for Spring Boot Actuator console
Improved LFI module with new UTF-8 payloads
Improved EL Injection with new payloads
Added check for Apache Roller OGNL Injection (CVE-2013-4212)
Added check for Apache Struts 2 S2-023 - thanks to @h3xstream
Added check for Weblogic Admin Console Weak Password
Added check for Oracle Application Server multiple file disclosure issues
Added check for Oracle Log Database Accessible
Added check for AJP service identification
Added check for Weblogic UDDI Explorer SSRF (CVE-2014-4210)
Improved performance for passive checks
Improved Apache Wicket Information Disclosure
Improved J2EE incorrect exception handling
Added check for End Of Life Software - Jetty
Added check for End Of Life Software - Tomcat
Added check for End Of Life Software - Oracle Application Server
Added check for Oracle Application Server version
Added check for Oracle Glassfish version
Added check for Oracle Weblogic version
Added check Apache Struts OGNL Console
Added check for Happy Axis
",4
https://github.com/darg0001/J2EEScan,"### Version 1.2.3dev (26 Feb, 2015):","  
Added check for Jetty Remote Leak Shared Buffers (CVE-2015-2080) found by @gdssecurity
Improved check for Information Disclosure Issues - Remote JVM version
Added check for Apache Wicket Arbitrary Resource Access
Added check for Incorrect Error Handling - Apache Tapestry
Added check for Incorrect Error Handling - Grails
Added check for Incorrect Error Handling - GWT
Fixed references for EL Injection issue
",4
https://github.com/darg0001/J2EEScan,"### Version 1.2.2dev (23 Feb, 2015):","  
Added check for Information Disclosure Issues - Remote JVM version
Added check for Information Disclosure Issues - Apache Tomcat version
Added check for weak password on HTTP Authentication
Fix some bugs on issues reporting
",4
https://github.com/darg0001/J2EEScan,"### Version 1.2.1dev (16 Feb, 2015):","  
Improved LFI checks
Added initial support for compliance checks
",4
https://github.com/darg0001/J2EEScan,"### Version 1.2 (25 Jan, 2015):","  
Added checks for Apache Axis2
Added checks for Jboss Admin Console Weak Password
Added checks for Jboss JMX Invoker
Added checks for Status Servlet
Added checks for Snoop Resources
Added checks for Apache Tomcat Host Manager Console
Multiple bug fixes
Pushed BApp Store.
",4
https://github.com/darg0001/J2EEScan,"### Version 1.1.2 (18 Oct, 2014):","  
Initial Public Release
",4
https://github.com/gaborbernat/buildship,# Buildship: Eclipse Plug-ins for Gradle," Buildship is a set of Eclipse Plug-ins that provide a deep integration of Gradle into Eclipse. Buildship is hosted
on eclipse.org.",1
https://github.com/gaborbernat/buildship,## Requirements,"  Buildship can be used with Eclipse 3.6.x or newer. Older versions of Eclipse might work but have not been tested explicitly. Depending
on the version of Gradle that Buildship interacts with, certain features of Buildship may not be available.",3
https://github.com/gaborbernat/buildship,## Documentation,"  All documentation of Buildship for users and developers is hosted on GitHub. More specifically, you can find 
User documentation (plugin installation, current functionality)
Developer documentation (development environment setup)
Build documentation (building Eclipse projects with Gradle)
Outline of upcoming stories
",6
https://github.com/gaborbernat/buildship,## Discussions &amp; News,"  We are very interested in feedback from the Gradle and Eclipse communities. All things Buildship are discussed on 
Gradle Forums
Eclipse Mailinglist
",56
https://github.com/gaborbernat/buildship,## Issue Tracking,"  You can report issues that you find in Buildship as well as in Gradle through 
Bugzilla (for Buildship issues)
Gradle Forums (for Gradle issues)
",6
https://github.com/gaborbernat/buildship,## License,"  Buildship is available under the Eclipse Public License, Version 1.0.",5
https://github.com/peppy6582/serviceLogs,## Before You Begin," Before you begin we recommend you read about the basic building blocks that assemble a MEAN.JS application: 
MongoDB - Go through MongoDB Official Website and proceed to their Official Manual, which should help you understand NoSQL and MongoDB better.
Express - The best way to understand express is through its Official Website, which has a Getting Started guide, as well as an ExpressJS Guide guide for general express topics. You can also go through this StackOverflow Thread for more resources.
AngularJS - Angular's Official Website is a great starting point. You can also use Thinkster Popular Guide, and the Egghead Videos.
Node.js - Start by going through Node.js Official Website and this StackOverflow Thread, which should get you going with the Node.js platform in no time.
",6
https://github.com/peppy6582/serviceLogs,## Prerequisites,"  Make sure you have installed all these prerequisites on your development machine. 
Node.js - Download & Install Node.js and the npm package manager, if you encounter any problems, you can also use this GitHub Gist to install Node.js.
MongoDB - Download & Install MongoDB, and make sure it's running on the default port (27017).
Bower - You're going to use the Bower Package Manager to manage your front-end packages, in order to install it make sure you've installed Node.js and npm, then install bower globally using npm:
 $ npm install -g bower
 
Grunt - You're going to use the Grunt Task Runner to automate your development process, in order to install it make sure you've installed Node.js and npm, then install grunt globally using npm:
 $ sudo npm install -g grunt-cli
",3
https://github.com/peppy6582/serviceLogs,## Downloading MEAN.JS,  There are several ways you can get the MEAN.JS boilerplate:,3
https://github.com/peppy6582/serviceLogs,### Yo Generator,  The recommended way would be to use the Official Yo Generator which will generate the latest stable copy of the MEAN.JS boilerplate and supplies multiple sub-generators to ease your daily development cycles.,3
https://github.com/peppy6582/serviceLogs,### Cloning The GitHub Repository,"  You can also use Git to directly clone the MEAN.JS repository: $ git clone https://github.com/meanjs/mean.git meanjs
 This will clone the latest version of the MEAN.JS repository to a meanjs folder.",3
https://github.com/peppy6582/serviceLogs,### Downloading The Repository Zip File,"  Another way to use the MEAN.JS boilerplate is to download a zip copy from the master branch on GitHub. You can also do this using wget command: $ wget https://github.com/meanjs/mean/archive/master.zip -O meanjs.zip; unzip meanjs.zip; rm meanjs.zip
 Don't forget to rename mean-master after your project name.",3
https://github.com/peppy6582/serviceLogs,## Quick Install,"  Once you've downloaded the boilerplate and installed all the prerequisites, you're just a few steps away from starting to develop you MEAN application. The first thing you should do is install the Node.js dependencies. The boilerplate comes pre-bundled with a package.json file that contains the list of modules you need to start your application, to learn more about the modules installed visit the NPM & Package.json section. To install Node.js dependencies you're going to use npm again, in the application folder run this in the command-line: $ npm install
 This command does a few things: 
First it will install the dependencies needed for the application to run.
If you're running in a development environment, it will then also install development dependencies needed for testing and running your application.
Finally, when the install process is over, npm will initiate a bower install command to install all the front-end modules needed for the application
",3
https://github.com/peppy6582/serviceLogs,## Running Your Application,"  After the install process is over, you'll be able to run your application using Grunt, just run grunt default task: $ grunt
 Your application should run on the 3000 port so in your browser just go to http://localhost:3000 That's it! your application should be running by now, to proceed with your development check the other sections in this documentation.
If you encounter any problem try the Troubleshooting section.",3
https://github.com/peppy6582/serviceLogs,## Development and deployment With Docker,"  

Install Docker


Install Fig


Local development and testing with fig:

 $ fig up 
Local development and testing with just Docker:
 $ docker build -t mean .
$ docker run -p 27017:27017 -d --name db mongo
$ docker run -p 3000:3000 --link db:db_1 mean
$ 
To enable live reload forward 35729 port and mount /app and /public as volumes:
 $ docker run -p 3000:3000 -p 35729:35729 -v /Users/mdl/workspace/mean-stack/mean/public:/home/mean/public -v /Users/mdl/workspace/mean-stack/mean/app:/home/mean/app --link db:db_1 mean",3
https://github.com/peppy6582/serviceLogs,## Running in a secure environment,"  To run your application in a secure manner you'll need to use OpenSSL and generate a set of self-signed certificates. Unix-based users can use the following commnad: $ sh generate-ssl-certs.sh
 Windows users can follow instructions found here
To generate the key and certificate and place them in the config/sslcert folder.",3
https://github.com/peppy6582/serviceLogs,## Getting Started With MEAN.JS,"  You have your application running but there are a lot of stuff to understand, we recommend you'll go over the Official Documentation.
In the docs we'll try to explain both general concepts of MEAN components and give you some guidelines to help you improve your development process. We tried covering as many aspects as possible, and will keep update it by your request, you can also help us develop the documentation better by checking out the gh-pages branch of this repository.",36
https://github.com/peppy6582/serviceLogs,## Community,"  
Use to Offical Website to learn about changes and the roadmap.
Join #meanjs on freenode.
Discuss it in the new Google Group
Ping us on Twitter and Facebook
",5
https://github.com/peppy6582/serviceLogs,## Live Example,  Browse the live MEAN.JS example on http://meanjs.herokuapp.com.,36
https://github.com/peppy6582/serviceLogs,## Credits,"  Inspired by the great work of Madhusudhan Srinivasa
The MEAN name was coined by Valeri Karpov",5
https://github.com/peppy6582/serviceLogs,## License,"  (The MIT License) Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
'Software'), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions: The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",5
https://github.com/petrjanda/ICDM2015,# ICDM2015, ICDM 2015 Drawbridge Cross-Device Connections Challenge: Third Prize Solution,1
https://github.com/petrjanda/ICDM2015,# Instalation:,"  This software is implemented in python and uses the external software XGBoost. The libraries of python needed are: 
[Numpy] (http://www.numpy.org/)
[Scipy] (http://www.scipy.org/)
SciKit Learn
 XGBoost software can be downloaded from:
XGBoost: https://github.com/dmlc/xgboost
In this challenge we used the version 0.3.",3
https://github.com/petrjanda/ICDM2015,# Settings:,"  This software contains two setting files: 'Variables.py' contains the environment variables that the software needs: 
There is an environment variable for the absolute path of every file provided in the challenge.
There is an environment variable for the python wrapper folder of XGBoost.
There is an environment variable for the path to save/load the model.
 'VariablesTST.py' contains two environment variables: 
There is an environment variable for the absolute path of the test file.
There is an environment variable for the absolute path of the file with the results to submit to kaggle.
 Edit 'Variables.py' and 'VariablesTST.py' and use the values of you files and the path that contains the wrapper of your installation of XGBoost. The procedure 'train.py' makes use of 'Variable.py'
The procedure 'test.py' makes use of 'Variable.py' and 'VariableTST.py' (it uses Variable.py because the model has very big data structures that is more practical to load again from the training files than saving and loading again, if you want to evaluate your model in a different test file than the one provided for the challenge uses the variable ""testfile"" in 'Variables.py' for the original test file provided by Drawbridge and the variable ""predictFile"" in 'VariablesTST.py' for the file that you wish to evaluate).",3
https://github.com/petrjanda/ICDM2015,# Requirements:,"  The experiments were executed on a HP DL160 G6 server with 48 GBytes and 2 Intel Xeon X5675 processors (each one has 6 cores with hyperthreading technology).
The operating system was linux gentoo (32 GB of RAM should be enough).",3
https://github.com/petrjanda/ICDM2015,# Running the code:,"  To train the algorithm and create the model: python train.py
 To use the model and make the predictions on a test file: python predict.py
",3
https://github.com/petrjanda/ICDM2015,# Description of the algorithm:,"  

Preprocessing
At the initial stage, we iterate over the list of cookies looking for other cookies with the same handle. Then, for every pair of cookies with the same handle, if one of them doesn't appear in an IP address that the other cookie appears, we include all the information about this IP address in the cookie.


Initial selection of candidate cookies for every Device:
It is not possible to create a training set containing every combination of devices and cookies due to the high number of them. In order to reduce the initial complexity of the problem and to create an affordable dataset, some basic rules have been created to obtain an initial reduced set of candidate cookies for every device. The rules are based on the IP addresses that both device and cookie have in common and how frequent they are in other devices and cookies. The procedure, for every device, is as follows.

We create a set that contains the device's IP addresses that appear in less than ten devices and less than twenty cookies. The initial list of candidates is every cookie with known handle that appears in any of theses IP addresses.
If the previous rule returned an empty set of candidates we create a set that contains the device's IP addresses that appear in less than twenty five devices and less than fifty cookies. The initial list of candidates is every with known handle cookie that appears in any of theses IP addresses.
If the previous rule returned an empty set of candidates we create a set that contains the device's IP addresses. The initial list of candidates is every cookie with known handle that appears in any of theses IP addresses.
If the previous rule returned an empty set of candidates we create a set that contains the device's IP addresses. The initial list of candidates is every cookie that appears in any of theses IP addresses.
If a cookie has the same handle than any of the candidates then this cookie is a candidate too.



Creating the datasets:
Every pattern in the training and test set represents a device/candidate cookie pair obtained by the previous step and contains information about the device (Operating System (OS), Country, ...), the cookie (Cookie Browser Version, Cookie Computer OS,...) and the relation between them (number of IP addresses shared by both device and cookie, number of other cookies with the same handle than the cookie,...).


Training procedure (Supervised Learning + Bagging)
To create the classifier, we have selected a Regularized Boosted Trees algorithm. The software that we used was XGBoost.
We have used 8 baggers creating 8 different subdatasets from the original dataset.


Semi Supervised Learning:
Semi-supervised learning is a class of supervised learning that also make use of unlabeled data. In our case we make use of the data contained in the test set. If we sort the scores obtained by every candidate and the first score is high and the second is very low, is very likely that the first cookie belongs to the device. We make use of this information to update some features in the training set and retrain the algorithm again.


PostProcessing:
We iterate over the devices using the following procedure:
If the initial selection of candidates did not find a candidate with enough likelihood (logistic output of the classifier) we choose a new set of candidate cookies selecting every cookie that shares an IP address with the device and we score them using the classifier.
We label the cookie with highest score as one of the device's cookies. If there are other cookies with the same handle than this cookie we label them too.
We sort the candidates in descending order by the score they have reached and we iterate over them. We label them as a device's cookie if they reach a threshold.
The value of the threshold changes attending to:
The number of cookies already labeled as device's cookies.
The number of other cookies with the same handle than this one.
The handle of the cookie is known or not.
The of the best candidate is known or not.

",3
https://github.com/petrjanda/ICDM2015,# Feature extraction:,"  This section contains the description of every feature contained in the training and test sets. 
Device Features:
 
Device Type
Device OS
Device Country
Device Annonymous c0
Device Annonymous c1
Device Annonymous c2
Device Annonymous 5
Device Annonymous 6
Device Annonymous 7
Number of IP addresses associated to the Device
Number of Properties associated to the Device
 
Cookie Features:
 
Cookie Computer OS
Cookie Browser Version
Cookie Country
Cookie Annonymous c0
Cookie Annonymous c1
Cookie Annonymous c2
Cookie Annonymous 5
Cookie Annonymous 6
Cookie Annonymous 7
Number of IP addresses visited by the Cookie
 
Relational Features
 we have created some sets in order to extract features that represent the relation between the device and the cookie: 
setIP: It contains IP addresses that appear in less than ten devices and less than twenty cookies visited by both device and cookie. If this set is empty we include every IP address visited by both device and cookie.
setOtherDevices: This set contains every device of the training set with the same handle than the cookie except by the device of this pattern.
setOtherIP: This set contains the IP addresses visited by any device in setOtherCookies.
setOtherP roperties: This set contains the properties visited by any device in setOtherCookies.
 Using these sets we have created the following features: 
Number of IP addresses visited by both device and cookie.
Number of IP addresses that appear in less than ten devices and less than twenty cookies visited by both device and cookie.
Number of devices in setOtherDevices
Number of IP addresses that the device has in common with setOtherIP.
Number of Properties that the device has in common with setOtherP roperties.
Number of cookies with the same handle than this cookie.
Addition of features IsCell, Total Frequency, Count C0, Count C1 and Count C2 of every IP address in setIP.
Average of features IsCell, Total Frequency, Count C0, Count C1 and Count C2 of every IP address in setIP.
Addition of features Frequency Count, Count 1, Count 2, Count 3, Count 4 and Count 5 of the device’s IP addresses in setIP.
Average of features Frequency Count, Count 1, Count 2, Count 3, Count 4 and Count 5 of the device’s IP addresses in setIP.
Addition of features Frequency Count, Count 1, Count 2, Count 3, Count 4 and Count 5 of the cookie’s IP addresses in setIP.
Average of features Frequency Count, Count 1, Count 2, Count 3, Count 4 and Count 5 of the cookie’s IP addresses in setIP.
Addition of features Frequency Count, Count 1, Count 2, Count 3, Count 4 and Count 5 of the device’s IP addresses in setIP minus addition of features Frequency Count, Count 1, Count 2, Count 3, Count 4 and Count 5 of the cookie’s IP addresses in setIP.
",1
https://github.com/harrywithcode/elasticsearch-definitive-guide,# The Definitive Guide to Elasticsearch," This repository contains the sources to the ""Definitive Guide to Elasticsearch"" which you can read online.",16
https://github.com/harrywithcode/elasticsearch-definitive-guide,## Building the Definitive Guide,"  In order to build this project, we rely on our docs infrastructure. To build the HTML of the complete project, run the following commands: # clone this repo
git clone git@github.com:elastic/elasticsearch-definitive-guide.git
# clone the docs build infrastructure
git clone git@github.com:elastic/docs.git
# Build HTML and open a browser
cd elasticsearch-definitive-guide
../docs/build_docs.pl --doc book.asciidoc --open
 This assumes that you have all necessary prerequisites installed. For a more complete reference, please refer to the README in the docs repo. The Definitive Guide is written in Asciidoc and the docs repo also contains a short Asciidoc guide.",36
https://github.com/harrywithcode/elasticsearch-definitive-guide,# clone this repo,,-
https://github.com/harrywithcode/elasticsearch-definitive-guide,# clone the docs build infrastructure,,-
https://github.com/harrywithcode/elasticsearch-definitive-guide,# Build HTML and open a browser,,-
https://github.com/harrywithcode/elasticsearch-definitive-guide,## Supported versions,"  The Definitive Guide is available for multiple versions of Elasticsearch: 
The branch 1.x applies to Elasticsearch 1.x
The branch 2.x applies to Elasticsearch 2.x
The branch master applies to master branch of Elasticsearch (the current development version)
",4
https://github.com/harrywithcode/elasticsearch-definitive-guide,## Contributing,  Before contributing a change please read our contribution guide.,7
https://github.com/harrywithcode/elasticsearch-definitive-guide,## License,  This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported License. See http://creativecommons.org/licenses/by-nc-nd/3.0/ for the full text of the License.,5
https://github.com/taf2/Recorderjs,# Recorder.js,,1
https://github.com/taf2/Recorderjs,## A plugin for recording/exporting the output of Web Audio API nodes,,1
https://github.com/taf2/Recorderjs,### Syntax,,3
https://github.com/taf2/Recorderjs,#### Constructor,"  var rec = new Recorder(source [, config])
 Creates a recorder instance. 
source - The node whose output you wish to capture
config - (optional) A configuration object (see config section below)
 ",3
https://github.com/taf2/Recorderjs,##,,-
https://github.com/taf2/Recorderjs,#### Config,"  
workerPath - Path to recorder.js worker script. Defaults to 'js/recorderjs/recorderWorker.js'
bufferLen - The length of the buffer that the internal JavaScriptNode uses to capture the audio. Can be tweaked if experiencing performance issues. Defaults to 4096.
callback - A default callback to be used with exportWAV.
type - The type of the Blob generated by exportWAV. Defaults to 'audio/wav'.
 ",3
https://github.com/taf2/Recorderjs,##,,-
https://github.com/taf2/Recorderjs,#### Instance Methods,"  rec.record()
rec.stop()
 Pretty self-explanatory... record will begin capturing audio and stop will cease capturing audio. Subsequent calls to record will add to the current recording. rec.clear()
 This will clear the recording. rec.exportWAV([callback][, type])
 This will generate a Blob object containing the recording in WAV format. The callback will be called with the Blob as its sole argument. If a callback is not specified, the default callback (as defined in the config) will be used. If no default has been set, an error will be thrown. In addition, you may specify the type of Blob to be returned (defaults to 'audio/wav'). rec.getBuffer([callback])
 This will pass the recorded stereo buffer (as an array of two Float32Arrays, for the separate left and right channels) to the callback. It can be played back by creating a new source buffer and setting these buffers as the separate channel data: function getBufferCallback( buffers ) {
	var newSource = audioContext.createBufferSource();
	var newBuffer = audioContext.createBuffer( 2, buffers[0].length, audioContext.sampleRate );
	newBuffer.getChannelData(0).set(buffers[0]);
	newBuffer.getChannelData(1).set(buffers[1]);
	newSource.buffer = newBuffer;

	newSource.connect( audioContext.destination );
	newSource.start(0);
}
 This sample code will play back the stereo buffer. rec.configure(config)
 This will set the configuration for Recorder by passing in a config object.",3
https://github.com/taf2/Recorderjs,#### Utility Methods (static),"  Recorder.forceDownload(blob[, filename])
 This method will force a download using the new anchor link download attribute. Filename defaults to 'output.wav'.",3
https://github.com/taf2/Recorderjs,## License (MIT),"  Copyright © 2013 Matt Diamond Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",5
https://github.com/alanwgeorge/Android-CleanArchitecture,# Android-CleanArchitecture [![Build Status](https://travis-ci.org/android10/Android-CleanArchitecture.svg?branch=master)](https://travis-ci.org/android10/Android-CleanArchitecture), This is a sample app that is part of a blog post I have written about how to architect android application using the Uncle Bob's clean architecture approach. Architecting Android…The clean way? Architecting Android…The evolution Tasting Dagger 2 on Android Demo video of this sample,16
https://github.com/alanwgeorge/Android-CleanArchitecture,## Clean architecture,  ,6
https://github.com/alanwgeorge/Android-CleanArchitecture,## Architectural approach,  ,6
https://github.com/alanwgeorge/Android-CleanArchitecture,## Architectural reactive approach,  ,6
https://github.com/alanwgeorge/Android-CleanArchitecture,## Local Development,"  Here are some useful Gradle/adb commands for executing this example: 
./gradlew clean build - Build the entire example and execute unit and integration tests plus lint check.
./gradlew installDebug - Install the debug apk on the current connected device.
./gradlew runUnitTests - Execute domain and data layer tests (both unit and integration).
./gradlew runAcceptanceTests - Execute espresso and instrumentation acceptance tests.
",3
https://github.com/alanwgeorge/Android-CleanArchitecture,## Discussions,  Refer to the issues section: https://github.com/android10/Android-CleanArchitecture/issues,6
https://github.com/alanwgeorge/Android-CleanArchitecture,## Code style,"  Here you can download and install the java codestyle.
https://github.com/android10/java-code-styles",6
https://github.com/alanwgeorge/Android-CleanArchitecture,## License,"  Copyright 2014 Fernando Cejas

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
  ",5
https://github.com/trujunzhang/ruby2-rails4-bootstrap-heroku,# Rails Starter App,"      This is a starter web application based on the following technology stack: 
Ruby 2.3.0
Rails 4.2.5
Puma
PostgreSQL
RSpec
Twitter Bootstrap for Sass 3.3.6
Autoprefixer
Font Awesome 4.5.0
SLIM
RuboCop
 Starter App is deployable on Heroku. Demo: http://ruby2-rails4-bootstrap-heroku.herokuapp.com/ Gemfile also contains a set of useful gems for performance, security, api building...",13
https://github.com/trujunzhang/ruby2-rails4-bootstrap-heroku,### Thread safety,"  We assume that this application is thread safe. If your application is not thread safe or you don't know, please set the minimum and maximum number of threads usable by puma on heroku to 1: $ heroku config:set MIN_THREADS=1 MAX_THREADS=1",3
https://github.com/trujunzhang/ruby2-rails4-bootstrap-heroku,### Heroku Platform API,"  This application supports fast setup and deploy via app.json: $ curl -n -X POST https://api.heroku.com/app-setups \
-H ""Content-Type:application/json"" \
-H ""Accept:application/vnd.heroku+json; version=3"" \
-d '{""source_blob"": { ""url"":""https://github.com/diowa/ruby2-rails4-bootstrap-heroku/tarball/master/""} }' More information: Setting Up Apps using the Platform API",36
https://github.com/trujunzhang/ruby2-rails4-bootstrap-heroku,### Recommended add-ons,"  Heroku's Production Check recommends the use of the following add-ons, here in the free version: $ heroku addons:add newrelic:stark # App monitoring
$ heroku config:set NEW_RELIC_APP_NAME=""Rails Starter App"" # Set newrelic app name
$ heroku addons:add papertrail # Log monitoring
$ heroku addons:add pgbackups:auto-month # Postgres backups",3
https://github.com/trujunzhang/ruby2-rails4-bootstrap-heroku,### Secrets.yml,"  Rails 4.1.0 introduced secrets.yml. Heroku automatically sets a proper configuration variable in new applications. Just in case you need, the command line is: $ heroku config:add SECRET_KEY_BASE=""$(bundle exec rake secret)"" NOTE: If you need to migrate old cookies, please read the above guide.",3
https://github.com/trujunzhang/ruby2-rails4-bootstrap-heroku,### Tuning Ruby's RGenGC,"  Generational GC (called RGenGC) was introduced from Ruby 2.1.0. RGenGC reduces marking time dramatically (about x10 faster). However, RGenGC introduce huge memory consumption. This problem has impact especially for small memory machines. Ruby 2.1.1 introduced new environment variable RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR to control full GC timing. By setting this variable to a value lower than the default of 2 (we are using the suggested value of 1.3) you can indirectly force the garbage collector to perform more major GCs, which reduces heap growth. $ heroku config:set RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR=1.3 More information: Change the full GC timing",36
https://github.com/trujunzhang/ruby2-rails4-bootstrap-heroku,### Nitrous.IO,"  Starter App supports online development on Nitrous.IO. You need: 
A Nitrous.IO box with at least 512MB of memory.
Two ""Dev Plan"" heroku databases (one for development and one for test)
The following environment variables on your Nitrous.IO box's .bashrc:
export STARTER_APP_DEV_DB_DATABASE=YOUR_DEV_DB_DATABASE
export STARTER_APP_DEV_DB_USER=YOUR_DEV_DB_USER
export STARTER_APP_DEV_DB_PASSWORD=YOUR_DEV_DB_PASSWORD
export STARTER_APP_DEV_DB_HOST=YOUR_DEV_DB_HOST
export STARTER_APP_DEV_DB_PORT=YOUR_DEV_DB_PORT

export STARTER_APP_TEST_DB_DATABASE=YOUR_TEST_DB_DATABASE
export STARTER_APP_TEST_DB_USER=YOUR_TEST_DB_USER
export STARTER_APP_TEST_DB_PASSWORD=YOUR_TEST_DB_PASSWORD
export STARTER_APP_TEST_DB_HOST=YOUR_TEST_DB_HOST
export STARTER_APP_TEST_DB_PORT=YOUR_TEST_DB_PORT

 A guide for creating heroku databases and edit .bashrc on Nitrous.IO is available here: http://help.nitrous.io/postgres/",36
https://github.com/MrItty/GeoIP2-perl,# NAME, GeoIP2 - Perl API for MaxMind's GeoIP2 web services and databases,1
https://github.com/MrItty/GeoIP2-perl,# VERSION,  version 2.003001,4
https://github.com/MrItty/GeoIP2-perl,# DESCRIPTION,"  This distribution provides an API for the GeoIP2
web services and
databases. The API also
works with the free
GeoLite2 databases. See GeoIP2::WebService::Client for details on the web service client API
and GeoIP2::Database::Reader for the database API.",16
https://github.com/MrItty/GeoIP2-perl,# SPEEDING UP DATABASE READING,"  This module only depends on the pure Perl implementation of the MaxMind
database reader (MaxMind::DB::Reader). If you install the libmaxminddb
library (http://maxmind.github.io/libmaxminddb/) and
MaxMind::DB::Reader::XS, then the XS implementation will be loaded
automatically. The XS implementation is approximately 100x faster than the
pure Perl implementation.",36
https://github.com/MrItty/GeoIP2-perl,# VALUES TO USE FOR DATABASE OR HASH KEYS,"  We strongly discourage you from using a value from any names accessor as
a key in a database or hash. These names may change between releases. Instead we recommend using one of the
following: 
GeoIP2::Record::City - $city->geoname_id
GeoIP2::Record::Continent - $continent->code or $continent->geoname_id
GeoIP2::Record::Country and GeoIP2::Record::RepresentedCountry - $country->iso_code or $country->geoname_id
GeoIP2::Record::Subdivision - $subdivision->iso_code or $subdivision->geoname_id
",3
https://github.com/MrItty/GeoIP2-perl,# INTEGRATION WITH GEONAMES,"  GeoNames (http://www.geonames.org/) offers web services and downloadable
databases with data on geographical features around the world, including
populated places. They offer both free and paid premium data. Each feature is
uniquely identified by a geoname_id, which is an integer. Many of the records returned by the GeoIP web services and databases include a
geoname_id field. This is the ID of a geographical feature (city, region,
country, etc.) in the GeoNames database. Some of the data that MaxMind provides is also sourced from GeoNames. We
source data such as place names, ISO codes, and other similar data from the
GeoNames premium data set.",3
https://github.com/MrItty/GeoIP2-perl,# REPORTING DATA PROBLEMS,"  If the problem you find is that an IP address is incorrectly mapped, please
submit your correction to MaxMind at http://www.maxmind.com/en/correction. If you find some other sort of mistake, like an incorrect spelling, please
check the GeoNames site (http://www.geonames.org/) first. Once you've searched
for a place and found it on the GeoNames map view, there are a number of links
you can use to correct data (""move"", ""edit"", ""alternate names"", etc.). Once
the correction is part of the GeoNames data set, it will be automatically
incorporated into future MaxMind releases. If you are a paying MaxMind customer and you're not sure where to submit a
correction, please contact MaxMind support at for help. See
http://www.maxmind.com/en/support for support details.",56
https://github.com/MrItty/GeoIP2-perl,# VERSIONING POLICY,"  This module uses semantic versioning as described by
http://semver.org/. Version numbers can be read as X.YYYZZZ, where X is the
major number, YYY is the minor number, and ZZZ is the patch number.",4
https://github.com/MrItty/GeoIP2-perl,# PERL VERSION SUPPORT,"  MaxMind has tested this API with Perl 5.8.8 and above. Reasonable patches for
earlier versions of Perl 5.8 will be applied. We will not accept patches to
support any version of Perl before 5.8. The data returned from the GeoIP2 web services includes Unicode characters in
several locales. This may expose bugs in earlier versions of Perl. If Unicode
support is important to you, we recommend that you use the most recent version
of Perl available.",3
https://github.com/MrItty/GeoIP2-perl,# SUPPORT,"  Please report all issues with this code using the GitHub issue tracker at
https://github.com/maxmind/GeoIP2-perl/issues. If you are having an issue with a MaxMind service that is not specific to the
client API please see http://www.maxmind.com/en/support for details.",6
https://github.com/MrItty/GeoIP2-perl,# AUTHORS,"  
Dave Rolsky <drolsky@maxmind.com>
Greg Oschwald <goschwald@maxmind.com>
Mark Fowler <mfowler@maxmind.com>
Olaf Alders <oalders@maxmind.com>
",5
https://github.com/MrItty/GeoIP2-perl,# CONTRIBUTORS,"  
Andy Jack <github@veracity.ca>
E. Choroba <choroba@matfyz.cz>
Graham Knop <haarg@haarg.org>
Mateu X Hunter <mhunter@maxmind.com>
",5
https://github.com/MrItty/GeoIP2-perl,# COPYRIGHT AND LICENSE,"  This software is copyright (c) 2013 - 2016 by MaxMind, Inc. This is free software; you can redistribute it and/or modify it under
the same terms as the Perl 5 programming language system itself.",5
https://github.com/nmjesus/sharedb,# ShareDB," 

 ShareDB is a realtime database backend based on Operational Transformation
(OT) of JSON
documents. It is the realtime backend for the DerbyJS web application
framework. For questions, discussion and announcements, join the ShareJS mailing
list. Please report any bugs you find to the issue
tracker.",156
https://github.com/nmjesus/sharedb,## Features,"  
Realtime synchronization of any JSON document
Concurrent multi-user collaboration
Synchronous editing API with asynchronous eventual consistency
Realtime query subscriptions
Simple integration with any database - MongoDB
Horizontally scalable with pub/sub integration - Redis
Projections to select desired fields from documents and operations
Middleware for implementing access control and custom extensions
Ideal for use in browsers or on the server
Reconnection of document and query subscriptions
Offline change syncing upon reconnection
In-memory implementations of database and pub/sub for unit testing
",1
https://github.com/nmjesus/sharedb,## Quick tour,"  var ShareDB = require('sharedb');
var db = require('sharedb-mongo')('localhost:27017/test');

var backend = ShareDB({db: db});
var connection = backend.connect();

// Subscribe to any database query
var query = connection.createSubscribeQuery('users', {accountId: 'acme'});

query.once('ready', function() {
  // Initially matching documents
  console.log(query.results);
});
query.on('insert', function(docs, index) {
  // Documents that now match the query
  console.log(docs);
});
query.on('remove', function(docs, index) {
  // Documents that no longer match the query
  console.log(docs);
});
query.on('move', function(docs, from, to) {
  // Documents that were moved in the results order for sorted queries
  console.log(docs);
});

// Create and modify documents with synchronously applied operations
var doc = connection.get('users', 'jane');
doc.create({accountId: 'acme', name: 'Jane'});
doc.submitOp({p: ['email'], oi: 'jane@example.com'});

// Create multiple concurrent connections to the same document for
// collaborative editing by multiple clients
var connection2 = backend.connect();
var doc2 = connection2.get('users', 'jane');

// Subscribe to documents directly as well as through queries
doc2.subscribe(function(err) {
  // Current document data
  console.log(doc2.data);
});
doc2.on('op', function(op, source) {
  // Op that changed the document
  console.log(op);
  // truthy if submitted locally and `false` if from another client
  console.log(source);
});",3
https://github.com/nmjesus/sharedb,## Data model,"  In ShareDB's view of the world, every document has 3 properties: 
version - An incrementing number starting at 0
type - An OT type. OT types are defined in
share/ottypes. Documents
which don't exist implicitly have a type of null.
data - The actual data that the document contains. This must be pure
acyclic JSON. Its also type-specific. (JSON type uses raw JSON, text documents
use a string, etc).
 ShareDB implicitly has a record for every document you can access. New documents
have version 0, a null type and no data. To use a document, you must first
submit a create operation, which will set the document's type and give it
initial data. Then you can submit editing operations on the document (using
OT). Finally you can delete the document with a delete operation. By
default, ShareDB stores all operations forever - nothing is truly deleted.",6
https://github.com/nmjesus/sharedb,## Operations,  See https://github.com/ottypes/json0 for documentation of the supported operations.,6
https://github.com/Robbe92/liferay-connector,# Liferay Connector,"  


 This module, available for Node.js and Titanium SDK, wraps the Liferay JSON WS into an easier to use (and easier to test!) API. Works and tested with Liferay 7.0.x and 6.2.x and 6.1.x, both CE and EE.",1
https://github.com/Robbe92/liferay-connector,## Installation,"  With npm for Node.js and io.js you can easily install it with $ npm install --save liferay-connector
 With gitTio for  Titanium SDK you can easily install it with $ gittio install liferay-connector
 To download the module for manual install (e.g. through Appcelerator Studio) then head over the releases page to download the latest packaged module.",3
https://github.com/Robbe92/liferay-connector,## Usage,"  An example is worth thousands of words. var liferay = require('liferay-connector');

liferay.authenticate('http://localhost:8080', {
    login: '??',
    password: '??'
}, function (err, session) {
  session.invoke({
  	""/group/get-user-sites"": {}
  }, function (err, sites) {
  	console.dir(sites);
  });
});",3
https://github.com/Robbe92/liferay-connector,## Credits,  Humbly made the spry ladies and gents at SMC.,5
https://github.com/Robbe92/liferay-connector,## License,"  This library, liferay-connector, is free software (""Licensed Software""); you can
redistribute it and/or modify it under the terms of the GNU Lesser General
Public License as published by the
Free Software Foundation; either version 2.1 of the License, or (at your
option) any later version. This library is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; including but not limited to, the implied warranty of MERCHANTABILITY,
NONINFRINGEMENT, or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General
Public License for more details. You should have received a copy of the GNU Lesser General Public
License along with this library; if
not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth
Floor, Boston, MA 02110-1301 USA",5
https://github.com/a3986/px-data-table,## Px-Data-Table [![Build Status](https://travis-ci.org/PredixDev/px-data-table.svg?branch=master)](https://travis-ci.org/PredixDev/px-data-table), ,1
https://github.com/a3986/px-data-table,## Overview,"  Px-Data-Table is a Predix UI component that defines a data table, optionally using a sub-element for advanced column settings.",1
https://github.com/a3986/px-data-table,## Usage, ,3
https://github.com/a3986/px-data-table,### Prerequisites,"  
node.js
npm
bower
webcomponents-lite.js polyfill
 Node, npm and bower are necessary to install the component and dependencies. webcomponents.js adds support for web components and custom elements to your application.",3
https://github.com/a3986/px-data-table,### Getting Started,"  First, install the component via bower on the command line. bower install https://github.com/PredixDev/px-data-table.git --save
 Second, import the component to your application with the following tag in your head. <link rel=""import"" href=""bower_components/px-data-table/px-data-table.html""/> Finally, use the component in your application: Minimum:

    <px-data-table table-data=""{{data}}""></px-data-table>

Advanced:

    <px-data-table filterable selectable table-data=""{{data}}""></px-data-table>

    <px-data-table selected-rows=""{{mySelectedItems}}"" filterable selectable striped table-data=""{{data}}"">
      <px-data-table-column
        name=""first""
        sortable
        filter-function-name=""myTableCustomFunctions.filterWholeWord""
        sort-function-name=""myTableCustomFunctions.sortByEmailDomain"">
      </px-data-table-column>
      <px-data-table-column name=""last"" ...></px-data-table-column>
      <px-data-table-column name=""color"" ...></px-data-table-column>
      <px-data-table-column name=""date"" ...></px-data-table-column>
    </px-data-table> Integrating with other frameworks (ex: Angular): You may not be able to use 2-way binding with the objects/arrays in other frameworks such as Angular. We suggest instead to use events and selectors, for example: document.getElementById(""myDataTable"").addEventListener(""px-row-click"", function(e) {
    ...
});

document.getElementById(""myDataTable"").addEventListener(""px-select-all-click"", function(e) {
    ...
});

$scope.doSomethingWithSelectedRows = function() {
    $scope.allSelectedRows = document.getElementById(""myDataTable"").selectedRows;
};
 You may also want to prevent your data from auto-synching with your model. If so, we've written up a [little explanation] to help you with that.",3
https://github.com/a3986/px-data-table,## Documentation,  Read the full API and view the demo here.,6
https://github.com/a3986/px-data-table,## Local Development,"  From the component's directory... $ npm install
$ bower install
$ gulp sass
 From the component's directory, to start a local server run: $ gulp serve
 The root of that server (e.g. http://localhost:8080/) will automatically open in your default browser with the API documentation page and interactive working examples. gulp serve also runs gulp watch concurrently so that when you make a change to your source files and save them, your preview will be updated in any browsers you have opened and turned on in LiveReload.",3
https://github.com/a3986/px-data-table,### GE Coding Style Guide,  GE JS Developer's Guide,6
https://github.com/a3986/px-data-table,## Known Issues,  Please use Github Issues to submit any bugs you might find.,6
https://github.com/Capri2014/tiny-dnn,## </div>,,-
https://github.com/Capri2014/tiny-dnn,## Table of contents," 
Features
Comparison with other libraries
Supported networks
Dependencies
Build
Examples
Contributing
References
License
Gitter rooms
 Check out the documentation for more info.",6
https://github.com/Capri2014/tiny-dnn,## What's New,"  
2016/11/30 v1.0.0a3 is released!
2016/9/14 tiny-dnn v1.0.0alpha is released!
2016/8/7  tiny-dnn is now moved to organization account, and rename into tiny-dnn :)
2016/7/27 tiny-dnn v0.1.1 released!
",4
https://github.com/Capri2014/tiny-dnn,## Features,"  
reasonably fast, without GPU

with TBB threading and SSE/AVX vectorization
98.8% accuracy on MNIST in 13 minutes training (@Core i7-3520M)


portable & header-only

Run anywhere as long as you have a compiler which supports C++11
Just include tiny_dnn.h and write your model in C++. There is nothing to install.


easy to integrate with real applications

no output to stdout/stderr
a constant throughput (simple parallelization model, no garbage collection)
work without throwing an exception
can import caffe's model


simply implemented

be a good library for learning neural networks


",1
https://github.com/Capri2014/tiny-dnn,## Comparison with other libraries,  Please see wiki page.,26
https://github.com/Capri2014/tiny-dnn,## Supported networks, ,1
https://github.com/Capri2014/tiny-dnn,### layer-types,"  
core

fully-connected
dropout
linear operation
power


convolution

convolutional
average pooling
max pooling
deconvolutional
average unpooling
max unpooling


normalization

contrast normalization (only forward pass)
batch normalization


split/merge

concat
slice
elementwise-add


",1
https://github.com/Capri2014/tiny-dnn,### activation functions,"  
tanh
sigmoid
softmax
rectified linear(relu)
leaky relu
identity
exponential linear units(elu)
",1
https://github.com/Capri2014/tiny-dnn,### loss functions,"  
cross-entropy
mean squared error
mean absolute error
mean absolute error with epsilon range
",1
https://github.com/Capri2014/tiny-dnn,### optimization algorithms,"  
stochastic gradient descent (with/without L2 normalization and momentum)
adagrad
rmsprop
adam
",1
https://github.com/Capri2014/tiny-dnn,## Dependencies,  Nothing. All you need is a C++11 compiler.,3
https://github.com/Capri2014/tiny-dnn,## Build,"  tiny-dnn is header-only, so there's nothing to build. If you want to execute sample program or unit tests, you need to install cmake and type the following commands: cmake .
 Then open .sln file in visual studio and build(on windows/msvc), or type make command(on linux/mac/windows-mingw). Some cmake options are available: 


options
description
default
additional requirements to use




USE_TBB
Use Intel TBB for parallelization
OFF1
Intel TBB


USE_OMP
Use OpenMP for parallelization
OFF1
OpenMP Compiler


USE_SSE
Use Intel SSE instruction set
ON
Intel CPU which supports SSE


USE_AVX
Use Intel AVX instruction set
ON
Intel CPU which supports AVX


USE_AVX2
Build tiny-dnn with AVX2 library support
OFF
Intel CPU which supports AVX2


USE_NNPACK
Use NNPACK for convolution operation
OFF
Acceleration package for neural networks on multi-core CPUs


USE_OPENCL
Enable/Disable OpenCL support (experimental)
OFF
The open standard for parallel programming of heterogeneous systems


USE_LIBDNN
Use Greentea LinDNN for convolution operation with GPU via OpenCL (experimental)
OFF
An universal convolution implementation supporting CUDA and OpenCL


USE_SERIALIZER
Enable model serialization
ON2
-


USE_DOUBLE
Use double precision computations instead of single precision
OFF
-


USE_ASAN
Use Address Sanitizer
OFF
clang or gcc compiler


USE_IMAGE_API
Enable Image API support
ON
-


USE_GEMMLOWP
Enable gemmlowp support
OFF
-


BUILD_TESTS
Build unit tests
OFF3
-


BUILD_EXAMPLES
Build example projects
OFF
-


BUILD_DOCS
Build documentation
OFF
Doxygen


PROFILE
Build unit tests
OFF
gprof


 1 tiny-dnn use c++11 standard library for parallelization by default 2 If you don't use serialization, you can switch off to speedup compilation time. 3 tiny-dnn uses Google Test as default framework to run unit tests. No pre-installation required, it's  automatically downloaded during CMake configuration. For example, type the following commands if you want to use intel TBB and build tests: cmake -DUSE_TBB=ON -DBUILD_TESTS=ON .",3
https://github.com/Capri2014/tiny-dnn,## Customize configurations,  You can edit include/config.h to customize default behavior.,3
https://github.com/Capri2014/tiny-dnn,## Examples,"  construct convolutional neural networks #include ""tiny_dnn/tiny_dnn.h""
using namespace tiny_dnn;
using namespace tiny_dnn::activation;
using namespace tiny_dnn::layers;

void construct_cnn() {
    using namespace tiny_dnn;

    network<sequential> net;

    // add layers
    net << conv(32, 32, 5, 1, 6) << tanh()  // in:32x32x1, 5x5conv, 6fmaps
        << ave_pool(28, 28, 6, 2) << tanh() // in:28x28x6, 2x2pooling
        << fc(14 * 14 * 6, 120) << tanh()   // in:14x14x6, out:120
        << fc(120, 10);                     // in:120,     out:10

    assert(net.in_data_size() == 32 * 32);
    assert(net.out_data_size() == 10);

    // load MNIST dataset
    std::vector<label_t> train_labels;
    std::vector<vec_t> train_images;

    parse_mnist_labels(""train-labels.idx1-ubyte"", &train_labels);
    parse_mnist_images(""train-images.idx3-ubyte"", &train_images, -1.0, 1.0, 2, 2);

    // declare optimization algorithm
    adagrad optimizer;

    // train (50-epoch, 30-minibatch)
    net.train<mse, adagrad>(optimizer, train_images, train_labels, 30, 50);

    // save
    net.save(""net"");

    // load
    // network<sequential> net2;
    // net2.load(""net"");
} construct multi-layer perceptron(mlp) #include ""tiny_dnn/tiny_dnn.h""
using namespace tiny_dnn;
using namespace tiny_dnn::activation;
using namespace tiny_dnn::layers;

void construct_mlp() {
    network<sequential> net;

    net << fc(32 * 32, 300) << sigmoid() << fc(300, 10);

    assert(net.in_data_size() == 32 * 32);
    assert(net.out_data_size() == 10);
} another way to construct mlp #include ""tiny_dnn/tiny_dnn.h""
using namespace tiny_dnn;
using namespace tiny_dnn::activation;

void construct_mlp() {
    auto mynet = make_mlp<tanh>({ 32 * 32, 300, 10 });

    assert(mynet.in_data_size() == 32 * 32);
    assert(mynet.out_data_size() == 10);
} more sample, read examples/main.cpp or MNIST example page.",3
https://github.com/Capri2014/tiny-dnn,"#include tiny_dnn/tiny_dnn.h""""",,3
https://github.com/Capri2014/tiny-dnn,"#include tiny_dnn/tiny_dnn.h""""",,3
https://github.com/Capri2014/tiny-dnn,"#include tiny_dnn/tiny_dnn.h""""",,3
https://github.com/Capri2014/tiny-dnn,## Contributing,"  Since deep learning community is rapidly growing, we'd love to get contributions from you to accelerate tiny-dnn development!
For a quick guide to contributing, take a look at the Contribution Documents.",7
https://github.com/Capri2014/tiny-dnn,## References,"  [1] Y. Bengio, Practical Recommendations for Gradient-Based Training of Deep Architectures.
arXiv:1206.5533v2, 2012 [2] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, Gradient-based learning applied to document recognition.
Proceedings of the IEEE, 86, 2278-2324. other useful reference lists: 
UFLDL Recommended Readings
deeplearning.net reading list
",6
https://github.com/Capri2014/tiny-dnn,## License,  The BSD 3-Clause License,5
https://github.com/Capri2014/tiny-dnn,## Gitter rooms,"  We have a gitter rooms for discussing new features & QA.
Feel free to join us! 

 developers 
 https://gitter.im/tiny-dnn/developers 


 users 
 https://gitter.im/tiny-dnn/users 

",5
https://github.com/carriercomm/rampant,# Rampant, Rampant launches your Node.js application into a profiler session using node-webkit-agent paired with the Developer Tools frontend inside Google Chrome Canary.,1
https://github.com/carriercomm/rampant,## Caveats,"  
Requires Mac OS X.
Requires Google Chrome Canary.
Does not work if your app depends on STDIN.
",3
https://github.com/carriercomm/rampant,## Install,"  npm install rampant
",3
https://github.com/carriercomm/rampant,## Usage,"  ./node_modules/.bin/rampant /path/to/your/file.js [arguments]
 Note: You must provide a fully-qualified path for your script to workaround my shortcomings of path handling. Here's how I workaround this problem in Yeti.",3
https://github.com/carriercomm/rampant,## Disclaimer,"  Rampant depends on bleeding edge Google Chrome to work correctly with node-webkit-agent and Node.js. If you expect this software to work flawlessly, you've chosen the wrong software. As of the time of this writing, using Rampant is a lot easier than using node-webkit-agent by hand. If you need a debugger, check out node-inspector because node-webkit-agent does not implement the debugger protocol.",3
https://github.com/carriercomm/rampant,## License,  BSD. See LICENSE file.,5
https://github.com/carriercomm/rampant,## Author,"  Reid Burke, Yahoo! Inc.",5
https://github.com/medos1472/BMCustomTableView,## BMCustomTableView," [![CI Status](http://img.shields.io/travis/Barbara M Brina/BMCustomTableView.svg?style=flat)](https://travis-ci.org/Barbara M Brina/BMCustomTableView)


",1
https://github.com/medos1472/BMCustomTableView,## Overview,"  BMCustomTableView is a UITableView subclass, written in Swift, that lets you customize and animate your table view cells. ",1
https://github.com/medos1472/BMCustomTableView,## Installation with CocoaPods,"  BMCustomTableView is available through CocoaPods. To install
it, simply add the following line to your Podfile: pod ""BMCustomTableView""",3
https://github.com/medos1472/BMCustomTableView,## Usage,"  import BMCustomTableView

@IBOutlet weak var customTableView: BMCustomTableView!

func tableView(tableView: UITableView, willDisplayCell cell: UITableViewCell, forRowAtIndexPath indexPath: NSIndexPath) {

        tableView.customizeCell(cell)
}",3
https://github.com/medos1472/BMCustomTableView,## Example Project,"  An example project is included with this repo. To run the example project, clone the repo, and run pod install from the Example directory first.",3
https://github.com/medos1472/BMCustomTableView,## Author,"  Barbara M Brina, bmbrina9@gmail.com",5
https://github.com/medos1472/BMCustomTableView,## License,  BMCustomTableView is available under the MIT license. See the LICENSE file for more info.,5
https://github.com/ZahoreczTibor/handson-ml,# Machine Learning Notebooks," This project aims at teaching you the fundamentals of Machine Learning in
python. It contains the example code and solutions to the exercises in my O'Reilly book Hands-on Machine Learning with Scikit-Learn and TensorFlow:  Simply open the Jupyter notebooks you are interested in: 
Using jupyter.org's notebook viewer

note: github.com's notebook viewer also works but it is slower and the math formulas are not displayed correctly,


or by cloning this repository and running Jupyter locally. This option lets you play around with the code. In this case, follow the installation instructions below.
",13
https://github.com/ZahoreczTibor/handson-ml,# Installation,"  First, you will need to install git, if you don't have it already. Next, clone this repository by opening a terminal and typing the following commands: $ cd $HOME  # or any other development directory you prefer
$ git clone https://github.com/ageron/handson-ml.git
$ cd handson-ml
 If you want to go through chapter 16 on Reinforcement Learning, you will need to install OpenAI gym and its dependencies for Atari simulations. If you are familiar with Python and you know how to install Python libraries, go ahead and install the libraries listed in requirements.txt and jump to the Starting Jupyter section. If you need detailed instructions, please read on.",3
https://github.com/ZahoreczTibor/handson-ml,## Python & Required Libraries,"  Of course, you obviously need Python. Python 2 is already preinstalled on most systems nowadays, and sometimes even Python 3. You can check which version(s) you have by typing the following commands: $ python --version   # for Python 2
$ python3 --version  # for Python 3
 Any Python 3 version should be fine, preferably ?.5. If you don't have Python 3, I recommend installing it (Python ?.6 should work, but it is deprecated so Python 3 is preferable). To do so, you have several options: on Windows or MacOSX, you can just download it from python.org. On MacOSX, you can alternatively use MacPorts or Homebrew. On Linux, unless you know what you are doing, you should use your system's packaging system. For example, on Debian or Ubuntu, type: $ sudo apt-get update
$ sudo apt-get install python3
 Another option is to download and install Anaconda. This is a package that includes both Python and many scientific libraries. You should prefer the Python 3 version. If you choose to use Anaconda, read the next section, or else jump to the Using pip section.",3
https://github.com/ZahoreczTibor/handson-ml,## Using Anaconda,"  When using Anaconda, you can optionally create an isolated Python environment dedicated to this project. This is recommended as it makes it possible to have a different environment for each project (e.g. one for this project), with potentially different libraries and library versions: $ conda create -n mlbook python=3.5 anaconda
$ source activate mlbook
 This creates a fresh Python 3.5 environment called mlbook (you can change the name if you want to), and it activates it. This environment contains all the scientific libraries that come with Anaconda. This includes all the libraries we will need (NumPy, Matplotlib, Pandas, Jupyter and a few others), except for TensorFlow, so let's install it: $ conda install -n mlbook -c conda-forge tensorflow=1.0.0
 This installs TensorFlow 1.0.0 in the mlbook environment (fetching it from the conda-forge repository). If you chose not to create an mlbook environment, then just remove the -n mlbook option. Next, you can optionally install Jupyter extensions. These are useful to have nice tables of contents in the notebooks, but they are not required. $ conda install -n mlbook -c conda-forge jupyter_contrib_nbextensions
 You are all set! Next, jump to the Starting Jupyter section.",3
https://github.com/ZahoreczTibor/handson-ml,## Using pip,"  If you are not using Anaconda, you need to install several scientific Python libraries that are necessary for this project, in particular NumPy, Matplotlib, Pandas, Jupyter and TensorFlow (and a few others). For this, you can either use Python's integrated packaging system, pip, or you may prefer to use your system's own packaging system (if available, e.g. on Linux, or on MacOSX when using MacPorts or Homebrew). The advantage of using pip is that it is easy to create multiple isolated Python environments with different libraries and different library versions (e.g. one environment for each project). The advantage of using your system's packaging system is that there is less risk of having conflicts between your Python libraries and your system's other packages. Since I have many projects with different library requirements, I prefer to use pip with isolated environments. These are the commands you need to type in a terminal if you want to use pip to install the required libraries. Note: in all the following commands, if you chose to use Python 2 rather than Python 3, you must replace pip3 with pip, and python3 with python. First you need to make sure you have the latest version of pip installed: $ pip3 install --user --upgrade pip
 The --user option will install the latest version of pip only for the current user. If you prefer to install it system wide (i.e. for all users), you must have administrator rights (e.g. use sudo pip3 instead of pip3 on Linux), and you should remove the --user option. The same is true of the command below that uses the --user option. Next, you can optionally create an isolated environment. This is recommended as it makes it possible to have a different environment for each project (e.g. one for this project), with potentially very different libraries, and different versions: $ pip3 install --user --upgrade virtualenv
$ virtualenv -p `which python3` env
 This creates a new directory called env in the current directory, containing an isolated Python environment based on Python 3. If you installed multiple versions of Python 3 on your system, you can replace `which python3` with the path to the Python executable you prefer to use. Now you must activate this environment. You will need to run this command every time you want to use this environment. $ source ./env/bin/activate
 Next, use pip to install the required python packages. If you are not using virtualenv, you should add the --user option (alternatively you could install the libraries system-wide, but this will probably require administrator rights, e.g. using sudo pip3 instead of pip3 on Linux). $ pip3 install --upgrade -r requirements.txt
 Great! You're all set, you just need to start Jupyter now.",3
https://github.com/ZahoreczTibor/handson-ml,## Starting Jupyter,"  If you want to use the Jupyter extensions (optional, they are mainly useful to have nice tables of contents), you first need to install them: $ jupyter contrib nbextension install --user
 Then you can activate an extension, such as the Table of Contents (2) extension: $ jupyter nbextension enable toc2/main
 Okay! You can now start Jupyter, simply type: $ jupyter notebook
 This should open up your browser, and you should see Jupyter's tree view, with the contents of the current directory. If your browser does not open automatically, visit localhost:8888. Click on index.ipynb to get started! Note: you can also visit http://localhost:8888/nbextensions to activate and configure Jupyter extensions. Congrats! You are ready to learn Machine Learning, hands on!",3
https://github.com/yu5y/geonotebook,## GeoNotebook [![CircleCI](https://circleci.com/gh/OpenGeoscience/geonotebook.svg?style=shield)](https://circleci.com/gh/OpenGeoscience/geonotebook) [![Gitter chat](https://badges.gitter.im/gitterHQ/gitter.png)](https://gitter.im/OpenGeoscience/geonotebook)," GeoNotebook is an application that provides client/server
environment with interactive visualization and analysis capabilities
using Jupyter, [GeoJS]
(http://www.github.com/OpenGeoscience/geojs) and other open source tools.
Jointly developed by  Kitware and
NASA Ames.",15
https://github.com/yu5y/geonotebook,## Screenshots,   Checkout some additional screenshots,6
https://github.com/yu5y/geonotebook,## Installation, ,3
https://github.com/yu5y/geonotebook,### System Prerequisites,"  For default tile serving 
GDAL >= 2.1.0
mapnik >= 3.1.0
python-mapnik >= 0.1
",3
https://github.com/yu5y/geonotebook,### Clone the repo:,"  git clone git@github.com:OpenGeoscience/geonotebook.git
cd geonotebook",3
https://github.com/yu5y/geonotebook,"### Make a virtualenv, install jupyter[notebook], install geonotebook","  mkvirtualenv -a . geonotebook

# Numpy must be fully installed before rasterio
pip install -r prerequirements.txt

pip install -r requirements.txt

pip install .

# Enable both the notebook and server extensions
jupyter serverextension enable --sys-prefix --py geonotebook
jupyter nbextension enable --sys-prefix --py geonotebook Note The serverextension and nbextension commands accept flags that configure how
and where the extensions are installed.  See jupyter serverextension --help for more
information.",3
https://github.com/yu5y/geonotebook,# Numpy must be fully installed before rasterio,,3
https://github.com/yu5y/geonotebook,# Enable both the notebook and server extensions,,3
https://github.com/yu5y/geonotebook,### Installing geonotebook for development,"  When developing geonotebook, it is often helpful to install packages as a reference to the
checked out repository rather than copying them to the system site-packages.  A ""development
install"" will allow you to make live changes to python or javascript without reinstalling the
package. # Install the geonotebook python package as ""editable""
pip install -e .

# Install the notebook extension as a symlink
jupyter nbextension install --sys-prefix --symlink --py geonotebook

# Enable the extension
jupyter serverextension enable --sys-prefix --py geonotebook
jupyter nbextension enable --sys-prefix --py geonotebook

# Start the javascript builder
cd js
npm run watch",3
https://github.com/yu5y/geonotebook,"# Install the geonotebook python package as editable""""","  cd notebooks/
jupyter notebook",3
https://github.com/yu5y/geonotebook,# Install the notebook extension as a symlink,"  Geonotebook relies on a configuration for several of its options. The system will merge configuration files in the following precedence: 
/etc/geonotebook.ini
/usr/etc/geonotebook.ini
/usr/local/etc/geonotebook.ini
sys.prefix/etc/geonotebook.ini
(e.g. /home/user/.virtual_environments/geonotebook/etc/geonotebook.inig)
~/.geonotebook.ini
os.getcwd()/.geonotebook.ini
any path specified in the GEONOTEBOOK_INI environment variable.
 The default configuration is installed in sys.prefix/etc/geonotebook.ini",3
https://github.com/yu5y/geonotebook,# Enable the extension,"  # From the source root
pip install -r requirements-dev.txt
tox

# Optionally only run tests on python 2.7
# tox -e py27",3
https://github.com/yu5y/geonotebook,# Start the javascript builder,,3
https://github.com/yu5y/geonotebook,### Run the notebook:,,3
https://github.com/yu5y/geonotebook,### Configure the notebook:,,3
https://github.com/yu5y/geonotebook,### Run the tests,,3
https://github.com/yu5y/geonotebook,# From the source root,,3
https://github.com/yu5y/geonotebook,# Optionally only run tests on python 2.7,,3
https://github.com/yu5y/geonotebook,# tox -e py27,,3
https://github.com/yu5y/geonotebook,## Docker Container,  System requirements for running the notebook can sometimes prove burdensome to install. To ease these issues we have included a docker container that will run the notebook inside a containerized process.,6
https://github.com/yu5y/geonotebook,## Vagrant Machine,"  Additionally there is a Vagrantfile for standing up an instance of Geonotebook within a virtual machine, further instructions can be found here.",6
https://github.com/yu5y/geonotebook,## Tile Server,  By default geonotebook provides its own tile server based on Mapnik and GDAL as a Jupyter Notebook server extension. Assuming system pre-requisites are available this should not need to be configured. Alternately geonotebook may be configured to use a pre-existing Geoserver for serving tiles. A built in geoserver implementation is available as a virtual machine in devops/geoserver/.,3
https://github.com/yu5y/geonotebook,### Use geoserver for tile serving,"  First provision the geoserver cd devops/geoserver/
vagrant up
 Second change the vis_server configuration to geoserver in the [default] section of your configuration. Then include a [geoserver] section with the pertinent configuration.  E.g.: [default]
vis_server=geoserver

...

[geoserver]
username = admin
password = geoserver
url = http://127.0.0.1:8080/geoserver
",3
https://github.com/ammarx/ARP-spoofing,# ARP-spoofing," 
Python script to perform ARP spoofing on a network
 This python script allows you to perform ARP spoofing, which can be used to perform attacks such as denial of service, man in the middle, or session hijacking.",1
https://github.com/ammarx/ARP-spoofing,# Requirements,"  For this attack to be performed, you need the following tools to be installed on the machine you will be performing this attacking from: * Python 2.7.6
* Scapy 2.2.0
* Nmap 6.40
* Wireshark
* This python script
",3
https://github.com/ammarx/ARP-spoofing,# Requirement details,"  Python comes installed on ubuntu by default. You can get Scapy from the Ubuntu Software Center:
 You can also get Nmap from the Ubuntu Software Center:
 Wireshark is also available on the Ubuntu Software Center, however I recommend getting the latest version from the website: https://www.wireshark.org/download.html
",3
https://github.com/ammarx/ARP-spoofing,# Installation,"  You can download this python script by running the following command in the terminal: $ wget https://raw.githubusercontent.com/ammarx/ARP-spoofing/master/src/mmattack.py
",3
https://github.com/ammarx/ARP-spoofing,# Setting up IP Forwarding,"  We will be using this script to perform man in the middle attack. Which means we will use this to get the data from another device connected to the same network. The first step you have to do it turn on the ip forwarding. This step is required so that the connection on the victim's device does not get interrupted. To turn on IP forwarding, open terminal and type: $ sudo nano '/proc/sys/net/ipv4/ip_forward'
 This will open up the ip_forward file. The default value in it should be 0, change it to 1 and then save and exit.
 Now that we have that sorted, we need to get the MAC address and the IP address of the victim we want to attack on our network. To do that, you first need to see what IP address the router has given you. On Ubuntu you can get that info by going to the Connection Information menu:
",3
https://github.com/ammarx/ARP-spoofing,# Gathering MAC and IP addresses,"  According to this we are connected on IP Address: 192.168.20.230 and the Route IP is: 192.168.20.1
Now here is where a things get a bit tricky because you need a bit of technical knowledge of how IPs work. I wont be going into full details, however I will explain the part that is required for this script to work. In the above image, you also can see that our Subnet Mask is: 255.255.255.0
The 0 in the above simply means that that block 1-254 is available to the client, while the rest of the blocks are available to the host. Now keep that in mind and look at this image below:  As you can see the Mask length for the 255.255.255.0 is 24, you can calculate this yourself by converting the Subnet Mask into binary and then counting all the ones. Example: 255.255.255.0 into binary: 1111 1111 . 1111 1111 . 1111 1111 . 0000 0000 So the number of ones are 24. Now you might be wondering why we need this number? Well this is required for the next step, which is to get the MAC addresses and the IP addresses of everyone connected to your network. Open up the terminal and type: $ sudo nmap -sP {Route IP with ending octate as zero}/{this magical number you got in the previous step}
 Here is mine: $ sudo nmap -sP 192.168.20.0/24
 You should see something like this after it is done scanning your network:
",3
https://github.com/ammarx/ARP-spoofing,# Performing the attack,"  Now that you have gotten the IP address and the MAC address of the victim, all you need to do is launch the actual attack. To do that fire up the script you downloaded. $ sudo python '/home/**[computer name]**/mmattack.py'
 Now all you need to do is enter the details it asks. Here is an example of what it should look like:
 If everything goes well, you should be able to start sending packets.
 Now while this ARP request is being spammed, we need to open wireshark
 Select the proper interface you are connected to. If you are not sure, select the any option and click start. You should see a screen like this now:
 With the ARP protocol requests getting spammed. If you don't see this, you have done something wrong. Now to see what the victim is browsing, you can type the following in the filter: ip.addr=={ipaddress_of_the_victim} and http.request
 
Note: This filter allows you to see the http traffic only. If you want to look at other traffic, I recommend you learn how to use wireshark as this will help you to snoop around more easily. Because the IP address of the victim is 192.168.20.240 for me, I will type the following in the filter:
 ip.addr==192.168.20.240 and http.request
 and press enter.  As you see from the image above, the victim is on an android device and is browsing the website www.tagcraftmc.com This sort of attack should work on any network that uses ARP request to get the device details.",3
https://github.com/ammarx/ARP-spoofing,# Extra,"  Here is a video of me performing all of these steps, so it is much easier for you to follow: ",6
https://github.com/ammarx/ARP-spoofing,# Credits,"  This script is made by www.arppoisoning.com
However, I have made this script easier to use.",5
https://github.com/RodrigoCm95/ionic-native,# Ionic Native," Ionic Native is a curated set of wrappers for Cordova plugins that make adding any native functionality you need to your Ionic, Cordova, or Web View mobile app easy.",1
https://github.com/RodrigoCm95/ionic-native,### Documentation,"  For the full Ionic Native documentation, please visit http://ionicframework.com/docs/v2/native/.",6
https://github.com/RodrigoCm95/ionic-native,### Promises and Observables,"  Ionic Native wraps plugin callbacks in a Promise or Observable, providing a common interface for all plugins and ensuring that native events trigger change detection in Angular 2. import { Geolocation } from 'ionic-native';

Geolocation.getCurrentPosition().then(pos => {
  console.log('lat: ' + pos.coords.latitude + ', lon: ' + pos.coords.longitude);
});

let watch = Geolocation.watchPosition().subscribe(pos => {
  console.log('lat: ' + pos.coords.latitude + ', lon: ' + pos.coords.longitude);
});

// to stop watching
watch.unsubscribe();
",6
https://github.com/RodrigoCm95/ionic-native,### Angular 1,"  Ionic Native works as a stand-in for ngCordova. In many cases, the usage is identical, but we import ionic.native instead of ngCordova as our module. As a rule of thumb: take the ES6 class name of the plugin and add $cordova to get the service name. For example, Geolocation would be $cordovaGeolocation, and Camera will be $cordovaCamera: angular.module('myApp', ['ionic', 'ionic.native'])

.controller('MyCtrl', function($scope, $cordovaCamera) {
  $scope.takePicture = function() {
    $cordovaCamera.getPicture(opts).then(function(p) {
    }, function(err) {
    });
  };
}); For services that return observables, the Angular 1 digest cycle must be done manually (currently): angular.module('myApp', ['ionic', 'ionic.native'])

.controller('MyCtrl', function($scope, $cordovaGeolocation) {
  $scope.takePicture = function() {
    $cordovaGeolocation.watchPosition(opts).subscribe(function(p) {
      $scope.$apply(function() {
        $scope.position = p.coords;
      });
    }, function(err) {
    });
  };
});",3
https://github.com/RodrigoCm95/ionic-native,### Runtime Diagnostics,  Spent way too long diagnosing an issue only to realize a plugin wasn't firing or installed? Ionic Native lets you know what the issue is and how you can resolve it. ,3
https://github.com/RodrigoCm95/ionic-native,## Installation,"  Run following commmand to install ionic-native in your project. npm install ionic-native --save
",3
https://github.com/RodrigoCm95/ionic-native,## Plugin Missing?,  Let us know or submit a PR! Take a look at the Developer Guide for more on how to contribute. ❤️,7
https://github.com/RodrigoCm95/ionic-native,# Credits,  Ibrahim Hadeed - @ihadeed Tim Lancina - @timlancina Max Lynch - @maxlynch Rob Wormald - @robwormald,5
https://github.com/tkylin/shadowsocks-windows,# Shadowsocks for Windows,  中文说明,1
https://github.com/tkylin/shadowsocks-windows,#### Features,"  
System proxy configuration
PAC mode and global mode
GFWList and user rules
Supports HTTP proxy
Supports server auto switching
Supports UDP relay (see Usage)
",1
https://github.com/tkylin/shadowsocks-windows,#### Download,  Download the latest release.,3
https://github.com/tkylin/shadowsocks-windows,#### Basic,"  
Find Shadowsocks icon in the notification tray
You can add multiple servers in servers menu
Select Enable System Proxy menu to enable system proxy. Please disable other
proxy addons in your browser, or set them to use system proxy
You can also configure your browser proxy manually if you don't want to enable
system proxy. Set Socks5 or HTTP proxy to 127.0.0.1:1080. You can change this
port in Servers -> Edit Servers
",3
https://github.com/tkylin/shadowsocks-windows,#### PAC,"  
You can change PAC rules by editing the PAC file. When you save the PAC file
with any editor, Shadowsocks will notify browsers about the change automatically
You can also update PAC file from GFWList (maintained by 3rd party)
You can also use online PAC URL
",3
https://github.com/tkylin/shadowsocks-windows,#### Server Auto Switching,"  
Load balance: choosing server randomly
High availability: choosing the best server (low latency and packet loss)
Choose By Total Package Loss: ping and choose. Please also enable
Availability Statistics in the menu if you want to use this
Write your own strategy by implement IStrategy interface and send us a pull request!
",3
https://github.com/tkylin/shadowsocks-windows,#### UDP,"  For UDP, you need to use SocksCap or ProxyCap to force programs you want
to be proxied to tunnel over Shadowsocks",3
https://github.com/tkylin/shadowsocks-windows,#### Multiple Instances,"  If you want to manage multiple servers using other tools like SwitchyOmega,
you can start multiple Shadowsocks instances. To avoid configuration conflicts,
copy Shadowsocks to a new directory and choose a different local port.",3
https://github.com/tkylin/shadowsocks-windows,#### Global hotkeys,"  Hotkeys are NOT registered automatically. You should re-register all hotkeys after
restarting Shadowsocks. If you are using multiple instances of Shadowsocks,
you must set different key combination for other instances.",3
https://github.com/tkylin/shadowsocks-windows,##### How to input?,"  
Put focus in the corresponding textbox.
Press the key combination that you want to use.
Release all keys when you think it is ready.
Your input appears in the textbox.
",3
https://github.com/tkylin/shadowsocks-windows,##### How to change?,"  
Put focus in the corresponding textbox.
Press BackSpace key to clear content.
Re-input new key combination.
",3
https://github.com/tkylin/shadowsocks-windows,##### How to deactivate?,"  
Clear content in the textbox that you want to deactivate,
if you want to deactivate all, please clear all textboxes.
Press OK button to confirm.
",3
https://github.com/tkylin/shadowsocks-windows,##### Meaning of label color,"  
Green: This key combination is not occupied by other programs and register successfully.
Yellow: This key combination is occupied by other programs and you have to change to another one.
Transparent without color: The initial status.
",3
https://github.com/tkylin/shadowsocks-windows,#### Server Configuration,  Please visit Servers for more information.,36
https://github.com/tkylin/shadowsocks-windows,#### Develop,  Visual Studio 2015 & .NET Framework 4.6.2 Developer Pack are required.,3
https://github.com/tkylin/shadowsocks-windows,#### License,  GPLv3,5
https://github.com/voDox17/Viberr,# What is Viberr?," Viberr is an application that let's you upload, store, and play all of your music from the cloud. You can now manage and listen to your music from any device, anywhere in the world. ",1
https://github.com/voDox17/Viberr,## How does it work?,"  To get started, first create a new album. When adding an album cover logo, it's best to have a resolution of at least 512x512 and to use common image formats such as JPG, JPEG, or PNG. ",3
https://github.com/voDox17/Viberr,## Adding Songs,"  After an album is created you will then be able to add/upload songs. Currently supported file types are WAV, MP3, and OGG. ",3
https://github.com/voDox17/Viberr,## My Songs,"  Once songs are added to an album you are then able to play, favorite, and delete them. ",3
https://github.com/voDox17/Viberr,## Searching,"  You can also search for music using the search feature at the top of every page. Any relevant albums will appear at the top of the results page, and the results for individual songs will appear below. ",3
https://github.com/ChadLactaoen/Blackjack,# Blackjack," This is a simple blackjack server over WebSockets that leverages the Simple Text Oriented Messaging Protocol (STOMP). You will need to create a client in order to interface with the blackjack server. The server is written using Java 8, so if you wish to run this locally, you'll need to have Java 8 or greater installed.",13
https://github.com/ChadLactaoen/Blackjack,## Purpose,"  The server was written as an entrance exercise for potential intern candidates and test their critical thinking, coding skill, ability to parse messages and leverage APIs, and competitiveness by putting their clients up against other interns' clients. But most importantly, it's written with the idea to have fun! The goal of the challenge is to create a working client that can run through several hands against the dealer without any hiccups. Once you have a basic client working, if time allows, try to add strategy to your player to improve its performance and beat other clients.",2
https://github.com/ChadLactaoen/Blackjack,## Blackjack Resources and Strategy,"  NOTE: The below link may not work. You can refer to that page here If you are unfamiliar with blackjack, try starting here. Hint: Even if you do know all the rules, the website is VERY useful for all kinds of strategy and tips. In fact, it would be beneficial to take advantage of everything the website has to offer.",6
https://github.com/ChadLactaoen/Blackjack,## Requirements,"  
Git

You could of course just download this source code directly if you don't want have time to download git.
If you don't have git installed, you can download it here


Java 8 or greater

You can test this by running java --version in your terminal to tell what java version, if any, is installed on your computer
NOTE: Java 8 is only required if you would like to run the server locally for testing purposes. If not, don't fret! There will be test servers you can use to test if you don't have Java 8 installed.


",3
https://github.com/ChadLactaoen/Blackjack,## Blackjack Client Code,"  You won't be changing any code on the server. Instead, you will have a client that you'll need to implement logic for in order to interact with the server. Luckily for you, the websocket configuration part is already done, all you need to do is write the logic to register into the game, make bets, and act on your hand. There are two versions of the client that you can find here: 
Java: https://github.com/chadtomas/BlackjackClient
Python: https://github.com/chadtomas/PythonBlackjackClient
",36
https://github.com/ChadLactaoen/Blackjack,## Quick'n'Dirty Server Startup,"  If you plan on running this locally, be sure you meet all the requirements above so that it will run properly. 
Locate the .jar file located in the target/ folder.
From the terminal, you can run java -jar {jar_name}.jar. This starts the server on an embedded Tomcat instance on port 8080. If you'd like to change the default port on startup, you can append --server.port={desired port number} at the end of java command.
Once the server is started up, you can hit the UI at localhost:8080, where you can either connect to the server and manually play blackjack or connect your client and watch it communicate with the server.
",3
https://github.com/ChadLactaoen/Blackjack,## Rules,"  Here are the current rules that are enforced by the blackjack server: 
Two Deck Blackjack
Blackjack Pays 3:2
Support for up to 4 players
Cut Card with ~70% Penetration
Players start with $1000 in chips
If you lose all your money, you are done
Bet increments of $10 with no upper betting limit
Dealer Stands on Soft 17
No Insurance
Surrender Allowed on First Two Cards (including after splitting)
Dealer Peeks for Blackjack
Aces Split Only Once
Split up to Four Hands (except Aces)
Double After Splitting Allowed (except Aces)
",3
https://github.com/ChadLactaoen/Blackjack,## Subscriptions,"  WebSockets allow for two-way communication between the server and clients. When a message is received by the server from any clients, it will send back a response to different subscription destinations. The most important message destinations are described below: 
/topic/game The main destination for all game info. Any messages sent from here is broadcasted to all clients currently connected to the server. Messages sent to this destination will usually be triggered from clients sending their bets and players sending their actions.
/queue/player Messages sent here are only sent to the client that sent a message to an endpoint on the server whose message destination is here. This will be especially important to listen to when your client first registers to play blackjack. During registration, you'll be assigned a secret playerId which is sent to only you, and you'll need to keep track of this playerId to perform any actions and play any hands.
/queue/errors If your client sent an invalid message (such as betting when a hand is already in progress or attempting an invalid action on a hand), an error code and an error message will be sent to this queue, which is only sent to the offending client. You may want to consider handling various errors in case your client commits an invalid message. Any unhandled errors committed by your client will hold up the game and could result in a disqualification of the hand or even the game. Possible error messages will be discussed in a later section.
",3
https://github.com/ChadLactaoen/Blackjack,## API Reference, ,3
https://github.com/ChadLactaoen/Blackjack,### /register,"  {
   ""name"":""Zangief""
} This is the name that you will register into the game with. Choose wisely as you won't be able to change this.",3
https://github.com/ChadLactaoen/Blackjack,#### Attempts to register a player into the current game,"  {  
   ""playerId"":""2f658c62-89c2-4a2d-8839-fa56343d5f0d"",
   ""name"":""Zangief"",
   ""seatNum"":1,
   ""chips"":1000,
   ""active"":true
} The most important field in the return object is the playerId. This is your secret key that's given to you and only you! Guard this with your life and make sure you store it somewhere or you'll never be able to play a hand. The active field should always be true. It is only set to false when you no longer have enough chips to play another hand or an admin sets it manually if your client isn't behaving normally.",3
https://github.com/ChadLactaoen/Blackjack,##### Expects:, ,6
https://github.com/ChadLactaoen/Blackjack,##### Returns:, ,6
https://github.com/ChadLactaoen/Blackjack,### /unregister,"  {
   ""playerId"":""2f658c62-89c2-4a2d-8839-fa56343d5f0d""
}",3
https://github.com/ChadLactaoen/Blackjack,#### Attempts to unregister a player from the current game, ,6
https://github.com/ChadLactaoen/Blackjack,##### Expects:, ,6
https://github.com/ChadLactaoen/Blackjack,### /bet,"  {
   ""playerId"":""a2bfc615-6a30-4cc2-b172-771e10ae5e66"",
   ""betAmount"":450
} Use the player id that was given to you. betAmount is the amount you want to place on your next hand.",3
https://github.com/ChadLactaoen/Blackjack,#### Attempts to place a bet on the next hand for a player, ,6
https://github.com/ChadLactaoen/Blackjack,##### Expects:, ,6
https://github.com/ChadLactaoen/Blackjack,### /action,"  {
   ""playerId"":""a2bfc615-6a30-4cc2-b172-771e10ae5e66"",
   ""action"":""HIT"",
   ""handNum"":0
} The action is an enum that tells the server what action you want to perform on a given hand. Possible actions include HIT, STAND, SURRENDER, DOUBLE, SPLIT. Refer to the Rules section of this guide to determine when you can perform these actions. handNum is the index (zero-based) in that player's hand array that you want to perform the action on. For example, if you want to hit on your original hand, handNum would be 0. The only time handNum will not be 0 is you've split a hand and want to act on the second hand after a split. In which case, handNum would be 1 in that specific case, but could be anywhere between 0 and 3.",3
https://github.com/ChadLactaoen/Blackjack,#### Attempts to send an action to be executed on a given hand,"  {
   ""players"":[
      {
         ""name"":""Blanka"",
         ""seatNum"":1,
         ""chips"":550,
         ""hands"":[
            {
               ""betAmount"":450,
               ""cards"":[
                  {
                     ""rank"":""THREE"",
                     ""suit"":""DIAMONDS"",
                     ""cardValue"":3,
                     ""alias"":""3""
                  },
                  {
                     ""rank"":""FOUR"",
                     ""suit"":""HEARTS"",
                     ""cardValue"":4,
                     ""alias"":""4""
                  },
                  {
                     ""rank"":""JACK"",
                     ""suit"":""SPADES"",
                     ""cardValue"":10,
                     ""alias"":""J""
                  }
               ],
               ""result"":null,
               ""handStatus"":""IN_PLAY"",
               ""turn"":true,
               ""handValue"":17
            }
         ],
         ""handsPlayed"":1,
         ""betInForNextRound"":false,
         ""active"":true
      }
   ],
   ""dealer"":null,
   ""dealerUpCard"":{
      ""rank"":""TEN"",
      ""suit"":""DIAMONDS"",
      ""cardValue"":10,
      ""alias"":""T""
   },
   ""gameStatus"":""HAND_IN_PROGRESS"",
   ""lastAction"":{
      ""playerName"":""Blanka"",
      ""action"":""HIT""
   },
   ""cardsLeftInDeck"":99
} You'll see there's a lot going on in this return object. Most of these are self-explanatory, but I'll go through some of the most important fields: 
players is an array of all the currently registered players in the order they were seated. Each player object has some useful info.

hands is an array associated to each player with all the hands (up to 4) that he's currently playing. There should only be one hand per player unless they performed a split.

The result in each hand object is null if the hand is currently in progress. After the hand is over and the hand is evaluated, it'll either be WIN, PUSH, or LOSE
The handStatus field in each hand object represents the current status of the hand. It is IN_PLAY if the hand has not busted, BUST if the hand value is over 21, BLACKJACK if you were dealt a blackjack, and SURRENDER if you decided to surrender for half your bet.
turn is a boolean that determines if it's that hand's turn to be acted on.


betInForNextRound is a boolean that will be set to false if a hand is currently in progress. This is used during a betting round to determine if that player has placed a bet for the upcoming hand, in which case, would be set to true.


dealer will be null if the hand is in progress as it holds information on what cards are in the dealer's hand. During the hand, you can refer to the dealerUpCard field to see what his top card is. After everyone has acted on their hand, the dealer object will be present with information about the dealer and his hand, and the game status will then change to BETTING_ROUND
gameStatus This will either be HAND_IN_PROGRESS or BETTING_ROUND. During the betting round, you can place bets. During a hand, only actions on the current hand to act will be accepted.
",6
https://github.com/ChadLactaoen/Blackjack,##### Expects:,,6
https://github.com/ChadLactaoen/Blackjack,##### Returns:,,6
https://github.com/ChadLactaoen/Blackjack,## Error Messages,"  There may be instances where a client will send an invalid message to the server, and the server will respond with an error message to the offending client with what caused the error to be sent. The entire list of errors is encompassed in the BlackjackErrorCode.java file. For convenience, here's a list of what each error code means and why you may have gotten the error. 
BJ1xx - Error codes in the 100's represent betting errors

BJ101 - The bet amount being sent is more than what the player can afford
BJ102 - You've already made a bet for the current hand
BJ105 - You can't place a bet at this time because there is already a hand in progress
BJ110 - Bet must be in increments of 10


BJ5xx - Error codes in the 500's represent player errors

BJ500 - The game is at max capacity and cannot register another player
BJ550 - Unable to process an action due to an invalid player id
BJ570 - Unable to place a bet because the player's status is currently Inactive. It is only sent to Inactive by the admin, and can only be switched back to Active by an admin


BJ7xx - Error codes in the 700's represent in-game action errors

BJ700 - You send an action for a hand, but it is the betting round
BJ701 - The hand number you want to act on does not exist for the given player
BJ720 - You attempted to double down on a hand that was not eligible for a double down
BJ730 - You attempted to surrender a hand that was not eligible for a surrender
BJ740 - You attempted to split a hand that was not eligible for a split
BJ799 - You are attempting to act on a hand when it is not your turn to act


BJ9xx - Error codes in the 900's are reserved for the Trebek admin panel and should never be sent to clients. If you see an error in the 900's, you're probably accessing endpoints you shouldn't be hitting
",3
https://github.com/ChadLactaoen/Blackjack,## What is Trebek?,"  While perusing the source code for the Blackjack server, you may notice references to Trebek and might be wondering what it is in the first place. Trebek is the admin panel for the blackjack server that has access to override hands and kick players out of the game. The endpoints and logic is intentionally left out of Git since it should only be used by those administering the exercise (although if you're resourceful enough, you could find these endpoints and use them, but please don't). Any illegal use of Trebek could result in disqualification. If you are administrating the Blackjack server and need the source code for the Trebek panel, please contact Chad Tomas.",6
https://github.com/ChadLactaoen/Blackjack,## Final Thoughts,"  Depending on time at the end of the exercise, the idea would be to have four clients at a time going up against each other for a certain number of hands or a certain amount of time. At the end of the given time, the two highest earning clients in that session advance to the next round. The process will repeat until we have 4 clients left, and the highest earner in that final session wins. Note: Winning does not guarantee an internship, but it could be taken into consideration, so try your best. As far as blackjack strategy goes, take advantage of the internet and any other sources you can get your hands on in the allotted time. As a hint, you should consider looking into implementing basic strategy once your client can play the game. Then if there's time, you might even look into card counting and betting strategies. If you're reading this and writing a client, chances are you're a potential intern candidate. Meaning you're probably in Vegas. There will be people in the room who live and breathe blackjack including myself, so feel free to ask questions on strategy or programming. With all that being said, the server is not fool-proof. It was written by one engineer in the span of a week. Meaning, things haven't been fully tested and may have sparse documentation due to time constraints. So, if you look hard enough, you may find some loop holes in the source code that might give you an advantage in one way or another. Use whatever you can to gain an advantage, but also consider the ethics of the situation before doing anything that could critically make the game less fun for everyone else. If you have any questions regarding the project, feel free to contact me. And lastly...",6
https://github.com/ChadLactaoen/Blackjack,### Have fun!, ,-
https://github.com/jrudel/SoccerApp,# Blank HTML App Designer Template for Building Packaged Mobile Web Apps,,135
https://github.com/oscarsale/oscarsale.github.io,# Jekyll Now," Jekyll is a static site generator that's perfect for GitHub hosted blogs (Jekyll Repository) Jekyll Now makes it easier to create your Jekyll blog, by eliminating a lot of the up front setup. 
You don't need to touch the command line
You don't need to install/configure ruby, rvm/rbenv, ruby gems ☺️
You don't need to install runtime dependencies like markdown processors, Pygments, etc
If you're on Windows, this will make setting up Jekyll a lot easier
It's easy to try out, you can just delete your forked repository if you don't like it
 In a few minutes you'll be set up with a minimal, responsive blog like the one below giving you more time to spend on writing epic blog posts! ",12
https://github.com/oscarsale/oscarsale.github.io,## Quick Start, ,3
https://github.com/oscarsale/oscarsale.github.io,### Step 1) Fork Jekyll Now to your User Repository,"  Fork this repo, then rename the repository to yourgithubusername.github.io. Your Jekyll blog will often be viewable immediately at http://yourgithubusername.github.io (if it's not, you can often force it to build by completing step 2) ",3
https://github.com/oscarsale/oscarsale.github.io,### Step 2) Customize and view your site,"  Enter your site name, description, avatar and many other options by editing the _config.yml file. You can easily turn on Google Analytics tracking, Disqus commenting and social icons here too. Making a change to _config.yml (or any file in your repository) will force GitHub Pages to rebuild your site with jekyll. Your rebuilt site will be viewable a few seconds later at http://yourgithubusername.github.io - if not, give it ten minutes as GitHub suggests and it'll appear soon 
There are 3 different ways that you can make changes to your blog's files:
 

Edit files within your new username.github.io repository in the browser at GitHub.com (shown below).
Use a third party GitHub content editor, like Prose by Development Seed. It's optimized for use with Jekyll making markdown editing, writing drafts, and uploading images really easy.
Clone down your repository and make updates locally, then push them to your GitHub repository.

 ",3
https://github.com/oscarsale/oscarsale.github.io,### Step 3) Publish your first blog post,"  Edit /_posts/2014-3-3-Hello-World.md to publish your first blog post. This Markdown Cheatsheet might come in handy.  
You can add additional posts in the browser on GitHub.com too! Just hit the + icon in /_posts/ to create new content. Just make sure to include the front-matter block at the top of each new blog post and make sure the post's filename is in this format: year-month-day-title.md
",3
https://github.com/oscarsale/oscarsale.github.io,## Local Development,"  
Install Jekyll and plug-ins in one fell swoop. gem install github-pages This mirrors the plug-ins used by GitHub Pages on your local machine including Jekyll, Sass, etc.
Clone down your fork git clone https://github.com/yourusername/yourusername.github.io.git
Serve the site and watch for markup/sass changes jekyll serve
View your website at http://127.0.0.1:4000/
Commit any changes and push everything to the master branch of your GitHub user repository. GitHub Pages will then rebuild and serve your website.
",3
https://github.com/oscarsale/oscarsale.github.io,## Moar!,"  I've created a more detailed walkthrough, Build A Blog With Jekyll And GitHub Pages over at the Smashing Magazine website. Check it out if you'd like a more detailed walkthrough and some background on Jekyll. 🤘 It covers: 
A more detailed walkthrough of setting up your Jekyll blog
Common issues that you might encounter while using Jekyll
Importing from Wordpress, using your own domain name, and blogging in your favorite editor
Theming in Jekyll, with Liquid templating examples
A quick look at Jekyll 2.0’s new features, including Sass/Coffeescript support and Collections
",6
https://github.com/oscarsale/oscarsale.github.io,## Jekyll Now Features,"  ?Command-line free fork-first workflow, using GitHub.com to create, customize and post to your blog
?Fully responsive and mobile optimized base theme (Theme Demo)
?Sass/Coffeescript support using Jekyll 2.0
?Free hosting on your GitHub Pages user site
?Markdown blogging
?Syntax highlighting
?Disqus commenting
?Google Analytics integration
?SVG social icons for your footer
?3 http requests, including your avatar ?No installing dependencies
?No need to set up local development
?No configuring plugins
?No need to spend time on theming
?More time to code other things ... wait ?",1
https://github.com/oscarsale/oscarsale.github.io,## Questions?,  Open an Issue and let's chat!,56
https://github.com/oscarsale/oscarsale.github.io,## Other forkable themes,"  You can use the Quick Start workflow with other themes that are set up to be forked too! Here are some of my favorites: 
Hyde by MDO
Lanyon by MDO
mojombo.github.io by Tom Preston-Werner
Left by Zach Holman
Minimal Mistakes by Michael Rose
Skinny Bones by Michael Rose
",6
https://github.com/oscarsale/oscarsale.github.io,## Credits,"  
Jekyll - Thanks to its creators, contributors and maintainers.
SVG icons - Thanks, Neil Orange Peel. They're beautiful.
Solarized Light Pygments - Thanks, Edward.
Joel Glovier - Great Jekyll articles. I used Joel's feed.xml in this repository.
David Furnes, Jon Uy, Luke Patton - Thanks for the design/code reviews.
Bart Kiers, Florian Simon, Henry Stanley, Hun Jae Lee, Javier Cejudo, Peter Etelej, Ben Abbott, Ray Nicholus, Erin Grand, Léo Colombaro, Dean Attali, Clayton Errington, Colton Fitzgerald, Trace Mayer - Thanks for your fantastic contributions to the project!
",5
https://github.com/oscarsale/oscarsale.github.io,## Contributing,"  Issues and Pull Requests are greatly appreciated. If you've never contributed to an open source project before I'm more than happy to walk you through how to create a pull request. You can start by opening an issue describing the problem that you're looking to resolve and we'll go from there. I want to keep Jekyll Now as minimal as possible. Every line of code should be one that's useful to 90% of the people using it. Please bear that in mind when submitting feature requests. If it's not something that most people will use, it probably won't get merged. 💂‍♂?,7
1284,https://github.com/emil10001/QuickGraphAndroid,#QuickGraph for Android,,125
1285,https://github.com/choreographing-quokka/Q,Q, Q is a community playlist app that allows users to share and manage a music playlist together in a group setting. With Q",7
https://github.com/emil10001/QuickGraphAndroid,#QuickGraph for Android,,125
https://github.com/choreographing-quokka/Q,# Q,"Q is a community playlist app that allows users to share and manage a music playlist together in a group setting. With Q, a designated host can create a room in which other users can join. In this room, users and the host can collaborate on a playlist by searching for songs on Soundcloud and adding them to a playlist queue. The host has the ability to play, pause, skip, and delete songs on the playlist. Audio is only played through the hosts computer or device. You and the people around you can all use Q's server to search for music and manage the playlist together in REAL-TIME.",1
https://github.com/choreographing-quokka/Q,## Team,"Product Owner: Harun Davood
Scrum Master: Joan Xie,
Development Team Members: Spencer Gulbronson, Jaylum Chen",5
https://github.com/choreographing-quokka/Q,## Table of Contents,"1. [Usage](#Usage)
2. [Requirements](#requirements)
3. [Development](#development)
    3a. [Installing Dependencies](#installing-dependencies)
    3b. [Tasks](#tasks)
4. [Team](#team)
5. [Contributing](#contributing)",6
https://github.com/choreographing-quokka/Q,## Usage,"For Q to work properly, a designated host needs to login by clicking 'CREATE ROOM' on the login page and entering 'test' as the password. The host also needs to login before any other user adds a song to the queue; this is a known issue and flawed feature. Users who are not the host must click 'ENTER ROOM' to join the host's room. 

Multiple rooms for different hosts is a feature that has not yet been developed. Ideally, a host should be able to create a room which will have a distinct URL has that the host can give to other users. Other users can use this url to access the host's playlist. 

It was also concious decsion to enhace user experience to not handle strict authentication for users to make it easy and effortless for users to join and create rooms.

TO start Q's server, first start mongodb server (mongod) and run npm start inside the project's main directory.

Q uses soundcloud's API.  In the current implementation, we had the client ID visible in the front end, but in later iterations, this searching should be moved to and hidden in the backend.

**Q uses ionic framework to enhance UI for mobile users: http://ionicframework.com/**",3
https://github.com/choreographing-quokka/Q,## Requirements,"npm modules----------------
""bower"": ""^1.3.3"",
""body-parser"": ""^1.14.2"",
""express"": ""^4.13.3"",
""mongoose"": ""^4.3.4"",
""socket.io"": ""^1.4.0""

bower-----------------------
""ionic"": ""driftyco/ionic-bower#v1.1.1""
""angular"": ""1.4.3"",
""angular-animate"": ""1.4.3"",
""angular-sanitize"": ""1.4.3"",
""angular-ui-router"": ""0.2.13""",3
https://github.com/choreographing-quokka/Q,## Development,"(file structure: view in sublime or raw to see formatted structure)
Q
 bower.json (bower components: installed in client/www/lib)
 client
    config.xml (ionic config file x)
    ionic.project (for ionic x)
    scss
       ionic.app.scss (for ionic x)
    www
    css
       style.css (main css file for custom styles)
    img
       icon2.png (main logo)
       icon.png (alternative logo)
       ionic.png (ionic logo)
       logoQ.png (large main logo)
       notavailable.gif (image unavailable soundcloud image)
       notavailable.jpg (image unavailable soundcloud image)
       notavailable.png (image unavailable soundcloud image)
       playing.gif
    index.html (main index file)
    js
       angular-soundmanager2-Q.js (soundplayer with socket config)
       app.js (font-end main js)
       controllers.js
       services.js
    lib
       angular-soundmanager2
       dist
       angular-soundmanager2-Q.js (original untouched)
    templates
    landingPage.html (landing page)
    playlist.html (playlist index)
 _CONTRIBUTING.md
 _.editorconfig
 _.gitattributes
 _.gitignore
 _.jshintrc
 package.json
 _PRESS-RELEASE.md
 Procfile
 _README.md
 server
    db
       dbConfig.js
       userController.js
       userModel.js
    README.txt
    routes.js (server routing)
    server.js (main server)
    test.html (not used)
 _STYLE-GUIDE.md
 _.travis.yml",3
https://github.com/choreographing-quokka/Q,## Installing Dependencies,"From within the root directory:
sudo npm install -g bower
npm install
bower install
run bower install",3
https://github.com/choreographing-quokka/Q,## Roadmap,View the project roadmap www.github.com/mightychondria/Q/issues,4
https://github.com/choreographing-quokka/Q,## Contributing,See CONTRIBUTING.md for contribution guidelines.,7
https://github.com/kwangkim/jekyll-bootstrap,# Jekyll-Bootstrap, The quickest way to start and publish your Jekyll powered blog. 100% compatible with GitHub pages,1
https://github.com/kwangkim/jekyll-bootstrap,## Usage,  For all usage and documentation please see: http://jekyllbootstrap.com,3
https://github.com/kwangkim/jekyll-bootstrap,## Version,"  0.3.0 - stable and versioned using semantic versioning. NOTE: 0.3.0 introduces a new theme which is not backwards compatible in the sense it won't look like the old version.
However, the actual API has not changed at all.
You might want to run 0.3.0 in a branch to make sure you are ok with the theme design changes.",4
https://github.com/kwangkim/jekyll-bootstrap,## Contributing,"  To contribute to the framework please make sure to checkout your branch based on jb-development!!
This is very important as it allows me to accept your pull request without having to publish a public version release. Small, atomic Features, bugs, etc.
Use the jb-development branch but note it will likely change fast as pull requests are accepted.
Please rebase as often as possible when working.
Work on small, atomic features/bugs to avoid upstream commits affecting/breaking your development work. For Big Features or major API extensions/edits:
This is the one case where I'll accept pull-requests based off the master branch.
This allows you to work in isolation but it means I'll have to manually merge your work into the next public release.
Translation : it might take a bit longer so please be patient! (but sincerely thank you). Jekyll-Bootstrap Documentation Website. The documentation website at http://jekyllbootstrap.com is maintained at https://github.com/plusjade/jekyllbootstrap.com",67
https://github.com/kwangkim/jekyll-bootstrap,## License,  MIT,5
https://github.com/zawieja/java8collections,# Crash course in collections with Java 8, All exercises can be done in main method of CollectionsExercises class.,1
https://github.com/zawieja/java8collections,## Lambda Expressions, ,3
https://github.com/zawieja/java8collections,### Example,  Writing down elements of given beerNames list: beerNames.forEach(s -> System.out.println(s));,3
https://github.com/zawieja/java8collections,### Example,"  Sorting given list in aphabet order: beerNames.sort((String a, String b) -> {return a.compareTo(b);});",3
https://github.com/zawieja/java8collections,### Explanation,"  Functional Inrerface is interface with exaclty one abstract method. It can be annotated with @FuctionalInterface. In Java 8 there are built in functional interfaces i.e. Comparator (with compare abstract method). When lambda is implementation of abstract method of functional interface, instance of this functional interface can be created as follows.",3
https://github.com/zawieja/java8collections,#### Example,"  Comparator<String> comparator = (String a, String b) -> {return a.compareTo(b);};

beerNames.sort(comparator);",3
https://github.com/zawieja/java8collections,### Syntax,"  General form of lambda expression is (parameters) -> { statements;}  // (String a, String b) -> {return a.compareTo(b);} When there is only one expresion, it can be simplified as follows (return should me ommitted): (parameters) -> expression      // (String a, String b) -> a.compareTo(b) When type declaration can be ommited, it can be simplified as follows: (parameters) -> expression      // (a, b) -> a.compareTo(b) When there is only one parameter and there is no need to declare type, it can be simplified as follows: parameter -> expression         // (String s) -> System.out.printout(s)
                                // to
                                // s -> System.out.println(s)",3
https://github.com/zawieja/java8collections,### Exercise 1,"  Simplify lambda in following code snippet. Collections.sort(beerNames, (String a, String b) -> {return a.compareTo(b);} );
",3
https://github.com/zawieja/java8collections,#### Solution,"  
Click to show
Lambda can be simplified as follows:
(String a, String b) -> a.compareTo(b)
or
(a, b) -> a.compareTo(b)
",3
https://github.com/zawieja/java8collections,### Example,"  Consider following code snippet. Collections.sort(beerNames, (a, b) -> a.compareTo(b));
 Since Java 8, List interface has sort method which takes one parameter - instance of Comparator. Collections.sort can be replaced as follows: beerNames.sort((a, b) -> a.compareTo(b));",3
https://github.com/zawieja/java8collections,### Exercise 2,"  Refactor following code to Java 8 level. Collections.sort(beers, new Comparator<Beer>() {
    @Override
    public int compare(Beer a, Beer b) {
        return a.getBottleVolume() - b.getBottleVolume();
    }
});
",3
https://github.com/zawieja/java8collections,#### Solution,"  
Click to show
Replace Collections.sort with List.sort and replace anonymous class with lambda:
beers.sort((a, b) -> a.getBottleVolume() - b.getBottleVolume());
",3
https://github.com/zawieja/java8collections,## Method References,  Lambda expressions can be replaced with method references. Method reference has following form: ClassName :: methodName,3
https://github.com/zawieja/java8collections,#### Rule of thumb for replacing lambda with reference method:,"  lambda form                      |  reference method form
-------------------------------------------------------------------------------------------------
p -> ClassName.methodName(p)     |  ClassName::methodName
p -> new ClassName(p)            |  ClassName::new
p -> p.methodName()              |  ClassName::methodName // where ClassName is class of object p
(p, q) -> p.methodName(q)        |  ClassName::methodName // where ClassName is class of object p Examples (respectivly): lambda                           |  reference method
-------------------------------------------------------------------------------------------------
p -> System.out.println(p)       |  System.out::println
p -> new HashSet<>(p)            |  HashSet::new
p -> p.getName()                 |  Beer::getName 
(p, q) -> p.compareTo(q)         |  String::compareTo",3
https://github.com/zawieja/java8collections,## lambda form                      |  reference method form,  Replace lambda expression with method reference. beerNames.forEach(s -> System.out.println(s));,3
https://github.com/zawieja/java8collections,## lambda                           |  reference method,"  
Click to show
beerNames.forEach(System.out::println);
",3
https://github.com/zawieja/java8collections,### Exercise 3,"  Replace lambda expression with method reference. beerNames.sort((a, b) -> a.compareTo(b));",3
https://github.com/zawieja/java8collections,#### Solution,"  
Click to show
beerNames.sort(String::compareTo);
",3
https://github.com/zawieja/java8collections,### Exercise 4,"  Replace lambda expressions with method references. beers.stream()
        .map(b -> b.getName())
        .forEach(b -> System.out.println(b));",3
https://github.com/zawieja/java8collections,#### Solution,"  
Click to show
beers.stream()
        .map(Beer::getName)
        .forEach(System.out::println);
",3
https://github.com/zawieja/java8collections,### Exercise 5,"  Replace lambda expressions with method reference. beers.stream()
        .map(b -> b.getHops())
        .map(b -> new HashSet<>(b))
        .forEach(b -> System.out.println(b));",3
https://github.com/zawieja/java8collections,#### Solution,"  
Click to show
beers.stream()
        .map(Beer::getHops)
        .map(HashSet::new)
        .forEach(System.out::println);
",3
https://github.com/zawieja/java8collections,### Exercise 6,"  Stream (java.util.Stream) is a sequence of elements supporting operations. There are two kinds of stream operations: 
intermediate (returns Stream) i.e.: filter
terminal  (returns other type) i.e.: forEach
 Operations on stream don't modify source of stream. Stream operations form stream pipelines.",3
https://github.com/zawieja/java8collections,#### Solution, ,3
https://github.com/zawieja/java8collections,## Streams,"  Writing down beers that have more than 5.0% alcohol in volume: beers.stream()
        .filter(b -> b.getAlcoholByValue() > 5.0)
        .forEach(System.out::println);",3
https://github.com/zawieja/java8collections,## Streams: filter,"  Predicate is functional interface which is boolean-valued function of one argument.
Operation filter takes instance of Predicate as argument and reduces stream to elements for which Predicate return true. In above example predicate is lambda b -> b.getAlcoholByValue() > 5.0. filter is intermediate operation (as it returns stream).",3
https://github.com/zawieja/java8collections,### Example,  Write down beers containg Cascade hop and not containg Amarillo hop.,3
https://github.com/zawieja/java8collections,#### Explanation,"  
Click to show
beers.stream()
        .filter(b -> b.getHops().contains(HOP_CASCADE))
        .filter(b -> !b.getHops().contains(HOP_AMARILLO))
        .forEach(System.out::println);
",3
https://github.com/zawieja/java8collections,### Exercise 7, ,3
https://github.com/zawieja/java8collections,#### Solution,"  Writing down names of beers from given list. beers.stream()
        .map(b -> b.getName())
        .forEach(System.out::println);",3
https://github.com/zawieja/java8collections,## Streams: map,  Operation map is intermediate operation (returns stream) which takes instance of Function as argument. It transforms (maps) each element of stream to another according to passed Function. Function is functonal interface.,3
https://github.com/zawieja/java8collections,### Example,  Write down names of beers containg Cascade hop.,3
https://github.com/zawieja/java8collections,#### Explanation,"  
Click to show
beers.stream()
        .filter(b -> b.getHops().contains(HOP_CASCADE))
        .map(b -> b.getName() )
        .forEach(System.out::println);
",3
https://github.com/zawieja/java8collections,### Exercise 8,"  Elements of stream can be sorted with sorted method. It takes instance of Comparator as argument. When sorted is called whitout argument, stream elements are sorted with natural order. sorted is intermediate operation.",3
https://github.com/zawieja/java8collections,#### Solution,  Write down beers from given list ordered by bottle volume.,3
https://github.com/zawieja/java8collections,## Streams: sorted,"  
Click to show
beers.stream()
        .sorted((a, b) -> (a.getBottleVolume() - b.getBottleVolume()))
        .forEach(System.out::println);
",3
https://github.com/zawieja/java8collections,### Exercise 9,  Write down names of beers in alphabetical (natural) order.,3
https://github.com/zawieja/java8collections,#### Solution,"  
Click to show
beers.stream()
        .map(Beer::getName)
        .sorted()
        .forEach(System.out::println);
",3
https://github.com/zawieja/java8collections,### Exercise 10,"  Stream elements can be accumulated into collection with collect method (i.e. collect(Collectors.toList()), Collectors.toCollection(toSet())).",3
https://github.com/zawieja/java8collections,#### Solution,  Create a list of beer names.,3
https://github.com/zawieja/java8collections,## Streams: collect,"  beerNames = beers.stream()
        .map(b -> b.getName())
        .collect(Collectors.toList());",3
https://github.com/zawieja/java8collections,### Exercise 11,  Create a list of beers that have more than 5.0% alcohol in volume.,3
https://github.com/zawieja/java8collections,#### Solution,"  
Click to show
List strongBeers = beers.stream()
        .filter(b -> b.alcoholByValue > 5.0)
        .collect(Collectors.toList());
",3
https://github.com/zawieja/java8collections,### Exercise 12,"  Creating a map of beers with value of bottle volume as keys: Map beersByVolume = beers.stream()
        .collect(Collectors.groupingBy(b -> b.getBottleVolume()));

beersByVolume.forEach((k,v) -> System.out.println(""key: "" + k.toString() + "" value: "" + v.toString())); Method Collectors.groupingBy is used to create map. It groups elements according to passed classification function.",3
https://github.com/zawieja/java8collections,#### Solution,  Create a map of beer names with first letters as keys.,3
https://github.com/zawieja/java8collections,### Example,"  
Click to show
Map beerIndex = beerNames.stream()
        .collect(Collectors.groupingBy(s -> s.charAt(0)));

beerIndex.forEach((k,v) -> System.out.println(""key: "" + k.toString() + "" value: "" + v.toString()));

",3
https://github.com/zawieja/java8collections,### Exercise 13,  Create a sorted list of beer names containing Cascade hop.,3
https://github.com/zawieja/java8collections,#### Solution,"  
Click to show
List<String> cascadeBeers = beers.stream()
        .filter(b -> b.getHops().contains(HOP_CASCADE))
        .map(Beer::getName)
        .sorted()
        .collect(Collectors.toList());
",3
https://github.com/zawieja/java8collections,"### Exercise 14 (summing up: filter, map, sorted, collect)", ,3
https://github.com/zawieja/java8collections,#### Solution,"  Printing sum of bottle volumes of beers from given list: int volumeSum = beers.stream()
          .mapToInt((beer) -> beer.getBottleVolume())
          .sum();

System.out.println(volumeSum);",3
https://github.com/zawieja/java8collections,## Streams: other terminating methods,"  Printing maximum bottle volume: OptionalInt maxVolume = beers.stream()
       .mapToInt((beer) -> beer.getBottleVolume())
       .max();
        
maxVolume.ifPresent(System.out::println);                ",3
https://github.com/zawieja/java8collections,### Example,  Operation max() returns OptionalInt object. Class Optional (along with OptionalInt and OptionalDouble) is introduced to Java 8. It is container which can contain or not contain value. It protects against NullPointerException (no need to write if (maxVolume != null) checks).,3
https://github.com/zawieja/java8collections,### Example,  Print average bottle volume.,3
https://github.com/zawieja/java8collections,#### Explanation,,3
https://github.com/zawieja/java8collections,### Example,,3
https://github.com/zawieja/java8collections,#### Solution,"  OptionalDouble averageVolume = beers.stream()
        .mapToInt((beer) -> beer.getBottleVolume())
        .average();

averageVolume.ifPresent(System.out::println);",3
https://github.com/zawieja/java8collections,### Exercise 15,"  Print average alcohol of beers: 
containing Cascade hop
with bottles volume bigger than 500 ml
",3
https://github.com/zawieja/java8collections,#### Solution,"  
Click to show
OptionalDouble averageAlcohol = beers.stream()
        .filter(b -> b.getHops().contains(HOP_CASCADE))
        .filter(b -> b.getBottleVolume() > 500)
        .mapToDouble(b -> b.getAlcoholByValue())
        .average();

averageAlcohol.ifPresent(System.out::println);
",3
https://github.com/zawieja/java8collections,## References,"  
Lambda Expressions (The Java Tutorials): https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html
Java 8 Tutorial: http://winterbe.com/posts/2014/03/16/java-8-tutorial/
Java 8 Stream Tutorial: http://winterbe.com/posts/2014/07/31/java8-stream-tutorial-examples/
",6
https://github.com/Jaiimmortal/LCS,# LCS," The longest common subsequence (LCS) problem is the problem of finding the longest subsequence common to all sequences in a set of sequences (often just two sequences). It differs from problems of finding common substrings: unlike substrings, subsequences are not required to occupy consecutive positions within the original sequences. The longest common subsequence problem is a classic computer science problem, and has applications in bioinformatics. Use Python 2.7 (while entering the string, enter them in quotes :P) This algorithm, printing the Longest Common Subsequence problem falls under Dynammic programming and has been implemented two compare two DNA strands and get the lenghthiest subsequence of all the genereated subsequences and print it's length. It also focuses on avoiding the overlapping i.e., avoid calculating the subsequence that has already been generated. Random DNA sequences can be generated here Screenshot:  The above is a screenshot of py2 version of the code. For python3 version , execute the try.py For python2 version , execute the main.py",136
https://github.com/Crysty-Yui/android-async-http,# Asynchronous Http Client for Android,"  An asynchronous, callback-based Http client for Android built on top of Apache's HttpClient libraries.",1
https://github.com/Crysty-Yui/android-async-http,## Changelog,  See what is new in version 1.4.7 released on 9th May 2015 https://github.com/loopj/android-async-http/blob/1.4.7/CHANGELOG.md,4
https://github.com/Crysty-Yui/android-async-http,## Javadoc,  Latest Javadoc for 1.4.7 release are available here (also included in Maven repository): http://loopj.com/android-async-http/doc/,6
https://github.com/Crysty-Yui/android-async-http,## Features,"  
Make asynchronous HTTP requests, handle responses in anonymous callbacks
HTTP requests happen outside the UI thread
Requests use a threadpool to cap concurrent resource usage
GET/POST params builder (RequestParams)
Multipart file uploads with no additional third party libraries
Tiny size overhead to your application, only 60kb for everything
Automatic smart request retries optimized for spotty mobile connections
Automatic gzip response decoding support for super-fast requests
Optional built-in response parsing into JSON (JsonHttpResponseHandler)
Optional persistent cookie store, saves cookies into your app's SharedPreferences
",1
https://github.com/Crysty-Yui/android-async-http,## Examples,"  For inspiration and testing on device we've provided Sample Application.
See individual samples here on Github
To run Sample application, simply clone the repository and run this command, to install it on connected device gradle :sample:installDebug",36
https://github.com/Crysty-Yui/android-async-http,## Maven,"  You can now integrate this library in your project via Maven. There are available two kind of builds. releases, maven central http://central.maven.org/maven2/com/loopj/android/android-async-http/ Maven URL: http://repo1.maven.org/maven2/
GroupId: com.loopj.android
ArtifactId: android-async-http
Version: 1.4.7
Packaging: JAR or AAR
 Gradle: com.loopj.android:android-async-http:1.4.7 development snapshots https://oss.sonatype.org/content/repositories/snapshots/com/loopj/android/android-async-http/ Maven URL: https://oss.sonatype.org/content/repositories/snapshots/
GroupId: com.loopj.android
ArtifactId: android-async-http
Version: 1.4.8-SNAPSHOT
Packaging: JAR or AAR
 Gradle: com.loopj.android:android-async-http:1.4.8-SNAPSHOT",3
https://github.com/Crysty-Yui/android-async-http,"## Documentation, Features and Examples",  Full details and documentation can be found on the project page here: http://loopj.com/android-async-http/ ,6
https://github.com/paige11/cartoon-collections-001-prework-web,## Cartoon Collections,,1
https://github.com/paige11/cartoon-collections-001-prework-web,## Objectives,"  
Get familiar iterating through arrays with enumerator methods like .collect or .map, .find, and .include.
Build methods and control their return values.
Practice control flow with if and else statements.
",12
https://github.com/paige11/cartoon-collections-001-prework-web,## Instructions,"  There are four methods to complete in this lab: 
roll_call_dwarves
summon_captain_planet
long_planeteer_calls
find_the_cheese
",3
https://github.com/paige11/cartoon-collections-001-prework-web,#### Method 1 ?`roll_call_dwarves`,"   This method should accept an array of dwarf names, for instance: [""Doc"", ""Dopey"", ""Bashful"", ""Grumpy""] It should then print out each name using puts. The print-out should look like this: 

Doc
Dopey
Bashful
Grumpy

 Look into the each_with_index method. Once the test for this method is passing, move on to the next method.",3
https://github.com/paige11/cartoon-collections-001-prework-web,#### Method 2 ?`summon_captain_planet`,"   This method should accept an array argument of planeteer calls that will look like this: planeteer_calls = [""earth"", ""wind"", ""fire"", ""water"", ""heart""] It should then capitalize each element and add an exclamation point at the end. The return value of this method should be an array, in this example: summon_captain_planet(planeteer_calls)
#=> [""Earth!"", ""Wind!"", ""Fire!"", ""Water!"", ""Heart!""]
 The .map or .collect method might be appropriate for this task, take a look at it here and here. Once the test for this method is passing, move on to the next method, long planeteer calls.",3
https://github.com/paige11/cartoon-collections-001-prework-web,"#=> [Earth!""",,-
https://github.com/paige11/cartoon-collections-001-prework-web,#### Method 3 ?`long_planeteer_calls`,"  The long_planeteer_calls method should accept an array of calls. The method should tell us if any of the calls are longer than four characters. For example: short_words = [""puff"", ""go"", ""two""]
long_planeteer_calls(short_words)
#=> false

assorted_words = [""two"", ""go"", ""industrious"", ""bop""]
long_planeteer_calls(assorted_words)
#=> true Notice the return value of this method is either true or false, depending on the array it was given as an argument. Checkout the Ruby docs on arrays for a hint. Once the test for this method is passing, move on to the last method.",36
https://github.com/paige11/cartoon-collections-001-prework-web,#=> false,,3
https://github.com/paige11/cartoon-collections-001-prework-web,#=> true,,3
https://github.com/paige11/cartoon-collections-001-prework-web,#### Method 4 ?`find_the_cheese`,"   The find_the_cheese method should accept an array of strings. It should then look through these strings to find and return the first string that is a type of cheese. The types of cheese that appear are  ""cheddar"", ""gouda"", and ""camembert"". For example: snacks = [""crackers"", ""gouda"", ""thyme""]
find_the_cheese(snacks)
#=> ""gouda""

soup = [""tomato soup"", ""cheddar"", ""oyster crackers"", ""gouda""]
find_the_cheese(soup)
#=> ""cheddar"" If, sadly, a list of ingredients does not include cheese, return nil: ingredients = [""garlic"", ""rosemary"", ""bread""]
find_the_cheese(ingredients)
#=> nil You can assume that all strings will be lowercase. Take a look at the .include method for a hint. This method asks you to return a string value instead of printing it so keep that in mind.",3
https://github.com/paige11/cartoon-collections-001-prework-web,"#=> gouda""""",,3
https://github.com/paige11/cartoon-collections-001-prework-web,"#=> cheddar""""",,3
https://github.com/paige11/cartoon-collections-001-prework-web,#=> nil,,3
https://github.com/paige11/cartoon-collections-001-prework-web,## Resources,"  
The .include method
The .each_with_index method
The .map method
",6
https://github.com/iL-Mattone/konstantin-fluentd,# Fluentd,"  Install, configure, and manage Fluentd data collector.",1
https://github.com/iL-Mattone/konstantin-fluentd,## Module Description,"  
Installs td-agent package
Generates configuration file td-agent.conf
Generates custom configuration files and saves them to config.d/
Manages td-agent service
Installs Fluentd gem plugins
",1
https://github.com/iL-Mattone/konstantin-fluentd,## Usage, ,3
https://github.com/iL-Mattone/konstantin-fluentd,### Routing Events To Elasticsearch,"  include fluentd

fluentd::plugin { 'fluent-plugin-elasticsearch': }

fluentd::config { '500_elasticsearch.conf':
  config => {
    'source' => {
      'type' => 'unix',
      'path' => '/tmp/td-agent/td-agent.sock',
    },
    'match'  => {
      'tag_pattern'     => '**',
      'type'            => 'elasticsearch',
      'index_name'      => 'foo',
      'type_name'       => 'bar',
      'logstash_format' => true,
    }
  }
}",3
https://github.com/iL-Mattone/konstantin-fluentd,### Forwarding Events To Fluentd Aggregator,"  include fluentd

fluentd::config { '600_forwarding.conf':
  config => {
    'source' => {
      'type' => unix,
      'path' => '/tmp/td-agent/td-agent.sock',
    },
    'match'  => {
      'tag_pattern' => '**',
      'type'        => forward,
      'server'      => [
        { 'host' => 'example1.com', 'port' => 24224 },
        { 'host' => 'example2.com', 'port' => 24224 },
      ]
    }
  }
}",3
https://github.com/iL-Mattone/konstantin-fluentd,### Config File Naming,"  All configs employ a numbering system in the resource's title that is used for
ordering. When titling your config, make sure you prefix the filename with a
number, for example, 999_catch_all.conf, 500_elasticsearch.conf (999 has
smaller priority than 500)",3
https://github.com/iL-Mattone/konstantin-fluentd,## Reference, ,6
https://github.com/iL-Mattone/konstantin-fluentd,### Classes, ,6
https://github.com/iL-Mattone/konstantin-fluentd,#### Public Classes,"  
fluentd: Main class, includes all other classes.
",6
https://github.com/iL-Mattone/konstantin-fluentd,#### Private Classes,"  
fluentd::install: Handles the packages.
fluentd::service: Handles the service.
",6
https://github.com/iL-Mattone/konstantin-fluentd,### Parameters,  The following parameters are available in the fluentd class:,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `repo_install`,  Default value: true,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `repo_name`,  Default value: 'treasuredata',6
https://github.com/iL-Mattone/konstantin-fluentd,#### `repo_desc`,  Default value: 'TreasureData',6
https://github.com/iL-Mattone/konstantin-fluentd,#### `repo_url`,  Default value: 'http://packages.treasuredata.com/2/redhat/$releasever/$basearch',6
https://github.com/iL-Mattone/konstantin-fluentd,#### `repo_enabled`,  Default value: true,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `repo_gpgcheck`,  Default value: true,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `repo_gpgkey`,  Default value: 'https://packages.treasuredata.com/GPG-KEY-td-agent',6
https://github.com/iL-Mattone/konstantin-fluentd,#### `repo_gpgkeyid`,  Default value: 'C901622B5EC4AF820C38AB861093DB45A12E206F',6
https://github.com/iL-Mattone/konstantin-fluentd,#### `package_name`,  Default value: 'td-agent',6
https://github.com/iL-Mattone/konstantin-fluentd,#### `package_ensure`,  Default value: present,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `service_name`,  Default value: 'td-agent',6
https://github.com/iL-Mattone/konstantin-fluentd,#### `service_ensure`,  Default value: running,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `service_enable`,  Default value: true,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `service_manage`,  Default value: true,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `config_file`,  Default value: '/etc/td-agent/td-agent.conf',6
https://github.com/iL-Mattone/konstantin-fluentd,### Public Defines,"  
fluentd::config: Generates custom configuration files.
fluentd::plugin: Installs plugins.
 The following parameters are available in the fluentd::plugin defined type:",6
https://github.com/iL-Mattone/konstantin-fluentd,#### `title`,  Plugin name,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `plugin_ensure`,  Default value: present,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `plugin_source`,  Default value: 'https://rubygems.org' The following parameters are available in the fluentd::config defined type:,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `title`,  Config filename,6
https://github.com/iL-Mattone/konstantin-fluentd,#### `config`,"  Config Hash, please see usage examples.",6
https://github.com/iL-Mattone/konstantin-fluentd,## Limitations,"  Tested only on CentOS 7, Ubuntu 14.04, Debian 7.8",3
https://github.com/iL-Mattone/konstantin-fluentd,## Development,  Bug reports and pull requests are welcome!,6
https://github.com/iL-Mattone/konstantin-fluentd,### Running Tests,"  $ bundle install
$ bundle exec rake lint
$ bundle exec rake metadata
$ bundle exec rake spec
$ bundle exec rake beaker BEAKER_set=centos-7-x64
$ bundle exec rake beaker BEAKER_set=debian-7-amd64
$ bundle exec rake beaker BEAKER_set=ubuntu-server-1404-x64
 Relevant Beaker docs: https://github.com/puppetlabs/beaker/blob/master/docs/How-to-Write-a-Beaker-Test-for-a-Module.md",3
https://github.com/iL-Mattone/konstantin-fluentd,### TODO:,"  
Remove rubygems package dependency
",4
https://github.com/iL-Mattone/konstantin-fluentd,## License,"  Copyright 2015 SPB TV AG Licensed under the Apache License, Version 2.0 (the ""License""); you may not use
this file except in compliance with the License. You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed
under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR
CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations
under the License.",5
https://github.com/neumanta/frontend-nanodegree-feedreader,#Frontend Nanodegree Tom's FeedReader Instructions,,1
https://github.com/neumanta/frontend-nanodegree-feedreader,##,,-
https://github.com/neumanta/frontend-nanodegree-feedreader,##Loading Tom's FeedReader,,13
https://github.com/neumanta/frontend-nanodegree-feedreader,# Project Overview as provided by Udacity,"  In this project you are given a web-based application that reads RSS feeds. The original developer of this application clearly saw the value in testing, they've already included Jasmine and even started writing their first test suite! Unfortunately, they decided to move on to start their own company and we're now left with an application with an incomplete test suite. That's where you come in.",1
https://github.com/neumanta/frontend-nanodegree-feedreader,##,,-
https://github.com/neumanta/frontend-nanodegree-feedreader,## Why this Project?,"  Testing is an important part of the development process and many organizations practice a standard of development known as ""test-driven development"". This is when developers write tests first, before they ever start developing their application. All the tests initially fail and then they start writing application code to make these tests pass. Whether you work in an organization that uses test-driven development or in an organization that uses tests to make sure future feature development doesn't break existing features, it's an important skill to have!",2
https://github.com/neumanta/frontend-nanodegree-feedreader,## What will I learn?,  You will learn how to use Jasmine to write a number of tests against a pre-existing application. These will test the underlying business logic of the application as well as the event handling and DOM manipulation.,1
https://github.com/neumanta/frontend-nanodegree-feedreader,## How will this help my career?,"  
Writing effective tests requires analyzing multiple aspects of an application including the HTML, CSS and JavaScript - an extremely important skill when changing teams or joining a new company.
Good tests give you the ability to quickly analyze whether new code breaks an existing feature within your codebase, without having to manually test all of the functionality.
",1
https://github.com/neumanta/frontend-nanodegree-feedreader,# How will I complete this project?,"  
---Download the required project assets.
---Review the functionality of the application within your browser.
---Explore the application's HTML (./index.html), CSS (./css/style.css) and JavaScript (./js/app.js) to gain an understanding of how it works.
---Explore the Jasmine spec file in ./jasmine/spec/feedreader.js
---Edit the allFeeds variable in ./js/app.js to make the provided test fail and see how Jasmine visualizes this failure in your application.
---Return the allFeeds variable to a passing state.
---Write a test that loops through each feed in the allFeeds object and ensures it has a URL defined and that the URL is not empty.
---Write a test that loops through each feed in the allFeeds object and ensures it has a name defined and that the name is not empty.
---Write a new test suite named ""The menu"".
---Write a test that ensures the menu element is hidden by default. You'll have to analyze the HTML and the CSS to determine how we're performing the hiding/showing of the menu element.
---Write a test that ensures the menu changes visibility when the menu icon is clicked. This test should have two expectations: does the menu display when clicked and does it hide when clicked again.
---Write a test that ensures when the loadFeed function is called and completes its work, there is at least a single .entry element within the .feed container. Remember, loadFeed() is asynchronous so this test wil require the use of Jasmine's beforeEach and asynchronous done() function.
---Write a test that ensures when a new feed is loaded by the loadFeed function that the content actually changes. Remember, loadFeed() is asynchronous.
---When complete - all of your tests should pass.
",3
https://github.com/randhika/LOST,# LOST,  Location Open Source Tracker for Android,1
https://github.com/randhika/LOST,## Usage,"  LOST is a drop-in replacement for Google Play Services FusedLocationProviderApi that makes calls directly to the LocationManger. This project seeks to provide an open source alternative to the Fused Location Provider that depends only on the Android SDK. Operations supported at this time include getting the last known location and registering for location updates. Connecting to the LOST API Client When using LOST, GoogleApiClient is replaced by LostApiClient. Connecting to LOST is even easier since there are no ConnectionCallbacks or OnConnectionFailedListener objects to manage. LostApiClient lostApiClient = new LostApiClient.Builder(this).build();
lostApiClient.connect(); LOST instantly connects to the LocationManager and can immediately retrieve that last known location or begin sending location updates. Getting the Last Known Location Once connected you can request the last known location. The actual logic to determine the best most recent location is based this classic blog post by Reto Meier. Location location = LocationServices.FusedLocationApi.getLastLocation();
if (location != null) {
  // Do stuff
} Requesting Location Updates LOST also provides the ability to request ongoing location updates. You can specify the update interval, minimum displacement, and priority. The priority determines which location providers will be activated. LocationRequest request = LocationRequest.create()
    .setInterval(5000)
    .setSmallestDisplacement(10)
    .setPriority(LocationRequest.PRIORITY_LOW_POWER);

LocationListener listener = new LocationListener() {
  @Override
  public void onLocationChanged(Location location) {
    // Do stuff
  }
};

LocationServices.FusedLocationApi.requestLocationUpdates(request, listener); Currently location updates can only be requested with a LocationListener object. In the future we are planning to add location updates via a PendingIntent as well. Mock Locations With LOST you can mock not just individual locations but also entire routes. By loading a GPX trace file onto the device you can configure LOST to replay locations from the trace file including latitude, longitude, speed, and bearing. Mocking a single location To mock a single location with LOST you must first enable mock mode. Then you simply create a mock location object and pass it to the API. Location mockLocation = new Location(""mock"");
mockLocation.setLatitude(40.7484);
mockLocation.setLongitude(-73.9857);
LocationServices.FusedLocationApi.setMockMode(true);
LocationServices.FusedLocationApi.setMockLocation(mockLocation); The mock location object you set will be immediately returned to all registered listeners and will be returned the next time getLastLocation() is called. Mocking an entire route To mock an entire route you must first transfer a GPX trace file to the device using adb. Sample GPX traces can be found on the public GPS traces page for OpenStreetMap. Once the trace file is loaded on the device you can tell LOST to replay the locations in the trace at the requested update interval. File file = new File(Environment.getExternalStorageDirectory(), ""mock_track.gpx"");
LocationServices.FusedLocationApi.setMockMode(true);
LocationServices.FusedLocationApi.setMockTrace(file); For more in-depth examples, please refer to the sample application.",3
https://github.com/randhika/LOST,## Install,"  Download Jar Download the latest JAR. Maven Include dependency using Maven. <dependency>
  <groupId>com.mapzen.android</groupId>
  <artifactId>lost</artifactId>
  <version>1.0.1</version>
</dependency> Gradle Include dependency using Gradle. compile 'com.mapzen.android:lost:1.0.1'",3
https://github.com/dhaval2025/RoaringBitmap,# RoaringBitmap [![Build Status](https://travis-ci.org/lemire/RoaringBitmap.png)](https://travis-ci.org/lemire/RoaringBitmap)," Bitsets, also called bitmaps, are commonly used as fast data structures.
Unfortunately, they can use too much memory. To compensate, we often use
compressed bitmaps. Roaring bitmaps are compressed bitmaps which tend to outperform conventional
compressed bitmaps such as WAH, EWAH or Concise. In some instances, roaring bitmaps can
be hundreds of times faster and they often offer significantly better compression.
They can even be faster than uncompressed bitmaps. This library is used by Apache Spark (https://spark.apache.org/) and
Druid.io (http://druid.io/). Apache Lucene (http://lucene.apache.org/) uses  Roaring bitmaps, though they have their own independent implementation. (c) 2013-2015 Daniel Lemire, Owen Kaser, Samy Chambi, Jon Alvarado, Rory Graves, Björn Sperber, Seth Pellegrino, Borislav Ivanov, Gregory Ssi-Yan-Kai This code is licensed under Apache License, Version 2.0 (ASL2.0).",1256
https://github.com/dhaval2025/RoaringBitmap,## API docs,  http://lemire.me/docs/RoaringBitmap/,6
https://github.com/dhaval2025/RoaringBitmap,## Scientific Documentation,"  Samy Chambi, Daniel Lemire, Owen Kaser, Robert Godin,
Better bitmap performance with Roaring bitmaps,
Software: Practice and Experience (to appear)
http://arxiv.org/abs/1402.6407 This paper used data from http://lemire.me/data/realroaring2014.html",6
https://github.com/dhaval2025/RoaringBitmap,## Code sample,"      import org.roaringbitmap.*;
    
    //...
    
    RoaringBitmap rr = RoaringBitmap.bitmapOf(1,2,3,1000);
    RoaringBitmap rr2 = new RoaringBitmap();
    for(int k = 4000; k<4255;++k) rr2.add(k);
    
    RoaringBitmap rror = RoaringBitmap.or(rr, rr2);
 Please see the examples folder for more examples.",3
https://github.com/dhaval2025/RoaringBitmap,## Working with memory-mapped bitmaps,"  If you want to have your bitmaps lie in memory-mapped files, you can
use the org.roaringbitmap.buffer package instead. The following code sample illustrates how to create an ImmutableRoaringBitmap
from a ByteBuffer. In such instances, the constructor only loads the meta-data
in RAM while the actual data is accessed from the ByteBuffer on demand.     import org.roaringbitmap.buffer.*;
    
    //...
    
    MutableRoaringBitmap rr1 = MutableRoaringBitmap.bitmapOf(1, 2, 3, 1000);
    MutableRoaringBitmap rr2 = MutableRoaringBitmap.bitmapOf( 2, 3, 1010);
    ByteArrayOutputStream bos = new ByteArrayOutputStream();
    DataOutputStream dos = new DataOutputStream(bos);
    rr1.serialize(dos);
    rr2.serialize(dos);
    dos.close();
    ByteBuffer bb = ByteBuffer.wrap(bos.toByteArray());
    ImmutableRoaringBitmap rrback1 = new ImmutableRoaringBitmap(bb);
    bb.position(bb.position() + rrback1.serializedSizeInBytes());
    ImmutableRoaringBitmap rrback2 = new ImmutableRoaringBitmap(bb);
 Operations on an ImmutableRoaringBitmap such as and, or, xor, flip, will
generate a RoaringBitmap which lies in RAM. As the name suggest, the
ImmutableRoaringBitmap itself cannot be modified. This design was inspired by druid.io. One can find a complete working example in the test file TestMemoryMapping.java. Note that you should not mix the classes from the org.roaringbitmap package with the classes
from the org.roaringbitmap.buffer package. They are incompatible. They serialize to the same output however.",3
https://github.com/dhaval2025/RoaringBitmap,## Download,"  You can download releases from the Maven repository:
http://central.maven.org/maven2/org/roaringbitmap/RoaringBitmap/ or from github:
https://github.com/lemire/RoaringBitmap/releases",3
https://github.com/dhaval2025/RoaringBitmap,## Maven repository,"  If your project depends on roaring, you  can  specify the dependency in the Maven ""pom.xml"" file:     <dependencies>
      <dependency>
        <groupId>org.roaringbitmap</groupId>
        <artifactId>RoaringBitmap</artifactId>
        <version>0.4.9</version>
      </dependency>
    </dependencies>
 where you should replace the version number by the version you require.",3
https://github.com/dhaval2025/RoaringBitmap,## Usage,"  

Get java


Get maven 2


mvn compile will compile


mvn test will run the unit tests


mvn package will package in a jar (found in target)

",3
https://github.com/dhaval2025/RoaringBitmap,## Benchmark,"  To run JMH benchmarks, use the following command:      $ ./jmh/run.sh
 You can also run specific benchmarks...      $ ./jmh/run.sh org.roaringbitmap.aggregation.newand.identical.*
",3
https://github.com/dhaval2025/RoaringBitmap,## Funding,  This work was supported by NSERC grant number 26143.,5
https://github.com/dluxemburg/node-google-spreadsheets,# NodeJS Google Spreadsheets Data API, A simple Node.js library to read data from a Google Spreadsheet.,1
https://github.com/dluxemburg/node-google-spreadsheets,## Basic Example,"  var GoogleSpreadsheets = require(""google-spreadsheets"");

GoogleSpreadsheets({
	key: ""<spreadsheet key>""
}, function(err, spreadsheet) {
	spreadsheet.worksheets[0].cells({
		range: ""R1C1:R5C5""
	}, function(err, cells) {
		// Cells will contain a 2 dimensional array with all cell data in the
		// range requested.
	});
});
",3
https://github.com/dluxemburg/node-google-spreadsheets,## API,"  GoogleSpreadsheets = module.exports = function(opts, callback); Loads a Spreadsheet from the API. opts may contain the following: - `key`: *(required)* spreadsheet key
- `auth`: *(optional)* authentication key from Google ClientLogin
 GoogleSpreadsheets.rows = function(opts, callback); Loads a set of rows for a specific Spreadsheet from the API. Note that this call is direct, you must supply all auth, spreadsheet and worksheet information. opts:
- key: (required) spreadsheet key
- worksheet: (required) worksheet id. Can be a numeric index (starting from 1), or the proper string identifier for a worksheet.
- start: (optional) starting index for returned results
- num: (optional) number of results to return
- auth: (optional) authentication key from Google ClientLogin GoogleSpreadsheets.cells = function(opts, callback); Loads a group of cells for a specific Spreadsheet from the API. Note that this call is direct, you must supply all auth, spreadsheet and worksheet information. opts:
- key: (required) spreadsheet key
- worksheet: (required) worksheet id. Can be a numeric index (starting from 1), or the proper string identifier for a worksheet.
- range: (optional) A range (in the format of R1C1) of cells to retrieve. e.g R15C2:R37C8. Range is inclusive.
- auth: (optional) authentication key from Google ClientLogin Spreadsheet Object returned from GoogleSpreadsheets() call. This object has the following properties:
- title: title of Spreadsheet
- updated: date Spreadsheet was last updated.
- author: object containing name and email of author of Spreadsheet.
- worksheets: Array of Worksheets contained in this spreadsheet. Worksheet Represents a single worksheet contained in a Spreadsheet. Obtain this via Spreadsheet.worksheets. Worksheet has the following properties:
- rowCount: number of rows in worksheet.
- colCount: number of columns in worksheet.
- Worksheet.rows(opts, cb): convenience method to call Spreadsheets.rows, just pass in start and num - will automatically pass spreadsheet key, worksheet id, and auth info (if applicable)
- Worksheet.cols(opts, cb): convenience method to call Spreadsheets.cols, will automatically pass spreadsheet key, worksheet id, and auth info (if applicable). opts can contain range, etc.",36
https://github.com/dluxemburg/node-google-spreadsheets,## A note on authentication,"  The Google Spreadsheets Data API reference and developers guide is a little ambiguous
about how you access a ""published"" public Spreadsheet. If you wish to work with a Google Spreadsheet without authenticating, not only
must the Spreadsheet in question be visible to the web, but it must also have
been explicitly published using the ""Share"" button in the top right corner of
the Google Spreadsheets GUI. Generally, you'll find alot of public spreadsheets may not have had this
treatment, so your best bet is to just authenticate a Google account and
access the API in that manner. This library supports authenticated calls, when it is provided an authentication
key from Google ClientLogin. The actualy authentication is not handled by this
library. I would recommend the googleclientlogin",36
https://github.com/dluxemburg/node-google-spreadsheets,### Authentication example (using googleclientlogin):,"  var googleAuth = new GoogleClientLogin({
  email: '<email>',
  password: '<password>',
  service: 'spreadsheets',
  accountType: GoogleClientLogin.accountTypes.google
});

googleAuth.on(GoogleClientLogin.events.login, function(){
	GoogleSpreadsheets({
		key: ""<key>"",
		auth: googleAuth.getAuthId()
	}, function(err, spreadsheet) {
		spreadsheet.worksheets[0].cells({
			range: ""R1C1:R5C6""
		}, function(err, cells) {
			// bleh!
		});
	});
});

googleAuth.login();
",3
https://github.com/dluxemburg/node-google-spreadsheets,## TODO:,"  - Publish to npm (lol)
- Write some tests
",4
https://github.com/dluxemburg/node-google-spreadsheets,## Further possibilities for this library,"  - Edit functionality
- Sorting/filtering on row listing
- Filtering on cell listing.
",6
https://github.com/dluxemburg/node-google-spreadsheets,## Links,"  - <http://code.google.com/apis/spreadsheets/>
- <https://github.com/Ajnasz/GoogleClientLogin>
",6
https://github.com/mroth/extwitter,"# ExTwitter [![Build Status](https://img.shields.io/travis/parroty/extwitter.svg Build Status"")](http://travis-ci.org/parroty/extwitter) [![Coverage Status](http://img.shields.io/coveralls/parroty/extwitter.svg)](https://coveralls.io/r/parroty/extwitter) [![Inline docs](http://inch-ci.org/github/parroty/extwitter.svg?branch=master&style=flat)](http://inch-ci.org/github/parroty/extwitter)""", Twitter client library for elixir. It uses erlang-oauth to call Twitter's REST API. It only supports very limited set of functions yet. Refer to lib/extwitter.ex and test/extwitter_test.exs for available functions and examples.,16
https://github.com/mroth/extwitter,### Documentation,"  
http://hexdocs.pm/extwitter
",6
https://github.com/mroth/extwitter,### Usage,"  
Add extwitter to deps section in the mix.exs.
Use ExTwitter.configure to setup Twitter's OAuth authentication paramters. Refer to https://dev.twitter.com/docs for the detail.
Call functions in ExTwitter module (ex. ExTwitter.search(""test"")).
",3
https://github.com/mroth/extwitter,#### Configuration,"  The default behaviour is to configure using the application environment: In config/config.exs, add: config :ex_twitter, :oauth, [
   consumer_key: """",
   consumer_secret: """",
   access_token: """",
   access_token_secret: """"
] Or manually at runtime: ExTwitter.configure([consumer_key: """", ...]) You can also configure the current process only: ExTwitter.configure(:process, [consumer_key: """", ...])",3
https://github.com/mroth/extwitter,#### mix.exs,"  defp deps do
  [
    {:oauth, github: ""tim/erlang-oauth""},
    {:extwitter, ""~> 0.2""}
  ]
end",3
https://github.com/mroth/extwitter,### Sample,  Sample execution on iex.,3
https://github.com/mroth/extwitter,#### configure,"  $ iex -S mix
Interactive Elixir - press Ctrl+C to exit (type h() ENTER for help) ExTwitter.configure(
   consumer_key: System.get_env(""TWITTER_CONSUMER_KEY""),
   consumer_secret: System.get_env(""TWITTER_CONSUMER_SECRET""),
   access_token: System.get_env(""TWITTER_ACCESS_TOKEN""),
   access_token_secret: System.get_env(""TWITTER_ACCESS_SECRET"")
)

:ok",3
https://github.com/mroth/extwitter,#### search,"  Example for normal API. ExTwitter.search(""elixir-lang"", [count: 5]) |>
   Enum.map(fn(tweet) -> tweet.text end) |>
   Enum.join(""\n-----\n"") |>
   IO.puts

# => Tweets will be displayed in the console as follows.
@xxxx have you tried this yet?
-----
@yyyy You mean this? http://t.co/xxxx That had sailed below my radar thus far.
-----
@zzzz #elixir-lang. I'm jadams
-----
Akala ko 100 nalang kulang ko sa dark elixir para sa Barb King summoner level.
-----
@aaaa usually kasi magbbuzz lang yan pag luma na string. talaga ang elixir.
:ok",3
https://github.com/mroth/extwitter,# => Tweets will be displayed in the console as follows.,"  Example for streaming API. stream = ExTwitter.stream_filter(track: ""apple"") |>
  Stream.map(fn(x) -> x.text end) |>
  Stream.map(fn(x) -> IO.puts ""#{x}\n---------------\n"" end)
Enum.to_list(stream)

# => Tweets will be displayed in the console as follows.
Apple 'iWatch' rumour round-up
---------------
Apple iPhone 4s 16GB Black Verizon - Cracked Screen, WORKS PERFECTLY!
---------------
Apple iPod nano 7th Generation (PRODUCT) RED (16 GB) (Latest Model) - Full read by
---------------
...
... The ExTwitter.stream_control method allows to send a message to stop the stream. # An example to stop receiving stream after 5 seconds passed.
pid = spawn(fn ->
  stream = ExTwitter.stream_filter(track: ""apple"")
  for tweet <- stream do
    IO.puts tweet.text
  end
end)

:timer.sleep(5000)
ExTwitter.stream_control(pid, :stop) Twitter returns several message types (dev.twitter.com - Streaming message types). These messages are returned when receive_messages option is specified. stream = ExTwitter.stream_sample(receive_messages: true)
for message <- stream do
  case message do
    tweet = %ExTwitter.Model.Tweet{} ->
      IO.puts ""tweet = #{tweet.text}""

    deleted_tweet = %ExTwitter.Model.DeletedTweet{} ->
      IO.puts ""deleted tweet = #{deleted_tweet.status[""id""]}""

    limit = %ExTwitter.Model.Limit{} ->
      IO.puts ""limit = #{limit.track}""

    stall_warning = %ExTwitter.Model.StallWarning{} ->
      IO.puts ""stall warning = #{stall_warning.code}""

    _ ->
      IO.inspect message
  end
end",3
https://github.com/mroth/extwitter,## @xxxx have you tried this yet?,"  Some of Twtitter API have paging capability for retrieving large number of items through cursor. The following is an example to iteratively call the API to fetch all the items. defmodule Retriever do
  def follower_ids(screen_name, acc \\ [], cursor \\ -1) do
    cursor = fetch_next(screen_name, cursor)
    if Enum.count(cursor.items) == 0 do
      List.flatten(acc)
    else
      follower_ids(screen_name, [cursor.items|acc], cursor.next_cursor)
    end
  end

  defp fetch_next(screen_name, cursor) do
    try do
      ExTwitter.follower_ids(screen_name, cursor: cursor)
    rescue
      e in ExTwitter.RateLimitExceededError ->
        :timer.sleep ((e.reset_in + 1) * 1000)
        fetch_next(screen_name, cursor)
    end
  end
end

ids = Retriever.follower_ids(""TwitterDev"")
IO.puts ""Follower count for TwitterDev is #{Enum.count(ids)}.""
# => Follower count for TwitterDev is 38469.",3
https://github.com/mroth/extwitter,## @yyyy You mean this? http://t.co/xxxx That had sailed below my radar thus far.,,3
https://github.com/mroth/extwitter,## @zzzz #elixir-lang. I'm jadams,,3
https://github.com/mroth/extwitter,## Akala ko 100 nalang kulang ko sa dark elixir para sa Barb King summoner level.,,3
https://github.com/mroth/extwitter,#### streaming,"Example for streaming API.

stream = ExTwitter.stream_filter(track: ""apple"") |>
  Stream.map(fn(x) -> x.text end) |>
  Stream.map(fn(x) -> IO.puts ""#{x}\n---------------\n"" end)
Enum.to_list(stream)",3
https://github.com/mroth/extwitter,# => Tweets will be displayed in the console as follows.,,3
https://github.com/mroth/extwitter,## Apple 'iWatch' rumour round-up,,3
https://github.com/mroth/extwitter,"## Apple iPhone 4s 16GB Black Verizon - Cracked Screen, WORKS PERFECTLY!",,3
https://github.com/mroth/extwitter,## Apple iPod nano 7th Generation (PRODUCT) RED (16 GB) (Latest Model) - Full read by,,3
https://github.com/mroth/extwitter,# An example to stop receiving stream after 5 seconds passed.,,3
https://github.com/mroth/extwitter,#### cursor,"Some of Twtitter API have paging capability for retrieving large number of items through cursor. The following is an example to iteratively call the API to fetch all the items.

defmodule Retriever do
  def follower_ids(screen_name, acc \\ [], cursor \\ -1) do
    cursor = fetch_next(screen_name, cursor)
    if Enum.count(cursor.items) == 0 do
      List.flatten(acc)
    else
      follower_ids(screen_name, [cursor.items|acc], cursor.next_cursor)
    end
  end

  defp fetch_next(screen_name, cursor) do
    try do
      ExTwitter.follower_ids(screen_name, cursor: cursor)
    rescue
      e in ExTwitter.RateLimitExceededError ->
        :timer.sleep ((e.reset_in + 1) * 1000)
        fetch_next(screen_name, cursor)
    end
  end
end

ids = Retriever.follower_ids(""TwitterDev"")
IO.puts ""Follower count for TwitterDev is #{Enum.count(ids)}.""",3
https://github.com/mroth/extwitter,# => Follower count for TwitterDev is 38469.,,3
https://github.com/mroth/extwitter,### Notes,"  run_iex.sh launches iex, with initially calling ExTwitter.configure defined as iex/dot.iex. $ ./run_iex.sh
Erlang/OTP 17 [erts-6.3] [source] [64-bit] [smp:4:4] [async-threads:10]...
Interactive Elixir (1.0.2) - press Ctrl+C to exit (type h() ENTER for help)
iex(1)> (ExTwitter.search(""elixir"") |> List.first).text
...",3
https://github.com/arodrime/homebrew,# Homebrew," Features, usage and installation instructions are summarized on the homepage.",16
https://github.com/arodrime/homebrew,## What Packages Are Available?,"  
You can browse the Formula directory on GitHub.
Or type brew search for a list.
Or visit braumeister.org to browse packages online.
",6
https://github.com/arodrime/homebrew,## More Documentation,  brew help or man brew or check our wiki.,6
https://github.com/arodrime/homebrew,## Troubleshooting,"  First, please run brew update and brew doctor. Second, read the Troubleshooting Checklist. If you don't read these it will take us far longer to help you with your problem.",36
https://github.com/arodrime/homebrew,## Who Are You?,  Homebrew is maintained by the core contributors. Homebrew was originally created by Max Howell.,5
https://github.com/arodrime/homebrew,## License,  Code is under the BSD 2 Clause (NetBSD) license.,5
https://github.com/arodrime/homebrew,## Donations,  We accept tips through Gittip. ,5
https://github.com/tylabs/quicksand_lite,# QuickSand.io,"   For QuickSand Version 2 written in Python with PDF analysis support, see quicksand.io. QuickSand Version 1 Lite is no longer being actively developed. QuickSand is a compact C framework to analyze suspected malware documents to 1) identify exploits in streams of different encodings, 2) locate and extract embedded executables. By having the ability to locate embedded obfuscated executables, QuickSand could detect documents that contain zero-day or unknown obfuscated exploits.",12
https://github.com/tylabs/quicksand_lite,## File Formats For Exploit and Active Content Detection,"  
doc, docx, docm, rtf, etc
ppt, pptx, pps, ppsx, etc
xls, xlsx, etc
mime mso
eml email
",1
https://github.com/tylabs/quicksand_lite,## File Formats For Executable Detection,"  
All of the above, plus PDF.
Any document format such as HWP.
",1
https://github.com/tylabs/quicksand_lite,## Lite Version - Mplv2 License,"  
Key dictionary up to 256 byte XOR
Bitwise ROL, ROR, NOT
Addition or substraction math cipher
Executable extraction: Windows, Mac, Linux, VBA
Exploit search
RTF pre processing
Hex stream extract
Base 64 Stream extract
Embedded Zip extract
ExOleObjStgCompressedAtom extract
zLib Decode
Mime Mso xml Decoding
OpenXML decode (unzip)
Yara signatures included: Executables, active content, exploits CVE 2014 and earlier
 Example results and more info blog post",6
https://github.com/tylabs/quicksand_lite,## Full Version - Commercial License,"  
Key cryptanalysis 1-1024 bytes factors of 2; or a specified odd size 1-1024 bytes
1 Byte zerospace not replaced brute force XOR search
XOR Look Ahead cipher
More Yara signatures included: All lite plus most recent exploits 2014-2016 for CVE identification
Try the full version online at QuickSand.io
",4
https://github.com/tylabs/quicksand_lite,## Dependencies (not included),"  
Yara 3.4+
zlib 1.2.1+
libzip 1.1.1+
",3
https://github.com/tylabs/quicksand_lite,## Distributed components under their own licensing,"  
MD5 by RSA Data Security, Inc.
SHA1 by Paul E. Jones
SHA2 by Aaron D. Gifford
jWrite by TonyWilk for json output
tinydir by Cong Xu, Baudouin Feildel for directory processing
",3
https://github.com/tylabs/quicksand_lite,## Quick Start,"  
./build.sh
./quicksand.out -h
./quicksand.out malware.doc
",3
https://github.com/tylabs/quicksand_lite,## Documentation,  QuickSand.io,6
https://github.com/tylabs/quicksand_lite,"## Copyright, License, and Trademark","  ""QuickSand.io"" name and the QuickSand application logo are Copyright 2016 Tyler McLellan and Tylabs and their use requires written permission from the author. Source code quicksand.c, libqs.h, libqs.c and the yara signatures except where noted are Copyright 2016 Tyler McLellan and Tylabs. See included Mozilla Public License Version 2.0 for licensing information.",5
https://github.com/EmanueleMinotto/installer,# The Puli Installer," 




 Latest release: none PHP >= 5.3.9 Installs puli.phar on your system. Use it like this: $ curl https://puli.io/installer | php
",134
https://github.com/EmanueleMinotto/installer,## Authors,"  
Bernhard Schussek a.k.a. @webmozart
The Community Contributors
",5
https://github.com/EmanueleMinotto/installer,## Contribute,"  Contributions to are very welcome! 
Report any bugs or issues you find on the issue tracker.
You can grab the source code at Puli’s Git repository.
",7
https://github.com/EmanueleMinotto/installer,## Support,"  If you are having problems, send a mail to bschussek@gmail.com or shout out to
@webmozart on Twitter.",6
https://github.com/EmanueleMinotto/installer,## License,  All contents of this package are licensed under the MIT license.,5
https://github.com/manekinekko/gaia,# Gaia," Gaia is Mozilla's Phone UX for the Boot to Gecko (B2G) project. Boot to Gecko aims to create a complete, standalone operating system for the open web. You can read more about B2G here: 
http://mozilla.org/b2g
 follow us on twitter: @Boot2Gecko 
http://twitter.com/Boot2Gecko
 join the Gaia mailing list: 
http://groups.google.com/group/mozilla.dev.gaia
 and talk to us on IRC: 
#gaia on irc.mozilla.org
",156
https://github.com/manekinekko/gaia,## Hacking Gaia,"  The Gaia/Hacking page on MDN has all the information that you need to start working on Gaia, including building and running Gaia on a compatible device or desktop computer.",6
https://github.com/manekinekko/gaia,## Autolander (bot),"  Autolander is a bot which integrations github and bugzilla workflows. Opt-into new features by adding +autolander to your pull request title. Features available: 
Automatic pull request to bugzilla attachment linking.
Automatic landing, on green integration run, with a R+ from a suggested reviewer and checkin-needed keyword.
Comments in the bug with the landed commit, and marks the bug as fixed.
Validates pull request title and commit message formats.
Currently only runs a subset of the gaia CI tests which are stable on taskcluster. Ensure you have a green gaia-try run before adding checkin-needed.
See more at: https://github.com/mozilla/autolander
",1
https://github.com/manekinekko/gaia,## Tests, ,3
https://github.com/manekinekko/gaia,### Unit Tests,"  Unit tests for an app go in apps/<APP>/test/unit/. To run all the unit tests with B2G Desktop: 

Run DEBUG=1 make


Run make test-agent-server &


Run B2G Desktop and open the Test Agent app


Run make test-agent-test
or make test-agent-test APP=<APP> to run unit tests for a
specific app

 More importantly, you can use test-agent-server to watch the files
on the filesystem and execute relevant tests when they change: 
Run DEBUG=1 make
Run make test-agent-server &
Run B2G Desktop and open the Test Agent app
Edit files and when you save them, glance at the console with
test-agent-server running
 Note: If you add new files, you will need to restart test-agent-server. As a convenience, you can also use the gaia-test script to launch the
test-agent-server and open the Test Agent app in firefox: 
Add firefox to your $PATH or set $FIREFOX to your preferred
firefox/aurora/nightly binary.
Run ./bin/gaia-test to run the test-agent-server and launch firefox.
Run make test-agent-test or modify files as described above.
 For more details on writing tests, see:
https://developer.mozilla.org/en/Mozilla/Boot_to_Gecko/Gaia_Unit_Tests",3
https://github.com/manekinekko/gaia,### Integration Tests,"  Gaia uses
marionette-js-runner
to run the tests with a custom builder for gaia. Tests should live with the rest of your apps code (in apps/my_app/test/marionette) and
test files should end in _test.js. All integration tests run under a node environment. You need node >= 0.10
for this to work predictably. Shared code for tests lives under shared/test/integration.",3
https://github.com/manekinekko/gaia,#### Running integration tests,"  NOTE: unless your tests end in _test.js they will not be
automatically picked up by make test-integration. make test-integration",3
https://github.com/manekinekko/gaia,#### Invoking a test file,"  make test-integration TEST_FILES=<test> For example, we could run the day_view_test.js test in calendar app with the below command. make test-integration TEST_FILES=apps/calendar/test/marionette/day_view_test.js
 If you would like to run more than one test, we could do the below command. make test-integration TEST_FILES=""apps/calendar/test/marionette/day_view_test.js apps/calendar/test/marionette/today_test.js""
",3
https://github.com/manekinekko/gaia,#### Invoking tests for a specific app,"  make test-integration APP=<APP> For example, we could run all tests for the calendar app with make test-integration APP=calendar.",3
https://github.com/manekinekko/gaia,#### Skipping a test file,"  make test-integration SKIP_TEST_FILES=<test> For example, we could skip the day_view_test.js test in calendar app with the below command. make test-integration SKIP_TEST_FILES=apps/calendar/test/marionette/day_view_test.js
 If you would like to skip more than one test, we could do the below command. make test-integration SKIP_TEST_FILES=""apps/calendar/test/marionette/day_view_test.js apps/calendar/test/marionette/today_test.js""
 Notice that we could not use the TEST_FILES and SKIP_TEST_FILES parameters at the same time.",3
https://github.com/manekinekko/gaia,#### Running tests while working,"  If you wish to run many tests in background you might not want to be disturbed
by the b2g-desktop window popping everytime, or the sound. One solution for
the first issue is to use Xvfb: xvfb-run make test-integration If you are using PulseAudio and want to keep the tests quied, then just force
an invalid server: PULSE_SERVER="":"" make test-integration You can of course combine both: PULSE_SERVER="":"" xvfb-run make test-integration",3
https://github.com/manekinekko/gaia,#### Running tests without building profile,"  if you would like to run tests without building profile, use make test-integration-test: PROFILE_FOLDER=profile-test make # generate profile directory in first time
make test-integration-test",3
https://github.com/manekinekko/gaia,#### Debugging Tests,  To view log out from a test make test-integration VERBOSE=1,3
https://github.com/manekinekko/gaia,#### Running tests in OOP mode,  To run tests in OOP mode make test-integration OOP=1,3
https://github.com/manekinekko/gaia,#### Where to find documentation,"  
Node.js
MDN: for high level overview
mocha: which is wrapped by marionette-js-runner
marionette-js-runner: for the test framework
marionette-client: for anything to do with client.X
",6
https://github.com/manekinekko/gaia,#### Gotchas,"  

For performance reasons we don't run make profile for each test
run this means you need to manually remove the profile-test
folder when you make changes to your apps.


If you don't have a b2g folder one will be downloaded for you.
This can be problematic if you're offline. You can symlink a
b2g-desktop directory to b2g/ in gaia to avoid the download.


If you have some weird node errors, try removing node_modules since
things may be stale.


To get debug information from the b2g desktop client, run this:
DEBUG=b2g-desktop TEST_FILES=name/of/test.js ./bin/gaia-marionette


To get debug information from b2g desktop and all of the marionette
plugins, run this:
DEBUG=* TEST_FILES=name/of/test.js ./bin/gaia-marionette

",3
https://github.com/manekinekko/gaia,### UI Tests, ,6
https://github.com/manekinekko/gaia,#### Functional,  See Gaia functional tests README,6
https://github.com/manekinekko/gaia,#### Endurance,  See how to run the Gaia endurance tests,6
https://github.com/manekinekko/gaia,### Build System Tests,  Build system has its own unit test and integration test. Both are running on Node.js,3
https://github.com/manekinekko/gaia,#### Build System Unit Tests,"  To run unit test locally, using following command: $ make build-test-unit
",3
https://github.com/manekinekko/gaia,#### Build System Integration Tests,"  To run integration test locally, using following command: $ make build-test-integration
",3
https://github.com/manekinekko/gaia,## Generate jsdoc,"  To generate API reference locally, you have to install grunt with following command: $ npm -g grunt-cli then run make docs command to generate docs.
The generated API docs will be located in docs folder. You could generate single app doc with this: $ grunt jsdoc:system",3
https://github.com/Koulio/jison,# Jison," 
issues
discuss
 ",16
https://github.com/Koulio/jison,## An API for creating parsers in JavaScript,"  Jison generates bottom-up parsers in JavaScript. Its API is similar to Bison's, hence the name. It supports many of Bison's major features, plus some of its own. If you are new to parser generators such as Bison, and Context-free Grammars in general, a good introduction is found in the Bison manual. If you already know Bison, Jison should be easy to pickup. Briefly, Jison takes a JSON encoded grammar or Bison style grammar and outputs a JavaScript file capable of parsing the language described by that grammar. You can then use the generated script to parse inputs and accept, reject, or perform actions based on the input.",1
https://github.com/Koulio/jison,## Installation,"  Jison can be installed for Node using npm Using npm: npm install jison -g
",3
https://github.com/Koulio/jison,## Usage from the command line,"  Clone the github repository for examples: git clone git://github.com/zaach/jison.git
cd jison/examples
 Now you're ready to generate some parsers: jison calculator.jison
 This will generate calculator.js in your current working directory. This file can be used to parse an input file, like so: echo ""2^32 / 1024"" > testcalc
node calculator.js testcalc
 This will print out 4194304. Full cli option list: Usage: jison [file] [lexfile] [options]

file        file containing a grammar
lexfile     file containing a lexical grammar

Options:
   -j, --json                    force jison to expect a grammar in JSON format
   -o FILE, --outfile FILE       Filename and base module name of the generated parser
   -t, --debug                   Debug mode
   -m TYPE, --module-type TYPE   The type of module to generate (commonjs, amd, js)
   -p TYPE, --parser-type TYPE   The type of algorithm to use for the parser (lr0, slr, lalr, lr)
   -V, --version                 print version and exit
",3
https://github.com/Koulio/jison,## Usage from a CommonJS module,"  You can generate parsers programatically from JavaScript as well. Assuming Jison is in your commonjs environment's load path: // mygenerator.js
var Parser = require(""jison"").Parser;

// a grammar in JSON
var grammar = {
    ""lex"": {
        ""rules"": [
           [""\\s+"", ""/* skip whitespace */""],
           [""[a-f0-9]+"", ""return 'HEX';""]
        ]
    },

    ""bnf"": {
        ""hex_strings"" :[ ""hex_strings HEX"",
                         ""HEX"" ]
    }
};

// `grammar` can also be a string that uses jison's grammar format
var parser = new Parser(grammar);

// generate source, ready to be written to disk
var parserSource = parser.generate();

// you can also use the parser directly from memory

// returns true
parser.parse(""adfe34bc e82a"");

// throws lexical error
parser.parse(""adfe34bc zxg"");
",3
https://github.com/Koulio/jison,## More Documentation,"  For more information on creating grammars and using the generated parsers, read the documentation.",6
https://github.com/Koulio/jison,## How to contribute,"  See CONTRIBUTING.md for contribution guidelines, how to run the tests, etc.",7
https://github.com/Koulio/jison,## Projects using Jison,"  View them on the wiki, or add your own.",6
https://github.com/Koulio/jison,## Contributors,"  Githubbers Special thanks to Jarred Ligatti, Manuel E. Bermúdez",5
https://github.com/Koulio/jison,## License,"  
Copyright (c) 2009-2014 Zachary Carter
Permission is hereby granted, free of
charge, to any person  obtaining a
copy of this software and associated
documentation  files (the ""Software""),
to deal in the Software without
restriction, including without
limitation the rights to use,  copy,
modify, merge, publish, distribute,
sublicense, and/or sell  copies of the
Software, and to permit persons to
whom the  Software is furnished to do
so, subject to the following
conditions:
The above copyright notice and this
permission notice shall be  included
in all copies or substantial portions
of the Software.
THE SOFTWARE IS PROVIDED ""AS IS"",
WITHOUT WARRANTY OF ANY KIND,  EXPRESS
OR IMPLIED, INCLUDING BUT NOT LIMITED
TO THE WARRANTIES  OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT  HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY,  WHETHER IN AN ACTION OF
CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR  OTHER DEALINGS
IN THE SOFTWARE.
",5
https://github.com/DimGreyWolf/448Hmwk5,# EECS 448 Homework 5, This program is part of an assignment for the University of Kansas course EECS 48 in which we develop a drug analysis program. Homework Assignment Document,16
https://github.com/DimGreyWolf/448Hmwk5,# Authors,"  Harrison Hetler, Henry Nguyen, Tony Nguyen, Lei Wang",5
https://github.com/DimGreyWolf/448Hmwk5,# Requirements,"  This program will require an installation of Python 2.7 and Qt4 to run.
The implementation is written for Python 2.7 and the GUI is implemented
using the Qt4 framework. Graph plotting functionality is provided by
pyqtgraph which requires the previous requirements and NumPy. To clarify, the list of dependencies are: 
Python 2.7
Qt4
NumPy
 Most, if not all, these dependencies are usually already installed in your selected OS.",1
https://github.com/DimGreyWolf/448Hmwk5,# How to use,"  To run the program, with a terminal navigate to the folder containing the python scripts. Then run the command: python HW5.py This command will then launch the GUI to the program and will prompt you with various functions.",3
https://github.com/DimGreyWolf/448Hmwk5,# Using unit tests,"  There are various unit tests included in this package to verify if certain modules are operating properly. Simply run the ""test"" prefixed python script associated with the module you would like to test. For example to test the DrugDatabase module, run: python test_drug_database.py",3
https://github.com/DimGreyWolf/448Hmwk5,# MVC Architecture,"  This program was created with the MVC architecture in mind.
The three main classes of this program are: 
DrugDatabase, which represents the Model class
DrugGraph, which represents the View class
DrugAnalysis, which represents the Controller class
 Several classes may contain their own subclasses as part of their implementation. NOTE: The DrugGraph class is contained in the executable HW5.py script.",6
https://github.com/pivotal-mikegresham/github-changelog-generator,# GitHub Changelog Generator ![GitHub Logo](../master/images/logo.jpg)," 
Installation
Output example
Usage

Params
GitHub token


Features and advantages of this project

Alternatives
Projects using this library


Am I missing some essential feature?
Contributing
License
",1
https://github.com/pivotal-mikegresham/github-changelog-generator,### Changelog generation has never been so easy,"  Fully automated changelog generation - This gem generates a change log file based on tags, issues and merged pull requests (and splits them into separate lists according to labels) from  GitHub Issue Tracker. Since now you don't have to fill your CHANGELOG.md manually: just run the script, relax and take a cup of ?before your next release! 🎉 
What’s the point of a change log?
 To make it easier for users and contributors to see precisely what notable changes have been made between each release (or version) of the project.",1
https://github.com/pivotal-mikegresham/github-changelog-generator,### *Why should I care?*,"  Because software tools are for people. If you don’t care, why are you contributing to open source? Surely, there must be a kernel (ha!) of care somewhere in that lovely little brain of yours. 
➡️ http://keepachangelog.com
",2
https://github.com/pivotal-mikegresham/github-changelog-generator,## Installation,"  gem install github_changelog_generator
 See also Troubleshooting.",3
https://github.com/pivotal-mikegresham/github-changelog-generator,## Output example,"  

Look at CHANGELOG.md for this project


ActionSheetPicker-3.0/CHANGELOG.md  was generated by command:
  github_changelog_generator -u skywinder -p ActionSheetPicker-3.0



In general, it looks like this:

 
1.2.5 (2015-01-15)
Full Changelog
Implemented enhancements:

Use milestone to specify in which version bug was fixed #22

Fixed bugs:

Error when trying to generate log for repo without tags #32

Merged pull requests:


PrettyPrint class is included using lowercase 'pp' #43 (schwing)


support enterprise github via command line options #42 (glenlovett)


",3
https://github.com/pivotal-mikegresham/github-changelog-generator,## Usage,"  It's really simple! 

If your git remote origin refers to your GitHub repo, just go to your project folder and run:
  github_changelog_generator



Or, run this from anywhere:

github_changelog_generator -u github_username -p github_project
github_changelog_generator  github_username/github_project



If you are running it against a repository on a Github Enterprise install, you must specify both --github-site and --github-api command line options:
  github_changelog_generator --github-site=""https://github.yoursite.com"" \
                             --github-api=""https://github.yoursite.com/api/v3/""


 This generates a changelog to the CHANGELOG.md file, with pretty markdown formatting.",3
https://github.com/pivotal-mikegresham/github-changelog-generator,### Params,"  Type github_changelog_generator --help for details. For more details about params, read the Wiki page: Advanced change log generation examples",36
https://github.com/pivotal-mikegresham/github-changelog-generator,### Params File,"  In your project root, you can put a params file named .github_changelog_generator to override default params: Example: unreleased=false
future-release=5.0.0
since-tag=1.0.0
",3
https://github.com/pivotal-mikegresham/github-changelog-generator,### GitHub token,"  GitHub only allows only 50 unauthenticated requests per hour.
Therefore, it's recommended to run this script with authentication by using a token. Here's how: 
Generate a token here - you only need ""repo"" scope for private repositories
Either:

Run the script with --token <your-40-digit-token>; OR
Set the CHANGELOG_GITHUB_TOKEN environment variable to your 40 digit token


 You can set an environment variable by running the following command at the prompt, or by adding it to your shell profile (e.g., ~/.bash_profile or ~/.zshrc):     export CHANGELOG_GITHUB_TOKEN=""«your-40-digit-github-token»""
 So, if you got an error like this: 
! /Library/Ruby/Gems/2.0.0/gems/github_api-0.12.2/lib/github_api/response/raise_error.rb:14:in `on_complete'
 It's time to create this token! (Or, wait an hour for GitHub to reset your unauthenticated request limit.)",3
https://github.com/pivotal-mikegresham/github-changelog-generator,## Migrating from a manual changelog,"  Knowing how dedicated you are to your project, you probably haven't been waiting for github-changelog-generator to keep a changelog.
But you probably don't want your project's open issues and PRs for all past features listed in your historic changelog, either. That's where --base <your-manual-changelog.md> comes in handy!
This option lets append your old manual changelog to the end of the generated entries. If you have a HISTORY.md file in your project, it will automatically be picked as the static historical changelog and appended.",3
https://github.com/pivotal-mikegresham/github-changelog-generator,### Rake task,"  You love rake? We do, too! So, we've made it even easier for you:
we've provided a rake task library for your changelog generation. Just put something like this in your Rakefile: require 'github_changelog_generator/task'

GitHubChangelogGenerator::RakeTask.new :changelog do |config|
  config.since_tag = '0.1.14'
  config.future_release = '0.2.0'
end All command line options can be passed to the rake task as config parameters. And since you're naming the rake task yourself, you can create as many as you want. You can look for params names from the parser source code (#setup_parser). For example, to translate the bugs label to Portuguese, instead of setting config.bugs_label, you have to set config.bug_prefix, and so on.",3
https://github.com/pivotal-mikegresham/github-changelog-generator,## Features and advantages of this project,"  

Generate canonical, neat change log file, followed by basic change log guidelines 💎


Optionally generate Unreleased changes (closed issues that have not released yet) 💫


GitHub Enterprise support via command line options! 🏭


Flexible format customization:

Customize issues that should be added to changelog ✳️
Custom date formats supported (but keep ISO 8601 in mind!) 📅
Manually specify the version that fixed an issue (for cases when the issue's Closed date doesn't match) by giving the issue's milestone the same name as the tag of version 📌
Automatically exclude specific issues that are irrelevant to your changelog (by default, any issue labeled question, duplicate, invalid, or wontfix) ✂️



Distinguish issues by labels. 🔎

Merged pull requests (all merged pull-requests) 🔀
Bug fixes (issues labeled bug) 🐞
Enhancements (issues labeled enhancement) 🌟
Issues (closed issues with no labels) 🚱



Manually include or exclude issues by labels 🔧


Customize lots more! Tweak the changelog to fit your preferences 🎩
(See github_changelog_generator --help  for details)

 ###Alternatives
Here is a wikipage list of alternatives that I found. But none satisfied my requirements. If you know other projects, feel free to edit this Wiki page!",12
https://github.com/pivotal-mikegresham/github-changelog-generator,###Alternatives,"Alternatives Here is a wikipage list of alternatives that I found. But none satisfied my requirements.

If you know other projects, feel free to edit this Wiki page!",6
https://github.com/pivotal-mikegresham/github-changelog-generator,### Projects using this library,"  Here's a wikipage list of projects. If you've used this project in a live app, please let me know! Nothing makes me happier than seeing someone else take my work and go wild with it. If you are using github_changelog_generator to generate your project's changelog, or know of other projects using it, please [add it to this list] (https://github.com/skywinder/Github-Changelog-Generator/wiki/Projects-using-Github-Changelog-Generator).",6
https://github.com/pivotal-mikegresham/github-changelog-generator,## Am I missing some essential feature?,"  

Nothing is impossible!


Open an issue and let's make the generator better together!


Bug reports, feature requests, patches, and well-wishes are always welcome. ?
",56
https://github.com/pivotal-mikegresham/github-changelog-generator,## FAQ,"  
I already use GitHub Releases. Why do I need this?
 GitHub Releases is a very good thing. And it's very good practice to maintain it. (Not a lot of people are using it yet!) ㊗️ BTW: I would like to support GitHub Releases in next releases ;) I'm not trying to compare the quality of handwritten and auto-generated logs. That said.... An auto-generated changelog really helps, even if you manually fill in the release notes! For example: When I found a closed bug, it's very useful know which release fixed it.
In this case, you can easily find the issue by # in CHANGELOG.md. 
it's not quite as easy to find this in handwritten releases notes
a generated file saves you the trouble of remembering everything;
sometimes people forget to add things to a handwritten file
 Ultimately, I think GitHub Releases is ideal for end-users.
Meanwhile, CHANGELOG.md lives right in the repository, with its detailed list of changes, which is handy for developers.
Finally, there's nothing wrong with using GitHub Releases alongside CHANGELOG.md in this combination. 
I received a warning: ""GitHub API rate limit exceed""  What does this mean?
 GitHub limits the number of API requests you can make in an hour. You can make up to 5,000 requests per hour. For unauthenticated requests, the rate limit is only up to 60 requests per hour. Unauthenticated requests are associated with your IP address (not the user making requests). If you're seeing this warning, please do the following: 
Make sure you're providing an OAuth token, so you're not making requests anonymously. Using an OAuth token increases your hourly request maximum from 60 to 5000.
If you have a large repo with lots of issues/PRs, you can use --max-issues NUM to limit the number of issues that are pulled back. For example: --max-issues 1000
 
My Ruby version is very old, can I use this?
 When your Ruby is old, and you don't want to upgrade, and you want to
control which libraries you use, you can use Bundler. In a Gemfile, perhaps in a non-deployed :development group, add this
gem: group :development do
  gem 'github_changelog_generator', require: false
end Then you can keep back dependencies like rack, which currently is only
compatible with Ruby >= 2.2.2. So, use an older version for your app by
adding a line like this to the Gemfile: gem 'rack', '~> 1.6'
 This way, you can keep on using github_changelog_generator, even if you
can't get the latest version of Ruby installed.",6
https://github.com/pivotal-mikegresham/github-changelog-generator,## Contributing,"  
Create an issue and describe your idea
[Fork it] (https://github.com/skywinder/Github-Changelog-Generator/fork)
Create your feature branch (git checkout -b my-new-feature)
Commit your changes (git commit -am 'Add some feature')
Publish the branch (git push origin my-new-feature)
Create a new Pull Request
Profit! ? To test your workflow with changelog generator, you can use test repo",7
https://github.com/pivotal-mikegresham/github-changelog-generator,## License,  Github Changelog Generator is released under the MIT License.,5
https://github.com/vpothuri/phpiredis,# Phpiredis #," 
 Phpiredis is an extension for PHP 5.x and 7.x based on hiredis
that provides a simple and efficient client for Redis and a fast incremental parser / serializer for
the RESP protocol.",1
https://github.com/vpothuri/phpiredis,## Installation ##,"  Building and using this extension requires hiredis (>=0.9.0 <1.0.0) to be installed on the system.
hiredis is usually available in the repositories of most Linux distributions, alternatively it is
possible to build it by fetching the code from its repository. git clone https://github.com/nrk/phpiredis.git
cd phpiredis
phpize && ./configure --enable-phpiredis
make && make install When the configuration script is unable to locate hiredis on your system, you can specify in which
directory it can be found using --with-hiredis-dir= (e.g. --with-hiredis-dir=/usr/local). Phpiredis provides a basic test suite that can be launched with make test. Tests require a running
instance of redis-server listening on 127.0.0.1:6379 but make sure that your server does not
hold data you are interested: you could end up losing everything stored on it! If you notice a failing test or a bug, you can contribute by opening a pull request on GitHub or
simply file a bug on our issue tracker.",3
https://github.com/vpothuri/phpiredis,## Usage ##,"  Connecting to Redis is as simple as calling the phpiredis_connect() function with a server address
as the first parameter and an optional port number when the server is listening to a different port
than the default 6379: $redis = phpiredis_connect('127.0.0.1', 6379);      // normal connection
$redis = phpiredis_pconnect('127.0.0.1', 6379);     // persistent connection Alternatively you can connect to redis using UNIX domain socket connections. $redis = phpiredis_connect('/tmp/redis.sock');      // normal connection
$redis = phpiredis_pconnect('/tmp/redis.sock');     // persistent connection Once the connection is established, you can send commands to Redis using phpiredis_command_bs() or
pipeline them using phpiredis_multi_command_bs(): $response = phpiredis_command_bs($redis, array('DEL', 'test'));

$response = phpiredis_multi_command_bs($redis, array(
    array('SET', 'test', '1'),
    array('GET', 'test'),
)); The _bs suffix indicates that these functions can handle binary key names or values by using the
unified Redis protocol available since Redis >= 1.2. Commands can still be sent using the old and deprecated inline protocol using phpiredis_command()
and phpiredis_multi_command() (note the lack of the _bs suffix) but it's highly discouraged and
these functions will be removed in future versions of phpiredis. $response = phpiredis_command($redis, 'DEL test');

$response = phpiredis_multi_command($redis, array(
    'SET test 1',
    'GET test',
));",3
https://github.com/vpothuri/phpiredis,## Contributing ##,"  Any kind of contribution is extremely welcome! Just fork the project on GitHub, work on new features
or bug fixes using feature branches and open pull-requests
with concise but complete descriptions of your changes. If you are unsure about a proposal, you can
just open an issue to discuss it before writing actual code.",7
https://github.com/vpothuri/phpiredis,## Authors ##,"  Daniele Alessandri (current maintainer)
Sebastian Waisbrot (original developer)",5
https://github.com/vpothuri/phpiredis,## License ##,  The code for phpiredis is distributed under the terms of the BSD license (see LICENSE).,5
https://github.com/valley51/jfortune,# jfortune ![travis](https://travis-ci.org/tehsis/jfortune.svg)," A jquery plugin to make wheel of fortunes (roulettes) Working examples: 
http://codepen.io/tehsis/pen/AFCwz
http://codepen.io/tehsis/pen/zilBg
http://codepen.io/asleepypenguin/pen/bebZBj // Counter clockwise and divided wedges
",16
https://github.com/valley51/jfortune,## Description,"  Provides an UI component to make roulettes effects and provides methods to handle the
prices on which the roulette stops.",1
https://github.com/valley51/jfortune,## Usage,"  // You can initialize the roulette by specifying the number of elements
$(selector).roulette(8);

// Or by passing an array of elements
$(selector).roulette([{description: '1000 u$s'}, {description: '200 u$s'}]);

// Array elements can also be arrays of elements to allow for split wedges
$(selector).roulette([
    {description: '1000 u$s'}, 
    {description: '200 u$s'},
    [{description: '100 u$s'},{description: '5000 u$s'},{description: '100 u$s'}]
    ]);

// Or you can fully configurate the roulette behaviour
$(selector).roulette({
  prices: [{description: ""1000 u$s""}, {description: ""200 u$s""}],
  duration: 3000, // The amount of milliseconds the roulette to spin
  separation: 2, // The separation between each roulette price
  min_spins: 10, // The minimum number of spins 
  max_spins: 15, // The maximum number of spins
  clockWise: true, // The direction the wheel will spin
  onSpinBounce: function() {
    Sounds.play('taka');
  } // A callback to be called each time the roulette hits a price bound.
})

// After initialization you can spin the wheel and it will turn to a random
// position.
$(selector).spin();

// Or you can specify a predefined position
$(selector).spin(4);

// The spin methods returns a promise, which its first arguments is the object that
// is at that position (only if you have used the second form of initilization)
$(selector).spin().then(function(price) {
  console.log(price.description);
});

// or you can specify a fixed price
$(selector).spin(1).spin().then(function(price) {
  console.log(price.description); // ""200 u$s""
});",3
https://github.com/valley51/jfortune,## Usage notes,"  The plugin must be initiated using and array of elements or a number. Both, the array length
or the number's value, must be conscistent with the number of positions your roulette's image
has, this is not magic. (yet). At this moment, the css' styles for the roulette animation are hard-coded inside the plugin. This has been done on porpouse to not requiring external files.",3
https://github.com/maxamillion32/mobile-first-dashboard,# Mobile First Dashboard, Installs a default es2015 polymer/ellipticaljs dashboard app with mocked data.,1
https://github.com/maxamillion32/mobile-first-dashboard,# Installation,"  ##prerequisites node
gulp
babel
bower
 #clone repo git clone https://github.com/ellipticaljs/mobile-first-dashboard.git
mv ./mobile-first-dashboard  my-project
cd my-project
 #npm npm install
gulp init
gulp app-build
bower install
 #tasks gulp start-app
",3
https://github.com/maxamillion32/mobile-first-dashboard,##prerequisites,"  localhost:9040
",3
https://github.com/maxamillion32/mobile-first-dashboard,#clone repo,"  gulp sass-compile
gulp sass-compile-min
gulp sass-watch
gulp app-build
gulp app-imports
gulp app-clean
gulp app-watch
gulp watch
gulp vulcanize
gulp vulcanize-min
",3
https://github.com/maxamillion32/mobile-first-dashboard,#npm,"  # crud controller
gulp db-crud-controller --class <className> --icon <icon>

# empty controller
gulp db-empty-controller --name <controllerName>

# content controller
gulp db-empty-controller --name <controllerName>

# empty view
gulp db-empty-view --name <view> --folder <viewFolder>

# content view
gulp db-content-view --name <view> --folder <viewFolder>

# list view
gulp db-list-view --name <view> --folder <viewFolder> --class <className> --icon <icon>

# grid view
gulp db-grid-view --name <view> --folder <viewFolder> --class <className> --icon <icon>

# detail view
gulp db-detail-view --name <view> --folder <viewFolder> --class <className> --icon <icon>

# service
gulp db-service --class <className>

# provider
gulp db-provider --class <className>

# binding
gulp db-binding --name <name>

# web component
gulp web-component --tag <tag> --d <directory>

",3
https://github.com/maxamillion32/mobile-first-dashboard,#tasks,,3
https://github.com/maxamillion32/mobile-first-dashboard,# Browser,,3
https://github.com/maxamillion32/mobile-first-dashboard,## Additional Tasks,,3
https://github.com/maxamillion32/mobile-first-dashboard,## Scaffold tasks,,3
https://github.com/maxamillion32/mobile-first-dashboard,# crud controller,,-
https://github.com/maxamillion32/mobile-first-dashboard,# empty controller,,-
https://github.com/maxamillion32/mobile-first-dashboard,# content controller,,-
https://github.com/maxamillion32/mobile-first-dashboard,# empty view,,-
https://github.com/maxamillion32/mobile-first-dashboard,# content view,,-
https://github.com/maxamillion32/mobile-first-dashboard,# list view,,-
https://github.com/maxamillion32/mobile-first-dashboard,# grid view,,-
https://github.com/maxamillion32/mobile-first-dashboard,# detail view,,-
https://github.com/maxamillion32/mobile-first-dashboard,# service,,-
https://github.com/maxamillion32/mobile-first-dashboard,# provider,,-
https://github.com/maxamillion32/mobile-first-dashboard,# binding,,-
https://github.com/maxamillion32/mobile-first-dashboard,# web component,,-
https://github.com/maxamillion32/mobile-first-dashboard,# Demo,"  http://ellipticaljs.github.io/mobile-first-dashboard/ username:admin
password:admin",3
https://github.com/shyamalschandra/synfig,# Synfig Studio,,1
https://github.com/shyamalschandra/synfig,## About,"  Synfig Studio is a free and open-source 2D animation software, designed as
powerful industrial-strength solution for creating film-quality animation using
a vector and bitmap artwork. It eliminates the need to create animation
frame-by frame, allowing you to produce 2D animation of a higher quality with
fewer people and resources. Synfig Studio is available for Windows, Linux and
MacOS X. http://synfig.org/ (TODO: add more info)",12
https://github.com/shyamalschandra/synfig,## Installing,"  Old autotools instructions can be found here. We're currently in the process of switching to CMake build system and
you're welcome to take part in testing and improving it.",36
https://github.com/shyamalschandra/synfig,### CMake status,"  
all major components are buildable, installable and runnable
building all components without installing ETL & core is not tested
 Tested to work on (this will be updated as reports come in): 
Debian Sid
",3
https://github.com/shyamalschandra/synfig,### Cleanup,"  If you have previous synfig build installed in system path (e.g. /usr/local/),
you are recommended to uninstall that.",3
https://github.com/shyamalschandra/synfig,### Dependencies,"  You need development & library packages of the following libs: 
boost (system, filesystem, program_options, chrono)
zlib
libsigc++-2.0
glibmm-2.4
giomm-2.4
cairo
libxml++-2.6
mlt++
fftw3
pango
gtkmm-3.0 (only for studio)
gettext (probably optional)
some threading support (e.g. pthread)
 Generally CMake will throw error if it doesn't find something, so you can just
run it and see what's missing. Also note that this list might not be full.",3
https://github.com/shyamalschandra/synfig,### CMake backend,"  CMake provides generators for multiple build systems. You can use default make
or ninja, which should generally work somewhat faster. The following
configuration commands assume you want to use ninja. If you don't, remove
-GNinja from all commands containing it. All the building commands here are
invoked via cmake to make them (almost) backend-agnostic, but you can run make
or ninja directly (i.e.
ninja all test instead of cmake --build . -- all test).",3
https://github.com/shyamalschandra/synfig,### Build options,"  You may want to add -jN (where N is amount of threads you want to run) option
to build commands, because default for make is to run single-threaded and
ninja tends to use too much threads which eat up your RAM (may vary).",3
https://github.com/shyamalschandra/synfig,### Building,"$ pushd ETL
$ mkdir build && pushd build
$ cmake -GNinja .. -DCMAKE_BUILD_TYPE=RelWithDebInfo
$ cmake --build . -- all test
$ sudo cmake --build . -- install
$ popd # build
$ popd # ETL
$ pushd synfig-core
$ mkdir build && pushd build
$ cmake -GNinja .. -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_CXX_FLAGS=""-fdiagnostics-color""
$ cmake --build . -- all
$ sudo cmake --build . -- install
$ popd # build
$ popd # synfig-core
$ pushd synfig-studio
$ mkdir build && pushd build
$ cmake -GNinja .. -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_CXX_FLAGS=""-fdiagnostics-color""
$ cmake --build . -- all",3
https://github.com/shyamalschandra/synfig,"# this will take a while; alternatively, you can move/copy required images",,3
https://github.com/shyamalschandra/synfig,# to build/images directory and skip this step,"$ cmake --build . -- build_images
$ sudo cmake --build . -- install
$ popd # build
$ popd # synfig-studio",3
https://github.com/nigredo-tori/patty,# Patty - A pattern matching library," 
 Patty is a library to perform pattern matching in Nim. The patterns have to be variant objects, which in Nim are encoded with a field (usually called kind) which varies in an enum, and a different object layout based on the value of this tag. An example would be type
  ShapeKind = enum
    Circle, Rectangle
  Shape = object
    case kind: ShapeKind
    of Circle:
      r: float
    of Rectangle:
      w, h: float If you have such an algebraic data type, you can do the following with Patty: import patty

proc makeRect(w, h: float): Shape = Shape(kind: Rectangle, w: w, h: h)

match makeRect(3, 4):
  Circle(r: radius):
    echo ""it is a circle of radius "", radius
  Rectangle(w: width, h: height):
    echo ""it is a rectangle of height "", height This will be translated by the match macro into the following form let :tmp = makeRect(3, 4)
case :tmp.kind
of Circle:
  let radius = :tmp.r
  echo ""it is a circle of radius "", radius
of Rectangle:
  let
    width = :tmp.w
    height = :tmp.h
  echo ""it is a rectangle of height "", height Matching by position is also valid, like this: match makeRect(3, 4):
  Circle(radius):
    echo ""it is a circle of radius "", radius
  Rectangle(width, height):
    echo ""it is a rectangle of height "", height One can also use _ for a variable, in which case it will not be bound. That is, the following import patty

proc makeRect(w, h: float): Shape = Shape(kind: Rectangle, w: w, h: h)

match makeRect(3, 4):
  Circle(r: radius):
    echo ""it is a circle of radius "", radius
  Rectangle(w: _, h: height):
    echo ""it is a rectangle of height "", height becomes let :tmp = makeRect(3, 4)
case :tmp.kind
of Circle:
  let radius = :tmp.r
  echo ""it is a circle of radius "", radius
of Rectangle:
  let height = :tmp.h
  echo ""it is a rectangle of height "", height Notice that in the examples, the field you dispatch on is called kind, but any other name would do. Also, checks are exhaustive: if you miss a case, the compiler will complain. One can instead pattern-match on non-variant objects, which essentially amounts to deconstructing fields: type Person = object
  name: string
  age: int
let p = Person(name: ""John Doe"", age: 37)
match p:
  Person(name: n, age: a):
    echo n, ""is "", a, "" years old"" Again, this is the same as match p:
  Person(n, a):
    echo n, ""is "", a, "" years old""",13
https://github.com/nigredo-tori/patty,## Constructing variant objects,"  Patty also provides another macro to create algebraic data types. It looks like variant Shape:
  Circle(r: float)
  Rectangle(w: float, h: float)
  UnitCircle and expands to type
  ShapeKind {.pure.} = enum
    Circle, Rectangle, UnitCircle
  Shape = object
    case kind: ShapeKind
    of ShapeKind.Circle:
      r: float
    of ShapeKind.Rectangle:
      w: float
      h: float
    of ShapeKind.UnitCircle:
      nil

proc `==`(a: Shape; b: Shape): bool =
  if a.kind == b.kind:
    case a.kind
    of ShapeKind.Circle:
      return a.r == b.r
    of ShapeKind.Rectangle:
      return a.w == b.w and a.h == b.h
    of ShapeKind.UnitCircle:
      return true
  else:
    return false

proc Circle(r: float; x: float; y: float): Shape =
  Shape(kind: ShapeKind.Circle, r: r)

proc Rectangle(w: float; h: float): Shape =
  Shape(kind: ShapeKind.Rectangle, w: w, h: h)

proc UnitCircle(side: int): Shape =
  Shape(kind: ShapeKind.UnitCircle) Notice that the macro also generates three convenient constructors (Circle ,Rectangle and UnitCircle), and in fact the enum is pure to avoid a name conflict. Also, a proper definition of equality based on the actual contents of the record is generated. By default the generated ADT is private to the module. If you want to generate a public ADT use the variantp macro, which has the same syntax as variant but makes the types, fields, equality definition and generated constructors public. A couple of limitations fo the variant macro: 
field names must be unique across branches (that is, different variants cannot have two fields with the same name). This is actually a limitation of Nim.
the shortcut that groups field names by type does not seem to work, that is, in the above example one could not write Rectangle(w, h: float).
 In the future, Patty may also add copy constructors. Also, some work needs to be done to make it easier to use the generated contructors with ref types, in particular for the important case of recursive algebraic data types.",3
https://github.com/nigredo-tori/patty,## Versions,"  Patty 0.1.8 works for latest Nim (devel). For older versions of Nim (up to 0.13.0),
use Patty 0.1.7.",4
https://github.com/nigredo-tori/patty,## Things that do not work (yet),"  One would expect many forms of pattern matching but, at least for now, the support in Patty is very limited. Things that would be nice to support but do not work yet include: 
matching a constant
 match c:
  ""hello"":
    echo ""the string was hello"" 
matching an existing variable
 let x = 5
match c:
  x:
    echo ""c == 5"" 
nested pattern matching
 match c:
  Circle(Point(x: x, y: y), r: r):
    echo ""the abscissa of the center is "", x 
matching without binding
 match c:
  Circle:
    echo ""it is a circle!"" 
binding subpatterns
 match getMeACircle():
  c@Circle(x, y, r):
    echo ""there you have "", c 
pattern matching as an expression should be simply
 let coord = match c:
  Circle(x: x, y: y, r: r):
    x
  Rectangle(w: w, h: h):
    h Right now it works (with latest nim devel) like this: let coord = (block:
  match c:
    Circle(x: x, y: y, r: r):
      x
    Rectangle(w: w, h: h):
      h
) 
unification
 match r:
  Rectangle(w: x, h: x):
    echo ""it is a square"" 
guards
 match c:
  Circle(x: x, y: y, r: r) if r < 0:
    echo ""the circle has negative length"" 
variable-length pattern matching, such as with arrays
 match c:
  [a, b, c]:
    echo ""the length is 3 and the first elements is "", a 
custom pattern matchers, such as in regexes
 let Email = r""(\w+)@(\w+).(\w+)""
match c:
  Email(name, domain, tld):
    echo ""hello "", name 
combining patterns with or
 match c:
  Circle or Rectangle:
    echo ""it is a shape""",3
https://github.com/QuickQi1/ews-cpp,# Overview," EWS is an API that third-party programmers can use to communicate with
Microsoft Exchange Server. The API exists since Exchange Server 2007 and is
continuously up-dated by Microsoft and present in the latest iteration of the
product, Exchange Server 2016. This library provides a native and platform-independent way to use EWS in your
C++ application. ",1
https://github.com/QuickQi1/ews-cpp,## Supported Operations and Elements,"  
Autodiscover
<CreateItem/>, <SendItem/>, <FindItem/>, <GetItem/>, <UpdateItem/>,
and <DeleteItem/> operations
<CreateAttachment/>, <GetAttachment/>, <DeleteAttachment/> for file
attachments. Item attachments are not supported yet
<CalendarItem/>, <Message/>, <Contact/>, <Task/> items. Note that we
still don't support all properties of these items. But we're working on it
",1
https://github.com/QuickQi1/ews-cpp,## Supported Authentication Schemes,"  
HTTP basic auth
NTLM
Kerberos is currently not supported but its on the TODO list
",1
https://github.com/QuickQi1/ews-cpp,## Supported Compilers,"  
Visual Studio 2012
Visual Studio 2013
Visual Studio 2015
Clang since 3.5

with libc++ on Mac OS X
with libstdc++ on Linux (Note that libc++ on Linux is not supported)


GCC since 4.8 with libstdc++
 


Compiler
64-bit
32-bit




Visual Studio 2012
*
*


Visual Studio 2013




Visual Studio 2015




Clang 3.5 with libc++
*
*


GCC 4.8 with libstdc++

*


* = will be added soon




",1
https://github.com/QuickQi1/ews-cpp,## Supported Operating Systems,"  
Microsoft Windows 8.1 and Windows 10
macOS starting with 10.12
RHEL 7
Ubuntu starting with 16.04 LTS
SLES 12.1
",1
https://github.com/QuickQi1/ews-cpp,## Supported Microsoft Exchange Server Versions,"  
Microsoft Exchange Server 2013 SP1
 However, our goal is to support all Exchange Server versions since 2007.",1
https://github.com/QuickQi1/ews-cpp,## Run-time Dependencies,"  
libcurl, at least version 7.22
",3
https://github.com/QuickQi1/ews-cpp,## Dev Dependencies,"  
Git
CMake
Doxygen (optional)
Boost (optional)
Python 2 or 3 (optional)
",3
https://github.com/QuickQi1/ews-cpp,## Note Windows Users,"  You can obtain an up-to-date and easy-to-use binary distribution of libcurl
from here: confusedbycode.com/curl Additionally, you probably need to tell CMake where to find it. Just set
CMAKE_PREFIX_PATH to the path where you installed libcurl (e.g.
C:\Program Files\cURL) and re-configure. You can also use the Windows batch script provided in
scripts\build-curl.bat to download and compile libcurl for your particular
version of Visual Studio.",36
https://github.com/QuickQi1/ews-cpp,## Source Code,"  ews-cpp's source code is available as a Git repository. To obtain it, type: git clone --recursive https://github.com/otris/ews-cpp.git",3
https://github.com/QuickQi1/ews-cpp,## Building, ,3
https://github.com/QuickQi1/ews-cpp,### Linux,"  The library is header-only. So there is no need to build anything. Just copy the
include/ews/ directory wherever you may like. To build the accompanied tests with debugging symbols and Address Sanitizer
enabled do something like this: cmake -DCMAKE_BUILD_TYPE=Debug -DENABLE_ASAN=ON /path/to/source
make Type make edit_cache to see all configuration options. make help shows you
all available targets.",3
https://github.com/QuickQi1/ews-cpp,### Windows,"  To build the tests and examples on Windows you can use cmake-gui.  For more
see: https://cmake.org/runningcmake/ If you do not want to use any GUI to compile the examples and tests you could
do something like this with the Windows cmd.exe command prompt: set PATH=%PATH%;C:\Program Files (x86)\CMake\bin
mkdir builddir
cd builddir
cmake -G ""Visual Studio 14 2015 Win64"" ^
    -DCURL_LIBRARY=""C:\Program Files\cURL\7.49.1\win64-debug\lib\libcurl_debug.lib"" ^
    -DCURL_INCLUDE_DIR=""C:\Program Files\cURL\7.49.1\win64-debug\include"" ^
    C:\path\to\source
cmake --build . Make sure to choose the right generator for your environment.",3
https://github.com/QuickQi1/ews-cpp,### API Docs,"  Use the doc target to create the API documentation with Doxygen.  Type: make doc
open html/index.html",3
https://github.com/QuickQi1/ews-cpp,### Test Suite,"  In order to run individual examples or the test suite export following
environment variables like this: export EWS_TEST_DOMAIN=""DUCKBURG""
export EWS_TEST_USERNAME=""mickey""
export EWS_TEST_PASSWORD=""pluto""
export EWS_TEST_URI""https://hire-a-detective.com/ews/Exchange.asmx"" Be sure to change the values to an actual account on some Exchange server that
you can use for testing. Do not run the tests on your own production account. Once you've build the project, you can execute the tests with: ./tests --assets=/path/to/source/tests/assets",3
https://github.com/QuickQi1/ews-cpp,## Design Notes,"  ews-cpp is written in a ""modern C++"" way: 
C++ Standard Library, augmented with rapidxml for XML parsing
Smart pointers instead of raw pointers
Pervasive RAII idiom
Handle errors using C++ exceptions
Coding conventions inspired by Boost
",6
https://github.com/QuickQi1/ews-cpp,## API,"  Just add: #include <ews/ews.hpp> to your include directives and you are good to go. Take a look at the examples/ directory to get an idea of how the API feels.
ews-cpp is a thin wrapper around Microsoft's EWS API. You will need to refer to
the EWS reference for
Exchange
for all available parameters to pass and all available attributes on items.
From 10.000ft it looks like this:  You have items and you have the service. You use the service whenever you
want to talk to the Exchange server. Please note one important caveat though. ews-cpp's API is designed to be
""blocking"". This means whenever you call one of the service's member functions
to talk to an Exchange server that call blocks until it receives a request from
the server. And that may, well, just take forever (actually until a timeout is
reached). You need to keep this in mind in order to not block your main or UI
thread. Implications of this design choice Pros: 
A blocking API is much easier to use and understand
 Cons: 
You just might accidentally block your UI thread
You cannot issue thousands of EWS requests asynchronously simply because you
cannot spawn thousands of threads in your process. You may need additional
effort here
",6
https://github.com/QuickQi1/ews-cpp,#include <ews/ews.hpp>,,3
https://github.com/QuickQi1/ews-cpp,## Legal Notice,"  ews-cpp is developed by otris software AG and was initially released to the
public in July 2016. It is licensed under the Apache License, Version 2.0 (see
LICENSE file). For more information about otris software AG visit our website
otris.de or our Open Source repositories at
github.com/otris.",56
https://github.com/mdxprograms/visor,"# <img src=_demo/logo.png"" width=""35"" alt=""Visor logo"">&nbsp;Visor""", A simple admin overlay to get to the relevant areas of the Craft CMS control panel.,1
https://github.com/mdxprograms/visor,## Demo,  ,3
https://github.com/mdxprograms/visor,### Screengrab,  ,1
https://github.com/mdxprograms/visor,## Installation,"  To install Visor, follow these steps: 
Download & unzip the file and place the inner visor directory in your craft/plugins folder
Install plugin in the Craft Control Panel under Settings > Plugins
The plugin folder should be named visor for Craft to recognize it.
Add {% hook ""addVisor"" %} to any templates it should display on. Ideally this should be right before the </body> tag in your _layout.html file.
",3
https://github.com/mdxprograms/visor,### Keyboard Shortcuts,"  You can activate Visor by clicking the gear icon or using the following keyboard shortcuts: 


Key
Description




`
Toggles Visor open or close


ESC
Closes Visor (if open)


",3
https://github.com/mdxprograms/visor,## Customizing Visor, ,3
https://github.com/mdxprograms/visor,### Overriding styles,"  Visor has a class of craft-visor--override on the outer <section> element. To change any of the default styles, simply start your styles with .craft-visor.craft-visor--override. This will make your styles more specific without resorting to !important madness.",3
https://github.com/mdxprograms/visor,### Overriding icons,"  Visor also uses inline SVGs for all graphics. This: 
Reduces HTTP requests
Looks crisp at any pixel density
Allows you to re-style the icons using fill in your CSS
",3
https://github.com/mdxprograms/visor,### Overriding background,  If you'd prefer to replace purple with a different color you can change this by targeting .craft-visor__modal.,3
https://github.com/mdxprograms/visor,## Browser compatibility,"  This has been tested on Chrome, Firefox, Safari and IE 10+, but drop in an Issue if you notice any strangeness.",3
https://github.com/mdxprograms/visor,## Contributing,"  We welcome anyone and everyone who would like to improve Visor to fork it and send in pull requests. To start developing Visor: 
Ensure you have Node version 5.x.x running on your machine
Clone the repo to your computer
Run npm install
Run npm run build to compile the _styles and _scripts files into the main visor/ directory
",7
https://github.com/mdxprograms/visor,## Visor Changelog, ,4
https://github.com/mdxprograms/visor,### 1.0.0 -- 2016.09.16,"  
Initial release
",4
https://github.com/NunoEdgarGub1/jBloomberg,##Welcome to jBloomberg,"jBloomberg is a high-level API that wraps the low level Bloomberg Desktop Java API. Although most features of the underlying Bloomberg API are available, some options might not be reachable through the jBloomberg API.

You can browse the javadoc for more information, including example usages.",16
https://github.com/NunoEdgarGub1/jBloomberg,###Requirements,"As of v3, Java 8 is required.",3
https://github.com/NunoEdgarGub1/jBloomberg,###Usage,,3
https://github.com/NunoEdgarGub1/jBloomberg,####Maven dependency,"You can create a Maven dependency to download jBloomberg atrifact:

<dependency>
  <groupId>com.assylias</groupId>
  <artifactId>jbloomberg</artifactId>
  <version>3.3</version>
</dependency>",3
https://github.com/NunoEdgarGub1/jBloomberg,####Installing Bloomberg jar,"You need to manually install the jar of the Bloomberg API in your maven repository for this to work.

Download the file (version 3.8.7.2) from bloomberg's website. Extract and save the main jar file to a folder, c:/temp for example. Then run:

mvn install:install-file -Dfile=c:/temp/blpapi-3.8.7-2.jar -DgroupId=com.bloombergblp -DartifactId=blpapi -Dversion=3.8.7.2 -Dpackaging=jar",3
https://github.com/NunoEdgarGub1/jBloomberg,###Description,"The main advantages of this library vs. the Bloomberg API are:

Less string based configuration: whenever possible enums are used to remove the typos issues
Less verbose: retrieving historical data literally takes 5 lines of code, whereas when using the Bloomberg API, the code gets quickly cluttered with parsing, error handling and so on
Fluent design: most queries to Bloomberg are prepared with builders using the fluent interface pattern
The library takes thread safety seriously (so does the Bloomberg API): all actions / objects are thread safe and can be used in a multi threaded application (unless indicated otherwise, for example the builders)
Uses the standard java.util.concurrent package objects, so the syntax / way of doing things should look familiar to Java developers. For example, a historical data request returns a Future<HistoricalData>
It should however be noted that using jBloomberg does increase memory consumption and GC vs. using BLPAPI directly although for most applications that should not be noticeable.",2
https://github.com/NunoEdgarGub1/jBloomberg,###Stability,Note that the API is not stable yet and its design could be subject to changes in the future.,4
https://github.com/NunoEdgarGub1/jBloomberg,###License,Apache License v2.0,5
https://github.com/NunoEdgarGub1/jBloomberg,###Dependencies,,3
https://github.com/NunoEdgarGub1/jBloomberg,####Source dependencies,"guava (Apache License v2.0)
slf4j (MIT License)
Bloomberg BLPAPI (tested with 3.8.7.2) (MIT-like License)
Big Blue Utils (Apache License v2.0)",3
https://github.com/NunoEdgarGub1/jBloomberg,####Test dependencies,"jmockit (MIT License)
testNG (Apache License v2.0)",3
https://github.com/NunoEdgarGub1/jBloomberg,##Issues,If you find a bug or want a new feature you can ask in the Issues section on github. For general questions or if you are unable to get something to work you can ask on stackoverflow using the jbloomberg tag in your question.,6
https://github.com/1406504841/glide,# Glide,"  Glide is a fast and efficient open source media management and image loading framework for Android that wraps media
decoding, memory and disk caching, and resource pooling into a simple and easy to use interface.  Glide supports fetching, decoding, and displaying video stills, images, and animated GIFs. Glide includes a flexible API
that allows developers to plug in to almost any network stack. By default Glide uses a custom HttpUrlConnection based
stack, but also includes utility libraries plug in to Google's Volley project or Square's OkHttp library instead. Glide's primary focus is on making scrolling any kind of a list of images as smooth and fast as possible, but Glide is
also effective for almost any case where you need to fetch, resize, and display a remote image.",12
https://github.com/1406504841/glide,## Download,"  You can download a jar from GitHub's releases page. Or use Gradle: repositories {
    mavenCentral()
}

dependencies {
    compile 'com.github.bumptech.glide:glide:3.6.1'
    compile 'com.android.support:support-v4:19.1.0'
} Or Maven: <dependency>
    <groupId>com.github.bumptech.glide</groupId>
    <artifactId>glide</artifactId>
    <version>3.6.1</version>
</dependency>
<dependency>
    <groupId>com.google.android</groupId>
    <artifactId>support-v4</artifactId>
    <version>r7</version>
</dependency>",3
https://github.com/1406504841/glide,## Proguard,"  Depending on your proguard config and usage, you may need to include the following lines in your proguard.cfg: -keep public class * implements com.bumptech.glide.module.GlideModule
-keep public enum com.bumptech.glide.load.resource.bitmap.ImageHeaderParser$** {
    **[] $VALUES;
    public *;
}",3
https://github.com/1406504841/glide,## How do I use Glide?,"  Checkout the GitHub wiki for pages on a variety of topics, and see the javadocs. Simple use cases will look something like this: // For a simple view:
@Override
public void onCreate(Bundle savedInstanceState) {
    ...
    ImageView imageView = (ImageView) findViewById(R.id.my_image_view);

    Glide.with(this).load(""http://goo.gl/gEgYUd"").into(imageView);
}

// For a simple image list:
@Override
public View getView(int position, View recycled, ViewGroup container) {
    final ImageView myImageView;
    if (recycled == null) {
        myImageView = (ImageView) inflater.inflate(R.layout.my_image_view, container, false);
    } else {
        myImageView = (ImageView) recycled;
    }

    String url = myUrls.get(position);

    Glide.with(myFragment)
        .load(url)
        .centerCrop()
        .placeholder(R.drawable.loading_spinner)
        .crossFade()
        .into(myImageView);

    return myImageView;
}
",3
https://github.com/1406504841/glide,## OkHttp and Volley,"  Support for OkHttp and Volley is provided by integration libraries you can optionally include as dependencies.
The integration libraries are available via Maven or the releases page. For instructions on including either the OkHttp or the Volley integration libraries, see the Integration Libraries wiki page.",36
https://github.com/1406504841/glide,## Android SDK Version,  Glide requires a minimum SDK version of 10.,3
https://github.com/1406504841/glide,## License,"  BSD, part MIT and Apache 2.0. See the LICENSE file for details.",5
https://github.com/1406504841/glide,## Status,"  Version 3 is a stable public release used in multiple open source projects at Google including in the Android Camera
app and in the 2014 Google IO app. Version 4 is currently under development on the master branch.
Comments/bugs/questions/pull requests welcome!",4
https://github.com/1406504841/glide,## Build,"  Building Glide with gradle is fairly straight forward: git clone git@github.com:bumptech/glide.git # use https://github.com/bumptech/glide.git if ""Permission Denied""
cd glide
git submodule init && git submodule update
./gradlew jar Note: Make sure your Android SDK has the Android Support Repository installed, and that your $ANDROID_HOME environment
variable is pointing at the SDK or add a local.properties file in the root project with a sdk.dir=... line.",3
https://github.com/1406504841/glide,## Samples,"  Follow the steps in the Build section to setup the project and then: ./gradlew :samples:flickr:run
./gradlew :samples:giphy:run
./gradlew :samples:svg:run You may also find precompiled APKs on the releases page.",3
https://github.com/1406504841/glide,## Development,"  Follow the steps in the Build section to setup the project and then edit the files however you wish.
Intellij IDEA 14 cleanly imports both Glide's source and tests and is the recommended way to work with Glide. To open the project in Intellij 14: 
Go to File menu or the Welcome Screen
Click on Open...
Navigate to Glide's root directory.
Select build.gradle
",3
https://github.com/1406504841/glide,## Getting Help,"  To report a specific problem or feature request, open a new issue on Github. For questions, suggestions, or
anything else, join or email Glide's discussion group, or join our IRC channel: irc.freenode.net#glide-library.",6
https://github.com/1406504841/glide,## Contributing,"  Before submitting pull requests, contributors must sign Google's individual contributor license agreement.",7
https://github.com/1406504841/glide,## Thanks,"  
The Android team and Jake Wharton for the disk cache implementation Glide's disk cache is based on.
Dave Smith for the gif decoder gist Glide's gif decoder is based on.
Chris Banes for his gradle-mvn-push script.
Corey Hall for Glide's amazing logo.
Everyone who has contributed code and reported issues!
",5
https://github.com/1406504841/glide,## Author,  Sam Judd - @samajudd,5
https://github.com/1406504841/glide,## Disclaimer,  This is not an official Google product.,5
https://github.com/IbpTeam/sqlite3,# NAME," node-sqlite3 - Asynchronous, non-blocking SQLite3 bindings for Node.js 0.2-0.4 (versions 2.0.x), 0.6.13+, 0.8.x, and 0.10.x (versions 2.1.x). (Can also run in node-webkit if it uses a supported version of Node's engine.) 
",1
https://github.com/IbpTeam/sqlite3,# USAGE,"  Note: the module must be installed before use. var sqlite3 = require('sqlite3').verbose();
var db = new sqlite3.Database(':memory:');

db.serialize(function() {
  db.run(""CREATE TABLE lorem (info TEXT)"");

  var stmt = db.prepare(""INSERT INTO lorem VALUES (?)"");
  for (var i = 0; i < 10; i++) {
      stmt.run(""Ipsum "" + i);
  }
  stmt.finalize();

  db.each(""SELECT rowid AS id, info FROM lorem"", function(err, row) {
      console.log(row.id + "": "" + row.info);
  });
});

db.close();",3
https://github.com/IbpTeam/sqlite3,# FEATURES,"  
Straightforward query and parameter binding interface
Full Buffer/Blob support
Extensive debugging support
Query serialization API
Extension support
Big test suite
Written in modern C++ and tested for memory leaks
",1
https://github.com/IbpTeam/sqlite3,# API,  See the API documentation in the wiki.,6
https://github.com/IbpTeam/sqlite3,# INSTALLING,"  You can use npm to download and install: 

The latest sqlite3 package: npm install sqlite3


GitHub's master branch: npm install https://github.com/mapbox/node-sqlite3/tarball/master

 In both cases the module is automatically built with npm's internal version of node-gyp,
and thus your system must meet node-gyp's requirements. It is also possible to make your own build of sqlite3 from its source instead of its npm package (see below). It is possible to use the installed package in node-webkit instead of the vanilla Node.js, but a rebuild is required before use (see the next section).",3
https://github.com/IbpTeam/sqlite3,# REBUILDING FOR NODE-WEBKIT,"  Because of ABI differences, only a rebuilt version of sqlite3 can be used in node-webkit. After the sqlite3 module is installed (according to the previous section), do the following: 

Install nw-gyp globally: npm install nw-gyp -g (unless already installed)


Use nw-gyp to rebuild the module:

 NODE_WEBKIT_VERSION=""0.8.4"" # see latest version at https://github.com/rogerwang/node-webkit#downloads
nw-gyp rebuild --target=${NODE_WEBKIT_VERSION}
 Remember the following: 

In the nw-gyp rebuild command, specify the actual target version of your node-webkit. The command must be run in sqlite3's directory (where its package.json resides).


After the sqlite3 package is rebuilt for node-webkit it cannot run in the vanilla Node.js (and vice versa).

For example, npm test of the node-webkit's package would fail.
If you need sqlite3 package both for Node.js and node-webkit, then you should make two separate installations of sqlite3 (in different directories) and rebuild only one of them for node-webkit.


 Visit the “Using Node modules?article in the node-webkit's wiki for more details.",36
https://github.com/IbpTeam/sqlite3,# BUILDING FROM THE SOURCE,"  Unless building via npm install (which uses its own node-gyp) you will need node-gyp installed globally: npm install node-gyp -g
 The sqlite3 module depends only on libsqlite3. However, by default, an internal/bundled copy of sqlite will be built and statically linked, so an externally installed sqlite3 is not required. If you wish to install against an external sqlite then you need to pass the --sqlite argument to node-gyp, npm install or the configure wrapper. ./configure --sqlite=/usr/local
make
 Or, using the node-gyp directly:  node-gyp --sqlite=/usr/local
 make
 Or, using npm:  npm install --sqlite=/usr/local
 If building against an external sqlite3 make sure to have the development headers available. Mac OS X ships with these by default. If you don't have them installed, install the -dev package with your package manager, e.g. apt-get install libsqlite3-dev for Debian/Ubuntu. Make sure that you have at least libsqlite3 >= 3.6. Note, if building against homebrew-installed sqlite on OS X you can do: ./configure --sqlite=/usr/local/opt/sqlite/
make
",3
https://github.com/IbpTeam/sqlite3,# TESTING,"  mocha is required to run unit tests. In sqlite3's directory (where its package.json resides) run the following: npm install mocha
npm test
",3
https://github.com/IbpTeam/sqlite3,# CONTRIBUTORS,"  
Konstantin Käfer
Dane Springmeyer
Will White
Orlando Vazquez
Artem Kustikov
Eric Fredricksen
John Wright
Ryan Dahl
Tom MacWright
Carter Thaxton
Audrius Kažukauskas
Johannes Schauer
Mithgol
",5
https://github.com/IbpTeam/sqlite3,# ACKNOWLEDGEMENTS,"  Thanks to Orlando Vazquez,
Eric Fredricksen and
Ryan Dahl for their SQLite bindings for node, and to mraleph on Freenode's #v8 for answering questions. Development of this module is sponsored by MapBox.",5
https://github.com/IbpTeam/sqlite3,# LICENSE,  node-sqlite3 is BSD licensed.,5
https://github.com/Shamash2014/swirl_courses,# swirl courses,"  This is a collection of interactive courses for use with the swirl R package. You'll find instructions for installing courses further down on this page. Some courses are still in development and we'd love to hear any suggestions you have as you work through them. For more information regarding swirl, visit swirlstats.com or the swirl GitHub repository. If you'd like to write your own interactive content, please visit the Instructors page of our website. Here are our current offerings, organized by level of difficulty:",16
https://github.com/Shamash2014/swirl_courses,#### Beginner,"  
R Programming: The basics of programming in R
R Programming Alt: Same as the original, but modified slightly for in-class use (see below ***)
Data Analysis: Basic ideas in statistics and data visualization
Mathematical Biostatistics Boot Camp: One- and two-sample t-tests, power, and sample size
Open Intro: A very basic introduction to statistics, data analysis, and data visualization
 *** R Programming Alt is identical to R Programming, except we've eliminated the prompts for Coursera credentials at the end of each lesson and instead give students the option to send an email to their instructor notifying them of completion. Admittedly, it's sort of a hack until we come up with a more robust solution for in-class use (i.e. an instructor ""dashboard"").",1
https://github.com/Shamash2014/swirl_courses,#### Intermediate,"  
Regression Models: The basics of regression modeling in R
Getting and Cleaning Data: dplyr, tidyr, lubridate, oh my!
",1
https://github.com/Shamash2014/swirl_courses,#### Advanced,"  
Statistical Inference: This intermediate to advanced level course closely follows the
Statistical Inference course of the Johns Hopkins
Data Science Specialization on Coursera. It
introduces the student to basic concepts of statistical inference
including probability, hypothesis testing, confidence intervals and
p-values. It concludes with an initiation to topics of particular
relevance to big data, issues of multiple testing and resampling.
 Since our users come from a variety backgrounds, it's very hard to label material as Beginner, Intermediate, or Advanced. If you find something that is labelled Beginner to be challenging, please don't be discouraged. The first step of learning anything is to acknowledge that you are capable of understanding it. True understanding will come with time and practice.",1
https://github.com/Shamash2014/swirl_courses,#### Course Authors,"  
Writing swirl Courses: An interactive guides and example
for swirl course authors. The first group of lesson cover basics. The rest cover
special topics useful primarily as samples--points of departure for one's own material.
",5
https://github.com/Shamash2014/swirl_courses,## Install and run a course automatically from swirl,"  This is the preferred method of installing courses. It automates the process by allowing you to do everything right from the R console. 
Make sure you have a recent version version of swirl:
 install.packages(""swirl"")
 
Enter the following from the R console, substituting the name of the course that you wish to install:
 library(swirl)
install_from_swirl(""Course Name Here"")
swirl()
 For example, install_from_swirl(""R Programming"") will install the R Programming course. Please note that course names are case sensitive! If that doesn't work for you...",3
https://github.com/Shamash2014/swirl_courses,## Install and run a course manually,"  If the automatic course installation method outlined above does not work for you, then there's a simple alternative. 

Click on the Download ZIP button on the righthand side of this page.


Enter the following from the R console, substituting the correct file path to your downloaded file and the name of your desired course:

 library(swirl)
install_course_zip(""path/to/file/here/swirl_courses-master.zip"", multi=TRUE, 
                   which_course=""Course Name Here"")
swirl()
 For example, if you download the zip file to ~/Downloads/swirl_courses-master.zip, then the following command will install the R Programming course. install_course_zip(""~/Downloads/swirl_courses-master.zip"", multi=TRUE, which_course=""R Programming"")
 Please note that course names are case sensitive! Although we recommend you install one course at a time, if you omit the which_course argument, then all available courses from this repository will be installed: install_course_zip(""~/Downloads/swirl_courses-master.zip"", multi=TRUE)
",3
https://github.com/Shamash2014/swirl_courses,## Uninstall a course,"  If you'd like to remove a course at any time, you can use uninstall_course(""Course Name Here"").",3
https://github.com/Shamash2014/swirl_courses,## Using swirl in the classroom,"  Instructors around the world are using swirl in their classrooms. We think this is awesome. If you're an instructor, please feel free to do the same -- free of charge. While your students may be paying to take your course or attend your institution, we simply ask that you don't charge people directly for the use of our software or instructional content. If you are not sure about a particular use case, don't hesitate to send us an email at info@swirlstats.com.",56
https://github.com/luoyiqi/Colorful-1,# Colorful,  Colorful is a dynamic theme library allowing you to change your apps' color schemes easily.,1
https://github.com/luoyiqi/Colorful-1,## License,"  Colorful is licensed under the Apache 2.0 License, in common Android style. Copyright 2016 Garret Yoder",5
https://github.com/luoyiqi/Colorful-1,## Installation,"  Add jitpack to your maven sources allprojects {
    repositories {
        ...
        maven { url ""https://jitpack.io"" }
    }
} Add Colorful as a dependency to your build.gradle dependencies {
    compile 'com.github.garretyoder:Colorful:1.1'
}",3
https://github.com/luoyiqi/Colorful-1,## Usage,"  In your Application class, you must initialize Colorful public class SampleApp extends Application {
    @Override
    public void onCreate() {
        super.onCreate();
        Colorful.init(this);
    }
} Any Activity you wish to be themed must extend from CActivity public class MainActivity extends CActivity Alternatively you can call the following method after super.onCreate(savedInstanceState); and before setContentView(); Colorful.applyTheme(Activity activity); You can also use Colorful.applyTheme(Activity activity, Boolean overrideBase); where overrideBase defines whether you want Colorful to override your base theme as well, or simply set the primary and accent colors. This allows you to use Colorful with your own pre-defined style, but will break light/dark functionality. You can set the default theme colors Colorful will use with the defaults() method public class SampleApp extends Application {
    @Override
    public void onCreate() {
        super.onCreate();
        Colorful.defaults()
                .primaryColor(Colorful.ThemeColor.RED)
                .accentColor(Colorful.ThemeColor.BLUE)
                .translucent(false)
                .dark(true);
        Colorful.init(this);
    }
} You can set the colors at any time using the config method Colorful.config(this)
                .primaryColor(Colorful.ThemeColor.RED)
                .accentColor(Colorful.ThemeColor.BLUE)
                .translucent(false)
                .dark(true)
                .apply(); After which you must call apply(); to save your changes Colorful will handle saving and loading your theme preferences for you.",3
https://github.com/luoyiqi/Colorful-1,## Color Chooser,"  Colorful has a inbuilt color chooser dialog that will return a ThemeColor object you can pass directly to Colorful public class MainActivity extends CActivity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        setSupportActionBar(((Toolbar) findViewById(R.id.toolbar)));

        ColorPickerDialog dialog = new ColorPickerDialog(this);
        dialog.setOnColorSelectedListener(new ColorPickerDialog.OnColorSelectedListener() {
            @Override
            public void onColorSelected(Colorful.ThemeColor color) {
                //TODO: Do something with the color
            }
        });
        dialog.show();
    }
}",3
https://github.com/luoyiqi/Colorful-1,## Preference Item,"  Colorful has a inbuilt preference item that will automatically set Colorful's colors. Use colorpicker:primary_color and colorpicker:accent_color to tell Colorful which value to set.         <org.polaric.colorful.ColorPickerPreference
            android:title=""@string/primary_color""
            android:summary=""@string/primary_color_desc""
            colorpicker:primary_color=""true""/>

        <org.polaric.colorful.ColorPickerPreference
            android:title=""@string/accent_color""
            android:summary=""@string/accent_color_desc""
            colorpicker:accent_color=""true""/>",3
https://github.com/luoyiqi/Colorful-1,## Screenshots,  ,3
https://github.com/MariyaS/movies,# movies, README for Movie Website Project A Python module that provides a static web-page with a few movies with box art imagery and a movie trailer URL.  The data of several movies is served as a web page allowing visitors to browse movies and their trailers.,1
https://github.com/MariyaS/movies,## I. File list,"  media.py			- Python class to store data structure for the class Movie fresh_tomatoes.py		- Python module that creates the HTML page and populates it with any argument movie instances entertainment_center.py		- Python file that creates movie class instances, populates them into an array, and passes the array to a fresh_tomatoes method to display them in an HTML page",3
https://github.com/MariyaS/movies,## II. How to Run the 'Movie_Website' project,"  The three python files were written in Python 2.7.8 and should be run with compatible Python installations. You will need to navigate to the location of the files, have an Internet connection, and run the python module 'entertainment_center.py'. Running the 'entertainment_center.py' file will create compiled python files (.pyc) for media and fresh_tomatoes. Also the newly-created fresh_tomatoes.html file should open in a default browser. You may need to use a browser with ActiveX controls, if you are on a Windows machine, else some features may not work. To run these files from a location on your computer make sure to have the appropriate version of Python installed: 

Navigate to the correct folder


Run the python module 'entertainment_center.py'.


This should open a new tab in the default browser with the newly created page fresh_tomatoes.html.

",3
https://github.com/MariyaS/movies,## III. Design Decisions,"  The Movie class is defined in the media.py file.  This approach separates the Movie object from other code. The fresh_tomatoes.py file creates the HTML page and populates it with the movie instance arguments. The entertainment_center.py file creates movie class instances, populates them into an array, and passes it to the fresh_tomatoes method to display them in the HTML page.  This module utilizes both of the other python files to produce the final product. Future improvements include:
- Use YouTube API to fill in the details for the movie class instances, so there will be no hard-coding of movie class instance attributes.
- Show movie information in separate pop-up module via a button",3
https://github.com/haisonle/passwordless,# Passwordless," Passwordless is a modern node.js module for Express that allows authentication and authorization without passwords by simply sending one-time password (OTPW) tokens via email or other means. It utilizes a very similar mechanism as the reset password feature of classic websites. The module was inspired by Justin Balthrop's article ""Passwords are Obsolete"" Check out a demo and further documentation on https://passwordless.net or have a look at an example. Token-based authentication is... 
Faster to implement compared to typical user auth systems (you only need one form)
Better for your users as they get started with your app quickly and don't have to remember passwords
More secure for your users avoiding the risks of reused passwords
",1236
https://github.com/haisonle/passwordless,## Getting you started,"  The following should provide a quick-start in using Passwordless. If you need more details check out the example, the deep dive, or the documentation. Also, don't hesitate to raise comments and questions on GitHub.",36
https://github.com/haisonle/passwordless,### 1. Install the module:,"  $ npm install passwordless --save You'll also want to install a TokenStore such as MongoStore and something to deliver the tokens (be it email, SMS or any other means). For example: $ npm install passwordless-mongostore --save $ npm install emailjs --save If you need to store your tokens differently consider developing a new TokenStore and let us know.",3
https://github.com/haisonle/passwordless,### 2. Require the needed modules,"  You will need: 
Passwordless
A TokenStore to store the tokens such as MongoStore
Something to deliver the tokens such as emailjs for email or twilio for text messages / SMS
 var passwordless = require('passwordless');
var MongoStore = require('passwordless-mongostore');
var email   = require('emailjs');",3
https://github.com/haisonle/passwordless,### 3. Setup your delivery,"  This is very much depending on how you want to deliver your tokens, but if you use emailjs this could look like this: var smtpServer  = email.server.connect({
   user:    yourEmail, 
   password: yourPwd, 
   host:    yourSmtp, 
   ssl:     true
});",3
https://github.com/haisonle/passwordless,### 4. Initialize Passwordless,"  passwordless.init() will take your TokenStore, which will store the generated tokens as shown below for a MongoStore: // Your MongoDB TokenStore
var pathToMongoDb = 'mongodb://localhost/passwordless-simple-mail';
passwordless.init(new MongoStore(pathToMongoDb));",3
https://github.com/haisonle/passwordless,### 5. Tell Passwordless how to deliver a token,"  passwordless.addDelivery(deliver) adds a new delivery mechanism. deliver is called whenever a token has to be sent. By default, the mechanism you choose should provide the user with a link in the following format: http://www.example.com/token={TOKEN}&uid={UID} That's how you could do this with emailjs: // Set up a delivery service
passwordless.addDelivery(
	function(tokenToSend, uidToSend, recipient, callback) {
		var host = 'localhost:3000';
		smtpServer.send({
			text:    'Hello!\nAccess your account here: http://' 
			+ host + '?token=' + tokenToSend + '&uid=' 
			+ encodeURIComponent(uidToSend), 
			from:    yourEmail, 
			to:      recipient,
			subject: 'Token for ' + host
		}, function(err, message) { 
			if(err) {
				console.log(err);
			}
			callback(err);
		});
});",3
https://github.com/haisonle/passwordless,### 6. Setup the middleware for express,"  app.use(passwordless.sessionSupport());
app.use(passwordless.acceptToken({ successRedirect: '/'})); sessionSupport() makes the login persistent, so the user will stay logged in while browsing your site. Make sure to have added your session middleware before this line. Have a look at express-session how to setup sessions if you are unsure. Please be aware: If you decide to use cookie-session rather than e.g. express-session as your middleware you have to set passwordless.init(tokenStore, {skipForceSessionSave:true}) acceptToken() will accept incoming tokens and authenticate the user (see the URL in step 5). While the option successRedirect is not strictly needed, it is strongly recommended to use it to avoid leaking valid tokens via the referrer header of outgoing HTTP links. When provided, the user will be forwarded to the given URL as soon as she has been authenticated. Instead of accepting tokens on any URL as done above you can also restrict the acceptance of tokens to certain URLs: // Accept tokens only on /logged_in (be sure to change the
// URL you deliver in step 5)
router.get('/logged_in', passwordless.acceptToken(), 
	function(req, res) {
		res.render('homepage');
});",3
https://github.com/haisonle/passwordless,### 7. The router,"  The following takes for granted that you've already setup your router var router = express.Router(); as explained in the express docs You will need at least URLs to: 
Display a page asking for the user's email (or phone number, ...)
Receive these details (via POST) and identify the user
 For example like this: /* GET login screen. */
router.get('/login', function(req, res) {
   res.render('login');
});

/* POST login details. */
router.post('/sendtoken', 
	passwordless.requestToken(
		// Turn the email address into an user's ID
		function(user, delivery, callback, req) {
			// usually you would want something like:
			User.find({email: user}, callback(ret) {
			   if(ret)
			      callback(null, ret.id)
			   else
			      callback(null, null)
	      })
	      // but you could also do the following 
	      // if you want to allow anyone:
	      // callback(null, user);
		}),
	function(req, res) {
	   // success!
  		res.render('sent');
}); What happens here? passwordless.requestToken(getUserId) has two tasks: Making sure the email address exists and transforming it into a proper user ID that will become the identifier from now on. For example user@example.com becomes 123 or 'u1002'. You call callback(null, ID) if all is good, callback(null, null) if you don't know this email address, and callback('error', null) if something went wrong. At this stage, please make sure that you've added middleware to parse POST data (such as body-parser). Most likely, you want a user registration page where you take an email address and any other user details and generate an ID. However, you can also simply accept any email address by skipping the lookup and just calling callback(null, user). In an even simpler scenario and if you just have a fixed list of users do the following: // GET login as above

var users = [
	{ id: 1, email: 'marc@example.com' },
	{ id: 2, email: 'alice@example.com' }
];

/* POST login details. */
router.post('/sendtoken', 
	passwordless.requestToken(
		function(user, delivery, callback) {
			for (var i = users.length - 1; i >= 0; i--) {
				if(users[i].email === user.toLowerCase()) {
					return callback(null, users[i].id);
				}
			}
			callback(null, null);
		}),
		function(req, res) {
			// success!
		res.render('sent');
});",3
https://github.com/haisonle/passwordless,### 8. Login page,"  All you need is a form where users enter their email address, for example: <html>
	<body>
		<h1>Login</h1>
		<form action=""/sendtoken"" method=""POST"">
			Email:
			<br><input name=""user"" type=""text"">
			<br><input type=""submit"" value=""Login"">
		</form>
	</body>
</html> By default, Passwordless will look for a field called user submitted via POST.",3
https://github.com/haisonle/passwordless,### 9. Protect your pages,"  You can protect all pages that should only be accessed by authenticated users by using the passwordless.restricted() middleware, for example: /* GET restricted site. */
router.get('/restricted', passwordless.restricted(),
 function(req, res) {
  // render the secret page
}); You can also protect a full path, by adding: router.use('/admin', passwordless.restricted());",3
https://github.com/haisonle/passwordless,### 10. Who is logged in?,"  Passwordless stores the user ID in req.user (this can be changed via configuration). So, if you want to display the user's details or use them for further requests, do something like: router.get('/admin', passwordless.restricted(),
	function(req, res) {
		res.render('admin', { user: req.user });
}); You could also create a middleware that is adding the user to any request and enriching it with all user details. Make sure, though, that you are adding this middleware after acceptToken() and sessionSupport(): app.use(function(req, res, next) {
	if(req.user) {
		User.findById(req.user, function(error, user) {
			res.locals.user = user;
			next();
		});
	} else { 
		next();
	}
})",3
https://github.com/haisonle/passwordless,## Common options, ,3
https://github.com/haisonle/passwordless,### Logout,"  Just call passwordless.logout() as in: router.get('/logout', passwordless.logout(),
	function(req, res) {
		res.redirect('/');
});",3
https://github.com/haisonle/passwordless,### Redirects,"  Redirect non-authorised users who try to access protected resources with failureRedirect (default is a 401 error page): router.get('/restricted', 
	passwordless.restricted({ failureRedirect: '/login' }); Redirect unsuccessful login attempts with failureRedirect (default is a 401 or 400 error page): router.post('/login', 
	passwordless.requestToken(function(user, delivery, callback) {
		// identify user
}, { failureRedirect: '/login' }),
	function(req, res){
		// success
}); After the successful authentication through acceptToken(), you can redirect the user to a specific URL with successRedirect: app.use(passwordless.acceptToken(
	{ successRedirect: '/' })); While the option successRedirect is not strictly needed, it is strongly recommended to use it to avoid leaking valid tokens via the referrer header of outgoing HTTP links on your site. When provided, the user will be forwarded to the given URL as soon as she has been authenticated. If not provided, Passwordless will simply call the next middleware.",3
https://github.com/haisonle/passwordless,### Error flashes,"  Error flashes are session-based error messages that are pushed to the user with the next request. For example, you might want to show a certain message when the user authentication was not successful or when a user was redirected after accessing a resource she should not have access to. To make this work, you need to have sessions enabled and a flash middleware such as connect-flash installed. Error flashes are supported in any middleware of Passwordless that supports failureRedirect (see above) but only(!) if failureRedirect is also supplied: 
restricted() when the user is not authorized to access the resource
requestToken() when the supplied user details are unknown
 As an example: router.post('/login', 
	passwordless.requestToken(function(user, delivery, callback) {
		// identify user
}, { failureRedirect: '/login', failureFlash: 'This user is unknown!' }),
	function(req, res){
		// success
}); The error flashes are pushed onto the passwordless array of your flash middleware. Check out the connect-flash docs how to pull the error messages, but a typical scenario should look like this: router.get('/mistake',
	function(req, res) {
		var errors = req.flash('passwordless'), errHtml;
		for (var i = errors.length - 1; i >= 0; i--) {
			errHtml += '<p>' + errors[i] + '</p>';
		}
		res.send(200, errHtml);
});",3
https://github.com/haisonle/passwordless,### Success flashes,"  Similar to error flashes success flashes are session-based messages that are pushed to the user with the next request. For example, you might want to show a certain message when the user has clicked on the token URL and the token was accepted by the system. To make this work, you need to have sessions enabled and a flash middleware such as connect-flash installed. Success flashes are supported by the following middleware of Passwordless: 
acceptToken() when the token was successfully validated
logout() when the user was logged in and was successfully logged out
requestToken() when the token was successfully stored and send out to the user
 Consider the following example: router.get('/logout', passwordless.logout( 
	{successFlash: 'Hope to see you soon!'} ),
	function(req, res) {
  	res.redirect('/home');
}); The messages are pushed onto the passwordless-success array of your flash middleware. Check out the connect-flash docs how to pull the messages, but a typical scenario should look like this: router.get('/home',
	function(req, res) {
		var successes = req.flash('passwordless-success'), html;
		for (var i = successes.length - 1; i >= 0; i--) {
			html += '<p>' + successes[i] + '</p>';
		}
		res.send(200, html);
});",3
https://github.com/haisonle/passwordless,### 2-step authentication (e.g. for SMS),"  For some token-delivery channels you want to have the shortest possible token (e.g. for text messages). One way to do so is to remove the user ID from the token URL and to only keep the token for itself. The user ID is then kept in the session. In practice his could look like this: A user types in his phone number, hits submit, is redirected to another page where she has to type in the token received per SMS, and then hit submit another time. To achieve this, requestToken stores the requested UID in req.passwordless.uidToAuth. Putting it all together, take the following steps: 1: Read out req.passwordless.uidToAuth // Display a new form after the user has submitted the phone number
router.post('/sendtoken', passwordless.requestToken(function(...) { },
	function(req, res) {
  	res.render('secondstep', { uid: req.passwordless.uidToAuth });
}); 2: Display another form to submit the token submitting the UID in a hidden input <html>
	<body>
		<h1>Login</h1>
		<p>You should have received a token via SMS. Type it in below:</p>
		<form action=""/auth"" method=""POST"">
			Token:
			<br><input name=""token"" type=""text"">
			<input type=""hidden"" name=""uid"" value=""<%= uid %>"">
			<br><input type=""submit"" value=""Login"">
		</form>
	</body>
</html> 3: Allow POST to accept tokens router.post('/auth', passwordless.acceptToken({ allowPost: true }),
	function(req, res) {
		// success!
});",3
https://github.com/haisonle/passwordless,### Successful login and redirect to origin,"  Passwordless supports the redirect of users to the login page, remembering the original URL, and then redirecting them again to the originally requested page as soon as the token has been accepted. Due to the many steps involved, several modifications have to be undertaken: 1: Set originField and failureRedirect for passwordless.restricted() Doing this will call /login with /login?origin=/admin to allow later reuse router.get('/admin', passwordless.restricted( 
	{ originField: 'origin', failureRedirect: '/login' })); 2: Display origin as hidden field on the login page Be sure to pass origin to the page renderer. <form action=""/sendtoken"" method=""POST"">
	Token:
	<br><input name=""token"" type=""text"">
	<input type=""hidden"" name=""origin"" value=""<%= origin %>"">
	<br><input type=""submit"" value=""Login"">
</form> 3: Let requestToken() accept origin This will store the original URL next to the token in the TokenStore. app.post('/sendtoken', passwordless.requestToken(function(...) { }, 
	{ originField: 'origin' }),
	function(req, res){
		// successfully sent
}); 4: Reconfigure acceptToken() middleware app.use(passwordless.acceptToken( { enableOriginRedirect: true } ));",3
https://github.com/haisonle/passwordless,### Several delivery strategies,"  In case you want to use several ways to send out tokens you have to add several delivery strategies to Passwordless as shown below: passwordless.addDelivery('email', 
	function(tokenToSend, uidToSend, recipient, callback) {
		// send the token to recipient
});
passwordless.addDelivery('sms', 
	function(tokenToSend, uidToSend, recipient, callback) {
		// send the token to recipient
}); To simplify your code, provide the field delivery to your HTML page which submits the recipient details. Afterwards, requestToken() will allow you to distinguish between the different methods: router.post('/sendtoken', 
	passwordless.requestToken(
		function(user, delivery, callback) {
			if(delivery === 'sms')
				// lookup phone number
			else if(delivery === 'email')
				// lookup email
		}),
	function(req, res) {
  		res.render('sent');
});",3
https://github.com/haisonle/passwordless,### Modify lifetime of a token,"  This is particularly useful if you use shorter tokens than the default to keep security on a high level: // Lifetime in ms for the specific delivery strategy
passwordless.addDelivery(
	function(tokenToSend, uidToSend, recipient, callback) {
		// send the token to recipient
}, { ttl: 1000*60*10 });",3
https://github.com/haisonle/passwordless,### Allow token reuse,"  By default, all tokens are invalidated after they have been used by the user. Should a user try to use the same token again and is not yet logged in, she will not be authenticated. In some cases (e.g. stateless operation or increased convenience) you might want to allow the reuse of tokens. Please be aware that this might open up your users to the risk of valid tokens being used by third parties without the user being aware of it. To enable the reuse of tokens call init() with the option allowTokenReuse: true, as shown here: passwordless.init(new TokenStore(), 
	{ allowTokenReuse: true });",3
https://github.com/haisonle/passwordless,### Different tokens,"  You can generate your own tokens. This is not recommended except you face delivery constraints such as SMS-based authentication. If you reduce the complexity of the token, please consider reducing as well the lifetime of the token (see above): passwordless.addDelivery(
	function(tokenToSend, uidToSend, recipient, callback) {
		// send the token to recipient
}, {tokenAlgorithm: function() {return 'random'}});",3
https://github.com/haisonle/passwordless,### Stateless operation,"  Just remove the app.use(passwordless.sessionSupport()); middleware. Every request for a restricted resource has then to be combined with a token and uid. You should consider the following points: 
By default, tokens are invalidated after their first use. For stateless operations you should call passwordless.init() with the following option: passwordless.init(tokenStore, {allowTokenReuse:true}) (for details see above)
Tokens have a limited lifetime. Consider extending it (for details see above), but be aware about the involved security risks
Consider switching off redirects such as successRedirect on the acceptToken() middleware
",3
https://github.com/haisonle/passwordless,## The tokens and security,"  By default, tokens are generated using 16 Bytes of pseudo-random data as produced by the cryptographically strong crypto library of Node.js. This can be considered strong enough to withstand brute force attacks especially when combined with a finite time-to-live (set by default to 1h). In addition, it is absolutely mandatory to store the tokens securely by hashing and salting them (done by default with TokenStores such as MongoStore). Security can be further enhanced by limiting the number of tries per user ID before locking that user out from the service for a certain amount of time.",3
https://github.com/haisonle/passwordless,## Further documentation,"  
Full API documentation
Getting started
Deep dive
",6
https://github.com/haisonle/passwordless,## Tests,"  Download the whole repository and call:
$ npm test",3
https://github.com/haisonle/passwordless,## License,  MIT License,5
https://github.com/haisonle/passwordless,## Author,  Florian Heinemann @thesumofall,5
https://github.com/JoseEnrique04/r-graph-catalog,# R Graph Catalog," The r-graph-catalog subdirectory of this repo creates the R Graph Catalog Shiny app. This catalog is a complement to ""Creating More Effective Graphs"" by Naomi Robbins. All graphs were produced using the R language and the add-on package ggplot2, written by Hadley Wickham. The gallery is maintained by Joanna Zhao and Jennifer Bryan. The initial work on this project was facilitated by an NSERC Undergraduate Student Research Award.",15
https://github.com/JoseEnrique04/r-graph-catalog,#### Inspiration,"  We are inspired by the R graph gallery and rCharts Gallery. Our goal is to create a simple and organized visual index of diverse ggplot2 graphs. Naomi Robbins' book provided a great set of figures to start with. We are very interested in extending this catalog, possibly helping to revive to the dormant R graph gallery.",12
https://github.com/JoseEnrique04/r-graph-catalog,#### Useful Resources,"  ""Creating More Effective Graphs"" by Naomi Robbins ggplot2 written by Hadley Wickham Winston Chang's book ""R Graphics Cookbook"" and the Graphs section of his Cookbook for R website ggplot2 tutorial from May 2014, Vancouver R Users Group ggplot2 Version of Figures in ""Lattice: Multivariate Data Visualization with R""",6
https://github.com/JoseEnrique04/r-graph-catalog,#### Contributing a figure,"  Ideally, this would be easier, but let's just see if anyone wants to contribute a figure before we worry about this too much! 
Fork this repository and pull to your local machine.
Run make init to create your own figure directory under figures
In the newly generated figure directory, read instuctions.md and make the appropriate changes.
Make a single commit (include *.R, *_tags.txt, README-fodder.md, and data file (if any))
Push back to your fork on GitHub.
Make a pull request.
",7
https://github.com/MaxAdamyan/NightNight,## Features," 
 Integrate night mode easily
 UIColor and UIImage support
 Support NSAttributedString
 Better autocompletion
 Customize with notification
",12
https://github.com/MaxAdamyan/NightNight,## Usage,"  

Use MixedColor instead of UIColor
let view = UIView()

view.mixedBackgroundColor = MixedColor(normal: 0xffffff, night: 0x000000)


Use MixedImage instead of UIImage
let imageView = UIImageView()

imageView.mixedImage = MixedImage(normal: normal, night: night)


Support NSAttributedString
let attributedString = NSMutableAttributedString(string: ""NightNight"")
attributedString.setMixedAttributes(
    [NNForegroundColorAttributeName: MixedColor(normal: 0x000000, night: 0xfafafa)],
    range: NSRange(location: 0, length: 9)
)

public let NNForegroundColorAttributeName
public let NNBackgroundColorAttributeName
public let NNUnderlineColorAttributeName


NavigationBar barStyle
let navigationBar = navigationController?.navigationBar

navigationBar.mixedBarStyle = MixedBarStyle(normal: .Default, night: .Black)


Change current theme to .NORMAL or .NIGHT
NightNight.theme = .NORMAL
NightNight.theme = .NIGHT

",3
https://github.com/MaxAdamyan/NightNight,## Customize,"  NightNight will send NightNightThemeChangeNotification. if you wanna some customize features, you can observe it and change what you want in corresponding selector. public let NightNightThemeChangeNotification",3
https://github.com/MaxAdamyan/NightNight,## Demo,"  

",3
https://github.com/MaxAdamyan/NightNight,## Installation, ,3
https://github.com/MaxAdamyan/NightNight,### Carthage,"  Carthage is a decentralized dependency manager that automates the process of adding frameworks to your Cocoa application. You can install Carthage with Homebrew using the following command: $ brew update
$ brew install carthage To integrate NightNight into your Xcode project using Carthage, specify it in your Cartfile: github ""draveness/NightNight""
",3
https://github.com/MaxAdamyan/NightNight,### Cocoapods,"  CocoaPods is a dependency manager for Cocoa projects. You can install it with the following command: $ gem install cocoapods To integrate NightNight into your Xcode project using CocoaPods, specify it in your Podfile: use_frameworks!

pod 'NightNight'",3
https://github.com/MaxAdamyan/NightNight,### Manually,"  
Download and drop NightNight/Classesfolder in your project.
Congratulations!
",3
https://github.com/MaxAdamyan/NightNight,## License,"  Copyright (c) 2016 Draveness (http://github.com/draveness) NightNight is available under the MIT license. See the LICENSE file for more info. Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.",5
https://github.com/iamxufeng/SlidingTutorial-Android,"##SlidingTutorial [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) <img src=https://www.cleveroad.com/public/comercial/label-android.svg"" height=""20""> <a href=""https://www.cleveroad.com/?utm_source=github&utm_medium=label&utm_campaign=contacts""><img src=""https://www.cleveroad.com/public/comercial/label-cleveroad.svg"" height=""20""></a>"""," Hey guys, hope you haven’t started developing a tutorial for your Android app yet, as we have already completed a part of your job. Don’t worry, we act from good motives only. Our aim is to help you create a sliding tutorial in a fast and simple manner. So we’ve done some work and voila!. A simple Android Sliding Tutorial library is at your service. ",1
https://github.com/iamxufeng/SlidingTutorial-Android,## Cleveroad introduces Sliding Tutorial Library for Android,"  The invention is going to ease the problem of structural design but not to limit a stretch of your imagination at the same time. We took care of the suitability aspect. So, your app is not going to look alien among other Android elements. Read our Case Study: Sliding tutorial for Android by Cleveroad to make sure that you don’t miss a detail: 
 Applied parallax effects will make your product presentation look like Google apps tutorial. All you need to do is:
1. Create background designs for each screen of your tutorial (assistance with mobile design)
2. Create icons for each screen of your tutorial
3. Follow the instructions below ",12
https://github.com/iamxufeng/SlidingTutorial-Android,"###### Also you can watch the animation of the <strong><a target=_blank"" href=""https://www.youtube.com/watch?v=lJSGIk4Zh9s&feature=youtu.be"">Sliding Tutorial for Android on YouTube</a></strong> in HD quality.""",,1
https://github.com/iamxufeng/SlidingTutorial-Android,## Using,"  First, add gradle dependency into your build.gradle: dependencies {
    compile 'com.cleveroad:slidingtutorial:1.0.5'
} There are two common variants of using library: via TutorialPageProvider and via TutorialPageOptionsProvider.",3
https://github.com/iamxufeng/SlidingTutorial-Android,### Via TutorialPageProvider,"  You have to create page fragments where each fragment must extend from PageFragment, override PageFragment#getLayoutResId() and PageFragment#getTransformItems(). Also you have to create your layout xml file with images. public class FirstCustomPageFragment extends PageFragment {

    @Override
    protected int getLayoutResId() {
        return R.layout.fragment_page_first;
    }

    @Override
    protected TransformItem[] provideTransformItems() {
        return new TransformItem[] {
                // TransformItem.create(view for transform, moving direction, shift coefficient)
                TransformItem.create(R.id.ivFirstImage, Direction.LEFT_TO_RIGHT, 0.2f),
                TransformItem.create(R.id.ivSecondImage, Direction.RIGHT_TO_LEFT, 0.06f),
                TransformItem.create(R.id.ivThirdImage, Direction.LEFT_TO_RIGHT, 0.08f),
                TransformItem.create(R.id.ivFourthImage, Direction.RIGHT_TO_LEFT, 0.1f),
                TransformItem.create(R.id.ivFifthImage, Direction.RIGHT_TO_LEFT, 0.03f),
                TransformItem.create(R.id.ivSixthImage, Direction.RIGHT_TO_LEFT, 0.09f),
                TransformItem.create(R.id.ivSeventhImage, Direction.RIGHT_TO_LEFT, 0.14f),
                TransformItem.create(R.id.ivEighthImage, Direction.RIGHT_TO_LEFT, 0.07f)
        };
    }
} Pass TutorialPageProvider instance to TutorialOptions.Builder#setTutorialPageProvider(TutorialPageProvider). public class CustomTutorialFragment extends TutorialFragment {

    private static final int TOTAL_PAGES = 3;

    private final TutorialPageProvider<Fragment> mTutorialPageProvider = new TutorialPageProvider<Fragment>() {
        @NonNull
        @Override
        public Fragment providePage(int position) {
            switch (position) {
                case 0:
                    return new FirstCustomPageFragment();
                case 1:
                    return new SecondCustomPageFragment();
                case 2:
                    return new ThirdCustomPageFragment();
                default:
                    throw new IllegalArgumentException(""Unknown position: "" + position);
            }
        }
    };

    @Override
    protected TutorialOptions provideTutorialOptions() {
        return newTutorialOptionsBuilder(getContext())
                .setPagesCount(TOTAL_PAGES)
                .setTutorialPageProvider(mTutorialPageProvider)
                .build();
    }
}",3
https://github.com/iamxufeng/SlidingTutorial-Android,### Via TutorialPageOptionsProvider,"  Or you can create TutorialPageOptionsProvider and pass it to TutorialOptions.Builder#setTutorialPageProvider(TutorialPageOptionsProvider). It will automatically provide PageFragment instance with specified PageOptions configuration. public class CustomTutorialFragment extends TutorialFragment {

    private static final int TOTAL_PAGES = 3;

    private final TutorialPageOptionsProvider mTutorialPageOptionsProvider = new TutorialPageOptionsProvider() {
        @NonNull
        @Override
        public PageOptions provide(int position) {
            @LayoutRes int pageLayoutResId;
            TransformItem[] tutorialItems;
            switch (position) {
                case 0: {
                    pageLayoutResId = R.layout.fragment_page_first;
                    tutorialItems = new TransformItem[]{
                            TransformItem.create(R.id.ivFirstImage, Direction.LEFT_TO_RIGHT, 0.2f),
                            TransformItem.create(R.id.ivSecondImage, Direction.RIGHT_TO_LEFT, 0.06f),
                            TransformItem.create(R.id.ivThirdImage, Direction.LEFT_TO_RIGHT, 0.08f),
                            TransformItem.create(R.id.ivFourthImage, Direction.RIGHT_TO_LEFT, 0.1f),
                            TransformItem.create(R.id.ivFifthImage, Direction.RIGHT_TO_LEFT, 0.03f),
                            TransformItem.create(R.id.ivSixthImage, Direction.RIGHT_TO_LEFT, 0.09f),
                            TransformItem.create(R.id.ivSeventhImage, Direction.RIGHT_TO_LEFT, 0.14f),
                            TransformItem.create(R.id.ivEighthImage, Direction.RIGHT_TO_LEFT, 0.07f)
                    };
                    break;
                }
                case 1: {
                    pageLayoutResId = R.layout.fragment_page_second;
                    tutorialItems = new TransformItem[]{
                            TransformItem.create(R.id.ivFirstImage, Direction.RIGHT_TO_LEFT, 0.2f),
                            TransformItem.create(R.id.ivSecondImage, Direction.LEFT_TO_RIGHT, 0.06f),
                            TransformItem.create(R.id.ivThirdImage, Direction.RIGHT_TO_LEFT, 0.08f),
                            TransformItem.create(R.id.ivFourthImage, Direction.LEFT_TO_RIGHT, 0.1f),
                            TransformItem.create(R.id.ivFifthImage, Direction.LEFT_TO_RIGHT, 0.03f),
                            TransformItem.create(R.id.ivSixthImage, Direction.LEFT_TO_RIGHT, 0.09f),
                            TransformItem.create(R.id.ivSeventhImage, Direction.LEFT_TO_RIGHT, 0.14f),
                            TransformItem.create(R.id.ivEighthImage, Direction.LEFT_TO_RIGHT, 0.07f)
                    };
                    break;
                }
                case 2: {
                    pageLayoutResId = R.layout.fragment_page_third;
                    tutorialItems = new TransformItem[]{
                            TransformItem.create(R.id.ivFirstImage, Direction.RIGHT_TO_LEFT, 0.2f),
                            TransformItem.create(R.id.ivSecondImage, Direction.LEFT_TO_RIGHT, 0.06f),
                            TransformItem.create(R.id.ivThirdImage, Direction.RIGHT_TO_LEFT, 0.08f),
                            TransformItem.create(R.id.ivFourthImage, Direction.LEFT_TO_RIGHT, 0.1f),
                            TransformItem.create(R.id.ivFifthImage, Direction.LEFT_TO_RIGHT, 0.03f),
                            TransformItem.create(R.id.ivSixthImage, Direction.LEFT_TO_RIGHT, 0.09f),
                            TransformItem.create(R.id.ivSeventhImage, Direction.LEFT_TO_RIGHT, 0.14f)
                    };
                    break;
                }
                default: {
                    throw new IllegalArgumentException(""Unknown position: "" + position);
                }
            }

            return PageOptions.create(pageLayoutResId, position, tutorialItems);
        }
    };

    @Override
    protected TutorialOptions provideTutorialOptions() {
        return newTutorialOptionsBuilder(getContext())
                .setPagesCount(TOTAL_PAGES)
                .setTutorialPageProvider(mTutorialPageOptionsProvider)
                .build();
    }
}",3
https://github.com/iamxufeng/SlidingTutorial-Android,### Using with AppCompat library (Recommended way),"  Here's the list of changes in code to use SlidingTutorial library with AppCompat library: 
Your fragment pages must extend PageSupportFragment.
Your tutorial fragment must extend TutorialSupportFragment.
TutorialPageProvider must provide android.support.v4.app.Fragment instances.
That's all.
",3
https://github.com/iamxufeng/SlidingTutorial-Android,## Customization, ,3
https://github.com/iamxufeng/SlidingTutorial-Android,### Setup skip button click listener,"  You have to implement View.OnClickListener interface and provide it to TutorialOptions.Builder#setOnSkipClickListener(OnClickListener). Example: public class CustomTutorialFragment extends TutorialFragment {
    @Override
    protected TutorialOptions provideTutorialOptions() {
        return newTutorialOptionsBuilder(getContext())
                .setOnSkipClickListener(new View.OnClickListener() {
                    @Override
                    public void onClick(View v) {
                        Toast.makeText(getContext(), ""Skip button clicked"", Toast.LENGTH_SHORT).show();
                    }
                })
                // setup other configuration ...
                .build();
    }
}",3
https://github.com/iamxufeng/SlidingTutorial-Android,### Setup pages colors,"  Just provide array of color values to TutorialOptions.Builder#setPagesColors(int array). The array with colors must have length equal to pages count. public class CustomTutorialFragment extends TutorialFragment {

    private static final int TOTAL_PAGES = 3;

    private int[] pagesColors = new int[] { Color.RED, Color.BLUE, Color.DKGRAY };

    @Override
    protected TutorialOptions provideTutorialOptions() {
        return newTutorialOptionsBuilder(getContext())
                .setPagesCount(TOTAL_PAGES)
                .setPagesColors(pagesColors)
                // setup other configuration ...
                .build();
    }
}",3
https://github.com/iamxufeng/SlidingTutorial-Android,### Infinite scroll,  To loop tutorial pages you have set TutorialOptions.Builder#setUseInfiniteScroll(boolean) to true.,3
https://github.com/iamxufeng/SlidingTutorial-Android,### Auto remove TutorialFragment - scroll from last tutorial page to your content,  If you want to provide smooth transition from last tutorial page to content - just setup TutorialOptions.Builder#setUseAutoRemoveTutorialFragment(boolean) to true.,3
https://github.com/iamxufeng/SlidingTutorial-Android,### Indicator view customization,"  There is IndicatorOptions class for configuration indicator view. Here's example: public class CustomTutorialFragment extends TutorialFragment {
    @Override
    protected TutorialOptions provideTutorialOptions() {
        return newTutorialOptionsBuilder(getContext())
                .setIndicatorOptions(IndicatorOptions.newBuilder(getContext())
                        .setElementSizeRes(R.dimen.indicator_size)
                        .setElementSpacingRes(R.dimen.indicator_spacing)
                        .setElementColorRes(android.R.color.darker_gray)
                        .setSelectedElementColor(android.R.color.white)
                        .setRenderer(Drawable.create(getContext()))
                        .build())
                // setup other configuration ...
                .build();
    }
} As you can see, you can specify element size, element spacing (aka padding), element color, selected element color, and implementation of Renderer interface. There are 2 default implementation inside Renderer.Factory: 
Renderer.Factory#newCircleRenderer() - draw indicators with circle shape
Renderer.Factory#newSquareRenderer() - draw indicators with square shape
 Also in sample module there are two implementations: 
DrawableRenderer - draw indicators with drawable background
RhombusRenderer - draw indicators with rhombus shape
",3
https://github.com/iamxufeng/SlidingTutorial-Android,### Add OnTutorialPageChangeListener,"  You can listen change page events - just implement OnTutorialPageChangeListener and add listener via TutorialFragment#addOnTutorialPageChangeListener(OnTutorialPageChangeListener). To remove listener use TutorialFragment#removeOnTutorialPageChangeListener(OnTutorialPageChangeListener). In OnTutorialPageChangeListener#onPageChanged(int) method you will receive a page index every time page changes. If you enabled TutorialOptions.Builder#setUseAutoRemoveTutorialFragment(boolean) to true, you will receive TutorialFragment.EMPTY_FRAGMENT_POSITION (or TutorialSupportFragment.EMPTY_FRAGMENT_POSITION if you are using support library) as page index. public class CustomTutorialFragment extends TutorialFragment
        implements OnTutorialPageChangeListener {

    private static final String TAG = ""CustomTutorialFragment"";

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        addOnTutorialPageChangeListener(this);
    }

    @Override
    public void onPageChanged(int position) {
        Log.i(TAG, ""onPageChanged: position = "" + position);
        if (position == TutorialFragment.EMPTY_FRAGMENT_POSITION) {
            Log.i(TAG, ""onPageChanged: Empty fragment is visible"");
        }
    }

}",3
https://github.com/iamxufeng/SlidingTutorial-Android,### Add PageTransformer,"You can apply your own property transformation to the given page - just implement ViewPager.PageTransformer interface and set it via TutorialOptions.Builder#setPageTransformer(ViewPager.PageTransformer pageTransformer).

ViewPager.PageTransformer pageTransformer = new ViewPager.PageTransformer() {
    @Override
    public void transformPage(View page, float position) {
        //Implement your transformation here
    }
};

TutorialOptions tutorialOptions = newTutorialOptionsBuilder(getContext())
    // ...
    .setPageTransformer(pageTransformer)
    .build();",3
https://github.com/iamxufeng/SlidingTutorial-Android,## Migrations,  See all migration manuals.,6
https://github.com/iamxufeng/SlidingTutorial-Android,## Changelog,  See changelog history.,4
https://github.com/iamxufeng/SlidingTutorial-Android,## Support,"  If you have any questions regarding the use of this tutorial, please contact us for support
at info@cleveroad.com (email subject: «Sliding android app tutorial. Support request.»)
or
Use our contacts:
Cleveroad.com
Facebook account
Twitter account
Google+ account",56
https://github.com/iamxufeng/SlidingTutorial-Android,## License,"      The MIT License (MIT)

    Copyright (c) 2015-2016 Cleveroad

    Permission is hereby granted, free of charge, to any person obtaining a copy
    of this software and associated documentation files (the ""Software""), to deal
    in the Software without restriction, including without limitation the rights
    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
    copies of the Software, and to permit persons to whom the Software is
    furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in all
    copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
    SOFTWARE.
",5
https://github.com/duguruiyuan/date-time-picker,# date-time-picker,,1
https://github.com/duguruiyuan/date-time-picker,## Installation," No Dependencies Lightweight Material Date/Time Picker For Mobile Web date-time-picker.min.js: ~9k when gzipped
date-time-picker.min.css: ~2k when gzipped  ",3
https://github.com/duguruiyuan/date-time-picker,## Usage,"  Download from https://github.com/dolymood/date-time-picker/tree/master/dist, it contains minified js and css files. Or use npm: npm install date-time-picker
",3
https://github.com/duguruiyuan/date-time-picker,### DatePicker,  As a npm package: var DateTimePicker = require('date-time-picker') AMD: var DateTimePicker = require('/path/to/date-time-picker.min.js') Script load: var DateTimePicker = window.DateTimePicker,3
https://github.com/duguruiyuan/date-time-picker,### TimePicker,"  btn.onclick = function () {
  var datePicker = new DateTimePicker.Date(options, config)
  datePicker.on('selected', function (formatDate, now) {
    // formatData = 2016-10-19
    // now = Date instance -> Wed Oct 19 2016 20:28:12 GMT+0800 (CST)
  })
}",3
https://github.com/duguruiyuan/date-time-picker,### API and Events,"  btn.onclick = function () {
  var timePicker = new DateTimePicker.Time(options, config)
  timePicker.on('selected', function (formatTime, now) {
    // formatTime = 18:30
    // now = Date instance -> Wed Oct 19 2016 18:30:13 GMT+0800 (CST)
  })
}",3
https://github.com/duguruiyuan/date-time-picker,## Options and Config,"  API: picker.show()
picker.hide()
picker.destroy() Events: picker
  // click OK button
  .on('selected', function (formatValue, now) {
    console.log(formatValue, now)
  })
  // click CANCEL button
  // also trigger `destroy` event
  .on('canceled', function () {
    console.log('canceled')
  })
  .on('destroy', function () {
    console.log('destroy')
  })",3
https://github.com/duguruiyuan/date-time-picker,### DatePicker Options,"  {
  lang: 'EN', // default 'EN'. One of 'EN', 'zh-CN'
  format: 'yyyy-MM-dd', // default 'yyyy-MM-dd'
  default: '2016-10-19', // default `new Date()`. If `default` type is string, then it will be parsed to `Date` instance by `format` . Or it can be a `Date` instance
}",3
https://github.com/duguruiyuan/date-time-picker,### TimePicker Options,"  {
  lang: 'EN', // default 'EN'
  format: 'HH:mm', // default 'HH:mm'
  default: '12:27', // default `new Date()`. If `default` type is string, then it will be parsed to `Date` instance by `format` . Or it can be a `Date` instance
  minuteStep: 5 // default 5. Select minutes step, must be one of [1, 5, 10]
}",3
https://github.com/duguruiyuan/date-time-picker,### Config,"  Default English(EN): {
  day: ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'],
  shortDay: ['S', 'M', 'T', 'W', 'T', 'F', 'S'],
  MDW: 'D, MM-d',
  YM: 'yyyy-M',
  OK: 'OK',
  CANCEL: 'CANCEL'
} Default 中文(zh-CN): {
  day: ['周日', '周一', '周二', '周三', '周四', '周五', '周六'],
  shortDay: ['?, '一', '?, '?, '?, '?, '?],
  MDW: 'M月d日D',
  YM: 'yyyy年M?,
  OK: '确定',
  CANCEL: '取消'
}",3
https://github.com/duguruiyuan/date-time-picker,## License,  MIT,5
https://github.com/sd6352051/NiftyNotification,#NiftyNotification,,1
https://github.com/sd6352051/NiftyNotification,# ScreenShot, ,1
https://github.com/sd6352051/NiftyNotification,# Usage,"  NiftyNotificationView.build(this,msg, effect,R.id.mLyout)
      .setIcon(R.drawable.lion)    //You must call this method if you use ThumbSlider effect
      show();
<!-- ViewGroup-->
<RelativeLayout
      android:id=""@+id/mLyout""
      android:layout_width=""match_parent""
      android:layout_height=""match_parent""
      >

</RelativeLayout>",3
https://github.com/sd6352051/NiftyNotification,#,,-
https://github.com/sd6352051/NiftyNotification,# Configuration,"  Configuration cfg=new Configuration.Builder()
      .setAnimDuration(700)
      .setDispalyDuration(1500)
      .setBackgroundColor(""#FFBDC3C7"")
      .setTextColor(""#FF444444"")
      .setIconBackgroundColor(""#FFFFFFFF"")
      .setTextPadding(5)                      //dp
      .setViewHeight(48)                      //dp
      .setTextLines(2)                        //You had better use setViewHeight and setTextLines together
      .setTextGravity(Gravity.CENTER)         //only text def  Gravity.CENTER,contain icon Gravity.CENTER_VERTICAL
      .build();

NiftyNotificationView.build(this,msg, effect,R.id.mLyout,cfg)
      .setIcon(R.drawable.lion)               //remove this line ,only text
      .setOnClickListener(new View.OnClickListener() {
      @Override
      public void onClick(View view) {
      //add your code
      }
      })
      .show();                               //  show(boolean) allow duplicates   or showSticky() sticky notification,you can call removeSticky() method close it
",3
https://github.com/sd6352051/NiftyNotification,# Install,"  You can install using Gradle from JitPack. Add this to your build.gradle file: 	repositories {
	    maven { url ""https://jitpack.io"" }
	}
	
	dependencies {
	    compile 'com.github.sd6352051:NiftyNotification:1.2'
	} Or copy this into your libs directory. 

NineOldAndroid-2.4.0


NiftyNotification-1.2

",3
https://github.com/sd6352051/NiftyNotification,# Effects,"  Flip, Jelly, Scale, SlideIn, SlideOnTop, Standard, ThumbSlider",6
https://github.com/sd6352051/NiftyNotification,# License,"  Copyright 2014 litao. Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.",5
https://github.com/itlackey/assemble-workshop,# Assemble recipes [![NPM version](https://img.shields.io/npm/v/assemble-workshop.svg?style=flat)](https://www.npmjs.com/package/assemble-workshop) [![Build Status](https://img.shields.io/travis/Stefan%20Walther/assemble-workshop.svg?style=flat)](https://travis-ci.org/Stefan%20Walther/assemble-workshop)," 
Some recipes using assemble v0.16.0.
",1
https://github.com/itlackey/assemble-workshop,## Recipes,"  All recipes contain some explanation but also a fully working version of the recipe in the according folder. 
Assemble & BrowserSync
Working with collections
Default layout
Drafts
Gulp sitemap
Less to CSS
Loading handlebar helpers
Permalinks
Permalinks - Folder per file
Permalinks with subfolders/images
Events to hook into with middleware
Middleware example: Bind TOC to view
Visual Studio Integration: Basic Bootstrap Site
VS Code
",16
https://github.com/itlackey/assemble-workshop,## Running tests,  Install dev dependencies: $ npm install -d && npm test,3
https://github.com/itlackey/assemble-workshop,## Contributing,"  Pull requests and stars are always welcome. For bugs and feature requests, please create an issue.",7
https://github.com/itlackey/assemble-workshop,## Author,"  Stefan Walther 
qliksite.io
twitter/waltherstefan
github.com/stefanwalther
",5
https://github.com/itlackey/assemble-workshop,## License,"  Copyright © 2016, Stefan Walther.
Released under the MIT license.",5
https://github.com/EarLyMe/ruby-object-initialize-lab-v-000,# Ruby Object Initialize Lab,,1
https://github.com/EarLyMe/ruby-object-initialize-lab-v-000,## Objectives,"  
Define a class with a custom initialize routine.
Set instance variable attributes from initialize.
Include a default argument for an initialize argument.
",1
https://github.com/EarLyMe/ruby-object-initialize-lab-v-000,## Overview,"  You're going to be building a Person class that accepts a person's name when a person is initialized. You're also going to be building a Dog class that accepts a dog's name and breed on initialization. If no value for the dog's breed is provided, it should default to ""Mut""",1
https://github.com/EarLyMe/ruby-object-initialize-lab-v-000,## Instructions,  Open this lab with learn open and run the tests with learn.,3
https://github.com/EarLyMe/ruby-object-initialize-lab-v-000,#### 1. `Person#initialize` with a Name,  Define a Person class in lib/person.rb that provides an #initialize method that accepts an argument for the person's name. That argument should be stored within a @name instance variable.,3
https://github.com/EarLyMe/ruby-object-initialize-lab-v-000,"#### 2. `Dog#initialize` with Name and Breed defaulting to Mut""""","  Define a Dog class in lib/dog.rb that provides an #initialize method that accepts an argument for the dog's name. That argument should be stored within a @name instance variable. Additionally, Dog#initialize should accept a second optional argument for the dog's breed stored in an instance variable @breed. When none is provided, it should default to ""Mut"". Submit your solution with learn submit. View this lesson on Learn.co",3
https://github.com/sandriichenko/tcp-qa,# tcp-qa, Default template used here requires 20 vCPU and 52Gb host RAM.,1
https://github.com/sandriichenko/tcp-qa,## Clone the repo,"  git clone https://github.com/Mirantis/tcp-qa
cd ./tcp-qa
",3
https://github.com/sandriichenko/tcp-qa,## Install requirements,"  pip install -r ./tcp_tests/requirements.txt
 
Note: Please read [1] if you don't have fuel-devops installed, because there are required some additional packages and configuration.
",3
https://github.com/sandriichenko/tcp-qa,## Get cloudinit images,"  wget https://cloud-images.ubuntu.com/trusty/current/trusty-server-cloudimg-amd64-disk1.img -O ./trusty-server-cloudimg-amd64.qcow2
wget https://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img -O ./xenial-server-cloudimg-amd64.qcow2
",3
https://github.com/sandriichenko/tcp-qa,## Export variables,"  Required: export IMAGE_PATH1404=./trusty-server-cloudimg-amd64.qcow2
export IMAGE_PATH1604=./xenial-server-cloudimg-amd64.qcow2
 Optional: export SHUTDOWN_ENV_ON_TEARDOWN=false  # Optional
",3
https://github.com/sandriichenko/tcp-qa,## Run deploy test for mk22-lab-dvr,"  Note: This lab is not finished yet. TBD: configure vsrx node export ENV_NAME=tcpcloud-mk22-dvr  # You can set any env name
export LAB_CONFIG_NAME=mk22-lab-dvr  # Name of set of templates

LC_ALL=en_US.UTF-8  py.test -vvv -s -k test_tcp_install_default


Run deploy test for mk22-lab-ovs
--------------------------------
Note: This lab is not finished yet. TBD: configure vsrx node
 export ENV_NAME=tcpcloud-mk22-ovs  # You can set any env name
export LAB_CONFIG_NAME=mk22-lab-ovs  # Name of set of templates LC_ALL=en_US.UTF-8  py.test -vvv -s -k test_tcp_install_default",3
https://github.com/sandriichenko/tcp-qa,## Run deploy test for mk22-lab-ovs,,3
https://github.com/sandriichenko/tcp-qa,## Run deploy test for mk22-qa-lab01,"  Note: This lab is not finished yet. TBD: configure vsrx node export ENV_NAME=tcpcloud-mk22  # You can set any env name
export LAB_CONFIG_NAME=mk22-qa-lab01  # Name of set of templates
export VSRX_PATH=./vSRX.img           # /path/to/vSRX.img, or to ./xenial-server-cloudimg-amd64.qcow2 as a temporary workaround

LC_ALL=en_US.UTF-8  py.test -vvv -s -k test_tcp_install_default
 , or as an alternative there is another test that use deploy scripts from models repository written on bash [2]: LC_ALL=en_US.UTF-8  py.test -vvv -s -k test_tcp_install_with_scripts
 Labs with names mk22-lab-basic and mk22-lab-avdanced are deprecated and not recommended to use.",3
https://github.com/sandriichenko/tcp-qa,## Create and start the env for manual tests,"  dos.py create-env ./tcp_tests/templates/underlay/mk22-lab-basic.yaml
dos.py start ""${ENV_NAME}""
 Then, wait until cloud-init is finished and port 22 is open (~3-4 minutes), and login with root:r00tme [1] https://github.com/openstack/fuel-devops/blob/master/doc/source/install.rst [2] https://github.com/Mirantis/mk-lab-salt-model/tree/dash/scripts",3
https://github.com/nithiroj/Mining-the-Social-Web-2nd-Edition,# Mining the Social Web (2nd Edition),,1
https://github.com/nithiroj/Mining-the-Social-Web-2nd-Edition,## Summary,"  Mining the Social Web, 2nd Edition is available through O'Reilly Media, Amazon, and other fine book retailers. Purchasing the ebook directly from O'Reilly offers a number of great benefits, including a variety of digital formats and continual updates to the text of book for life! Better yet, if you choose to use O'Reilly's DropBox or Google Drive synchronization, your ebooks will automatically update every time there's an update. In other words, you'll always have the latest version of the book if you purchase the ebook through O'Reilly, which is why it's the recommended option in comparison to a paper copy or other electronic version. (If you prefer a paperback or Kindle version from Amazon, that's a fine option as well.) There's an incredible turn-key virtual machine experience for this second edition of the book that provides you with a powerful social web mining toolbox. This toolbox provides the ability to explore and run all of the source code in a hassle-free manner. All that you have to do is [follow a few simple steps](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/_Appendix A - Virtual Machine Experience.html) to get the virtual machine installed, and you'll be running the example code in as little as 20-30 minutes. (And by the way, most of that time is waiting for files to download.) This short screencast demonstrates the steps involved in installing the virtual machine, which installs every single dependency for you automatically and save you a lot of time. Even sophisticated power users tend to prefer using it versus using their own environments. If you experience any problems at all with installation of the virtual machine, file an issue here on GitHub. Be sure to also follow @SocialWebMining on Twitter and like http://facebook.com/MiningTheSocialWeb on Facebook. Be sure to also visit http://MiningTheSocialWeb.com for additional content, news, and updates about the book and code in this GitHub repository.",126
https://github.com/nithiroj/Mining-the-Social-Web-2nd-Edition,## Preview the Full-Text of Chapter 1 (Mining Twitter),"  Chapter 1 of the book provides a gentle introduction to hacking on Twitter data. It's available in a variety of convenient formats 
A free PDF download
An online ebook excerpt
An IPython Notebook (ipynb) file  (checked into this repository)
 Choose one, or choose them all. There's no better way to get started than following along with the opening chapter.",1
https://github.com/nithiroj/Mining-the-Social-Web-2nd-Edition,## Preview the IPython Notebooks,"  This edition of Mining the Social Web extensively uses IPython Notebook to facilitate the learning and development process. If you're interested in what the example code for any particular chapter does, the best way to preview it is with the links below. When you're ready to develop, pull the source for this GitHub repository and follow the instructions for installing the virtual machine to get started. A bit.ly bundle of all of these links is also available: http://bit.ly/mtsw2e-ipynb 
[Chapter 0 - Preface](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 0 - Preface.html)
[Chapter 1 - Mining Twitter: Exploring Trending Topics, Discovering What People Are Talking About, and More](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 1 - Mining Twitter.html)
[Chapter 2 - Mining Facebook: Analyzing Fan Pages, Examining Friendships, and More](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 2 - Mining Facebook.html)
[Chapter 3 - Mining LinkedIn: Faceting Job Titles, Clustering Colleagues, and More](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 3 - Mining LinkedIn.html)
[Chapter 4 - Mining Google+: Computing Document Similarity, Extracting Collocations, and More](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 4 - Mining Google+.html)
[Chapter 5 - Mining Web Pages: Using Natural Language Processing to Understand Human Language, Summarize Blog Posts and More](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 5 - Mining Web Pages.html)
[Chapter 6 - Mining Mailboxes: Analyzing Who's Talking To Whom About What, How Often, and More](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 6 - Mining Mailboxes.html)
[Chapter 7 - Mining GitHub: Inspecting Software Collaboration Habits, Building Interest Graphs, and More](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 7 - Mining GitHub.html)
[Chapter 8 - Mining the Semantically Marked-Up Web: Extracting Microformats, Inferencing Over RDF, and More](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 8 - Mining the Semantically Marked-Up Web.html)
[Chapter 9 - Twitter Cookbook](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/Chapter 9 - Twitter Cookbook.html)
[Appendix A - Virtual Machine Experience](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/_Appendix A - Virtual Machine Experience.html)
[Appendix B - OAuth Primer](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/_Appendix B - OAuth Primer.html)
[Appendix C - Python & IPython Notebook Tips](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/_Appendix C - Python & IPython Notebook Tips.html)
",1
https://github.com/nithiroj/Mining-the-Social-Web-2nd-Edition,## Blog & Screencasts,"  Be sure to bookmark the Mining the Social Web Vimeo Channel to stay up to date with short instructional videos that demonstrate how to use the tools in this repository. More screencasts are being added all the time, so check back often -- or better yet, subscribe to the channel. 

A ~3 minute screencast on installing a powerful toolbox for social web mining.
View a collection of all available screencasts at http://bit.ly/mtsw2e-screencasts
 You might also benefit from the content that is being regularly added to the companion blog at http://MiningTheSocialWeb.com",6
https://github.com/nithiroj/Mining-the-Social-Web-2nd-Edition,## The _Mining the Social Web_ Virtual Machine,"  You may enjoy this short screencast that demonstrates the step-by-step instructions involved in installing the book's virtual machine. The code for Mining the Social Web is organized by chapter in an IPython Notebook format to maximize enjoyment of following along with examples as part of an interactive experience. Unfortunately, some of the Python dependencies for the example code can be a little bit tricky to get installed and configured, so providing a completely turn-key virtual machine to make your reading experience as simple and enjoyable as possible is in order. Even if you are a seasoned developer, you may still find some value in using this virtual machine to get started and save yourself some time. The virtual machine is powered with Vagrant, an amazing development tool that you'll probably want to know about and arguably makes working with virtualization even easier than a native Virtualbox or VMWare image.",3
https://github.com/nithiroj/Mining-the-Social-Web-2nd-Edition,## Quick Start Guide,"  The recommended way of getting started with the example code is by taking advantage of the Vagrant-powered virtual machine as illusrated in this short screencast. After all, you're more interested in following along and learning from the examples than installing and managing all of the system dependencies just to get to that point, right? [Appendix A - Virtual Machine Experience](https://rawgithub.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/master/ipynb/html/_Appendix A - Virtual Machine Experience.html) provides clear step-by-step instructions for installing the virtual machine and is intended to serve as a quick start guide.",3
https://github.com/nithiroj/Mining-the-Social-Web-2nd-Edition,## The _Mining the Social Web_ Wiki,"  This project takes advantage of its GitHub repository's wiki to act as a point of collaboration for consumers of the source code. Feel free to use the wiki however you'd like to share your experiences, and create additional pages as needed to curate additional information. One of the more important wiki pages that you may want to bookmark is the Advisories page, which is an archive of notes about particularly disruptive commits or other changes that may affect you. Another page of interest is a listing of all 100+ numbered examples from the book that conveniently hyperlink to read-only version of the IPython Notebooks",6
https://github.com/nithiroj/Mining-the-Social-Web-2nd-Edition,"## Premium Support""""","  The source code in this repository is free for your use however you'd like. If you'd like to complete a more rigorous study about social web mining much like you would experience by following along with a textbook in a classroom, however, you should consider picking up a copy of Mining the Social Web and follow along. Think of the book as offering a form of ""premium support"" for this open source project. The publisher's description of the book follows for your convenience: How can you tap into the wealth of social web data to discover who’s making connections with whom, what they’re talking about, and where they’re located? With this expanded and thoroughly revised edition, you’ll learn how to acquire, analyze, and summarize data from all corners of the social web including Facebook, Twitter, LinkedIn, Google+, GitHub, email, websites, and blogs. 
Employ IPython Notebook, the Natural Language Toolkit, NetworkX, and other scientific computing tools to mine popular social web sites
Apply advanced text-mining techniques, such as clustering and TF-IDF, to extract meaning from human language data
Bootstrap interest graphs from GitHub by discovering affinities among people, programming languages, and coding projects
Build interactive visualizations with D3.js, a state-of-the-art HTML5 and JavaScript toolkit
Take advantage of more than two-dozen Twitter recipes presented in O’Reilly’s popular and well-known cookbook format
 The example code for this data science book is maintained in a public GitHub repository and is designed to be especially accessible through a turn-key virtual machine that facilitates interactive learning with an easy-to-use collection of IPython Notebooks.",6
https://github.com/josnthecaster/RepData_PeerAssessment1,## Introduction," It is now possible to collect a large amount of data about personal
movement using activity monitoring devices such as a
Fitbit, Nike
Fuelband, or
Jawbone Up. These type of devices are part of
the ""quantified self"" movement -- a group of enthusiasts who take
measurements about themselves regularly to improve their health, to
find patterns in their behavior, or because they are tech geeks. But
these data remain under-utilized both because the raw data are hard to
obtain and there is a lack of statistical methods and software for
processing and interpreting the data. This assignment makes use of data from a personal activity monitoring
device. This device collects data at 5 minute intervals through out the
day. The data consists of two months of data from an anonymous
individual collected during the months of October and November, 2012
and include the number of steps taken in 5 minute intervals each day.",12
https://github.com/josnthecaster/RepData_PeerAssessment1,## Data,"  The data for this assignment can be downloaded from the course web
site: 
Dataset: Activity monitoring data [52K]
 The variables included in this dataset are: 

steps: Number of steps taking in a 5-minute interval (missing
values are coded as NA)


date: The date on which the measurement was taken in YYYY-MM-DD
format


interval: Identifier for the 5-minute interval in which
measurement was taken

 The dataset is stored in a comma-separated-value (CSV) file and there
are a total of 17,568 observations in this
dataset.",3
https://github.com/josnthecaster/RepData_PeerAssessment1,## Assignment,"  This assignment will be described in multiple parts. You will need to
write a report that answers the questions detailed below. Ultimately,
you will need to complete the entire assignment in a single R
markdown document that can be processed by knitr and be
transformed into an HTML file. Throughout your report make sure you always include the code that you
used to generate the output you present. When writing code chunks in
the R markdown document, always use echo = TRUE so that someone else
will be able to read the code. This assignment will be evaluated via
peer assessment so it is essential that your peer evaluators be able
to review the code for your analysis. For the plotting aspects of this assignment, feel free to use any
plotting system in R (i.e., base, lattice, ggplot2) Fork/clone the GitHub repository created for this
assignment. You
will submit this assignment by pushing your completed files into your
forked repository on GitHub. The assignment submission will consist of
the URL to your GitHub repository and the SHA-1 commit ID for your
repository state. NOTE: The GitHub repository also contains the dataset for the
assignment so you do not have to download the data separately.",3
https://github.com/josnthecaster/RepData_PeerAssessment1,### Loading and preprocessing the data,"  Show any code that is needed to 

Load the data (i.e. read.csv())


Process/transform the data (if necessary) into a format suitable for your analysis

",3
https://github.com/josnthecaster/RepData_PeerAssessment1,### What is mean total number of steps taken per day?,"  For this part of the assignment, you can ignore the missing values in
the dataset. 

Make a histogram of the total number of steps taken each day


Calculate and report the mean and median total number of steps taken per day

",3
https://github.com/josnthecaster/RepData_PeerAssessment1,### What is the average daily activity pattern?,"  

Make a time series plot (i.e. type = ""l"") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)


Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?

",3
https://github.com/josnthecaster/RepData_PeerAssessment1,### Imputing missing values,"  Note that there are a number of days/intervals where there are missing
values (coded as NA). The presence of missing days may introduce
bias into some calculations or summaries of the data. 

Calculate and report the total number of missing values in the dataset (i.e. the total number of rows with NAs)


Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval, etc.


Create a new dataset that is equal to the original dataset but with the missing data filled in.


Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day. Do these values differ from the estimates from the first part of the assignment? What is the impact of imputing missing data on the estimates of the total daily number of steps?

",3
https://github.com/josnthecaster/RepData_PeerAssessment1,### Are there differences in activity patterns between weekdays and weekends?,"  For this part the weekdays() function may be of some help here. Use
the dataset with the filled-in missing values for this part. 

Create a new factor variable in the dataset with two levels -- ""weekday"" and ""weekend"" indicating whether a given date is a weekday or weekend day.


Make a panel plot containing a time series plot (i.e. type = ""l"") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis). The plot should look something like the following, which was created using simulated data:

  Your plot will look different from the one above because you will
be using the activity monitor data. Note that the above plot was made
using the lattice system but you can make the same version of the plot
using any plotting system you choose.",3
https://github.com/josnthecaster/RepData_PeerAssessment1,## Submitting the Assignment,"  To submit the assignment: 

Commit your completed PA1_template.Rmd file to the master branch of your git repository (you should already be on the master branch unless you created new ones)


Commit your PA1_template.md and PA1_template.html files produced by processing your R markdown file with the knit2html() function in R (from the knitr package)


If your document has figures included (it should) then they should have been placed in the figure/ directory by default (unless you overrode the default). Add and commit the figure/ directory to your git repository.


Push your master branch to GitHub.


Submit the URL to your GitHub repository for this assignment on the course web site.

 In addition to submitting the URL for your GitHub repository, you will
need to submit the 40 character SHA-1 hash (as string of numbers from
0-9 and letters from a-f) that identifies the repository commit that
contains the version of the files you want to submit. You can do this
in GitHub by doing the following: 

Go into your GitHub repository web page for this assignment


Click on the ""?? commits"" link where ?? is the number of commits you have in the repository. For example, if you made a total of 10 commits to this repository, the link should say ""10 commits"".


You will see a list of commits that you have made to this repository. The most recent commit is at the very top. If this represents the version of the files you want to submit, then just click the ""copy to clipboard"" button on the right hand side that should appear when you hover over the SHA-1 hash. Paste this SHA-1 hash into the course web site when you submit your assignment. If you don't want to use the most recent commit, then go down and find the commit you want and copy the SHA-1 hash.

 A valid submission will look something like (this is just an example!) https://github.com/rdpeng/RepData_PeerAssessment1

7c376cc5447f11537f8740af8e07d6facc3d9645",3
https://github.com/HanWenfang/libgdx-demo-cuboc,# libgdx-demo-cuboc,"  Cuboc is a simple 2D platformer game, written for LD48. You may be interested in the post mortem which explains some of the crazy code.",1
https://github.com/HanWenfang/libgdx-demo-cuboc,### Try it here,"  
WebGL/Browser
Desktop
Android
",3
https://github.com/HanWenfang/libgdx-demo-cuboc,### Running,"  
Setup your development environment
Clone the repository or download and extract the ZIP file
Import the project into your preferred development environment, run, debug and package it!

Eclipse
Intellij IDEA
NetBeans
Commandline|Gradle on the Commandline


",3
https://github.com/bfrosik/scikit-beam,# scikit-xray, This may be renamed to scikit-beam. This will soon be called scikit-beam. [Documentation] (http://scikit-xray.github.io/scikit-xray/),16
https://github.com/bfrosik/scikit-beam,## Examples,"  [scikit-xray-examples repository] (https://github.com/scikit-xray/scikit-xray-examples) 
[Powder calibration (still needs tilt correction)] (https://github.com/scikit-xray/scikit-xray-examples/blob/master/demos/powder_calibration/D_estimate_demo.ipynb)
1-time correlation

[dir] (https://github.com/scikit-xray/scikit-xray-examples/tree/master/demos/1_time_correlation)
[Jupyter notebook] (https://github.com/scikit-xray/scikit-xray-examples/blob/master/demos/1_time_correlation/Multi_tau_one_time_correlation_example.ipynb)


Differential Phase Contrast

[dir] (https://github.com/scikit-xray/scikit-xray-examples/blob/master/demos/dpc)
[Jupyter notebook] (https://github.com/scikit-xray/scikit-xray-examples/blob/master/demos/dpc/dpc_demo.ipynb)


[Fast conversion to reciprocal space] (https://github.com/scikit-xray/scikit-xray-examples/blob/master/demos/reciprocal_space/recip_example.ipynb)
[X-Ray Speckle Visibility Spectroscopy] (https://github.com/scikit-xray/scikit-xray-examples/blob/master/demos/speckle/speckle-plotting.ipynb)
[Basic Plotting of X-Ray Fluorescence Elemental Lines] (https://github.com/scikit-xray/scikit-xray-examples/blob/master/demos/xrf/plot_xrf_spectrum.ipynb)
",6
https://github.com/bfrosik/scikit-beam,## Quick start, ,3
https://github.com/bfrosik/scikit-beam,### install with conda,"  conda config --add channels scikit-xray
conda install scikit-xray
",3
https://github.com/bfrosik/scikit-beam,### install with pip,"  git clone git@github.com:scikit-xray/scikit-xray.git
cd scikit-xray
python setup.py install
",3
https://github.com/bfrosik/scikit-beam,### set up for development,"  git clone git@github.com:scikit-xray/scikit-xray.git
cd scikit-xray
python setup.py develop
pip install nose coverage setuptools
 make sure all the tests pass! python run_tests.py
",3
https://github.com/murongruomeng/hacker-scripts,# Hacker Scripts," Based on a true
story: 
xxx: OK, so, our build engineer has left for another company. The dude was literally living inside the terminal. You know, that type of a guy who loves Vim, creates diagrams in Dot and writes wiki-posts in Markdown... If something - anything - requires more than 90 seconds of his time, he writes a script to automate that.
 
xxx: So we're sitting here, looking through his, uhm, ""legacy""
 
xxx: You're gonna love this
 
xxx: smack-my-bitch-up.sh - sends a text message ""late at work"" to his wife (apparently). Automatically picks reasons from an array of strings, randomly. Runs inside a cron-job. The job fires if there are active SSH-sessions on the server after 9pm with his login.
 
xxx: kumar-asshole.sh - scans the inbox for emails from ""Kumar"" (a DBA at our clients). Looks for keywords like ""help"", ""trouble"", ""sorry"" etc. If keywords are found - the script SSHes into the clients server and rolls back the staging database to the latest backup. Then sends a reply ""no worries mate, be careful next time"".
 
xxx: hangover.sh - another cron-job that is set to specific dates. Sends automated emails like ""not feeling well/gonna work from home"" etc. Adds a random ""reason"" from another predefined array of strings. Fires if there are no interactive sessions on the server at 8:45am.
 
xxx: (and the oscar goes to) fucking-coffee.sh - this one waits exactly 17 seconds (!), then opens an SSH session to our coffee-machine (we had no frikin idea the coffee machine is on the network, runs linux and has SSHD up and running) and sends some weird gibberish to it. Looks binary. Turns out this thing starts brewing a mid-sized half-caf latte and waits another 24 (!) seconds before pouring it into a cup. The timing is exactly how long it takes to walk to the machine from the dudes desk.
 
xxx: holy sh*t I'm keeping those
 Original: http://bash.im/quote/436725 (in Russian)
Pull requests with other implementations (Python, Perl, Shell, etc) are welcome.",1
https://github.com/murongruomeng/hacker-scripts,## Usage,"  You need these environment variables: # used in `smack-my-bitch-up` and `hangover` scripts
TWILIO_ACCOUNT_SID=ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
TWILIO_AUTH_TOKEN=yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy

# used in `kumar_asshole` script
GMAIL_USERNAME=admin@example.org
GMAIL_PASSWORD=password For Ruby scripts you need to install gems:
gem install dotenv twilio gmail",3
https://github.com/murongruomeng/hacker-scripts,# used in `smack-my-bitch-up` and `hangover` scripts,,-
https://github.com/murongruomeng/hacker-scripts,# used in `kumar_asshole` script,,-
https://github.com/murongruomeng/hacker-scripts,## Cron jobs,"  # Runs `smack-my-bitch-up.sh` daily at 9:20 pm.
20 21 * * * /path/to/scripts/smack-my-bitch-up.sh >> /path/to/smack-my-bitch-up.log 2>&1

# Runs `hangover.sh` daily at 8:45 am.
45 8 * * * /path/to/scripts/hangover.sh >> /path/to/hangover.log 2>&1

# Runs `kumar-asshole.sh` every 10 minutes.
*/10 * * * * /path/to/scripts/kumar-asshole.sh

# Runs `fucking-coffee.sh` hourly from 9am to 6pm.
0 9-18 * * * /path/to/scripts/fucking-coffee.sh  Code is released under WTFPL.",3
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,# JavaScript Flow Control,,1
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,## Objectives,"  
Write if statements in JS
Write if-else if-else statements in JS
Use the ternary operator in JS
Write switch statements in JS
",1
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,## About,"  Sometimes, we only want to allow the execution of code under certain conditions. Think of it this way. When you're driving a car, you can only go through a light if the light is green. Otherwise, if the light is yellow, you prepare to slow down; and if the light is red, you stop. Notice that we have distinct cases that we want to check for. In programming, when we check for a statement in this way, we check to see whether the statement is true or false. JavaScript, being the friendly language that it is, uses true and false directly to mean exactly what they say.",1
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,## Comparisons,"  The example above might be written, in pseudo-JavaScript (for once, this won't work in the browser console), like this: if (lightIsGreen) {
  go()
} else if (lightIsRed) {
  stop()
} else if (lightIsYellow) {
  slowDown()
} When we get down to it, every if statement like the above is saying, ""If the thing in the parentheses is true, then do what's between the curly braces."" But before we dive in to if statements, how do the things in parentheses become true or false? JavaScript lets us compare things. Most of these comparisons come straight from math: we can ask if something is less than something else (enter these in your console!): 3 < 5 // true
3 < 2 // false
3 < 3 // false
3 < 10000000 // true
'alpha' < 'beta' // true (!) We can ask if something is greater than something else: 5 > -1 // true
5 > 5 // false
20 > 30 // false
'gamma' > 'beta' // true (!) We can even ask if something is less-than-or-equal-to something else: 20 <= 30 // true
20 <= 20 // true
20 <= 10 // false or greater-than-or-equal-to something: 5 >= 5 // true
5 >= 1 // true
5 >= 10 // false How do we test if something is exactly equal to something else? We know that we can't just use =, because that's how we assign values to variables. Instead, we need to use ===: 5 === 5 // true
4 === 5 // false
'5' === 5 // false
parseInt('5', 10) === 5 // true Top Tip: Sometimes you'll see only == for comparison in JavaScript. It's best to use ===, as the former will try to coerce values in order to compare them, meaning that it's not always comparing what it says it's comparing!",3
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,## Combining Comparisons,"  We can string together these comparisons using && (pronounced ""and"") and || (""or""): 5 === 5 && 10 < 11 // true
5 === 6 && 10 < 11 // false
5 === 5 && 10 < 9 // false

4 > 5 || 20 <= 20 // true
4 > 5 || 20 < 19 // false
4 > 3 || 20 < 19 // true With &&, both statements (to the left and right of &&) must be true in order for the entire expression (that is, the entire phrase) to be true; with ||, only one of the statements needs to be true. Keep in mind that JavaScript reads these combinations from left to right, returns the last statement it saw, and only evaluates as many statements as necessary. So if we write, 5 === 5 && 1 JavaScript won't return true, it will return 1. If instead we write, 5 === 4 && 0 JavaScript will return false, because it stops evaluating the && expression (again, this just means the entire phrase of comparisons) on its first false encounter. Similarly, if we write, 200 < 100 || 'alphabet' JavaScript will return 'alphabet', because it needs to evaluate the right-hand side of || (since 200 < 100 is false). But if we write, 200 > 100 || 'treasure' JavaScript simply returns true ?it doesn't even check the right-hand side of ||.",3
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,## Controlling the flow of our programs,"  JavaScript lets us control what blocks of code to execute using if statements, if-else statements, if-else if-else statements, ternary operators, and switch statements. You'll be writing your code in flow-control.js. Make sure to run the tests using learn.",3
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,### `if` Statements,"  if statements look like this: if (something) {
  // do something
} They work as the name implies: if something is truthy (so the boolean true or anything other than the empty string (''), 0, null, or undefined), the code in between the curly braces runs; if not, the code between the curly braces is skipped. Now, in flow-control.js let's write a function called basicTeenager that accepts an age as a parameter. The function should contain an if-statement that checks to see if the age is a teenager. If the age is between 13 and 19, return ""You are a teenager!""",3
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,### `if`-`else` Statements,"  You will often see an if statement used in combination with an  else clause. An else clause will only get executed if the previous if statement is falsey. Syntax: if (conditionToTest) {
  // executed if `conditionToTest` is truthy
} else {
  // executed if `conditionToTest` is falsey
} 
Define a function teenager that accepts an age as a parameter. If the age is between 13 and 19 it should return ""You are a teenager!"". Otherwise, the function should return ""You are not a teenager"".
",3
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,### `if`/`else if` Statements,"  if statements can also be combined with an else if clause. This is like an else statement, but with its own condition. It will only run if its condition is true, and the previous statement's condition was false. if (conditionToTest1) {
    // condition is false hence code is not executed
} else if (conditionToTest2) {
  // execute this code if `conditionToTest1`statement is falsey AND `conditionToTest2` is truthy
} You can optionally add a final else statement after all of your else if statements. You can probably guess what will happen: if all of the other statements are falsey, this final else block will execute; otherwise, an earlier statement executes and the else block is skipped. if (conditionToTest1) {
  // condition is false hence code is not executed
} else if (conditionToTest2) {
  // execute this code if `conditionToTest1` statement is falsey AND `conditionToTest2` is truthy
} else {
  // execute this code iff none of the other conditions are met
} 
Define a function ageChecker that takes in an age as a parameter. If the age is between 13-19 it should return ""You are a teenager!"". If the age is 12 or below, it should return ""You are a kid"". If the age is above 19, it should return ""You are a grownup""
 Top tip: Remember, if you place a return statement before the end of the function, anything after return won't get executed. We can use this to make code terser: function canGo(lightColor) {
  if (lightColor === 'green') {
    return true
  }

  return false
} The above function will return true if lightColor is 'green' ?go ahead
and try it out. canGo('green') // true And false otherwise: canGo('red') // false Notice that we didn't have to use an else statement; we can just depend on
return. We need to be careful with return, however, because it's easy to return too
early and not execute important parts of the function. For example, function canGo(lightColor) {
  return true

  if (lightColor === 'red') {
    return false
  }
} will always return true, even if lightColor is 'red'. Try it! canGo('red') // true And that's a great way to cause an accident.",3
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,### Ternary Operator,"  You can think of it as a shortcut for the if-else statement. This operator tests a condition; if the condition is truthy, it evaluates the left-hand side of the colon; otherwise it evaluates the right-hand side of the colon. Syntax: conditionToTest ? valueToBeReturnedIfTrue : valueToBeReturnedIfFalse 
Define a function ternaryTeenager that accepts age as a parameter. The body of the function should use the ternary operator to return ""You are a teenager"" if age is between 13-19 and returns ""You are not a teenager"" if the age is anything else.
 Top tip: In order for the function to actually return the evaluation of the ternary operator, you'll need to prepend return to the expression: return conditionToTest ? valueToBeReturnedIfTrue : valueToBeReturnedIfFalse",3
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,## Switch Statements,"  Switch statements acts like a big if/else if/else chain. The switch expression is evaluated once and the value of the expression is compared with the values of each case. If there is a match, the associated block of code is executed. Syntax: switch (expression) {
  case n:
      // code to be executed if case n is true
      break; // break out of switch statement once code executed
  case m:
      // code to be executed if case m is true
      break; // break out of switch statement once code executed
  default:  // all other cases
      // code to be executed if case n and case m false
} Example: var mood = ""hungry""
switch(mood) {
  case ""happy"":
    console.log(""Dance to Pharrell's 'Happy'"");
    break;
  case ""sad"":
    console.log(""You should eat a pint of ice cream"");
    break;
  case ""anxious"":
    console.log(""Take some deep breaths"");
    break;
  case ""hungry"":
    console.log(""You should eat a big chocolate cake"");
    break;
  default:
    console.log(""That's not a mood we support"");
} In the example above, we'll see ""You should eat a big chocolate cake"" printed to the console. If we change the value of the mood variable to sad you'll see ""You should eat a pint of ice cream"". If the value of mood changed to ""grumpy"", the default statement would trigger and print out ""That's not a mood we support"". 
Define a function switchAge that accepts an age as a parameter. The case statement should switch on age and return ""You are a teenager"" if the age is 13, 14, 15, 16, 17, 18, or 19, and return ""You have an age"" as the default.
 As with any function, return will halt execution at any point. Thus if we
wrote, function feelings(mood) {
  switch(mood) {
    case ""happy"":
      return ""Dance to Pharrell's 'Happy'""
    default:
      return ""I don't recognize that mood.""
  }

  console.log(""Let us know how you're feeling tomorrow!"")
} the console.log() statement at the bottom of the function will
never run. This is a major difference between return and break:
return exits the function and returns a value; break exits a
block and does not (generally speaking) have a value associated with it.",3
https://github.com/jwolfe890/skills-based-javascript-intro-to-flow-control-v-000,## Resources,"  
Codecademy - if/if else/if else if else
MDN - if..else
Codecademy - Ternary Operator
Codecademy - Switch Statements
 View JavaScript Flow Control on Learn.co and start learning to code for free.",6
https://github.com/hughker/Apollo-11,# Apollo-11,"Original Apollo 11 guidance computer (AGC) source code, converted from their custom .agc files to .s files for syntax highlighting, for Command Module (Comanche055) and Lunar Module (Luminary099). Digitized by the folks at Virtual AGC and MIT Museum. The goal is to be a repo for the original Apollo 11 source code. As such, PRs are welcome for any issues identified between the transcriptions in this repository and the original source scans for Luminary 099 and Comanche 055, as well as any files I may have missed.",15
https://github.com/hughker/Apollo-11,##Compilation,"If you are interested in compiling the original source code, check out Virtual AGC.",6
https://github.com/hughker/Apollo-11,##Attribution,"Copyright: Public domain.
 Filename:  CONTRACT_AND_APPROVALS.agc
 Purpose:   Part of the source code for Colossus 2A, AKA Comanche 055.
            It is part of the source code for the Command Module's (CM)
            Apollo Guidance Computer (AGC), for Apollo 11.
 Assembler: yaYUL
 Contact:   Ron Burkey <info@sandroid.org>.
 Website:   www.ibiblio.org/apollo.
 Mod history:   2009-05-06 RSB  Transcribed from page images.

 This source code has been transcribed or otherwise adapted from digitized
 images of a hardcopy from the MIT Museum.  The digitization was performed
 by Paul Fjeld, and arranged for by Deborah Douglas of the Museum.  Many
 thanks to both.  The images (with suitable reduction in storage size and
 consequent reduction in image quality as well) are available online at
 www.ibiblio.org/apollo.  If for some reason you find that the images are
 illegible, contact me at info@sandroid.org about getting access to the
 (much) higher-quality images which Paul actually created.

 Notations on the hardcopy document read, in part:

    Assemble revision 055 of AGC program Comanche by NASA
    2021113-051.  10:28 APR. 1, 1969  

 Page 1

#************************************************************************
#                                                                       *
#       THIS AGC PROGRAM SHALL ALSO BE REFERRED TO AS:                  *
#                                                                       *
#                                                                       *
#               COLOSSUS 2A                                             *
#                                                                       *
#                                                                       *
#   THIS PROGRAM IS INTENDED FOR USE IN THE CM AS SPECIFIED             *
#   IN REPORT R-577.  THIS PROGRAM WAS PREPARED UNDER DSR               *
#   PROJECT 55-23870, SPONSORED BY THE MANNED SPACECRAFT                *
#   CENTER OF THE NATIONAL AERONAUTICS AND SPACE                        *
#   ADMINISTRATION THROUGH CONTRACT NAS 9-4065 WITH THE                 *
#   INSTRUMENTATION LABORATORY, MASSACHUSETTS INSTITUTE OF              *
#   TECHNOLOGY, CAMBRIDGE, MASS.                                        *
#                                                                       *
#************************************************************************


SUBMITTED:  MARGARET H. HAMILTON        DATE:   28 MAR 69
    M.H.HAMILTON, COLOSSUS PROGRAMMING LEADER
    APOLLO GUIDANCE AND NAVIGATION

APPROVED:   DANIEL J. LICKLY        DATE:   28 MAR 69
    D.J.LICKLY, DIRECTOR, MISSION PROGRAM DEVELOPMENT
    APOLLO GUIDANCE AND NAVIGATION PROGRAM

APPROVED:   FRED H. MARTIN          DATE:   28 MAR 69
    FRED H. MARTIN, COLOSSUS PROJECT MANAGER
    APOLLO GUIDANCE AND NAVIGATION PROGRAM

APPROVED:   NORMAN E. SEARS         DATE:   28 MAR 69
    N.E. SEARS, DIRECTOR, MISSION DEVELOPMENT
    APOLLO GUIDANCE AND NAVIGATION PROGRAM

APPROVED:   RICHARD H. BATTIN       DATE:   28 MAR 69
    R.H. BATTIN, DIRECTOR, MISSION DEVELOPMENT
    APOLLO GUIDANCE AND NAVIGATION PROGRAM

APPROVED:   DAVID G. HOAG           DATE:   28 MAR 69
    D.G. HOAG, DIRECTOR
    APOLLO GUIDANCE AND NAVIGATION PROGRAM

APPROVED:   RALPH R. RAGAN          DATE:   28 MAR 69
    R.R. RAGAN, DEPUTY DIRECTOR
    INSTRUMENTATION LABORATORY
About
Original Apollo 11 Guidance Computer (AGC) source code for the command and lunar modules.

Resources
 Readme
Releases
No releases published
Packages
No packages published
Languages
Assembly
100.0%",5
https://github.com/Kryndex/microservices-examples,# Building and running the microservices," This project uses with Docker Compose to run the services as well as RabbitMQ and MongoDB. The spring-boot-webapp project uses Selenium to test the web UI using the Chrome browser.
You will need to install ChromeDriver.
On Mac OSX you can run brew install chromedriver.",3
https://github.com/Kryndex/microservices-examples,## The quick way,"  The quickest way to build and run the services on Linux/Mac OSX is with the following commands: . ./set-env.sh
./gradle-all.sh assemble
docker-compose up -d
./show-urls.sh
 Otherwise, follow these instructions.",3
https://github.com/Kryndex/microservices-examples,## Running MongoDB and RabbitMQ,"  The RESTful service uses RabbitMQ and MongoDB.
The easier way to run them is to using Docker:  docker-compose up -d mongodb rabbitmq
 You also need to set some environment variables so that the services can connect to them: export DOCKER_HOST_IP=$(docker-machine ip default 2>/dev/null)

export SPRING_DATA_MONGODB_URI=mongodb://${DOCKER_HOST_IP}/userregistration
export SPRING_RABBITMQ_HOST=${DOCKER_HOST_IP}
",3
https://github.com/Kryndex/microservices-examples,## Build the Eureka server,"  This application uses Netflix OSS Eureka for service discovery.
Build the Spring Cloud based Eureka server using the following commands: cd eureka-server
./gradlew build
",3
https://github.com/Kryndex/microservices-examples,## Build the Zipkin server,"  This application uses Zipkin for distributed tracing.
Build the Zipkin server using the following commands: cd zipkin-server
./gradlew build
",3
https://github.com/Kryndex/microservices-examples,## Building the RESTful service,"  Use the following commands to build the RESTful service:  cd spring-boot-restful-service
 ./gradlew build    
",3
https://github.com/Kryndex/microservices-examples,## Using the RESTful service,"  Once the service has started, you can send a registration request using: ./register-user.sh
 You can examine the MongoDB database using the following commands $ ./mongodb-cli.sh
> show dbs;
local             0.031GB
mydb              0.031GB
userregistration  0.031GB
> use userregistration;
switched to db userregistration
>
>
> show collections;
registeredUser
system.indexes
>
>
> db.registeredUser.find()
{ ""_id"" : ObjectId(""55a99b0993860551c6020e9d""), ""_class"" : ""net.chrisrichardson.microservices.restfulspringboot.backend.RegisteredUser"", ""emailAddress"" : ""1437178632863-b-foo@bar.com"", ""password"" : ""secret"" }
> exit
$
",3
https://github.com/Kryndex/microservices-examples,## Building the web application,"  Since the web application invokes the RESTful service you must set the following environment variable: export USER_REGISTRATION_URL=http://${DOCKER_HOST_IP}:8081/user
 Next, use the following commands to build the web application: cd spring-boot-webapp
./gradlew build
",3
https://github.com/Kryndex/microservices-examples,## Running the web application,"  Run the web application using the following command in the top-level directory: docker-compose up -d web
",3
https://github.com/Kryndex/microservices-examples,## Using the web application,"  You can access the web application by visiting the following URL: http://${DOCKER_HOST_IP?}:8080/register.html There are also other URLs that you can visit.
The following command will wait until the services are available and displays the URLs: ./show-urls.sh
",3
https://github.com/Kryndex/microservices-examples,# Building and running Docker images,"  The previous instructions deployed the services as Docker containers without actually packaging the services as Docker images.
The docker-compose.yml file ran the image java:openjdk-8u91-jdk and used volume mapping to make the Spring Boot jar files accessible.
Follow these instructions to build and run the Docker images.",3
https://github.com/Kryndex/microservices-examples,## Building the images,"  You can build the images by running the following command: ./build-docker-images.sh
 This script is a simple wrapper around docker build.",3
https://github.com/Kryndex/microservices-examples,## Running the images,"You can now run the Docker images using the docker-compose command with docker-compose-images.yml:

docker-compose -f docker-compose-images.yml up -d
The following command will wait until the services are available and displays the URLs:

./show-urls.sh",3
https://github.com/silverfern7/ExData_Plotting1,## Introduction," This assignment uses data from
the UC Irvine Machine
Learning Repository, a popular repository for machine learning
datasets. In particular, we will be using the ""Individual household
electric power consumption Data Set"" which I have made available on
the course web site: 

Dataset: Electric power consumption [20Mb]


Description: Measurements of electric power consumption in
one household with a one-minute sampling rate over a period of almost
4 years. Different electrical quantities and some sub-metering values
are available.

 The following descriptions of the 9 variables in the dataset are taken
from
the UCI
web site: 
Date: Date in format dd/mm/yyyy 
Time: time in format hh:mm:ss 
Global_active_power: household global minute-averaged active power (in kilowatt) 
Global_reactive_power: household global minute-averaged reactive power (in kilowatt) 
Voltage: minute-averaged voltage (in volt) 
Global_intensity: household global minute-averaged current intensity (in ampere) 
Sub_metering_1: energy sub-metering No. 1 (in watt-hour of active energy). It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered). 
Sub_metering_2: energy sub-metering No. 2 (in watt-hour of active energy). It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light. 
Sub_metering_3: energy sub-metering No. 3 (in watt-hour of active energy). It corresponds to an electric water-heater and an air-conditioner.
",16
https://github.com/silverfern7/ExData_Plotting1,## Loading the data,"  When loading the dataset into R, please consider the following: 

The dataset has 2,075,259 rows and 9 columns. First
calculate a rough estimate of how much memory the dataset will require
in memory before reading into R. Make sure your computer has enough
memory (most modern computers should be fine).


We will only be using data from the dates 2007-02-01 and
2007-02-02. One alternative is to read the data from just those dates
rather than reading in the entire dataset and subsetting to those
dates.


You may find it useful to convert the Date and Time variables to
Date/Time classes in R using the strptime() and as.Date()
functions.


Note that in this dataset missing values are coded as ?.

",3
https://github.com/silverfern7/ExData_Plotting1,## Making Plots,"  Our overall goal here is simply to examine how household energy usage
varies over a 2-day period in February, 2007. Your task is to
reconstruct the following plots below, all of which were constructed
using the base plotting system. First you will need to fork and clone the following GitHub repository:
https://github.com/rdpeng/ExData_Plotting1 For each plot you should 

Construct the plot and save it to a PNG file with a width of 480
pixels and a height of 480 pixels.


Name each of the plot files as plot1.png, plot2.png, etc.


Create a separate R code file (plot1.R, plot2.R, etc.) that
constructs the corresponding plot, i.e. code in plot1.R constructs
the plot1.png plot. Your code file should include code for reading
the data so that the plot can be fully reproduced. You should also
include the code that creates the PNG file.


Add the PNG file and R code file to your git repository

 When you are finished with the assignment, push your git repository to
GitHub so that the GitHub version of your repository is up to
date. There should be four PNG files and four R code files. The four plots that you will need to construct are shown below.",3
https://github.com/silverfern7/ExData_Plotting1,### Plot 1,  ,3
https://github.com/silverfern7/ExData_Plotting1,### Plot 2,  ,3
https://github.com/silverfern7/ExData_Plotting1,### Plot 3,  ,3
https://github.com/silverfern7/ExData_Plotting1,### Plot 4,  ,3
https://github.com/YangHaha11514/advanced-tensorflow,# Advanced TensorFlow," Collection of (Little More + Refactored) Advanced TensorFlow Implementations.
Try my best to implement algorithms with a single Jupyter Notebook.",1
https://github.com/YangHaha11514/advanced-tensorflow,### [AutoEncoder](https://github.com/sjchoi86/advanced-tensorflow/tree/master/ae),"  
Denoising AutoEncoder
Convolutional AutoEncoder (using deconvolution)
",1
https://github.com/YangHaha11514/advanced-tensorflow,### [Adversarial Variational Bayes](https://github.com/sjchoi86/advanced-tensorflow/tree/master/avb),"  
AVB on 2-dimensional Toy Example
",1
https://github.com/YangHaha11514/advanced-tensorflow,### [Basics](https://github.com/sjchoi86/advanced-tensorflow/tree/master/basic),"  
Basic Classification (MLP and CNN)
Custom Dataset Generation
Classification (MLP and CNN) using Custom Dataset
OOP Style Implementation of MLP and CNN
",1
https://github.com/YangHaha11514/advanced-tensorflow,### [Class Activation Map](https://github.com/sjchoi86/advanced-tensorflow/tree/master/cam),"  
Pretrained Network Usage with TF-SLIM
Class Activation Map with Pretrained Network
",1
https://github.com/YangHaha11514/advanced-tensorflow,### [Char-RNN](https://github.com/sjchoi86/advanced-tensorflow/tree/master/char-rnn),"  
Preprocess Linux Kernel Sources
Train and Sample with Char-RNN
",1
https://github.com/YangHaha11514/advanced-tensorflow,### [Domain Adaptation](https://github.com/sjchoi86/advanced-tensorflow/tree/master/dann),"  
Domain Adversarial Neural Network with Gradient Reversal Layer
",1
https://github.com/YangHaha11514/advanced-tensorflow,### [Generative Adversarial Network](https://github.com/sjchoi86/advanced-tensorflow/tree/master/dcgan),"  
Deep Convolutional Generative Adversarial Network with MNIST
",1
https://github.com/YangHaha11514/advanced-tensorflow,### [Mixture Density Network](https://github.com/sjchoi86/advanced-tensorflow/tree/master/mdn),"  
Mixture Density Network
Heteroscedastic Mixture Density Network
",1
https://github.com/YangHaha11514/advanced-tensorflow,### [TF-SLIM](https://github.com/sjchoi86/advanced-tensorflow/tree/master/mnist),"  
MNIST Classification with TF-SLIM
",1
https://github.com/YangHaha11514/advanced-tensorflow,### [Super Resolution](https://github.com/sjchoi86/advanced-tensorflow/tree/master/srgan),"  
Super-resolution with Generative Adversarial Network
",1
https://github.com/YangHaha11514/advanced-tensorflow,## Requirements,"  
Python-2.7
TensorFlow-1.0.1
SciPy
MatplotLib
Jupyter Notebook
",3
https://github.com/spkane/Device42-AutoDiscovery-Scripts,## Scripts Provided,"  
api-sample.py : Runs against a single windows system and uploads info to device42 appliance
ad-sample.py  : Can run against Active directory computers, servers or a given list and upload discovered systems' info to device42 appliance.
d42_api_linux_upload_sample_script.py : Runs on a single *nix based system and uploads info to device42 appliance.
sample-script-facter-facts-to-d42.py : Runs on puppet master and uploads nodes info from facter fact files to device42 appliance.
d42_api_solaris_sample_script.py: Runs on an individual solaris system and uploads info to device42 appliance.
linux_auto_dics_multi.py: Run on a *nix system with paramiko to get inventory using ssh from an IP range and upload to d42 appliance.
winservice.py  : Can run against Active directory computers, servers or a given list and upload discovered services as application components to device42 appliance.
",1
https://github.com/spkane/Device42-AutoDiscovery-Scripts,## ## Scripts Provided,,-
https://github.com/spkane/Device42-AutoDiscovery-Scripts,### Requirement,"   
python 2.7.x
ad-sample, api-sample and winservice scripts require Poweshell 1.0 or Powershell 2.0, .Net 4 and IronPython 2.7.x.
linux_auto_disc_multi requires installation of paramiko library. Install: sudo pip install paramiko (or Ubuntu/Debian: sudo apt-get install python-paramiko)
",3
https://github.com/spkane/Device42-AutoDiscovery-Scripts,## ### Requirement,,-
https://github.com/spkane/Device42-AutoDiscovery-Scripts,### Usage,"   
Follow the instructions in individual scripts. Instructions have been added as comments in the scripts provided.
",3
https://github.com/spkane/Device42-AutoDiscovery-Scripts,## ### Usage,,-
https://github.com/spkane/Device42-AutoDiscovery-Scripts,### Further Documentation,"   
For api-sample.py: Windows Single machine auto-discovery script
For ad-sample.py: Device42 windows AD based auto-disc script doc
For linux_auto_disc_multi.py: Python auto-discovery script to get system inventory info for linux machines on the network
",6
https://github.com/spkane/Device42-AutoDiscovery-Scripts,## ### Further Documentation,,-
https://github.com/AlluringJay/ripgrep,## ripgrep (rg)," ripgrep is a command line search tool that combines the usability of The
Silver Searcher (an ack clone) with the raw speed of GNU grep. ripgrep has
first class support on Windows, Mac and Linux, with binary downloads available
for every release. 

 Dual-licensed under MIT or the UNLICENSE.",15
https://github.com/AlluringJay/ripgrep,### Screenshot of search results,  ,1
https://github.com/AlluringJay/ripgrep,### Quick examples comparing tools,"  This example searches the entire Linux kernel source tree (after running
make defconfig && make -j8) for [A-Z]+_SUSPEND, where all matches must be
words. Timings were collected on a system with an Intel i7-6900K 3.2 GHz, and
ripgrep was compiled using the compile script in this repo. Please remember that a single benchmark is never enough! See my
blog post on ripgrep
for a very detailed comparison with more benchmarks and analysis. 


Tool
Command
Line count
Time




ripgrep (Unicode)
rg -n -w '[A-Z]+_SUSPEND'
450
0.134s


The Silver Searcher
ag -w '[A-Z]+_SUSPEND'
450
0.753s


git grep
LC_ALL=C git grep -E -n -w '[A-Z]+_SUSPEND'
450
0.823s


git grep (Unicode)
LC_ALL=en_US.UTF-8 git grep -E -n -w '[A-Z]+_SUSPEND'
450
2.880s


sift
sift --git -n -w '[A-Z]+_SUSPEND'
450
3.656s


The Platinum Searcher
pt -w -e '[A-Z]+_SUSPEND'
450
12.369s


ack
ack -w '[A-Z]+_SUSPEND'
1878
16.952s


 (Yes, ack has a
bug.) Here's another benchmark that disregards gitignore files and searches with a
whitelist instead. The corpus is the same as in the previous benchmark, and the
flags passed to each command ensures that they are doing equivalent work: 


Tool
Command
Line count
Time




ripgrep
rg -L -u -tc -n -w '[A-Z]+_SUSPEND'
404
0.108s


ucg
ucg --type=cc -w '[A-Z]+_SUSPEND'
392
0.219s


GNU grep
egrep -R -n --include='*.c' --include='*.h' -w '[A-Z]+_SUSPEND'
404
0.733s


 (ucg has slightly different behavior in the presence of symbolic links.) And finally, a straight up comparison between ripgrep and GNU grep on a single
large file (~9.3GB,
OpenSubtitles2016.raw.en.gz): 


Tool
Command
Line count
Time




ripgrep
rg -w 'Sherlock [A-Z]\w+'
5268
2.520s


GNU grep
LC_ALL=C egrep -w 'Sherlock [A-Z]\w+'
5268
7.143s


 In the above benchmark, passing the -n flag (for showing line numbers)
increases the times to 3.081s for ripgrep and 11.403s for GNU grep.",6
https://github.com/AlluringJay/ripgrep,### Why should I use `ripgrep`?,"  
It can replace both The Silver Searcher and GNU grep because it is faster
than both. (N.B. It is not, strictly speaking, a ""drop-in"" replacement for
both, but the feature sets are far more similar than different.)
Like The Silver Searcher, ripgrep defaults to recursive directory search
and won't search files ignored by your .gitignore files. It also ignores
hidden and binary files by default. ripgrep also implements full support
for .gitignore, where as there are many bugs related to that functionality
in The Silver Searcher.
ripgrep can search specific types of files. For example, rg -tpy foo
limits your search to Python files and rg -Tjs foo excludes Javascript
files from your search. ripgrep can be taught about new file types with
custom matching rules.
ripgrep supports many features found in grep, such as showing the context
of search results, searching multiple patterns, highlighting matches with
color and full Unicode support. Unlike GNU grep, ripgrep stays fast while
supporting Unicode (which is always on).
 In other words, use ripgrep if you like speed, sane defaults, fewer bugs and
Unicode.",2
https://github.com/AlluringJay/ripgrep,### Is it really faster than everything else?,"  Yes. A large number of benchmarks with detailed analysis for each is
available on my blog. Summarizing, ripgrep is fast because: 
It is built on top of
Rust's regex engine.
Rust's regex engine uses finite automata, SIMD and aggressive literal
optimizations to make searching very fast.
Rust's regex library maintains performance with full Unicode support by
building UTF-8 decoding directly into its deterministic finite automaton
engine.
It supports searching with either memory maps or by searching incrementally
with an intermediate buffer. The former is better for single files and the
latter is better for large directories. ripgrep chooses the best searching
strategy for you automatically.
Applies your ignore patterns in .gitignore files using a
RegexSet.
That means a single file path can be matched against multiple glob patterns
simultaneously.
It uses a lock-free parallel recursive directory iterator, courtesy of
crossbeam and
ignore.
",2
https://github.com/AlluringJay/ripgrep,### Installation,"  The binary name for ripgrep is rg. Binaries for ripgrep are available for Windows, Mac and
Linux. Linux binaries are
static executables. Windows binaries are available either as built with MinGW
(GNU) or with Microsoft Visual C++ (MSVC). When possible, prefer MSVC over GNU,
but you'll need to have the
Microsoft VC++ 2015 redistributable
installed. If you're a Mac OS X Homebrew user, then you can install ripgrep either
from homebrew-core, (compiled with rust stable, no SIMD): $ brew install ripgrep
 or you can install a binary compiled with rust nightly (including SIMD and all
optimizations) by utilizing a custom tap: $ brew tap burntsushi/ripgrep https://github.com/BurntSushi/ripgrep.git
$ brew install burntsushi/ripgrep/ripgrep-bin
 If you're an Arch Linux user, then you can install ripgrep from the official repos: $ pacman -S ripgrep
 If you're a Gentoo user, you can install ripgrep from the official repo: $ emerge ripgrep
 If you're a Fedora 24+ user, you can install ripgrep from copr: $ dnf copr enable carlgeorge/ripgrep
$ dnf install ripgrep
 If you're a RHEL/CentOS 7 user, you can install ripgrep from copr: $ yum-config-manager --add-repo=https://copr.fedorainfracloud.org/coprs/carlgeorge/ripgrep/repo/epel-7/carlgeorge-ripgrep-epel-7.repo
$ yum install ripgrep
 If you're a Nix user, you can install ripgrep from
nixpkgs: $ nix-env --install ripgrep
$ # (Or using the attribute name, which is also `ripgrep`.)
 If you're a Rust programmer, ripgrep can be installed with cargo: $ cargo install ripgrep
 ripgrep isn't currently in any other package repositories.
I'd like to change that.",3
https://github.com/AlluringJay/ripgrep,### Whirlwind tour,"  The command line usage of ripgrep doesn't differ much from other tools that
perform a similar function, so you probably already know how to use ripgrep.
The full details can be found in rg --help, but let's go on a whirlwind tour. ripgrep detects when its printing to a terminal, and will automatically
colorize your output and show line numbers, just like The Silver Searcher.
Coloring works on Windows too! Colors can be controlled more granularly with
the --color flag. One last thing before we get started: ripgrep assumes UTF-8 everywhere. It
can still search files that are invalid UTF-8 (like, say, latin-1), but it will
simply not work on UTF-16 encoded files or other more exotic encodings.
Support for other encodings may
happen. To recursively search the current directory, while respecting all .gitignore
files, ignore hidden files and directories and skip binary files: $ rg foobar
 The above command also respects all .ignore files, including in parent
directories. .ignore files can be used when .gitignore files are
insufficient. In all cases, .ignore patterns take precedence over
.gitignore. To ignore all ignore files, use -u. To additionally search hidden files
and directories, use -uu. To additionally search binary files, use -uuu.
(In other words, ""search everything, dammit!"") In particular, rg -uuu is
similar to grep -a -r. $ rg -uu foobar  # similar to `grep -r`
$ rg -uuu foobar  # similar to `grep -a -r`
 (Tip: If your ignore files aren't being adhered to like you expect, run your
search with the --debug flag.) Make the search case insensitive with -i, invert the search with -v or
show the 2 lines before and after every search result with -C2. Force all matches to be surrounded by word boundaries with -w. Search and replace (find first and last names and swap them): $ rg '([A-Z][a-z]+)\s+([A-Z][a-z]+)' --replace '$2, $1'
 Named groups are supported: $ rg '(?P<first>[A-Z][a-z]+)\s+(?P<last>[A-Z][a-z]+)' --replace '$last, $first'
 Up the ante with full Unicode support, by matching any uppercase Unicode letter
followed by any sequence of lowercase Unicode letters (good luck doing this
with other search tools!): $ rg '(\p{Lu}\p{Ll}+)\s+(\p{Lu}\p{Ll}+)' --replace '$2, $1'
 Search only files matching a particular glob: $ rg foo -g 'README.*'
 Or exclude files matching a particular glob: $ rg foo -g '!*.min.js'
 Search only HTML and CSS files: $ rg -thtml -tcss foobar
 Search everything except for Javascript files: $ rg -Tjs foobar
 To see a list of types supported, run rg --type-list. To add a new type, use
--type-add, which must be accompanied by a pattern for searching (rg won't
persist your type settings): $ rg --type-add 'foo:*.{foo,foobar}' -tfoo bar
 The type foo will now match any file ending with the .foo or .foobar
extensions.",3
https://github.com/AlluringJay/ripgrep,### Regex syntax,"  The syntax supported is
documented as part of Rust's regex library.",36
https://github.com/AlluringJay/ripgrep,### Building,"  ripgrep is written in Rust, so you'll need to grab a
Rust installation in order to compile it.
ripgrep compiles with Rust 1.9 (stable) or newer. Building is easy: $ git clone https://github.com/BurntSushi/ripgrep
$ cd ripgrep
$ cargo build --release
$ ./target/release/rg --version
0.1.3
 If you have a Rust nightly compiler, then you can enable optional SIMD
acceleration like so: RUSTFLAGS=""-C target-cpu=native"" cargo build --release --features 'simd-accel avx-accel'
 If your machine doesn't support AVX instructions, then simply remove
avx-accel from the features list. Similarly for SIMD.",3
https://github.com/AlluringJay/ripgrep,### Running tests,"  ripgrep is relatively well tested, including both unit tests and integration
tests. To run the full test suite, use: $ cargo test
 from the repository root.",3
https://github.com/dragon788/vimsert,# Vimsert,,1
https://github.com/dragon788/vimsert,###Overview,"Overview Vimsert is a simple, open-source Chrome extension for editing inputs on the web. It puts the power of Vim and the Ace editor together in the browser. Better yet, it uses the awesome Solarized dark theme.",1
https://github.com/dragon788/vimsert,###Installation,"From your chrome browser, click here and 'add to chrome'.",3
https://github.com/dragon788/vimsert,###Usage:,"Open the editor

Ctrl + i # focus must be on a textarea
Write changes to the textarea

:w
Close vimsert

:q
Write, then Close

:wq",3
https://github.com/dragon788/vimsert,###Contributing,"PRs are welcome! Fork, create a topic branch, do your work, submit a PR into master.

A few contrib ideas:

Make Vimsert play more nicely with Vimium
See license below
Issues
No reason this couldn't also work in Firefox",7
https://github.com/dragon788/vimsert,###License,"Help wanted I'm not a lawyer, feel free to submit a PR adding a license with an ELI5. I'd really only like attribution and I'm not sure which to choose.",5
https://github.com/dragon788/vimsert,###Credit,"Vimsert utilizes the following open source projects:

Ace editor
Solarized
jQuery
Special thanks goes to Nino Silva for the logo design.",56
https://github.com/ozalpdemir/angular2-busy,# Angular2-Busy,"   Angular 2 Busy can show busy/loading indicators on any promise, or on any Observable's subscription.  Rewritten from angular-busy, and add some new features in terms of Angular 2.",1
https://github.com/ozalpdemir/angular2-busy,### Built with Angular 2.0.0, ,4
https://github.com/ozalpdemir/angular2-busy,## Demo,  devyumao.github.io/angular2-busy/demo/asset/,3
https://github.com/ozalpdemir/angular2-busy,## Installation,  npm install --save angular2-busy,3
https://github.com/ozalpdemir/angular2-busy,## Link CSS,"  <link rel=""stylesheet"" href=""/node_modules/angular2-busy/build/style/busy.css"">",3
https://github.com/ozalpdemir/angular2-busy,## Getting Started,"  Import the BusyModule in your root application module: import {NgModule} from '@angular/core';
import {BusyModule} from 'angular2-busy';

@NgModule({
	imports: [
    	// ...
        BusyModule
    ],
	// ...
})
export class AppModule {} Reference your promise in the ngBusy directive: import {Component, OnInit} from '@angular/core';
import {Http} from '@angular/http';

@Component({
    selector: 'some',
    template: `
        <div [ngBusy]=""busy""></div>
    `
})
class SomeComponent implements OnInit {
    busy: Promise<any>;

    constructor(private http: Http) {}

    ngOnInit() {
        this.busy = this.http.get('...').toPromise();
    }
} Moreover, the subscription of an Observable is also supported: // ...
import {Subscription} from 'rxjs';

// ...
class SomeComponent implements OnInit {
    busy: Subscription;

    // ...

    ngOnInit() {
        this.busy = this.http.get('...').subscribe();
    }
}",3
https://github.com/ozalpdemir/angular2-busy,## Directive Syntax,"  The ngBusy directive expects a busy thing, which means: 
A promise
Or an Observable's subscription
Or an array of them
Or a configuration object
 In other words, you may use flexble syntax: <!-- Simple syntax -->
<div [ngBusy]=""busy""></div> <!-- Collection syntax -->
<div [ngBusy]=""[busyA, busyB, busyC]""></div> <!-- Advanced syntax -->
<div [ngBusy]=""{busy: busy, message: 'Loading...', backdrop: false, delay: 200, minDuration: 600}""></div>",3
https://github.com/ozalpdemir/angular2-busy,## Options,"  


Option
Required
Default
Details




busy
Required
null
A busy thing (or an array of busy things) that will cause the loading indicator to show.


message
Optional
'Please wait...'
The message to show in the indicator which will reflect the updated values as they are changed.


backdrop
Optional
true
A faded backdrop will be shown behind the indicator if true.


template
Optional
A default template string
If provided, the custom template will be shown in place of the default indicatory template. The scope can be augmented with a {{message}} field containing the indicator message text.


delay
Optional
0
The amount of time to wait until showing the indicator. Specified in milliseconds.


minDuration
Optional
0
The amount of time to keep the indicator showing even if the busy thing was completed quicker. Specified in milliseconds.


wrapperClass
Optional
'ng-busy'
The name(s) of the CSS classes to be applied to the wrapper element of the indicator.


",3
https://github.com/ozalpdemir/angular2-busy,## Overriding Defaults,"  The default values of options can be overriden by configuring the provider of the BusyModule. In the root application module, you can do this: import {NgModule} from '@angular/core';
import {BusyModule, BusyConfig} from 'angular2-busy';

@NgModule({
	imports: [
    	// ...
        BusyModule.forRoot(
        	new BusyConfig({
            	message: 'Don\'t panic!',
                backdrop: false,
                template: `
                    <div>{{message}}</div>
                `,
                delay: 200,
                minDuration: 600,
                wrapperClass: 'my-class'
            })
        )
    ],
	// ...
})
export class AppModule",3
https://github.com/ozalpdemir/angular2-busy,## FAQ, ,6
https://github.com/ozalpdemir/angular2-busy,### The indicator's position is not inside the `ngBusy` container,  You may add position: relative style to your ngBusy container.,6
https://github.com/ozalpdemir/angular2-busy,### SystemJS Config?,"  You may need this in your systemjs.config.js: {
    paths: {
        'npm:': 'node_modules/'
    },
    map: {
        // ...
        'ts-metadata-helper': 'npm:ts-metadata-helper',
        'angular2-dynamic-component': 'npm:angular2-dynamic-component',
        'angular2-busy': 'npm:angular2-busy'
    },
    packages: {
        // ...
        'ts-metadata-helper': {
            defaultExtension: 'js'
        },
        'angular2-dynamic-component': {
            defaultExtension: 'js'
        },
        'angular2-busy': {
            main: './index.js',
            defaultExtension: 'js'
        }
    }
}",6
https://github.com/ozalpdemir/angular2-busy,## TODO,"  

Provide custom animations for the indicator


Unit & E2E test

",4
https://github.com/ozalpdemir/angular2-busy,## Credits,  Rewritten from cgross's angular-busy. Inspired by ajoslin's angular-promise-tracker.,5
https://github.com/ozalpdemir/angular2-busy,## LICENSE,  This project is licensed under the MIT license. See the LICENSE file for more info.,5
https://github.com/midumitrescu/tokens,# tokens library," A Java library that keeps OAuth 2.0 service access tokens in memory for your usage. 



",1
https://github.com/midumitrescu/tokens,## Maven dependency,"  <dependency>
    <groupId>org.zalando.stups</groupId>
    <artifactId>tokens</artifactId>
    <version>see above</version>
</dependency>",3
https://github.com/midumitrescu/tokens,### Apache-Httpclient is also needed because we depend on it currently,"  So, you also have to add it with: <dependency>
    <groupId>org.apache.httpcomponents</groupId>
    <artifactId>httpclient</artifactId>
    <version>your version</version>
</dependency>",3
https://github.com/midumitrescu/tokens,## Usage,"  AccessTokens tokens = Tokens.createAccessTokensWithUri(new URI(""https://example.com/access_tokens""))
                            .manageToken(""exampleRW"")
                                .addScope(""read"")
                                .addScope(""write"")
                                .done()
                            .manageToken(""exampleRO"")
                                .addScope(""read"")
                                .done()
                            .start();

while (true) {
    final String token = tokens.get(""exampleRO"");

    Request.Get(""https://api.example.com"")
           .addHeader(""Authorization"", ""Bearer "" + token)
           .execute():

    Thread.sleep(1000);
}",3
https://github.com/midumitrescu/tokens,## Local testing,"  The ""tokens"" library allows injecting fixed OAuth2 access tokens via the OAUTH2_ACCESS_TOKENS environment variable.
This allows testing applications using the library locally with personal OAuth2 tokens (e.g. generated by ""zign""): $ MY_TOKEN=$(zign token -n mytok)
$ export OAUTH2_ACCESS_TOKENS=mytok=$MY_TOKEN
$ lein repl # start my local Clojure app using the tokens library",3
https://github.com/midumitrescu/tokens,## License,"  Copyright © 2015 Zalando SE Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.",5
https://github.com/AMorporkian/StarryPy3k,# StarryPy3k,,1
https://github.com/AMorporkian/StarryPy3k,##About," ##About
StarryPy3k is the successor to StarryPy. StarryPy is a plugin-driven Starbound
server wrapper that adds a great deal of functionality to Starbound. StarryPy3k
is written using asyncio is Python 3. Please note this is still in very active development and is not ready to be
used on general purpose servers. It should mostly work, but you have been
forewarned.",1
https://github.com/AMorporkian/StarryPy3k,## Requirements,"  Python 3.4.4 or greater is required. Test are only conducted on Python
versions 3.4 and 3.5. While StarryPy3k may work with earlier version of Python, it is not
recommended and will not be readily supported.",3
https://github.com/AMorporkian/StarryPy3k,## Installation,"  If you are installing during the development phase, please clone the repository
with git. While it is not strictly necessary, it is highly encouraged to
run your StarryPy3k instance from a virtual environment, as future plugins
may require more Python modules than are currently listed (eg - IRC3), and
using a virtual environment helps to keep a clean namespace and reduce the
chance of bugs.",3
https://github.com/AMorporkian/StarryPy3k,### Starbound Server Configuration,"  StarryPy works as a benevolent ""man in the middle"" between the Starbound game
client and the Starbound dedicated server, in effect acting as a proxy server.
As such, for easiest transition from a ""Vanilla"" server to one enhanced by
StarryPy, you need to set your Starbound server to accept incoming connections
on a new TCP port.  By default, this will be the port one lower than standard,
to wit: 21024.  To accomplish this, edit your starbound_server.config.  Look
for the lines below, and change them to specify port 21024:   ""gameServerPort"" : 21025,
  [...]
  ""queryServerPort"" : 21025,
",3
https://github.com/AMorporkian/StarryPy3k,### StarryPy Proxy Configuration,"  An example configuration file, config.json.default, is provided in the
config directory.  Copy that file to a new one named config.json in the
same location.  Open it in your text editor of choice.  The following are the
most likely changes you will have to make:         ""irc_bot"": {
            ""channel"": ""#YourChannel"",
            ""log_irc"": false,
            ""server"": ""irc.example.com"",
            ""strip_colors"": true,
            ""username"": ""Replace With Valid IRC Nick""
        },
 This section controls the built-in IRC-to-Starbound bridge.  It will be active
if you have the irc3 Python module installed on your system.  Edit the sample
values here to match your preferred IRC server, bot nick, et cetera.  Chat in
the Starbound server will be relayed to the specified IRC channel, and vice
versa.  You can also see who is on the server from IRC by saying .who in the
IRC channel (we cannot use / as the command leader in IRC for obvious reasons.         ""motd"": {
            ""message"": ""Insert your MOTD message here. ^red;Note^reset; color codes work.""
        },
        ""new_player_greeters"": {
            ""gifts"": {},
            ""greeting"": ""This message will be displayed to players the first time StarryPy sees them connect.""
        },
 The MOTD, or Message Of The Day, will be displayed to all players when they
connect to the Starbound server.  You can update this in-game by using the
/set_motd command.  The next section allows you to specify a message to be
displayed to any players the first time they connect to the server.  You can
also have StarryPy give items to new players by enumarating them in the gifts
property.  Use Starbound's names for items as specified in its .json files.         ""player_manager"": {
            ""owner_uuid"": ""!--REPLACE WITH YOUR UUID--!"",
            ""player_db"": ""config/player""
        },
 Replace the obvious value here with your UUID.  This is how StarryPy will
recognize you as the owner of the server and accord you the relevant rights
and privileges.  You can find your UUID by watching the Starbound server log
as you connect, by using the list RCON command, or by observing the names
of your save files on the computer you use to play Starbound.",3
https://github.com/AMorporkian/StarryPy3k,### Starting the proxy,"  Starting StarryPy is as simple as issueing the command python3 ./server.py
once you have finised editing config/config.json.  To terminate the proxy,
either press ^C in an interactive terminal session, or send it a TERM
signal.",3
https://github.com/AMorporkian/StarryPy3k,## Contributing,"  Contributions are highly encouraged and always welcome. Please feel free to
open an issue on GitHub if you are having an error, or wish to make a
suggestion. If you're feeling really motivated, fork the repo and contribute
some code. In addition, plugin development is encouraged. There are still a few features
missing from the core (particularly in the role system). A more comprehensive
guide on plugin development is in the works. Please note that plugins will not
work without modification from the original version of StarryPy. If you would like to talk with other contributors/ask questions about
development, please join #StarryPy on irc.freenode.net, or chat with us on
gitter.",7
https://github.com/AMorporkian/StarryPy3k,## History,"  StarryPy3k was originally developed by [CarrotsAreMediocre](https://github
.com/CarrotsAreMediocre), who set all the groundwork for AsyncIO and packet
interpreting. Due to personal circumstances, Carrots stepped away from the
project. After roughly 2 years of laying dormant, Kharidiron, having spent some time
learning the ropes of StarryPy, decided to take the reigns on StarryPy3k.
After many months of staring at the code (and many emails to
CarrotsAreMediocre requesting assistance in understanding just what it is
doing), is feeling a modicum more confident in handling this project and
keeping it running.",16
https://github.com/aceol/generator-gulp-angular,# generator-gulp-angular ![Logo](app/templates/src/assets/images/generator-gulp-angular-logo.png),,1
https://github.com/aceol/generator-gulp-angular,## Usage," 



  
Yeoman generator for AngularJS + Gulp.
 
Lets you quickly set up a project with:

your favorite technologies
web best pratices.
guidelines powered by Google.

 
Gulp provide fast workspace with quick feedback.
",36
https://github.com/aceol/generator-gulp-angular,### Install,"  More informations, options, parameters in the usage documentation page",3
https://github.com/aceol/generator-gulp-angular,"##### Install required tools `yo`, `gulp` and `bower`:", ,3
https://github.com/aceol/generator-gulp-angular,##### Install `generator-gulp-angular`:,"  npm install -g yo gulp bower
",3
https://github.com/aceol/generator-gulp-angular,### Run,"  npm install -g generator-gulp-angular
",3
https://github.com/aceol/generator-gulp-angular,"##### Create a new directory, and go into:", ,3
https://github.com/aceol/generator-gulp-angular,"##### Run `yo gulp-angular`, and select desired technologies:","  mkdir my-new-project && cd $_
",3
https://github.com/aceol/generator-gulp-angular,## Documentation,"  yo gulp-angular
",6
https://github.com/aceol/generator-gulp-angular,## Features,"  
docs/README
More informations about how to use your new project is available in the docs/user-guide
If you want to know: docs/how-it-works.
",1
https://github.com/aceol/generator-gulp-angular,## Questions the generator will ask,  Questions the generator will ask,6
https://github.com/aceol/generator-gulp-angular,## Changelog,  All changes listed in the GitHub releases,4
https://github.com/aceol/generator-gulp-angular,## Contributing,  Guidelines,7
https://github.com/aceol/generator-gulp-angular,## License,  MIT,5
https://github.com/aaronseib/smart-on-fhir.github.io,# SMART Technical Documentation," This is the SMART technical documentation, hosted at
http://docs.smarthealthit.org 
See http://smarthealthit.org for high-level project info and news
Need help? Ask a question at http://groups.google.com/group/smart-on-fhir
Found an error in these docs? Fork them on Github and send us a pull
request!
",156
https://github.com/aaronseib/smart-on-fhir.github.io,## Installing Jekyll and Friends,"  The SMART technical documentation is built using
Ruby tools. Using Bundler,
you can install all of the required dependencies to generate and run the
documentation locally by running the following command from the
smart-on-fhir.github.io/ directory: $ bundle install
 This will install Jekyll, a static site
generator and redcarpet, a Ruby Markdown
processor. Once the required software is installed, generating the static site (in
the _site directory) is simply running $ jekyll serve --watch -b /
 on the commandline.  If you prefer, you can serve the project with Node.js and grunt, which enables
""live reload"" behavior. This allows editing side-by-side with the web page; and
every time you save, your changes appear automatically in the browser. Just install nodejs and grunt, and then run: npm install
grunt
 And then open a browser to http://localhost:4000",3
https://github.com/gkarunakaran/kidsrubyinstaller-windows,# KidsRuby Installer, KidsRuby Installer,1
https://github.com/gkarunakaran/kidsrubyinstaller-windows,## Overview,"  This project builds an installer for the KidsRuby project http://kidsruby.com/ This project is entirely based on RailsInstaller (http://railsinstaller.org)
with additions for the kids ruby codebase.",1
https://github.com/gkarunakaran/kidsrubyinstaller-windows,## How to Contribute,"  KidsRuby Installer is bootstrapped, built and packaged via rake tasks. 

Download and install the latest RailsInstaller from
http://railsinstaller.org/


Bootstrap the project, from the project root run

 
rake bootstrap
 

Install latest Inno Setup Quick Start Pack, ensure iscc.exe is in your PATH
http://www.jrsoftware.org/isdl.php#qsp


[[ hackety hack... ]]


Download and build all components on the stage

 
rake build
 
Use Inno Setup to package KidsRubyInstaller
 
rake package
 
Use the generated KidsRubyInstaller.exe, be happy and prosperous! Be
sure to share it with all of your friends!
",7
https://github.com/gkarunakaran/kidsrubyinstaller-windows,### Releasing a new version,"  

Update VERSION.txt


Update CHANGELOG.txt

",3
https://github.com/gkarunakaran/kidsrubyinstaller-windows,### Development Kit (DevKit),"  A MSYS/MinGW based toolkit that enables KidsRuby Installer to build native C/C++
packages, both for Ruby and gems. DevKit is built and maintained by the
wonderful folks over at the RubyInstaller (http://rubyinstaller.org/) project.",36
https://github.com/gkarunakaran/kidsrubyinstaller-windows,### Ruby 1.9.2 on Windows,"  KidsRuby Installer is a self contained package installer which installs Ruby and
RubyGems on a windows system, head over to http://rubyinstaller.org/ for more
information.",6
https://github.com/gkarunakaran/kidsrubyinstaller-windows,### Packaging/Installer,"  We are using Inno Setup,
a free installer for Windows programs.",6
https://github.com/WaylandGod/cecil,# Cecil," Mono.Cecil is a library to generate and inspect programs and libraries in the ECMA CIL form. To put it simply, you can use Cecil to: 
Analyze .NET binaries using a simple and powerful object model, without having to load assemblies to use Reflection.
Modify .NET binaries, add new metadata structures and alter the IL code.
 Cecil has been around since 2004 and is widely used in the .NET community. The best way to learn how to use Cecil is to dive into the Cecil.Samples repository. It's a growing collection of samples with the goal of showing how to get things done using Cecil, as IL manipulation can sometime get tricky. Read about the Cecil development on the development log. To discuss Cecil, the best place is the mono-cecil Google Group. Cecil is a project under the benevolent umbrella of the .NET Foundation. 

",1356
https://github.com/houze2311/MMNumberKeyboard,# MMNumberKeyboard," A simple keyboard to use with numbers and, optionally, a decimal point. ",1
https://github.com/houze2311/MMNumberKeyboard,## Installation, ,3
https://github.com/houze2311/MMNumberKeyboard,### From CocoaPods,"  CocoaPods is a dependency manager for Objective-C, which automates and simplifies the process of using 3rd-party libraries like MMNumberKeyboard in your projects. First, add the following line to your Podfile: pod 'MMNumberKeyboard' Second, install MMNumberKeyboard into your project: pod install",3
https://github.com/houze2311/MMNumberKeyboard,### From Carthage,"  Carthage is a dependency manager for Objective-C and Swift. Add the following line to your Cartfile: github ""matmartinez/MMNumberKeyboard""
 The run carthage update. Follow the current instructions in Carthage's README
for up to date installation instructions.",3
https://github.com/houze2311/MMNumberKeyboard,## Usage,"  There is a sample Xcode project available. Just build & run. And profit. Basically you instantiate your own keyboard view to use as an .inputView of your UITextField, UITextView or whatever view that supports text editing. // Create and configure the keyboard.
MMNumberKeyboard *keyboard = [[MMNumberKeyboard alloc] initWithFrame:CGRectZero];
keyboard.allowsDecimalPoint = YES;
keyboard.delegate = self;

// Configure an example UITextField.
UITextField *textField = [[UITextField alloc] initWithFrame:CGRectZero];
textField.inputView = keyboard; You can adopt the MMNumberKeyboardDelegate protocol to handle the return key or whether text should be inserted or not.",3
https://github.com/houze2311/MMNumberKeyboard,## Development,  Pull requests are welcome and mostly appreciated.,7
https://github.com/houze2311/MMNumberKeyboard,## Credits,  Thanks to Pedro Burón for the encouragement and moral support to make this README file possible.,5
https://github.com/funze/cleanflight,# Cleanflight," Clean-code version of baseflight flight-controller - flight controllers are used to fly multi-rotor craft and fixed wing craft. This fork differs from baseflight in that it attempts to use modern software development practices which result in: 
greater reliability through code robustness and automated testing.
easier maintainance through code cleanliness.
easier to develop new features.
easier to re-use code though code de-coupling and modularisation.
 The MultiWii software, from which baseflight originated, violates many good software development best-practices. Hopefully this fork will go some way to address them. If you see any bad code in this fork please immediately raise an issue so it can be fixed, or better yet submit a pull request.",12
https://github.com/funze/cleanflight,## Additional Features,"  Cleanflight also has additional features not found in baseflight. 
Multi-color RGB LED Strip support (each LED can be a different color using variable length WS2811 Addressable RGB strips - use for Orientation Indicators, Low Battery Warning, Flight Mode Status, etc)
Oneshot ESC support.
Blackbox flight recorder logging (to onboard flash or external SD card).
Support for additional targets that use the STM32F3 processors (baseflight only supports STM32F1).
Support for the TauLabs Sparky board (~$35 STM32F303 I2C sensors, based board with acc/gyro/compass and baro!)
Support for the OpenPilot CC3D board. (~$20 STM32F103 board, SPI acc/gyro)
Support for the CJMCU nano quadcopter board.
Support for developer breakout boards: (Port103R, EUSTM32F103RC, Olimexino, STM32F3Discovery).
Support for more than 8 RC channels - (e.g. 16 Channels via FrSky X4RSB SBus).
Support for N-Position switches via flexible channel ranges - not just 3 like baseflight or 3/6 in MultiWii
Lux's new PID (uses float values internally, resistant to looptime variation).
Simultaneous Bluetooth configuration and OSD.
Better PWM and PPM input and failsafe detection than baseflight.
Better FrSky Telemetry than baseflight.
MSP Telemetry.
RSSI via ADC - Uses ADC to read PWM RSSI signals, tested with FrSky D4R-II and X8R.
Autotune - ported from BradWii, experimental - feedback welcomed.
OLED Displays - Display information on: Battery voltage, profile, rate profile, version, sensors, RC, etc.
In-flight manual PID tuning and rate adjustment.
Rate profiles and in-flight selection of them.
Graupner PPM failsafe.
Graupner HoTT telemetry.
Multiple simultantious telemetry providers.
Configurable serial ports for Serial RX, Telemetry, MSP, GPS - Use most devices on any port, softserial too.
 
more many minor bug fixes.
 For a list of features, changes and some discussion please review the thread on MultiWii forums and consult the documenation. http://www.multiwii.com/forum/viewtopic.php?f=23&t=5149",16
https://github.com/funze/cleanflight,## Installation,  See: https://github.com/cleanflight/cleanflight/blob/master/docs/Installation.md,6
https://github.com/funze/cleanflight,## Documentation,  There is lots of documentation here: https://github.com/cleanflight/cleanflight/tree/master/docs If what you need is not covered then refer to the baseflight documentation. If you still can't find what you need then visit the #cleanflight on the Freenode IRC network,6
https://github.com/funze/cleanflight,## IRC Support and Developers Channel,"  There's a dedicated IRC channel here: irc://irc.freenode.net/#cleanflight If you are using windows and don't have an IRC client installed then take a look at HydraIRC - here: http://hydrairc.com/ Etiquette: Don't ask to ask and please wait around long enough for a reply - sometimes people are out flying, asleep or at work and can't answer immediately.",6
https://github.com/funze/cleanflight,## Videos,"  There is a dedicated Cleanflight youtube channel which has progress update videos, flight demonstrations, instrutions and other related videos. https://www.youtube.com/playlist?list=PL6H1fAj_XUNVBEcp8vbMH2DrllZAGWkt8 Please subscribe and '+1' the videos if you find them useful.",6
https://github.com/funze/cleanflight,## Configuration Tool,  To configure Cleanflight you should use the Cleanlight-configurator GUI tool (Windows/OSX/Linux) that can be found here: https://chrome.google.com/webstore/detail/cleanflight-configurator/enacoimjcgeinfnnnpajinjgmkahmfgb The source for it is here: https://github.com/cleanflight/cleanflight-configurator,6
https://github.com/funze/cleanflight,## Contributing,"  Contributions are welcome and encouraged.  You can contribute in many ways: 
Documentation updates and corrections.
How-To guides - received help?  help others!
Bug fixes.
New features.
Telling us your ideas and suggestions.
 The best place to start is the IRC channel on freenode (see above), drop in, say hi. Next place is the github issue tracker: https://github.com/cleanflight/cleanflight/issues
https://github.com/cleanflight/cleanflight-configurator/issues Before creating new issues please check to see if there is an existing one, search first otherwise you waste peoples time when they could be coding instead!",7
https://github.com/funze/cleanflight,## Developers,"  There is a developers section in the docs/development folder. Before making any code contributions, take a note of the https://github.com/multiwii/baseflight/wiki/CodingStyle For this fork it is also advised to read about clean code, here are some useful links: 
http://cleancoders.com/
http://en.wikipedia.org/wiki/SOLID_%28object-oriented_design%29
http://en.wikipedia.org/wiki/Code_smell
http://en.wikipedia.org/wiki/Code_refactoring
http://www.amazon.co.uk/Working-Effectively-Legacy-Robert-Martin/dp/0131177052
 TravisCI is also used to run automatic builds https://travis-ci.org/cleanflight/cleanflight ",6
https://github.com/funze/cleanflight,## Cleanflight Releases,  https://github.com/cleanflight/cleanflight/releases,6
https://github.com/johnsonjr/vagrant-aws,# Vagrant AWS Provider," ![Gitter](https://badges.gitter.im/Join Chat.svg) 
[![Gem Version](https://badge.fury.io/rb/vagrant-aws.png)][gem]
[![Dependency Status](https://gemnasium.com/mitchellh/vagrant-aws.png)][gemnasium]
 This is a Vagrant 1.2+ plugin that adds an AWS
provider to Vagrant, allowing Vagrant to control and provision machines in
EC2 and VPC. NOTE: This plugin requires Vagrant 1.2+,",14
https://github.com/johnsonjr/vagrant-aws,## Features,"  
Boot EC2 or VPC instances.
SSH into the instances.
Provision the instances with any built-in Vagrant provisioner.
Minimal synced folder support via rsync.
Define region-specific configurations so Vagrant can manage machines
in multiple regions.
Package running instances into new vagrant-aws friendly boxes
",1
https://github.com/johnsonjr/vagrant-aws,## Usage,"  Install using standard Vagrant 1.1+ plugin installation methods. After
installing, vagrant up and specify the aws provider. An example is
shown below. $ vagrant plugin install vagrant-aws
...
$ vagrant up --provider=aws
...
 Of course prior to doing this, you'll need to obtain an AWS-compatible
box file for Vagrant.",3
https://github.com/johnsonjr/vagrant-aws,## Quick Start,"  After installing the plugin (instructions above), the quickest way to get
started is to actually use a dummy AWS box and specify all the details
manually within a config.vm.provider block. So first, add the dummy
box using any name you want: $ vagrant box add dummy https://github.com/mitchellh/vagrant-aws/raw/master/dummy.box
...
 And then make a Vagrantfile that looks like the following, filling in
your information where necessary. Vagrant.configure(""2"") do |config|
  config.vm.box = ""dummy""

  config.vm.provider :aws do |aws, override|
    aws.access_key_id = ""YOUR KEY""
    aws.secret_access_key = ""YOUR SECRET KEY""
    aws.session_token = ""SESSION TOKEN""
    aws.keypair_name = ""KEYPAIR NAME""

    aws.ami = ""ami-7747d01e""

    override.ssh.username = ""ubuntu""
    override.ssh.private_key_path = ""PATH TO YOUR PRIVATE KEY""
  end
end
 And then run vagrant up --provider=aws. This will start an Ubuntu 12.04 instance in the us-east-1 region within
your account. And assuming your SSH information was filled in properly
within your Vagrantfile, SSH and provisioning will work as well. Note that normally a lot of this boilerplate is encoded within the box
file, but the box file used for the quick start, the ""dummy"" box, has
no preconfigured defaults. If you have issues with SSH connecting, make sure that the instances
are being launched with a security group that allows SSH access.",3
https://github.com/johnsonjr/vagrant-aws,## Box Format,"  Every provider in Vagrant must introduce a custom box format. This
provider introduces aws boxes. You can view an example box in
the example_box/ directory.
That directory also contains instructions on how to build a box. The box format is basically just the required metadata.json file
along with a Vagrantfile that does default settings for the
provider-specific configuration for this provider.",3
https://github.com/johnsonjr/vagrant-aws,## Configuration,"  This provider exposes quite a few provider-specific configuration options: 
access_key_id - The access key for accessing AWS
ami - The AMI id to boot, such as ""ami-12345678""
availability_zone - The availability zone within the region to launch
the instance. If nil, it will use the default set by Amazon.
instance_ready_timeout - The number of seconds to wait for the instance
to become ""ready"" in AWS. Defaults to 120 seconds.
instance_check_interval - The number of seconds to wait to check the instance's
state
instance_package_timeout - The number of seconds to wait for the instance
to be burnt into an AMI during packaging. Defaults to 600 seconds.
instance_type - The type of instance, such as ""m3.medium"". The default
value of this if not specified is ""m3.medium"".  ""m1.small"" has been
deprecated in ""us-east-1"" and ""m3.medium"" is the smallest instance
type to support both paravirtualization and hvm AMIs
keypair_name - The name of the keypair to use to bootstrap AMIs
which support it.
monitoring - Set to ""true"" to enable detailed monitoring.
session_token - The session token provided by STS
private_ip_address - The private IP address to assign to an instance
within a VPC
elastic_ip - Can be set to 'true', or to an existing Elastic IP address.
If true, allocate a new Elastic IP address to the instance. If set
to an existing Elastic IP address, assign the address to the instance.
region - The region to start the instance in, such as ""us-east-1""
secret_access_key - The secret access key for accessing AWS
security_groups - An array of security groups for the instance. If this
instance will be launched in VPC, this must be a list of security group
Name. For a nondefault VPC, you must use security group IDs instead (http://docs.aws.amazon.com/cli/latest/reference/ec2/run-instances.html).
iam_instance_profile_arn - The Amazon resource name (ARN) of the IAM Instance
Profile to associate with the instance
iam_instance_profile_name - The name of the IAM Instance Profile to associate
with the instance
subnet_id - The subnet to boot the instance into, for VPC.
associate_public_ip - If true, will associate a public IP address to an instance in a VPC.
ssh_host_attribute - If :public_ip_address, :dns_name, or
:private_ip_address, will use the public IP address, DNS name, or private
IP address, respectively, to SSH to the instance. By default Vagrant uses the
first of these (in this order) that is known. However, this can lead to
connection issues if, e.g., you are assigning a public IP address but your
security groups prevent public SSH access and require you to SSH in via the
private IP address; specify :private_ip_address in this case.
tenancy - When running in a VPC configure the tenancy of the instance.  Supports 'default' and 'dedicated'.
tags - A hash of tags to set on the machine.
package_tags - A hash of tags to set on the ami generated during the package operation.
use_iam_profile - If true, will use IAM profiles
for credentials.
block_device_mapping - Amazon EC2 Block Device Mapping Property
elb - The ELB name to attach to the instance.
unregister_elb_from_az - Removes the ELB from the AZ on removal of the last instance if true (default). In non default VPC this has to be false.
terminate_on_shutdown - Indicates whether an instance stops or terminates
when you initiate shutdown from the instance.
 These can be set like typical provider-specific configuration: Vagrant.configure(""2"") do |config|
  # ... other stuff

  config.vm.provider :aws do |aws|
    aws.access_key_id = ""foo""
    aws.secret_access_key = ""bar""
  end
end In addition to the above top-level configs, you can use the region_config
method to specify region-specific overrides within your Vagrantfile. Note
that the top-level region config must always be specified to choose which
region you want to actually use, however. This looks like this: Vagrant.configure(""2"") do |config|
  # ... other stuff

  config.vm.provider :aws do |aws|
    aws.access_key_id = ""foo""
    aws.secret_access_key = ""bar""
    aws.region = ""us-east-1""

    # Simple region config
    aws.region_config ""us-east-1"", :ami => ""ami-12345678""

    # More comprehensive region config
    aws.region_config ""us-west-2"" do |region|
      region.ami = ""ami-87654321""
      region.keypair_name = ""company-west""
    end
  end
end The region-specific configurations will override the top-level
configurations when that region is used. They otherwise inherit
the top-level configurations, as you would probably expect.",3
https://github.com/johnsonjr/vagrant-aws,## Networks,"  Networking features in the form of config.vm.network are not
supported with vagrant-aws, currently. If any of these are
specified, Vagrant will emit a warning, but will otherwise boot
the AWS machine.",3
https://github.com/johnsonjr/vagrant-aws,## Synced Folders,"  There is minimal support for synced folders. Upon vagrant up,
vagrant reload, and vagrant provision, the AWS provider will use
rsync (if available) to uni-directionally sync the folder to
the remote machine over SSH. See Vagrant Synced folders: rsync",3
https://github.com/johnsonjr/vagrant-aws,## Other Examples, ,3
https://github.com/johnsonjr/vagrant-aws,### Tags,"  To use tags, simply define a hash of key/value for the tags you want to associate to your instance, like: Vagrant.configure(""2"") do |config|
  # ... other stuff

  config.vm.provider ""aws"" do |aws|
    aws.tags = {
	  'Name' => 'Some Name',
	  'Some Key' => 'Some Value'
    }
  end
end",3
https://github.com/johnsonjr/vagrant-aws,### User data,"  You can specify user data for the instance being booted. Vagrant.configure(""2"") do |config|
  # ... other stuff

  config.vm.provider ""aws"" do |aws|
    # Option 1: a single string
    aws.user_data = ""#!/bin/bash\necho 'got user data' > /tmp/user_data.log\necho""

    # Option 2: use a file
    aws.user_data = File.read(""user_data.txt"")
  end
end",3
https://github.com/johnsonjr/vagrant-aws,### Disk size,"  Need more space on your instance disk? Increase the disk size. Vagrant.configure(""2"") do |config|
  # ... other stuff

  config.vm.provider ""aws"" do |aws|
    aws.block_device_mapping = [{ 'DeviceName' => '/dev/sda1', 'Ebs.VolumeSize' => 50 }]
  end
end",3
https://github.com/johnsonjr/vagrant-aws,### ELB (Elastic Load Balancers),"  You can automatically attach an instance to an ELB during boot and detach on destroy. Vagrant.configure(""2"") do |config|
  # ... other stuff

  config.vm.provider ""aws"" do |aws|
    aws.elb = ""production-web""
  end
end",3
https://github.com/johnsonjr/vagrant-aws,## Development,"  To work on the vagrant-aws plugin, clone this repository out, and use
Bundler to get the dependencies: $ bundle
 Once you have the dependencies, verify the unit tests pass with rake: $ bundle exec rake
 If those pass, you're ready to start developing the plugin. You can test
the plugin without installing it into your Vagrant environment by just
creating a Vagrantfile in the top level of this directory (it is gitignored)
and add the following line to your Vagrantfile Vagrant.require_plugin ""vagrant-aws"" Use bundler to execute Vagrant: $ bundle exec vagrant up --provider=aws
",3
https://github.com/memorywarning/YouCompleteMe,# YouCompleteMe: a code-completion engine for Vim," 
 
Intro
Installation

Mac OS X
Ubuntu Linux x64
Fedora Linux x64
Windows
FreeBSD/OpenBSD
Full Installation Guide


Quick Feature Summary
User Guide

General Usage
Client-Server Architecture
Completion String Ranking
General Semantic Completion
C-family Semantic Completion
JavaScript Semantic Completion
Rust Semantic Completion
Python Semantic Completion
Semantic Completion for Other Languages
Writing New Semantic Completers
Diagnostic Display

Diagnostic Highlighting Groups




Commands

YcmCompleter subcommands

GoTo Commands
Semantic Information Commands
Refactoring and FixIt Commands
Miscellaneous Commands




Functions
Options
FAQ
Contributor Code of Conduct
Contact
License
",1
https://github.com/memorywarning/YouCompleteMe,## Intro,"  YouCompleteMe is a fast, as-you-type, fuzzy-search code completion engine for
Vim. It has several completion engines: 
an identifier-based engine that works with every programming language,
a Clang-based engine that provides native semantic code
completion for C/C++/Objective-C/Objective-C++ (from now on referred to as
""the C-family languages""),
a Jedi-based completion engine for Python 2 and 3 (using the JediHTTP wrapper),
an OmniSharp-based completion engine for C#,
a combination of Gocode and Godef semantic engines for Go,
a TSServer-based completion engine for TypeScript,
a Tern-based completion engine for JavaScript,
a racer-based completion engine for Rust,
and an omnifunc-based completer that uses data from Vim's omnicomplete system
to provide semantic completions for many other languages (Ruby, PHP etc.).
  Here's an explanation of what happens in the short GIF demo above. First, realize that no keyboard shortcuts had to be pressed to get the list
of completion candidates at any point in the demo. The user just types and the
suggestions pop up by themselves. If the user doesn't find the completion
suggestions relevant and/or just wants to type, they can do so; the completion
engine will not interfere. When the user sees a useful completion string being offered, they press the TAB
key to accept it. This inserts the completion string. Repeated presses of the
TAB key cycle through the offered completions. If the offered completions are not relevant enough, the user can continue typing
to further filter out unwanted completions. A critical thing to notice is that the completion filtering is NOT based on
the input being a string prefix of the completion (but that works too). The
input needs to be a subsequence match of a completion. This is a fancy way
of saying that any input characters need to be present in a completion string in
the order in which they appear in the input. So abc is a subsequence of
xaybgc, but not of xbyxaxxc. After the filter, a complicated sorting system
ranks the completion strings so that the most relevant ones rise to the top of
the menu (so you usually need to press TAB just once). All of the above works with any programming language because of the
identifier-based completion engine. It collects all of the identifiers in the
current file and other files you visit (and your tags files) and searches them
when you type (identifiers are put into per-filetype groups). The demo also shows the semantic engine in use. When the user presses ., ->
or :: while typing in insert mode (for C++; different triggers are used for
other languages), the semantic engine is triggered (it can also be triggered
with a keyboard shortcut; see the rest of the docs). The last thing that you can see in the demo is YCM's diagnostic display features
(the little red X that shows up in the left gutter; inspired by Syntastic)
if you are editing a C-family file. As Clang compiles your file and detects
warnings or errors, they will be presented in various ways. You don't need to
save your file or press any keyboard shortcut to trigger this, it ""just happens""
in the background. In essence, YCM obsoletes the following Vim plugins because it has all of their
features plus extra: 
clang_complete
AutoComplPop
Supertab
neocomplcache
 And that's not all... YCM also provides semantic IDE-like features in a
number of languages, including: 
finding declarations, definitions, usages, etc. of identifiers,
displaying type information for classes, variables, functions etc.,
displaying documentation for methods, members, etc. in the preview window,
fixing common coding errors, like missing semi-colons, typos, etc.,
semantic renaming of variables across files (JavaScript only).
 Features vary by file type, so make sure to check out the file type feature
summary and the
full list of completer subcommands to
find out what's available for your favourite languages. You'll also find that YCM has filepath completers (try typing ./ in a file)
and a completer that integrates with UltiSnips.",123
https://github.com/memorywarning/YouCompleteMe,## Installation, ,3
https://github.com/memorywarning/YouCompleteMe,### Mac OS X,"  Please refer to the full Installation Guide below; the following commands are
provided on a best-effort basis and may not work for you. Install the latest version of MacVim. Yes, MacVim. And yes, the latest. If you don't use the MacVim GUI, it is recommended to use the Vim binary that is
inside the MacVim.app package (MacVim.app/Contents/MacOS/Vim). To ensure it
works correctly copy the mvim script from the MacVim download to your
local binary folder (for example /usr/local/bin/mvim) and then symlink it: ln -s /usr/local/bin/mvim vim
 Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM
using Vundle and the ycm_core library APIs have changed (happens
rarely), YCM will notify you to recompile it. You should then rerun the install
process. NOTE: If you want C-family completion, you MUST have the latest Xcode
installed along with the latest Command Line Tools (they are installed
automatically when you run clang for the first time, or manually by running
xcode-select --install) Install CMake. Preferably with Homebrew, but here's the stand-alone
CMake installer. If you have installed a Homebrew Python and/or Homebrew MacVim, see the FAQ
for details. Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe
./install.py --clang-completer
 Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe
./install.py
 The following additional language support options are available: 
C# support: add --omnisharp-completer when calling ./install.py.
Go support: ensure go is installed and add --gocode-completer when calling
./install.py.
TypeScript support: install nodejs and npm then install the
TypeScript SDK with npm install -g typescript.
JavaScript support: install nodejs and npm and add
--tern-completer when calling ./install.py.
Rust support: install rustc and cargo and add
--racer-completer when calling ./install.py.
 To simply compile with everything enabled, there's a --all flag.  So, to
install with all language features, ensure npm, go, mono, rust,
and typescript API are installed and in your PATH, then simply run: cd ~/.vim/bundle/YouCompleteMe
./install.py --all
 That's it. You're done. Refer to the User Guide section on how to use YCM.
Don't forget that if you want the C-family semantic completion engine to work,
you will need to provide the compilation flags for your project to YCM. It's all
in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a
look at what's available for configuration. There are a few interesting options
that are conservatively turned off by default that you may want to turn on.",3
https://github.com/memorywarning/YouCompleteMe,### Ubuntu Linux x64,"  Please refer to the full Installation Guide below; the following commands are
provided on a best-effort basis and may not work for you. Make sure you have Vim 7.3.598 with python2 or python3 support. Ubuntu 14.04 and
later have a Vim that's recent enough. You can see the version of Vim installed
by running vim --version. If the version is too old, you may need to compile
Vim from source (don't worry, it's easy). Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM
using Vundle and the ycm_core library APIs have changed (happens
rarely), YCM will notify you to recompile it. You should then rerun the install
process. Install development tools and CMake: sudo apt-get install build-essential cmake Make sure you have Python headers installed: sudo apt-get install python-dev python3-dev. Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe
./install.py --clang-completer
 Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe
./install.py
 The following additional language support options are available: 
C# support: add --omnisharp-completer when calling ./install.py.
Go support: ensure go is installed and add --gocode-completer when calling
./install.py.
TypeScript support: install nodejs and npm then install the
TypeScript SDK with npm install -g typescript.
JavaScript support: install nodejs and npm and add
--tern-completer when calling ./install.py.
Rust support: install rustc and cargo and add
--racer-completer when calling ./install.py.
 To simply compile with everything enabled, there's a --all flag.  So, to
install with all language features, ensure npm, go, mono, rust,
and typescript API are installed and in your PATH, then simply run: cd ~/.vim/bundle/YouCompleteMe
./install.py --all
 That's it. You're done. Refer to the User Guide section on how to use YCM.
Don't forget that if you want the C-family semantic completion engine to work,
you will need to provide the compilation flags for your project to YCM. It's all
in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a
look at what's available for configuration. There are a few interesting options
that are conservatively turned off by default that you may want to turn on.",3
https://github.com/memorywarning/YouCompleteMe,### Fedora Linux x64,"  Please refer to the full Installation Guide below; the following commands are
provided on a best-effort basis and may not work for you. Make sure you have Vim 7.3.598 with Python 2 or Python 3 support. Fedora 21 and
later have a Vim that's recent enough. You can see the version of Vim installed
by running vim --version. If the version is too old, you may need to compile
Vim from source (don't worry, it's easy). Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM
using Vundle and the ycm_core library APIs have changed (happens
rarely), YCM will notify you to recompile it. You should then rerun the install
process. Install development tools and CMake: sudo dnf install automake gcc gcc-c++ kernel-devel cmake Make sure you have Python headers installed: sudo dnf install python-devel python3-devel. Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe
./install.py --clang-completer
 Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe
./install.py
 The following additional language support options are available: 
C# support: add --omnisharp-completer when calling ./install.py.
Go support: ensure go is installed and add --gocode-completer when calling
./install.py.
TypeScript support: install nodejs and npm then install the
TypeScript SDK with npm install -g typescript.
JavaScript support: install nodejs and npm and add
--tern-completer when calling ./install.py.
Rust support: install rustc and cargo and add
--racer-completer when calling ./install.py.
 To simply compile with everything enabled, there's a --all flag.  So, to
install with all language features, ensure npm, go, mono, rust,
and typescript API are installed and in your PATH, then simply run: cd ~/.vim/bundle/YouCompleteMe
./install.py --all
 That's it. You're done. Refer to the User Guide section on how to use YCM.
Don't forget that if you want the C-family semantic completion engine to work,
you will need to provide the compilation flags for your project to YCM. It's all
in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a
look at what's available for configuration. There are a few interesting options
that are conservatively turned off by default that you may want to turn on.",3
https://github.com/memorywarning/YouCompleteMe,### Windows,"  Please refer to the full Installation Guide below; the following commands are
provided on a best-effort basis and may not work for you. Important: we assume that you are using the cmd.exe command prompt and
that you know how to add an executable to the PATH environment variable. Make sure you have at least Vim 7.3.598 with Python 2 or Python 3 support. You
can check the version and which Python is supported by typing :version inside
Vim. Look at the features included: +python/dyn for Python 2 and
+python3/dyn for Python 3. Take note of the Vim architecture, i.e. 32 or
64-bit. It will be important when choosing the Python installer. We recommend
using a 64-bit client. Daily updated copies of 32-bit and 64-bit Vim with
Python 2 and Python 3 support are available. Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM
using Vundle and the ycm_core library APIs have changed (happens
rarely), YCM will notify you to recompile it. You should then rerun the install
process. Download and install the following software: 
Python 2 or Python 3. Be sure to pick the version
corresponding to your Vim architecture. It is Windows x86 for a 32-bit Vim and
Windows x86-64 for a 64-bit Vim. We recommend installing Python 3.
CMake. Add CMake executable to the PATH environment
variable.
Visual Studio. Download the community edition.
During setup, choose Custom as the installation type and select the Visual
C++ component.
7-zip. Required to build YCM with semantic support for
C-family languages.
 Compiling YCM with semantic support for C-family languages: cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe
install.py --clang-completer
 Compiling YCM without semantic support for C-family languages: cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe
install.py
 The following additional language support options are available: 
C# support: add --omnisharp-completer when calling install.py.
Be sure that the build utility msbuild is in your PATH.
Go support: ensure go is installed and add --gocode-completer when calling
install.py.
TypeScript support: install nodejs and npm then install the
TypeScript SDK with npm install -g typescript.
JavaScript support: install nodejs and npm and add
--tern-completer when calling install.py.
Rust support: install rustc and cargo and add
--racer-completer when calling install.py.
 To simply compile with everything enabled, there's a --all flag.  So, to
install with all language features, ensure npm, go, mono, rust,
and typescript API are installed and in your %PATH%, then simply run: cd %USERPROFILE%/vimfiles/bundle/YouCompleteMe
python install.py --all
 You can specify the Microsoft Visual C++ (MSVC) version using the --msvc
option. YCM officially supports MSVC 11 (Visual Studio 2012), 12 (2013), and 14
(2015). That's it. You're done. Refer to the User Guide section on how to use YCM.
Don't forget that if you want the C-family semantic completion engine to work,
you will need to provide the compilation flags for your project to YCM. It's all
in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a
look at what's available for configuration. There are a few interesting options
that are conservatively turned off by default that you may want to turn on.",3
https://github.com/memorywarning/YouCompleteMe,### FreeBSD/OpenBSD,"  Please refer to the full Installation Guide below; the following commands are
provided on a best-effort basis and may not work for you. OpenBSD / FreeBSD are
not officially supported platforms by YCM. Make sure you have Vim 7.3.598 with Python 2 or Python 3 support. OpenBSD 5.5 and later have a Vim that's recent enough. You can see the version of
Vim installed by running vim --version. FreeBSD 10.x comes with clang compiler but not the libraries needed to install. pkg install llvm35 boost-all boost-python-libs clang35
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/llvm35/lib/
 Install YouCompleteMe with Vundle. Remember: YCM is a plugin with a compiled component. If you update YCM
using Vundle and the ycm_core library APIs have changed (happens
rarely), YCM will notify you to recompile it. You should then rerun the install
process. Install dependencies and CMake: sudo pkg_add llvm boost cmake Compiling YCM with semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe
./install.py --clang-completer --system-libclang --system-boost
 Compiling YCM without semantic support for C-family languages: cd ~/.vim/bundle/YouCompleteMe
./install.py --system-boost
 The following additional language support options are available: 
C# support: add --omnisharp-completer when calling ./install.py.
Go support: ensure go is installed and add --gocode-completer when calling
./install.py.
TypeScript support: install nodejs and npm then install the
TypeScript SDK with npm install -g typescript.
JavaScript support: install nodejs and npm and add
--tern-completer when calling ./install.py.
Rust support: install rustc and cargo and add
--racer-completer when calling ./install.py.
 To simply compile with everything enabled, there's a --all flag.  So, to
install with all language features, ensure npm, go, mono, rust,
and typescript API are installed and in your PATH, then simply run: cd ~/.vim/bundle/YouCompleteMe
./install.py --all
 That's it. You're done. Refer to the User Guide section on how to use YCM.
Don't forget that if you want the C-family semantic completion engine to work,
you will need to provide the compilation flags for your project to YCM. It's all
in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a
look at what's available for configuration. There are a few interesting options
that are conservatively turned off by default that you may want to turn on.",3
https://github.com/memorywarning/YouCompleteMe,### Full Installation Guide,"  These are the steps necessary to get YCM working on a Unix OS and on Windows. Note to Windows users: we assume that you are running the cmd.exe command
prompt and that the needed executables are in the PATH environment variable. Do
not just copy the shell commands. Replace ~ by %USERPROFILE% in them and use
the right Vim home directory. It should be vimfiles by default instead of
.vim. See the FAQ if you have any issues. Remember: YCM is a plugin with a compiled component. If you update YCM
using Vundle and the ycm_core library APIs have changed (happens
rarely), YCM will notify you to recompile it. You should then rerun the install
process. Please follow the instructions carefully. Read EVERY WORD. 

Ensure that your version of Vim is at least 7.3.598 and that it has
support for Python 2 or Python 3 scripting.
Inside Vim, type :version. Look at the first two to three lines of output;
it should say Vi IMproved X.Y, where X.Y is the major version of vim. If
your version is greater than 7.3, then you're all set. If your version is
7.3 then look below that where it says, Included patches: 1-Z, where Z
will be some number. That number needs to be 598 or higher.
If your version of Vim is not recent enough, you may need to compile Vim
from source (don't worry, it's easy).
After you have made sure that you have Vim 7.3.598+, type the following in
Vim: :echo has('python') || has('python3'). The output should be 1. If
it's 0, then get a version of Vim with Python support.
On Windows, check also if your Vim architecture is 32 or 64-bit. This is
critical because it must match the Python and the YCM libraries
architectures. We recommend using a 64-bit Vim.


Install YCM with Vundle (or Pathogen, but Vundle is a better
idea). With Vundle, this would mean adding a Plugin 'Valloric/YouCompleteMe' line to your vimrc.
If you don't install YCM with Vundle, make sure you have run
git submodule update --init --recursive after checking out the YCM
repository (Vundle will do this for you) to fetch YCM's dependencies.


[Complete this step ONLY if you care about semantic completion support for
C-family languages. Otherwise it's not necessary.]
Download the latest version of libclang. Clang is an open-source
compiler that can compile C/C++/Objective-C/Objective-C++. The libclang
library it provides is used to power the YCM semantic completion engine for
those languages. YCM is designed to work with libclang version 3.6 or
higher, but can in theory work with any 3.2+ version as well.
You can use the system libclang only if you are sure it is version 3.3 or
higher, otherwise don't. Even if it is, we recommend using the official
binaries from llvm.org if at all possible. Make sure you
download the correct archive file for your OS.
We STRONGLY recommend AGAINST use of the system libclang instead of
the upstream compiled binaries. Random things may break. Save yourself the
hassle and use the upstream pre-built libclang.


Compile the ycm_core library that YCM needs. This library
is the C++ engine that YCM uses to get fast completions.
You will need to have cmake installed in order to generate the required
makefiles. Linux users can install cmake with their package manager (sudo apt-get install cmake for Ubuntu) whereas other users can download and
install cmake from its project site. Mac users can also get
it through Homebrew with brew install cmake.
On a Unix OS, you need to make sure you have Python headers installed. On a
Debian-like Linux distro, this would be sudo apt-get install python-dev python3-dev. On Mac they should already be present.
On Windows, you need to download and install Python 2 or
Python 3. Pick the version corresponding to your Vim
architecture. You will also need Microsoft Visual C++ (MSVC) to build YCM.
You can obtain it by installing Visual Studio.
MSVC 11 (Visual Studio 2012), 12 (2013), and 14 (2015) are officially
supported.
Here we'll assume you installed YCM with Vundle. That means that the
top-level YCM directory is in ~/.vim/bundle/YouCompleteMe.
We'll create a new folder where build files will be placed. Run the
following:
cd ~
mkdir ycm_build
cd ycm_build

Now we need to generate the makefiles. If you DON'T care about semantic
support for C-family languages, run the following command in the ycm_build
directory:
cmake -G ""<generator>"" . ~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp

where <generator> is Unix Makefiles on Unix systems and one of the
following Visual Studio generators on Windows:

Visual Studio 11 Win64
Visual Studio 12 Win64
Visual Studio 14 Win64

Remove the Win64 part in these generators if your Vim architecture is
32-bit.
For those who want to use the system version of boost, you would pass
-DUSE_SYSTEM_BOOST=ON to cmake. This may be necessary on some systems
where the bundled version of boost doesn't compile out of the box.
NOTE: We STRONGLY recommend AGAINST use of the system boost instead
of the bundled version of boost. Random things may break. Save yourself
the hassle and use the bundled version of boost.
If you DO care about semantic support for C-family languages, then your
cmake call will be a bit more complicated.  We'll assume you downloaded a
binary distribution of LLVM+Clang from llvm.org in step 3 and that you
extracted the archive file to folder ~/ycm_temp/llvm_root_dir (with bin,
lib, include etc. folders right inside that folder). On Windows, you can
extract the files from the LLVM+Clang installer using 7-zip.
NOTE: This only works with a downloaded LLVM binary package, not a
custom-built LLVM! See docs below for EXTERNAL_LIBCLANG_PATH when using a
custom LLVM build.
With that in mind, run the following command in the ycm_build directory:
cmake -G ""<generator>"" -DPATH_TO_LLVM_ROOT=~/ycm_temp/llvm_root_dir . ~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp

where <generator> is replaced like above.
Now that configuration files have been generated, compile the libraries
using this command:
cmake --build . --target ycm_core --config Release

The --config Release part is specific to Windows and will be ignored on a
Unix OS.
For those who want to use the system version of libclang, you would pass
-DUSE_SYSTEM_LIBCLANG=ON to cmake instead of the
-DPATH_TO_LLVM_ROOT=... flag.
NOTE: We STRONGLY recommend AGAINST use of the system libclang instead
of the upstream compiled binaries. Random things may break. Save yourself
the hassle and use the upstream pre-built libclang.
You could also force the use of a custom libclang library with
-DEXTERNAL_LIBCLANG_PATH=/path/to/libclang.so flag (the library would end
with .dylib on a Mac). Again, this flag would be used instead of the
other flags. If you compiled LLVM from source, this is the flag you should
be using.
Running the cmake command will also place the libclang.[so|dylib|dll] in
the YouCompleteMe/third_party/ycmd folder for you if you compiled with
clang support (it needs to be there for YCM to work).


Set up support for additional languages, as desired:

 

C# support: Navigate to
YouCompleteMe/third_party/ycmd/third_party/OmniSharpServer and run
msbuild (Windows) or xbuild (other platforms, using mono) depending on
your platform. If mono is not installed, install it.
When on Windows, be sure that the build utility msbuild is in your PATH.


Go support: If go is not installed on your system, install it and add it to
your path. Navigate to YouCompleteMe/third_party/ycmd/third_party/gocode
and run go build.


TypeScript support: As with the quick installation, simply npm install -g typescript after successfully installing nodejs and npm.


JavaScript support: Install nodejs and npm. Then navigate to
YouCompleteMe/third_party/ycmd/third_party/tern_runtime and run npm install --production


Rust support: Install rustc and cargo. Navigate to
YouCompleteMe/third_party/ycmd/third_party/racerd and run
cargo build --release.

 That's it. You're done. Refer to the User Guide section on how to use YCM.
Don't forget that if you want the C-family semantic completion engine to work,
you will need to provide the compilation flags for your project to YCM. It's all
in the User Guide. YCM comes with sane defaults for its options, but you still may want to take a
look at what's available for configuration. There are a few interesting options
that are conservatively turned off by default that you may want to turn on.",3
https://github.com/memorywarning/YouCompleteMe,## Quick Feature Summary, ,1
https://github.com/memorywarning/YouCompleteMe,### General (all languages),"  
Super-fast identifier completer including tags files and syntax elements
Intelligent suggestion ranking and filtering
File and path suggestions
Suggestions from Vim's OmniFunc
UltiSnips snippet suggestions
",1
https://github.com/memorywarning/YouCompleteMe,"### C-family languages (C, C++, Objective C, Objective C++)","  
Semantic auto-completion
Real-time diagnostic display
Go to include/declaration/definition (GoTo, etc.)
Semantic type information for identifiers (GetType)
Automatically fix certain errors (FixIt)
View documentation comments for identifiers (GetDoc)
",1
https://github.com/memorywarning/YouCompleteMe,"### C?,1""","Semantic auto-completion
Real-time diagnostic display
Go to declaration/definition (GoTo, etc.)
Semantic type information for identifiers (GetType)
Automatically fix certain errors (FixIt)
Management of OmniSharp server instance
View documentation comments for identifiers (GetDoc)",
https://github.com/memorywarning/YouCompleteMe,### Python,"Intelligent auto-completion
Go to declaration/definition, find references (GoTo, GoToReferences)
View documentation comments for identifiers (GetDoc)
Restart JediHTTP server using a different Python interpreter",1
https://github.com/memorywarning/YouCompleteMe,### Go,"Semantic auto-completion
Go to definition (GoTo)
Management of gocode server instance",1
https://github.com/memorywarning/YouCompleteMe,### TypeScript,"Semantic auto-completion
Go to definition, find references (GoToDefinition, GoToReferences)
Semantic type information for identifiers (GetType)
View documentation comments for identifiers (GetDoc)",1
https://github.com/memorywarning/YouCompleteMe,### JavaScript,"Intelligent auto-completion
Renaming variables (RefactorRename <new name>)
Go to definition, find references (GoToDefinition, GoToReferences)
Type information for identifiers (GetType)
View documentation comments for identifiers (GetDoc)
Management of Tern server instance",1
https://github.com/memorywarning/YouCompleteMe,### Rust,"Semantic auto-completion
Go to definition (GoTo, GoToDefinition, and GoToDeclaration are identical)
Management of racer server instance",1
https://github.com/memorywarning/YouCompleteMe,## User Guide,,3
https://github.com/memorywarning/YouCompleteMe,### General Usage,"If the offered completions are too broad, keep typing characters; YCM will continue refining the offered completions based on your input.
Filtering is ""smart-case"" sensitive; if you are typing only lowercase letters, then it's case-insensitive. If your input contains uppercase letters, then the uppercase letters in your query must match uppercase letters in the completion strings (the lowercase letters still match both). So, ""foo"" matches ""Foo"" and ""foo"", ""Foo"" matches ""Foo"" and ""FOO"" but not ""foo"".
Use the TAB key to accept a completion and continue pressing TAB to cycle through the completions. Use Shift-TAB to cycle backwards. Note that if you're using console Vim (that is, not Gvim or MacVim) then it's likely that the Shift-TAB binding will not work because the console will not pass it to Vim. You can remap the keys; see the Options section below.
Knowing a little bit about how YCM works internally will prevent confusion. YCM has several completion engines: an identifier-based completer that collects all of the identifiers in the current file and other files you visit (and your tags files) and searches them when you type (identifiers are put into per-filetype groups).

There are also several semantic engines in YCM. There's a libclang-based completer that provides semantic completion for C-family languages. There's a Jedi-based completer for semantic completion for Python. There's also an omnifunc-based completer that uses data from Vim's omnicomplete system to provide semantic completions when no native completer exists for that language in YCM.

There are also other completion engines, like the UltiSnips completer and the filepath completer.

YCM automatically detects which completion engine would be the best in any situation. On occasion, it queries several of them at once, merges the outputs and presents the results to you.",3
https://github.com/memorywarning/YouCompleteMe,### Client-Server Architecture,"  YCM has a client-server architecture; the Vim part of YCM is only a thin client
that talks to the ycmd HTTP+JSON server that has the vast majority of
YCM logic and functionality. The server is started and stopped automatically as
you start and stop Vim.",36
https://github.com/memorywarning/YouCompleteMe,### Completion String Ranking,"  The subsequence filter removes any completions that do not match the input, but
then the sorting system kicks in. It's actually very complicated and uses lots
of factors, but suffice it to say that ""word boundary"" (WB) subsequence
character matches are ""worth"" more than non-WB matches. In effect, this means
given an input of ""gua"", the completion ""getUserAccount"" would be ranked higher
in the list than the ""Fooguxa"" completion (both of which are subsequence
matches). A word-boundary character are all capital characters, characters
preceded by an underscore and the first letter character in the completion
string.",3
https://github.com/memorywarning/YouCompleteMe,### General Semantic Completion,"  
You can use Ctrl+Space to trigger the completion suggestions anywhere, even
without a string prefix. This is useful to see which top-level functions are
available for use.
",3
https://github.com/memorywarning/YouCompleteMe,### C-family Semantic Completion,"  YCM looks for a .ycm_extra_conf.py file in the directory of the opened file or
in any directory above it in the hierarchy (recursively); when the file is
found, it is loaded (only once!) as a Python module. YCM calls a FlagsForFile
method in that module which should provide it with the information necessary to
compile the current file. You can also provide a path to a global
.ycm_extra_conf.py file, which will be used as a fallback. To prevent the
execution of malicious code from a file you didn't write YCM will ask you once
per .ycm_extra_conf.py if it is safe to load. This can be disabled and you can
white-/blacklist files. See the Options section for more details. This system was designed this way so that the user can perform any arbitrary
sequence of operations to produce a list of compilation flags YCM should hand
to Clang. See YCM's own .ycm_extra_conf.py for details on how this
works. You should be able to use it as a starting point. Don't just
copy/paste that file somewhere and expect things to magically work; your project
needs different flags. Hint: just replace the strings in the flags variable
with compilation flags necessary for your project. That should be enough for 99%
of projects. Yes, Clang's CompilationDatabase system is also supported. Again,
see the above linked example file. You can get CMake to generate this file for
you by adding set( CMAKE_EXPORT_COMPILE_COMMANDS 1 ) to your project's
CMakeLists.txt file (if using CMake). If you're not using CMake, you could use
something like Bear to generate the compile_commands.json file. Consider using YCM-Generator to generate the ycm_extra_conf.py file. If Clang encounters errors when compiling the header files that your file
includes, then it's probably going to take a long time to get completions.  When
the completion menu finally appears, it's going to have a large number of
unrelated completion strings (type/function names that are not actually
members). This is because Clang fails to build a precompiled preamble for your
file if there are any errors in the included headers and that preamble is key to
getting fast completions. Call the :YcmDiags command to see if any errors or warnings were detected in
your file.",36
https://github.com/memorywarning/YouCompleteMe,### JavaScript Semantic Completion, ,36
https://github.com/memorywarning/YouCompleteMe,#### Quick start,"  

Ensure that you have enabled the Tern completer. See the
installation guide for details.


Create a .tern-project file in the root directory of your JavaScript
project, by following the instructions in the Tern
documentation.


Make sure that Vim's working directory is a descendent of that directory (or
that directory itself) when working with JavaScript files.

",3
https://github.com/memorywarning/YouCompleteMe,#### Explanation,"  JavaScript completion is based on Tern. This completion engine requires a
file named .tern-project to exist in the current working
directory or a directory which is an ancestor of the current working directory
when the tern server is started. YCM starts the Tern server the first time a
JavaScript file is edited, so Vim's working directory at that time needs to be a
descendent of the directory containing the .tern-project file (or that
directory itself). Alternatively, as described in the Tern documentation, a global
.tern-config file may be used. Multiple Tern servers, are not supported. To switch to a different
JavaScript project, you can do one of the following: 
start a new instance of Vim from the new project's directory
change Vim's working directory (:cd /path/to/new/project) and restart the
ycmd server (:YcmRestartServer)
change Vim's working directory (:cd /path/to/new/project), open a JavaScript
file (or set filetype to JavaScript) and restart the Tern server using YCM
completer subcommands :YcmCompleter StopServer and :YcmCompleter StartServer.
",3
https://github.com/memorywarning/YouCompleteMe,#### Tips and tricks,"  This section contains some advice for configuring .tern-project and working
with JavaScript files. The canonical reference for correctly configuring Tern is
the Tern documentation. Any issues, improvements, advice, etc.
should be sought from the Tern project. For example, see the list of tern
plugins for the list of plugins
which can be enabled in the plugins section of the .tern-project file.",36
https://github.com/memorywarning/YouCompleteMe,##### Configuring Tern for node support,"  The following simple example .tern-project file enables nodejs support: {
    ""plugins"": {
        ""node"": {}
    }
}
",3
https://github.com/memorywarning/YouCompleteMe,##### Configuring Tern for requirejs support,"  The Tern requirejs plugin requires that all included ""libraries"" are rooted
under the same base directory. If that's not the case for your projects, then it
is possible to make it work with appropriate symbolic links. For example, create
a directory ext_lib within your project and populate it with symlinks to your
libraries. Then set up the .tern-project something like this: {
  ""plugins"": {
    ""requirejs"": {
      ""baseURL"": ""./ext_lib"",
    }
  }
} Then, given the following structure: ./ext_lib/mylib (symlink)
./ext_lib/anotherlib (symlink)
 Can be used as follows: define( [ 'mylib/file1', 'anotherlib/anotherfile' ], function( f1, f2 ) {
    // etc.
} );",3
https://github.com/memorywarning/YouCompleteMe,### Rust Semantic Completion,"  Completions and GoTo commands within the current crate and its dependencies
should work out of the box with no additional configuration (provided that you
built YCM with the --racer-completer flag; see the Installation
section for details).  For semantic analysis inclusive of the
standard library, you must have a local copy of the rust source
code. You also need to set the following option so YouCompleteMe can
locate it. "" In this example, the rust source code zip has been extracted to
"" /usr/local/rust/rustc-1.5.0
let g:ycm_rust_src_path = '/usr/local/rust/rustc-1.5.0/src'",3
https://github.com/memorywarning/YouCompleteMe,### Python Semantic Completion,"  Completion and GoTo commands work out of the box with no additional
configuration. Those features are provided by the jedi library which
supports a variety of Python versions (2.6, 2.7, 3.2+) as long as it
runs in the corresponding Python interpreter. By default YCM runs jedi with
the same Python interpreter used by the ycmd server, so if you would like to
use a different interpreter, use the following option specifying the Python
binary to use. For example, to provide Python 3 completion in your project, set: let g:ycm_python_binary_path = '/usr/bin/python3'",3
https://github.com/memorywarning/YouCompleteMe,### Semantic Completion for Other Languages,"  Python, C#, Go, Rust, and TypeScript are supported natively by YouCompleteMe
using the Jedi, Omnisharp, Gocode, racer, and TSServer
engines, respectively. Check the installation section for
instructions to enable these features if desired. YCM will use your omnifunc (see :h omnifunc in Vim) as a source for semantic
completions if it does not have a native semantic completion engine for your
file's filetype. Vim comes with okayish omnifuncs for various languages like
Ruby, PHP etc. It depends on the language. You can get stellar omnifuncs for Java and Ruby with Eclim. Just make sure
you have the latest Eclim installed and configured (this means Eclim >= 2.2.*
and Eclipse >= 4.2.*). After installing Eclim remember to create a new Eclipse project within your
application by typing :ProjectCreate <path-to-your-project> -n ruby (or -n java)
inside vim and don't forget to have let g:EclimCompletionMethod = 'omnifunc'
in your vimrc. This will make YCM and Eclim play nice; YCM will use Eclim's omnifuncs
as the data source for semantic completions and provide the auto-triggering
and subsequence-based matching (and other YCM features) on top of it.",3
https://github.com/memorywarning/YouCompleteMe,### Writing New Semantic Completers,"  You have two options here: writing an omnifunc for Vim's omnicomplete system
that YCM will then use through its omni-completer, or a custom completer for YCM
using the Completer API. Here are the differences between the two approaches: 
You have to use VimScript to write the omnifunc, but get to use Python to
write for the Completer API; this by itself should make you want to use the
API.
The Completer API is a much more powerful way to integrate with YCM and it
provides a wider set of features. For instance, you can make your Completer
query your semantic back-end in an asynchronous fashion, thus not blocking
Vim's GUI thread while your completion system is processing stuff. This is
impossible with VimScript. All of YCM's completers use the Completer API.
Performance with the Completer API is better since Python executes faster than
VimScript.
 If you want to use the omnifunc system, see the relevant Vim docs with :h complete-functions. For the Completer API, see the API docs. If you want to upstream your completer into YCM's source, you should use the
Completer API.",36
https://github.com/memorywarning/YouCompleteMe,### Diagnostic Display,"  YCM will display diagnostic notifications for C-family and C# languages if you
compiled YCM with Clang and Omnisharp support, respectively. Since YCM continuously
recompiles your file as you type, you'll get notified of errors and warnings
in your file as fast as possible. Here are the various pieces of the diagnostic UI: 
Icons show up in the Vim gutter on lines that have a diagnostic.
Regions of text related to diagnostics are highlighted (by default, a red
wavy underline in gvim and a red background in vim).
Moving the cursor to a line with a diagnostic echoes the diagnostic text.
Vim's location list is automatically populated with diagnostic data (off by
default, see options).
 The new diagnostics (if any) will be displayed the next time you press any key
on the keyboard. So if you stop typing and just wait for the new diagnostics to
come in, that will not work. You need to press some key for the GUI to update. Having to press a key to get the updates is unfortunate, but cannot be changed
due to the way Vim internals operate; there is no way that a background task can
update Vim's GUI after it has finished running.  You have to press a key. This
will make YCM check for any pending diagnostics updates. You can force a full, blocking compilation cycle with the
:YcmForceCompileAndDiagnostics command (you may want to map that command to a
key; try putting nnoremap <F5> :YcmForceCompileAndDiagnostics<CR> in your
vimrc). Calling this command will force YCM to immediately recompile your file
and display any new diagnostics it encounters. Do note that recompilation with
this command may take a while and during this time the Vim GUI will be
blocked. YCM will display a short diagnostic message when you move your cursor to the
line with the error. You can get a detailed diagnostic message with the
<leader>d key mapping (can be changed in the options) YCM provides when your
cursor is on the line with the diagnostic. You can also see the full diagnostic message for all the diagnostics in the
current file in Vim's locationlist, which can be opened with the :lopen and
:lclose commands (make sure you have set let g:ycm_always_populate_location_list = 1 in your vimrc). A good way to toggle
the display of the locationlist with a single key mapping is provided by
another (very small) Vim plugin called ListToggle (which also makes it
possible to change the height of the locationlist window), also written by
yours truly.",36
https://github.com/memorywarning/YouCompleteMe,#### Diagnostic Highlighting Groups,"  You can change the styling for the highlighting groups YCM uses. For the signs
in the Vim gutter, the relevant groups are: 
YcmErrorSign, which falls back to group SyntasticErrorSign and then
error if they exist
YcmWarningSign, which falls back to group SyntasticWarningSign and then
todo if they exist
 You can also style the line that has the warning/error with these groups: 
YcmErrorLine, which falls back to group SyntasticErrorLine if it exists
YcmWarningLine, which falls back to group SyntasticWarningLine if it
exists
 Note that the line highlighting groups only work when gutter signs are turned
on. The syntax groups used to highlight regions of text with errors/warnings: 
YcmErrorSection, which falls back to group SyntasticError if it exists and
then SpellBad
YcmWarningSection, which falls back to group SyntasticWarning if it exists
and then SpellCap
 Here's how you'd change the style for a group: highlight YcmErrorLine guibg=#3f0000",3
https://github.com/memorywarning/YouCompleteMe,## Commands, ,3
https://github.com/memorywarning/YouCompleteMe,### The `:YcmRestartServer` command,"  If the ycmd completion server suddenly stops for some reason, you can
restart it with this command.",3
https://github.com/memorywarning/YouCompleteMe,### The `:YcmForceCompileAndDiagnostics` command,"  Calling this command will force YCM to immediately recompile your file
and display any new diagnostics it encounters. Do note that recompilation with
this command may take a while and during this time the Vim GUI will be
blocked. You may want to map this command to a key; try putting nnoremap <F5> :YcmForceCompileAndDiagnostics<CR> in your vimrc.",3
https://github.com/memorywarning/YouCompleteMe,### The `:YcmDiags` command,"  Calling this command will fill Vim's locationlist with errors or warnings if
any were detected in your file and then open it. If a given error or warning can
be fixed by a call to :YcmCompleter FixIt, then  (FixIt available) is
appended to the error or warning text. See the FixIt completer subcommand for
more information. NOTE: The absense of  (FixIt available) does not strictly imply a fix-it is
not available as not all completers are able to provide this indication. For
example, the c-sharp completer provides many fix-its but does not add this
additional indication. The g:ycm_open_loclist_on_ycm_diags option can be used to prevent the location
list from opening, but still have it filled with new diagnostic data. See the
Options section for details.",3
https://github.com/memorywarning/YouCompleteMe,### The `:YcmShowDetailedDiagnostic` command,"  This command shows the full diagnostic text when the user's cursor is on the
line with the diagnostic.",3
https://github.com/memorywarning/YouCompleteMe,### The `:YcmDebugInfo` command,"  This will print out various debug information for the current file. Useful to
see what compile commands will be used for the file if you're using the semantic
completion engine.",3
https://github.com/memorywarning/YouCompleteMe,### The `:YcmToggleLogs` command,"  This command automatically opens in windows the stdout and stderr logfiles
written by the ycmd server. If one or both logfiles are already opened,
they are automatically closed. stderr or stdout can be specified as an
argument of this command to only open the corresponding logfile instead of both.
If this logfile is already opened, it will be closed. Only for debugging
purpose.",3
https://github.com/memorywarning/YouCompleteMe,### The `:YcmCompleter` command,"  This command gives access to a number of additional IDE-like
features in YCM, for things like semantic GoTo, type
information, FixIt and refactoring. Technically the command invokes completer-specific commands.  If the first
argument is of the form ft=... the completer for that file type will be used
(for example ft=cpp), else the native completer of the current buffer will be
used.
Call YcmCompleter without further arguments for a list of the
commands you can call for the current completer. See the file type feature summary for an overview of
the features available for each file type. See the YcmCompleter subcommands
section for more information on the available subcommands and their usage.",36
https://github.com/memorywarning/YouCompleteMe,## YcmCompleter Subcommands,"  NOTE: See the docs for the YcmCompleter command before tackling this section. The invoked subcommand is automatically routed to the currently active semantic
completer, so :YcmCompleter GoToDefinition will invoke the GoToDefinition
subcommand on the Python semantic completer if the currently active file is a
Python one and on the Clang completer if the currently active file is a
C/C++/Objective-C one. You may also want to map the subcommands to something less verbose; for
instance, nnoremap <leader>jd :YcmCompleter GoTo<CR>
maps the <leader>jd sequence to the longer subcommand invocation.",3
https://github.com/memorywarning/YouCompleteMe,### GoTo Commands,"  These commands are useful for jumping around and exploring code. When moving
the cursor, the subcommands add entries to Vim's jumplist so you can use
CTRL-O to jump back to where you where before invoking the command (and
CTRL-I to jump forward; see :h jumplist for details).",3
https://github.com/memorywarning/YouCompleteMe,#### The `GoToInclude` subcommand,"  Looks up the current line for a header and jumps to it. Supported in filetypes: c, cpp, objc, objcpp",3
https://github.com/memorywarning/YouCompleteMe,#### The `GoToDeclaration` subcommand,"  Looks up the symbol under the cursor and jumps to its declaration. Supported in filetypes: c, cpp, objc, objcpp, cs, go, python, rust",3
https://github.com/memorywarning/YouCompleteMe,#### The `GoToDefinition` subcommand,"  Looks up the symbol under the cursor and jumps to its definition. NOTE: For C-family languages this only works in certain situations, namely when
the definition of the symbol is in the current translation unit. A translation
unit consists of the file you are editing and all the files you are including
with #include directives (directly or indirectly) in that file. Supported in filetypes: c, cpp, objc, objcpp, cs, go, javascript, python, rust, typescript",3
https://github.com/memorywarning/YouCompleteMe,#### The `GoTo` subcommand,"  This command tries to perform the ""most sensible"" GoTo operation it can.
Currently, this means that it tries to look up the symbol under the cursor and
jumps to its definition if possible; if the definition is not accessible from
the current translation unit, jumps to the symbol's declaration. For
C/C++/Objective-C, it first tries to look up the current line for a header and
jump to it. For C#, implementations are also considered and preferred. Supported in filetypes: c, cpp, objc, objcpp, cs, go, javascript, python, rust",3
https://github.com/memorywarning/YouCompleteMe,#### The `GoToImprecise` subcommand,"  WARNING: This command trades correctness for speed! Same as the GoTo command except that it doesn't recompile the file with
libclang before looking up nodes in the AST. This can be very useful when you're
editing files that take long to compile but you know that you haven't made any
changes since the last parse that would lead to incorrect jumps. When you're
just browsing around your codebase, this command can spare you quite a bit of
latency. Supported in filetypes: c, cpp, objc, objcpp",3
https://github.com/memorywarning/YouCompleteMe,#### The `GoToReferences` subcommand,"  This command attempts to find all of the references within the project to the
identifier under the cursor and populates the quickfix list with those
locations. Supported in filetypes: javascript, python, typescript",3
https://github.com/memorywarning/YouCompleteMe,#### The `GoToImplementation` subcommand,"  Looks up the symbol under the cursor and jumps to its implementation (i.e.
non-interface). If there are multiple implementations, instead provides a list
of implementations to choose from. Supported in filetypes: cs",3
https://github.com/memorywarning/YouCompleteMe,#### The `GoToImplementationElseDeclaration` subcommand,"  Looks up the symbol under the cursor and jumps to its implementation if one,
else jump to its declaration. If there are multiple implementations, instead
provides a list of implementations to choose from. Supported in filetypes: cs",3
https://github.com/memorywarning/YouCompleteMe,### Semantic Information Commands,"  These commands are useful for finding static information about the code, such
as the types of variables, viewing declarations and documentation strings.",3
https://github.com/memorywarning/YouCompleteMe,#### The `GetType` subcommand,"  Echos the type of the variable or method under the cursor, and where it differs,
the derived type. For example:     std::string s; Invoking this command on s returns std::string => std::basic_string<char> NOTE: Due to limitations of libclang, invoking this command on the word
auto typically returns auto. However, invoking it on a usage of the variable
with inferred type returns the correct type, but typically it is repeated due to
libclang returning that the types differ. For example: const char *s = ""String"";
auto x = &s; // invoking on x or auto returns ""auto"";
             // invoking on s returns ""const char *""
std::cout << *x; // invoking on x returns ""const char ** => const char **"" NOTE: Causes re-parsing of the current translation unit. Supported in filetypes: c, cpp, objc, objcpp, javascript, typescript",3
https://github.com/memorywarning/YouCompleteMe,#### The `GetParent` subcommand,"  Echos the semantic parent of the point under the cursor. The semantic parent is the item that semantically contains the given position. For example: class C {
    void f();
};

void C::f() {

} In the out-of-line definition of C::f, the semantic parent is the class C,
of which this function is a member. In the example above, both declarations of C::f have C as their semantic
context, while the lexical context of the first C::f is C and the lexical
context of the second C::f is the translation unit. For global declarations, the semantic parent is the translation unit. NOTE: Causes re-parsing of the current translation unit. Supported in filetypes: c, cpp, objc, objcpp",3
https://github.com/memorywarning/YouCompleteMe,#### The `GetDoc` subcommand,"  Displays the preview window populated with quick info about the identifier
under the cursor. Depending on the file type, this includes things like: 
The type or declaration of identifier,
Doxygen/javadoc comments,
Python docstrings,
etc.
 Supported in filetypes: c, cpp, objc, objcpp, cs, python, typescript, javascript",3
https://github.com/memorywarning/YouCompleteMe,### Refactoring and FixIt Commands,"  These commands make changes to your source code in order to perform refactoring
or code correction. YouCompleteMe does not perform any action which cannot be
undone, and never saves or writes files to the disk.",3
https://github.com/memorywarning/YouCompleteMe,#### The `FixIt` subcommand,"  Where available, attempts to make changes to the buffer to correct the
diagnostic closest to the cursor position. Completers which provide diagnostics may also provide trivial modifications to
the source in order to correct the diagnostic. Examples include syntax errors
such as missing trailing semi-colons, spurious characters, or other errors which
the semantic engine can deterministically suggest corrections. If no fix-it is available for the current line, or there is no diagnostic on the
current line, this command has no effect on the current buffer. If any
modifications are made, the number of changes made to the buffer is echo'd and
the user may use the editor's undo command to revert. When a diagnostic is available, and g:ycm_echo_current_diagnostic is set to 1,
then the text  (FixIt) is appended to the echo'd diagnostic when the
completer is able to add this indication. The text  (FixIt available) is
also appended to the diagnostic text in the output of the :YcmDiags command
for any diagnostics with available fix-its (where the completer can provide this
indication). NOTE: Causes re-parsing of the current translation unit. NOTE: After applying a fix-it, the diagnostics UI is not immediately updated.
This is due to a technical restriction in Vim. Moving the cursor, or issuing
the :YcmForceCompileAndDiagnostics command will refresh the diagnostics.
Repeated invocations of the FixIt command on a given line, however, do apply
all diagnostics as expected without requiring refreshing of the diagnostics UI.
This is particularly useful where there are multiple diagnostics on one line, or
where after fixing one diagnostic, another fix-it is available. Supported in filetypes: c, cpp, objc, objcpp, cs",3
https://github.com/memorywarning/YouCompleteMe,#### The `RefactorRename <new name>` subcommand,"  In supported file types, this command attempts to perform a semantic rename of
the identifier under the cursor. This includes renaming declarations,
definitions and usages of the identifier, or any other language-appropriate
action. The specific behavior is defined by the semantic engine in use. Similar to FixIt, this command applies automatic modifications to your source
files. Rename operations may involve changes to multiple files, which may or may
not be open in Vim buffers at the time. YouCompleteMe handles all of this for
you. The behavior is described in the following section. Supported in filetypes: javascript (variables only)",3
https://github.com/memorywarning/YouCompleteMe,#### Multi-file Refactor,"  When a Refactor or FixIt command touches multiple files, YouCompleteMe attempts
to apply those modifications to any existing open, visible buffer in the current
tab. If no such buffer can be found, YouCompleteMe opens the file in a new
small horizontal split at the top of the current window, applies the change,
and then hides the window. NOTE: The buffer remains open, and must be
manually saved. A confirmation dialog is opened prior to doing this to remind
you that this is about to happen. Once the modifications have been made, the quickfix list (see :help quickfix)
is opened and populated with the locations of all modifications. This can be
used to review all automatic changes made. Typically, use the CTRL-W <enter> combination to open the selected file in a new split. The buffers are not saved automatically. That is, you must save the modified
buffers manually after reviewing the changes from the quickfix list. Changes
can be undone using Vim's powerful undo features (see :help undo). Note
that Vim's undo is per-buffer, so to undo all changes, the undo commands must
be applied in each modified buffer separately. NOTE: While applying modifications, Vim may find files which are already open
and have a swap file. The command is aborted if you select Abort or Quit in any
such prompts. This leaves the Refactor operation partially complete and must be
manually corrected using Vim's undo features. The quickfix list is not
populated in this case. Inspect :buffers or equivalent (see :help buffers)
to see the buffers that were opened by the command.",3
https://github.com/memorywarning/YouCompleteMe,### Miscellaneous Commands,"  These commands are for general administration, rather than IDE-like features.
They cover things like the semantic engine server instance and compilation
flags.",3
https://github.com/memorywarning/YouCompleteMe,#### The `ClearCompilationFlagCache` subcommand,"  YCM caches the flags it gets from the FlagsForFile function in your
ycm_extra_conf.py file if you return them with the do_cache parameter set to
True. The cache is in memory and is never invalidated (unless you restart Vim
of course). This command clears that cache entirely. YCM will then re-query your
FlagsForFile function as needed in the future. Supported in filetypes: c, cpp, objc, objcpp",3
https://github.com/memorywarning/YouCompleteMe,#### The `StartServer` subcommand,"  Starts the semantic-engine-as-localhost-server for those semantic engines that
work as separate servers that YCM talks to. Supported in filetypes: cs, go, javascript, rust",3
https://github.com/memorywarning/YouCompleteMe,#### The `StopServer` subcommand,"  Stops the semantic-engine-as-localhost-server for those semantic engines that
work as separate servers that YCM talks to. Supported in filetypes: cs, go, javascript, rust",3
https://github.com/memorywarning/YouCompleteMe,#### The `RestartServer` subcommand,"  Restarts the semantic-engine-as-localhost-server for those semantic engines that
work as separate servers that YCM talks to. An additional optional argument may be supplied for Python, specifying the
python binary to use to restart the Python semantic engine. :YcmCompleter RestartServer /usr/bin/python3.4 Supported in filetypes: cs, python, rust",3
https://github.com/memorywarning/YouCompleteMe,#### The `ReloadSolution` subcommand,"  Instruct the Omnisharp server to clear its cache and reload all files from disk.
This is useful when files are added, removed, or renamed in the solution, files
are changed outside of Vim, or whenever Omnisharp cache is out-of-sync. Supported in filetypes: cs",3
https://github.com/memorywarning/YouCompleteMe,## Functions, ,3
https://github.com/memorywarning/YouCompleteMe,### The `youcompleteme#GetErrorCount` function,"  Get the number of YCM Diagnostic errors. If no errors are present, this function
returns 0. For example:   call youcompleteme#GetErrorCount() Both this function and youcompleteme#GetWarningCount can be useful when
integrating YCM with other Vim plugins. For example, a lightline user could
add a diagnostics section to their statusline which would display the number of
errors and warnings.",3
https://github.com/memorywarning/YouCompleteMe,### The `youcompleteme#GetWarningCount` function,"  Get the number of YCM Diagnostic warnings. If no warnings are present, this
function returns 0. For example:   call youcompleteme#GetWarningCount()",3
https://github.com/memorywarning/YouCompleteMe,## Options,"  All options have reasonable defaults so if the plug-in works after installation
you don't need to change any options. These options can be configured in your
vimrc script by including a line like this: let g:ycm_min_num_of_chars_for_completion = 1 Note that after changing an option in your [vimrc script] vimrc you have to
restart Vim for the changes to take effect.",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_min_num_of_chars_for_completion` option,"  This option controls the number of characters the user needs to type before
identifier-based completion suggestions are triggered. For example, if the
option is set to 2, then when the user types a second alphanumeric character
after a whitespace character, completion suggestions will be triggered. This
option is NOT used for semantic completion. Setting this option to a high number like 99 effectively turns off the
identifier completion engine and just leaves the semantic engine. Default: 2 let g:ycm_min_num_of_chars_for_completion = 2",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_min_num_identifier_candidate_chars` option,"  This option controls the minimum number of characters that a completion
candidate coming from the identifier completer must have to be shown in the
popup menu. A special value of 0 means there is no limit. NOTE: This option only applies to the identifier completer; it has no effect on
the various semantic completers. Default: 0 let g:ycm_min_num_identifier_candidate_chars = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_auto_trigger` option,"  When set to 0, this option turns off YCM's identifier completer (the
as-you-type popup) and the semantic triggers (the popup you'd get after typing
. or -> in say C++). You can still force semantic completion with the
<C-Space> shortcut. If you want to just turn off the identifier completer but keep the semantic
triggers, you should set g:ycm_min_num_of_chars_for_completion to a high
number like 99. Default: 1 let g:ycm_auto_trigger = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_filetype_whitelist` option,"  This option controls for which Vim filetypes (see :h filetype) should YCM be
turned on. The option value should be a Vim dictionary with keys being filetype
strings (like python, cpp etc) and values being unimportant (the dictionary
is used like a hash set, meaning that only the keys matter). The * key is special and matches all filetypes. By default, the whitelist
contains only this * key. YCM also has a g:ycm_filetype_blacklist option that lists filetypes for which
YCM shouldn't be turned on. YCM will work only in filetypes that both the
whitelist and the blacklist allow (the blacklist ""allows"" a filetype by not
having it as a key). For example, let's assume you want YCM to work in files with the cpp filetype.
The filetype should then be present in the whitelist either directly (cpp key
in the whitelist) or indirectly through the special * key. It should not be
present in the blacklist. Filetypes that are blocked by the either of the lists will be completely ignored
by YCM, meaning that neither the identifier-based completion engine nor the
semantic engine will operate in them. You can get the filetype of the current file in Vim with :set ft?. Default: {'*' : 1} let g:ycm_filetype_whitelist = { '*': 1 }",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_filetype_blacklist` option,"  This option controls for which Vim filetypes (see :h filetype) should YCM be
turned off. The option value should be a Vim dictionary with keys being filetype
strings (like python, cpp etc) and values being unimportant (the dictionary
is used like a hash set, meaning that only the keys matter). See the g:ycm_filetype_whitelist option for more details on how this works. Default: [see next line] let g:ycm_filetype_blacklist = {
      \ 'tagbar' : 1,
      \ 'qf' : 1,
      \ 'notes' : 1,
      \ 'markdown' : 1,
      \ 'unite' : 1,
      \ 'text' : 1,
      \ 'vimwiki' : 1,
      \ 'pandoc' : 1,
      \ 'infolog' : 1,
      \ 'mail' : 1
      \}",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_filetype_specific_completion_to_disable` option,"  This option controls for which Vim filetypes (see :h filetype) should the YCM
semantic completion engine be turned off. The option value should be a Vim
dictionary with keys being filetype strings (like python, cpp etc) and
values being unimportant (the dictionary is used like a hash set, meaning that
only the keys matter). The listed filetypes will be ignored by the YCM semantic
completion engine, but the identifier-based completion engine will still trigger
in files of those filetypes. Note that even if semantic completion is not turned off for a specific filetype,
you will not get semantic completion if the semantic engine does not support
that filetype. You can get the filetype of the current file in Vim with :set ft?. Default: [see next line] let g:ycm_filetype_specific_completion_to_disable = {
      \ 'gitcommit': 1
      \}",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_show_diagnostics_ui` option,"  When set, this option turns on YCM's diagnostic display features. See the
Diagnostic display section in the User Manual for more details. Specific parts of the diagnostics UI (like the gutter signs, text highlighting,
diagnostic echo and auto location list population) can be individually turned on
or off. See the other options below for details. Note that YCM's diagnostics UI is only supported for C-family languages. When set, this option also makes YCM remove all Syntastic checkers set for the
c, cpp, objc and objcpp filetypes since this would conflict with YCM's
own diagnostics UI. If you're using YCM's identifier completer in C-family languages but cannot use
the clang-based semantic completer for those languages and want to use the GCC
Syntastic checkers, unset this option. Default: 1 let g:ycm_show_diagnostics_ui = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_error_symbol` option,"  YCM will use the value of this option as the symbol for errors in the Vim
gutter. This option is part of the Syntastic compatibility layer; if the option is not
set, YCM will fall back to the value of the g:syntastic_error_symbol option
before using this option's default. Default: >> let g:ycm_error_symbol = '>>'",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_warning_symbol` option,"  YCM will use the value of this option as the symbol for warnings in the Vim
gutter. This option is part of the Syntastic compatibility layer; if the option is not
set, YCM will fall back to the value of the g:syntastic_warning_symbol option
before using this option's default. Default: >> let g:ycm_warning_symbol = '>>'",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_enable_diagnostic_signs` option,"  When this option is set, YCM will put icons in Vim's gutter on lines that have a
diagnostic set. Turning this off will also turn off the YcmErrorLine and
YcmWarningLine highlighting. This option is part of the Syntastic compatibility layer; if the option is not
set, YCM will fall back to the value of the g:syntastic_enable_signs option
before using this option's default. Default: 1 let g:ycm_enable_diagnostic_signs = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_enable_diagnostic_highlighting` option,"  When this option is set, YCM will highlight regions of text that are related to
the diagnostic that is present on a line, if any. This option is part of the Syntastic compatibility layer; if the option is not
set, YCM will fall back to the value of the g:syntastic_enable_highlighting
option before using this option's default. Default: 1 let g:ycm_enable_diagnostic_highlighting = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_echo_current_diagnostic` option,"  When this option is set, YCM will echo the text of the diagnostic present on the
current line when you move your cursor to that line. If a FixIt is available
for the current diagnostic, then  (FixIt) is appended. This option is part of the Syntastic compatibility layer; if the option is not
set, YCM will fall back to the value of the g:syntastic_echo_current_error
option before using this option's default. Default: 1 let g:ycm_echo_current_diagnostic = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_always_populate_location_list` option,"  When this option is set, YCM will populate the location list automatically every
time it gets new diagnostic data. This option is off by default so as not to
interfere with other data you might have placed in the location list. See :help location-list in Vim to learn more about the location list. This option is part of the Syntastic compatibility layer; if the option is not
set, YCM will fall back to the value of the
g:syntastic_always_populate_loc_list option before using this option's
default. Default: 0 let g:ycm_always_populate_location_list = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_open_loclist_on_ycm_diags` option,"  When this option is set, :YcmDiags will automatically open the location list
after forcing a compilation and filling the list with diagnostic data. See :help location-list in Vim to learn more about the location list. Default: 1 let g:ycm_open_loclist_on_ycm_diags = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_allow_changing_updatetime` option,"  When this option is set to 1, YCM will change the updatetime Vim option to
2000 (see :h updatetime). This may conflict with some other plugins you have
(but it's unlikely). The updatetime option is the number of milliseconds that
have to pass before Vim's CursorHold (see :h CursorHold) event fires. YCM
runs the completion engines' ""file comprehension"" systems in the background on
every such event; the identifier-based engine collects the identifiers whereas
the semantic engine compiles the file to build an AST. The Vim default of 4000 for updatetime is a bit long, so YCM reduces
this. Set this option to 0 to force YCM to leave your updatetime setting
alone. Default: 1 let g:ycm_allow_changing_updatetime = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_complete_in_comments` option,"  When this option is set to 1, YCM will show the completion menu even when
typing inside comments. Default: 0 let g:ycm_complete_in_comments = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_complete_in_strings` option,"  When this option is set to 1, YCM will show the completion menu even when
typing inside strings. Note that this is turned on by default so that you can use the filename
completion inside strings. This is very useful for instance in C-family files
where typing #include "" will trigger the start of filename completion. If you
turn off this option, you will turn off filename completion in such situations
as well. Default: 1 let g:ycm_complete_in_strings = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_collect_identifiers_from_comments_and_strings` option,"  When this option is set to 1, YCM's identifier completer will also collect
identifiers from strings and comments. Otherwise, the text in comments and
strings will be ignored. Default: 0 let g:ycm_collect_identifiers_from_comments_and_strings = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_collect_identifiers_from_tags_files` option,"  When this option is set to 1, YCM's identifier completer will also collect
identifiers from tags files. The list of tags files to examine is retrieved from
the tagfiles() Vim function which examines the tags Vim option. See :h 'tags' for details. YCM will re-index your tags files if it detects that they have been modified. The only supported tag format is the Exuberant Ctags format. The
format from ""plain"" ctags is NOT supported. Ctags needs to be called with the
--fields=+l option (that's a lowercase L, not a one) because YCM needs the
language:<lang> field in the tags output. See the FAQ for pointers if YCM does not appear to read your tag files. This option is off by default because it makes Vim slower if your tags are on a
network directory. Default: 0 let g:ycm_collect_identifiers_from_tags_files = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_seed_identifiers_with_syntax` option,"  When this option is set to 1, YCM's identifier completer will seed its
identifier database with the keywords of the programming language you're
writing. Since the keywords are extracted from the Vim syntax file for the filetype, all
keywords may not be collected, depending on how the syntax file was written.
Usually at least 95% of the keywords are successfully extracted. Default: 0 let g:ycm_seed_identifiers_with_syntax = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_extra_conf_vim_data` option,"  If you're using semantic completion for C-family files, this option might come
handy; it's a way of sending data from Vim to your FlagsForFile function in
your .ycm_extra_conf.py file. This option is supposed to be a list of VimScript expression strings that are
evaluated for every request to the ycmd server and then passed to your
FlagsForFile function as a client_data keyword argument. For instance, if you set this option to ['v:version'], your FlagsForFile
function will be called like this: # The '704' value is of course contingent on Vim 7.4; in 7.3 it would be '703'
FlagsForFile(filename, client_data = {'v:version': 704}) So the client_data parameter is a dictionary mapping Vim expression strings to
their values at the time of the request. The correct way to define parameters for your FlagsForFile function: def FlagsForFile(filename, **kwargs): You can then get to client_data with kwargs['client_data']. Default: [] let g:ycm_extra_conf_vim_data = []",3
https://github.com/memorywarning/YouCompleteMe,# The '704' value is of course contingent on Vim 7.4; in 7.3 it would be '703',"  YCM will by default search for an appropriate Python interpreter on your system.
You can use this option to override that behavior and force the use of a
specific interpreter of your choosing. NOTE: This interpreter is only used for the ycmd server. The YCM client
running inside Vim always uses the Python interpreter that's embedded inside
Vim. Default: '' let g:ycm_server_python_interpreter = ''",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_server_python_interpreter` option,"  When this option is set to 1, the ycmd completion server will keep the
logfiles around after shutting down (they are deleted on shutdown by default). To see where the logfiles are, call :YcmDebugInfo. Default: 0 let g:ycm_server_keep_logfiles = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_server_keep_logfiles` option,"  The logging level that the ycmd completion server uses. Valid values are
the following, from most verbose to least verbose: 
debug
info
warning
error
critical
 Note that debug is very verbose. Default: info let g:ycm_server_log_level = 'info'",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_server_log_level` option,"  When set to 1, the OmniSharp server will be automatically started (once per
Vim session) when you open a C# file. Default: 1 let g:ycm_auto_start_csharp_server = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_auto_start_csharp_server` option,"  When set to 1, the OmniSharp server will be automatically stopped upon
closing Vim. Default: 1 let g:ycm_auto_stop_csharp_server = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_auto_stop_csharp_server` option,"  When g:ycm_auto_start_csharp_server is set to 1, specifies the port for
the OmniSharp server to listen on. When set to 0 uses an unused port provided
by the OS. Default: 0 let g:ycm_csharp_server_port = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_csharp_server_port` option,"  By default, when YCM inserts a namespace, it will insert the using statement
under the nearest using statement. You may prefer that the using statement is
inserted somewhere, for example, to preserve sorting. If so, you can set this
option to override this behavior. When this option is set, instead of inserting the using statement itself, YCM
will set the global variable g:ycm_namespace_to_insert to the namespace to
insert, and then evaluate this option's value as an expression. The option's
expression is responsible for inserting the namespace - the default insertion
will not occur. Default: '' let g:ycm_csharp_insert_namespace_expr = ''",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_csharp_insert_namespace_expr` option,"  When this option is set to 1, YCM will add the preview string to Vim's
completeopt option (see :h completeopt). If your completeopt option
already has preview set, there will be no effect. You can see the current
state of your completeopt setting with :set completeopt? (yes, the question
mark is important). When preview is present in completeopt, YCM will use the preview window at
the top of the file to store detailed information about the current completion
candidate (but only if the candidate came from the semantic engine). For
instance, it would show the full function prototype and all the function
overloads in the window if the current completion is a function name. Default: 0 let g:ycm_add_preview_to_completeopt = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_add_preview_to_completeopt` option,"  When this option is set to 1, YCM will auto-close the preview window after
the user accepts the offered completion string. If there is no preview window
triggered because there is no preview string in completeopt, this option is
irrelevant. See the g:ycm_add_preview_to_completeopt option for more details. Default: 0 let g:ycm_autoclose_preview_window_after_completion = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_autoclose_preview_window_after_completion` option,"  When this option is set to 1, YCM will auto-close the preview window after
the user leaves insert mode. This option is irrelevant if
g:ycm_autoclose_preview_window_after_completion is set or if no preview
window is triggered. See the g:ycm_add_preview_to_completeopt option for more
details. Default: 0 let g:ycm_autoclose_preview_window_after_insertion = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_autoclose_preview_window_after_insertion` option,"  This option controls the maximum number of diagnostics shown to the user when
errors or warnings are detected in the file. This option is only relevant if you
are using the C-family semantic completion engine. Default: 30 let g:ycm_max_diagnostics_to_display = 30",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_max_diagnostics_to_display` option,"  This option controls the key mappings used to select the first completion
string.  Invoking any of them repeatedly cycles forward through the completion
list. Some users like adding <Enter> to this list. Default: ['<TAB>', '<Down>'] let g:ycm_key_list_select_completion = ['<TAB>', '<Down>']",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_key_list_select_completion` option,"  This option controls the key mappings used to select the previous completion
string. Invoking any of them repeatedly cycles backwards through the completion
list. Note that one of the defaults is <S-TAB> which means Shift-TAB. That mapping
will probably only work in GUI Vim (Gvim or MacVim) and not in plain console Vim
because the terminal usually does not forward modifier key combinations to Vim. Default: ['<S-TAB>', '<Up>'] let g:ycm_key_list_previous_completion = ['<S-TAB>', '<Up>']",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_key_list_previous_completion` option,"  This option controls the key mapping used to invoke the completion menu for
semantic completion. By default, semantic completion is trigged automatically
after typing ., -> and :: in insert mode (if semantic completion support
has been compiled in). This key mapping can be used to trigger semantic
completion anywhere. Useful for searching for top-level functions and classes. Console Vim (not Gvim or MacVim) passes <Nul> to Vim when the user types
<C-Space> so YCM will make sure that <Nul> is used in the map command when
you're editing in console Vim, and <C-Space> in GUI Vim. This means that you
can just press <C-Space> in both console and GUI Vim and YCM will do the right
thing. Setting this option to an empty string will make sure no mapping is created. Default: <C-Space> let g:ycm_key_invoke_completion = '<C-Space>'",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_key_invoke_completion` option,"  This option controls the key mapping used to show the full diagnostic text when
the user's cursor is on the line with the diagnostic. It basically calls
:YcmShowDetailedDiagnostic. Setting this option to an empty string will make sure no mapping is created. Default: <leader>d let g:ycm_key_detailed_diagnostics = '<leader>d'",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_key_detailed_diagnostics` option,"  Normally, YCM searches for a .ycm_extra_conf.py file for compilation flags
(see the User Guide for more details on how this works). This option specifies
a fallback path to a config file which is used if no .ycm_extra_conf.py is
found. You can place such a global file anywhere in your filesystem. Default: '' let g:ycm_global_ycm_extra_conf = ''",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_global_ycm_extra_conf` option,"  When this option is set to 1 YCM will ask once per .ycm_extra_conf.py file
if it is safe to be loaded. This is to prevent execution of malicious code
from a .ycm_extra_conf.py file you didn't write. To selectively get YCM to ask/not ask about loading certain .ycm_extra_conf.py
files, see the g:ycm_extra_conf_globlist option. Default: 1 let g:ycm_confirm_extra_conf = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_confirm_extra_conf` option,"  This option is a list that may contain several globbing patterns. If a pattern
starts with a ! all .ycm_extra_conf.py files matching that pattern will be
blacklisted, that is they won't be loaded and no confirmation dialog will be
shown. If a pattern does not start with a ! all files matching that pattern
will be whitelisted. Note that this option is not used when confirmation is
disabled using g:ycm_confirm_extra_conf and that items earlier in the list
will take precedence over the later ones. Rules: 
*       matches everything
?       matches any single character
[seq]   matches any character in seq
[!seq]  matches any char not in seq
 Example: let g:ycm_extra_conf_globlist = ['~/dev/*','!~/*'] 
The first rule will match everything contained in the ~/dev directory so
.ycm_extra_conf.py files from there will be loaded.
The second rule will match everything in the home directory so a
.ycm_extra_conf.py file from there won't be loaded.
As the first rule takes precedence everything in the home directory excluding
the ~/dev directory will be blacklisted.
 NOTE: The glob pattern is first expanded with Python's os.path.expanduser()
and then resolved with os.path.abspath() before being matched against the
filename. Default: [] let g:ycm_extra_conf_globlist = []",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_extra_conf_globlist` option,"  By default, YCM's filepath completion will interpret relative paths like ../
as being relative to the folder of the file of the currently active buffer.
Setting this option will force YCM to always interpret relative paths as being
relative to Vim's current working directory. Default: 0 let g:ycm_filepath_completion_use_working_dir = 0",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_filepath_completion_use_working_dir` option,"  This option controls the character-based triggers for the various semantic
completion engines. The option holds a dictionary of key-values, where the keys
are Vim's filetype strings delimited by commas and values are lists of strings,
where the strings are the triggers. Setting key-value pairs on the dictionary adds semantic triggers to the
internal default set (listed below). You cannot remove the default triggers,
only add new ones. A ""trigger"" is a sequence of one or more characters that trigger semantic
completion when typed. For instance, C++ (cpp filetype) has . listed as a
trigger. So when the user types foo., the semantic engine will trigger and
serve foo's list of member functions and variables. Since C++ also has ->
listed as a trigger, the same thing would happen when the user typed foo->. It's also possible to use a regular expression as a trigger. You have to prefix
your trigger with re! to signify it's a regex trigger. For instance,
re!\w+\. would only trigger after the \w+\. regex matches. NOTE: The regex syntax is NOT Vim's, it's Python's. Default: [see next line] let g:ycm_semantic_triggers =  {
  \   'c' : ['->', '.'],
  \   'objc' : ['->', '.', 're!\[[_a-zA-Z]+\w*\s', 're!^\s*[^\W\d]\w*\s',
  \             're!\[.*\]\s'],
  \   'ocaml' : ['.', '#'],
  \   'cpp,objcpp' : ['->', '.', '::'],
  \   'perl' : ['->'],
  \   'php' : ['->', '::'],
  \   'cs,java,javascript,typescript,d,python,perl6,scala,vb,elixir,go' : ['.'],
  \   'ruby' : ['.', '::'],
  \   'lua' : ['.', ':'],
  \   'erlang' : [':'],
  \ }",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_semantic_triggers` option,"  Some omnicompletion engines do not work well with the YCM cache—in particular,
they might not produce all possible results for a given prefix. By unsetting
this option you can ensure that the omnicompletion engine is re-queried on every
keypress. That will ensure all completions will be presented, but might cause
stuttering and lagginess if the omnifunc is slow. Default: 1 let g:ycm_cache_omnifunc = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_cache_omnifunc` option,"  By default, YCM will query the UltiSnips plugin for possible completions of
snippet triggers. This option can turn that behavior off. Default: 1 let g:ycm_use_ultisnips_completer = 1",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_use_ultisnips_completer` option,"  Defines where GoTo* commands result should be opened.
Can take one of the following values:
[ 'same-buffer', 'horizontal-split', 'vertical-split', 'new-tab', 'new-or-existing-tab' ]
If this option is set to the 'same-buffer' but current buffer can not
be switched (when buffer is modified and nohidden option is set),
then result will be opened in horizontal split. Default: 'same-buffer' let g:ycm_goto_buffer_command = 'same-buffer'",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_goto_buffer_command` option,"  Defines the max size (in Kb) for a file to be considered for completion. If this
option is set to 0 then no check is made on the size of the file you're opening. Default: 1000 let g:ycm_disable_for_files_larger_than_kb = 1000",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_disable_for_files_larger_than_kb` option,"  This option specifies the Python interpreter to use to run the jedi
completion library.  Specify the Python interpreter to use to get completions.
By default the Python under which ycmd runs is used (ycmd runs on
Python 2.6, 2.7 or 3.3+). Default: '' let g:ycm_python_binary_path = '/usr/bin/python3'",3
https://github.com/memorywarning/YouCompleteMe,### The `g:ycm_python_binary_path` option, ,3
https://github.com/memorywarning/YouCompleteMe,## FAQ,,6
https://github.com/memorywarning/YouCompleteMe,"### I used to be able to `import vim` in `.ycm_extra_conf.py`, but now can't","  YCM was rewritten to use a client-server architecture where most of the logic is
in the ycmd server. So the magic vim module you could have previously
imported in your .ycm_extra_conf.py files doesn't exist anymore. To be fair, importing the magic vim module in extra conf files was never
supported in the first place; it only ever worked by accident and was never a
part of the extra conf API. But fear not, you should be able to tweak your extra conf files to continue
working by using the g:ycm_extra_conf_vim_data option. See the docs on that
option for details.",6
https://github.com/memorywarning/YouCompleteMe,### On very rare occasions Vim crashes when I tab through the completion menu,"  That's a very rare Vim bug most users never encounter. It's fixed in Vim
7.4.72. Update to that version (or above) to resolve the issue.",6
https://github.com/memorywarning/YouCompleteMe,### I get `ImportError` exceptions that mention `PyInit_ycm_core` or `initycm_core`,"  These errors are caused by building the YCM native libraries for Python 2 and
trying to load them into a Python 3 process (or the other way around). For instance, if building for Python 2 but loading in Python 3: ImportError: dynamic module does not define init function (PyInit_ycm_core)
 If building for Python 3 but loading in Python 2: ImportError: dynamic module does not define init function (initycm_core)
 Setting the g:ycm_server_python_interpreter option to force the use of a
specific Python interpreter for ycmd is usually the easiest way to solve the
problem. Common values for that option are /usr/bin/python and
/usr/bin/python3.",6
https://github.com/memorywarning/YouCompleteMe,### I get a linker warning regarding `libpython` on Mac when compiling YCM,"  If the warning is ld: warning: path '/usr/lib/libpython2.7.dylib' following -L not a directory, then feel free to ignore it; it's caused by a limitation of
CMake and is not an issue. Everything should still work fine.",6
https://github.com/memorywarning/YouCompleteMe,### I get a weird window at the top of my file when I use the semantic engine,"  This is Vim's preview window. Vim uses it to show you extra information about
something if such information is available. YCM provides Vim with such extra
information. For instance, when you select a function in the completion list,
the preview window will hold that function's prototype and the prototypes of
any overloads of the function. It will stay there after you select the
completion so that you can use the information about the parameters and their
types to write the function call. If you would like this window to auto-close after you select a completion
string, set the g:ycm_autoclose_preview_window_after_completion option to 1
in your vimrc file. Similarly, the g:ycm_autoclose_preview_window_after_insertion
option can be set to close the preview window after leaving insert mode. If you don't want this window to ever show up, add set completeopt-=preview to
your vimrc. Also make sure that the g:ycm_add_preview_to_completeopt option
is set to 0.",6
https://github.com/memorywarning/YouCompleteMe,### It appears that YCM is not working,"  In Vim, run :messages and carefully read the output. YCM will echo messages to
the message log if it encounters problems. It's likely you misconfigured
something and YCM is complaining about it. Also, you may want to run the :YcmDebugInfo command; it will make YCM spew out
various debugging information, including the ycmd logfile paths and the
compile flags for the current file if the file is a C-family language file and
you have compiled in Clang support. Logfiles can be automatically opened in the
editor using the :YcmToggleLogs command.",6
https://github.com/memorywarning/YouCompleteMe,### Sometimes it takes much longer to get semantic completions than normal,"  This means that libclang (which YCM uses for C-family semantic completion)
failed to pre-compile your file's preamble. In other words, there was an error
compiling some of the source code you pulled in through your header files. I
suggest calling the :YcmDiags command to see what they were. Bottom line, if libclang can't pre-compile your file's preamble because there
were errors in it, you're going to get slow completions because there's no AST
cache.",6
https://github.com/memorywarning/YouCompleteMe,### YCM auto-inserts completion strings I don't want!,"  This means you probably have some mappings that interfere with YCM's internal
ones. Make sure you don't have something mapped to <C-p>, <C-x> or <C-u>
(in insert mode). YCM never selects something for you; it just shows you a menu and the user has
to explicitly select something. If something is being selected automatically,
this means there's a bug or a misconfiguration somewhere.",6
https://github.com/memorywarning/YouCompleteMe,### I get a `E227: mapping already exists for <blah>` error when I start Vim,"  This means that YCM tried to set up a key mapping but failed because you already
had something mapped to that key combination. The <blah> part of the message
will tell you what was the key combination that failed. Look in the Options section and see if any of the default mappings conflict
with your own. Then change that option value to something else so that the
conflict goes away.",6
https://github.com/memorywarning/YouCompleteMe,### I get `'GLIBC_2.XX' not found (required by libclang.so)` when starting Vim,"  Your system is too old for the precompiled binaries from llvm.org. Compile
Clang on your machine and then link against the libclang.so you just produced.
See the full installation guide for help.",6
https://github.com/memorywarning/YouCompleteMe,### I'm trying to use a Homebrew Vim with YCM and I'm getting segfaults,"  Something (I don't know what) is wrong with the way that Homebrew configures and
builds Vim. I recommend using MacVim. Even if you don't like the MacVim GUI,
you can use the Vim binary that is inside the MacVim.app package (it's
MacVim.app/Contents/MacOS/Vim) and get the Vim console experience.",6
https://github.com/memorywarning/YouCompleteMe,### I have a Homebrew Python and/or MacVim; can't compile/SIGABRT when starting,"  You should probably run brew rm python; brew install python to get the latest
fixes that should make YCM work with such a configuration. Also rebuild Macvim
then. If you still get problems with this, see issue #18 for
suggestions.",6
https://github.com/memorywarning/YouCompleteMe,### Vim segfaults when I use the semantic completer in Ruby files,"  This was caused by a Vim bug. Update your version of Vim (Vim 7.3.874 is known
to work, earlier versions may also fix this issue).",6
https://github.com/memorywarning/YouCompleteMe,### I get `LONG_BIT definition appears wrong for platform` when compiling,"  Look at the output of your CMake call. There should be a line in it like the
following (with .dylib in place of .so on a Mac): -- Found PythonLibs: /usr/lib/libpython2.7.so (Required is at least version ""2.5"")
 That would be the correct output. An example of incorrect output would
be the following: -- Found PythonLibs: /usr/lib/libpython2.7.so (found suitable version ""2.5.1"", minimum required is ""2.5"")
 Notice how there's an extra bit of output there, the found suitable version ""<version>"" part, where <version> is not the same as the version of the
dynamic library. In the example shown, the library is version 2.7 but the second
string is version 2.5.1. This means that CMake found one version of Python headers and a different
version for the library. This is wrong. It can happen when you have multiple
versions of Python installed on your machine. You should probably add the following flags to your cmake call (again, dylib
instead of so on a Mac): -DPYTHON_INCLUDE_DIR=/usr/include/python2.7 -DPYTHON_LIBRARY=/usr/lib/libpython2.7.so
 This will force the paths to the Python include directory and the Python library
to use. You may need to set these flags to something else, but you need to make
sure you use the same version of Python that your Vim binary is built against,
which is highly likely to be the system's default Python.",6
https://github.com/memorywarning/YouCompleteMe,### I get `libpython2.7.a [...] relocation R_X86_64_32` when compiling,"  The error is usually encountered when compiling YCM on Centos or RHEL. The full
error looks something like the following: /usr/bin/ld: /usr/local/lib/libpython2.7.a(abstract.o): relocation R_X86_64_32 against `a local symbol' can not be used when making a shared object; recompile with -fPIC
 It's possible to get a slightly different error that's similar to the one above.
Here's the problem and how you solve it: Your libpython2.7.a was not compiled with -fPIC so it can't be linked into
ycm_core.so.  Use the -DPYTHON_LIBRARY= CMake flag to point it to a .so
version of libpython on your machine (for instance,
-DPYTHON_LIBRARY=/usr/lib/libpython2.7.so). Naturally, this means you'll have
to go through the full installation guide by hand.",6
https://github.com/memorywarning/YouCompleteMe,### I get `Vim: Caught deadly signal SEGV` on Vim startup,"  This can happen on some Linux distros. If you encounter this situation, run Vim
under gdb. You'll probably see something like this in the output when Vim
crashes: undefined symbol: clang_CompileCommands_dispose
 This means that Vim is trying to load a libclang.so that is too old. You need
at least a 3.2 libclang. Some distros ship with a system libclang.so that
identifies itself as 3.2 but is not; it was cut from the upstream sources before
the official 3.2 release and some API changes (like the addition of the
CompileCommands API) were added after their cut. So just go through the installation guide and make sure you are using a correct
libclang.so. I recommend downloading prebuilt binaries from llvm.org.",6
https://github.com/memorywarning/YouCompleteMe,### I get `Fatal Python error: PyThreadState_Get: no current thread` on startup,"  This is caused by linking a static version of libpython into ycmd's
ycm_core.so.  This leads to multiple copies of the python interpreter loaded
when python loads ycmd_core.so and this messes up python's global state.
The details aren't important. The solution is that the version of Python linked and run against must be built
with either --enable-shared or --enable-framework (on OS X).
This is achieved as follows (NOTE: for Mac, replace --enable-shared
with --enable-framework): 
When building python from source: ./configure --enable-shared {options}
When building python from pyenv:
PYTHON_CONFIGURE_OPTS=""--enable-shared"" pyenv install {version}
",6
https://github.com/memorywarning/YouCompleteMe,## `install.py` says python must be compiled with `--enable-framework`. Wat?,"  See the previous answer for how to ensure your python is built to support
dynamic modules.",6
https://github.com/memorywarning/YouCompleteMe,### YCM does not read identifiers from my tags files,"  First, put let g:ycm_collect_identifiers_from_tags_files = 1 in your vimrc. Make sure you are using Exuberant Ctags to produce your tags
files since the only supported tag format is the Exuberant Ctags
format. The format from ""plain"" ctags is NOT supported. The
output of ctags --version should list ""Exuberant Ctags"". Ctags needs to be called with the --fields=+l (that's a lowercase L, not a
one) option because YCM needs the language:<lang> field in the tags output. NOTE: Exuberant Ctags by default sets language tag for *.h
files as C++. If you have C (not C++) project, consider
giving parameter --langmap=c:.c.h to ctags to see tags from *.h files. NOTE: Mac OS X comes with ""plain"" ctags installed by default. brew install ctags will get you the Exuberant Ctags version. Also make sure that your Vim tags option is set correctly. See :h 'tags' for
details. If you want to see which tag files YCM will read for a given buffer,
run :echo tagfiles() with the relevant buffer active. Note that that function
will only list tag files that already exist.",6
https://github.com/memorywarning/YouCompleteMe,### `CTRL-U` in insert mode does not work,"  YCM keeps you in a completefunc completion mode when you're typing in insert
mode and Vim disables <C-U> in completion mode as a ""feature."" Sadly there's
nothing I can do about this.",6
https://github.com/memorywarning/YouCompleteMe,### YCM conflicts with UltiSnips TAB key usage,"  YCM comes with support for UltiSnips (snippet suggestions in the popup menu),
but you'll have to change the UltiSnips mappings. See :h UltiSnips-triggers in
Vim for details. You'll probably want to change some/all of the following
options: g:UltiSnipsExpandTrigger
g:UltiSnipsJumpForwardTrigger
g:UltiSnipsJumpBackwardTrigger",6
https://github.com/memorywarning/YouCompleteMe,"### Why isn't YCM just written in plain VimScript, FFS?","  Because of the identifier completion engine and subsequence-based filtering.
Let's say you have many dozens of files open in a single Vim instance (I often
do); the identifier-based engine then needs to store thousands (if not tens of
thousands) of identifiers in its internal data-structures. When the user types,
YCM needs to perform subsequence-based filtering on all of those identifiers
(every single one!) in less than 10 milliseconds. I'm sorry, but that level of performance is just plain impossible to achieve
with VimScript. I've tried, and the language is just too slow. No, you can't get
acceptable performance even if you limit yourself to just the identifiers in the
current file and simple prefix-based filtering.",6
https://github.com/memorywarning/YouCompleteMe,### Why does YCM demand such a recent version of Vim?,"  During YCM's development several show-stopper bugs were encountered in Vim.
Those needed to be fixed upstream (and were). A few months after those bugs were
fixed, Vim trunk landed the pyeval() function which improved YCM performance
even more since less time was spent serializing and deserializing data between
Vim and the embedded Python interpreter. A few critical bugfixes for pyeval()
landed in Vim 7.3.584 (and a few commits before that).",6
https://github.com/memorywarning/YouCompleteMe,### I get annoying messages in Vim's status area when I type,"  If you're referring to the User defined completion <bla bla> back at original
and similar, then just update to Vim 7.4.314 (or later) and they'll go away.",6
https://github.com/memorywarning/YouCompleteMe,### Nasty bugs happen if I have the `vim-autoclose` plugin installed,"  Use the delimitMate plugin instead. It does the same thing without
conflicting with YCM.",6
https://github.com/memorywarning/YouCompleteMe,### Is there some sort of YCM mailing list? I have questions,"  If you have questions about the plugin or need help, please use the
ycm-users mailing list, don't create issues on the tracker. The tracker is
for bug reports and feature requests.",6
https://github.com/memorywarning/YouCompleteMe,### I get an internal compiler error when installing,"  This can be a problem on virtual servers with limited memory. A possible
solution is to add more swap memory. A more practical solution would be to force
the build script to run only one compile job at a time. You can do this by
setting the YCM_CORES environment variable to 1. Example: YCM_CORES=1 ./install.py --clang-completer
",6
https://github.com/memorywarning/YouCompleteMe,### I get weird errors when I press `Ctrl-C` in Vim,"  Never use Ctrl-C in Vim. Using Ctrl-C to exit insert mode in Vim is a bad idea. The main issue here is
that Ctrl-C in Vim doesn't just leave insert mode, it leaves it without
triggering InsertLeave autocommands (as per Vim docs). This is a bad idea and
is likely to break many other things and not just YCM. Bottom line, if you use Ctrl-C to exit insert mode in Vim, you're gonna have a
bad time. If pressing <esc> is too annoying (agreed, it is), we suggest mapping it to
something more convenient. On a QWERTY keyboard, a good pick for the <esc> map
is inoremap jk <Esc>. This is right on the home row, it's an incredibly rare
digraph in English and if you ever need to type those two chars in sequence in
insert mode, you just type j, then wait 500ms, then type k.",6
https://github.com/memorywarning/YouCompleteMe,### Why did YCM stop using Syntastic for diagnostics display?,"  Previously, YCM would send any diagnostics it would receive from the libclang
semantic engine to Syntastic for display as signs in the gutter, red squiggles
etc. Today, YCM uses its own code to do that. Using Syntastic for this was always a kludge. Syntastic assumes its ""checker""
plugins behave in a certain way; those assumptions have never fit YCM. For
instance, YCM continuously recompiles your code in the background for C-family
languages and tries to push new diagnostics to the user as fast as possible,
even while the user types. Syntastic assumes that a checker only runs on file save (""active"" mode) or even
less frequently, when the user explicitly invokes it (""passive"" mode). This
mismatch in assumptions causes performance problems since Syntastic code isn't
optimized for this use case of constant diagnostic refreshing. Poor support for this use case also led to crash bugs in Vim caused by
Syntastic-Vim interactions (issue #593) and other problems, like
random Vim flickering. Attempts were made to resolve these issues in
Syntastic, but ultimately some of them failed (for various reasons). Implementing diagnostic display code directly in YCM resolves all of these
problems. Performance also improved substantially since the relevant code is now
written in Python instead of VimScript (which is very slow) and is tailored only
for YCM's use-cases. We were also able to introduce new features in this area
since we're now not limited to the Syntastic checker API. We've tried to implement this in the most backwards-compatible way possible; YCM
options that control diagnostic display fall back to Syntastic options that
control the same concepts if the user has those set. Still, some Syntastic-specific configuration you might have had might not
be supported by the new code. Please file issues on the tracker in such
cases; if we find the request to be reasonable, we'll find a way to address it.",6
https://github.com/memorywarning/YouCompleteMe,### Completion doesn't work with the C++ standard library headers,"  This is caused by an issue with libclang that only affects some operating
systems. Compiling with clang the binary will use the correct default header
search paths but compiling with libclang.so (which YCM uses) does not. Mac OS X is normally affected, but there's a workaround in YCM for that specific
OS. If you're not running that OS but still have the same problem, continue
reading. The workaround is to call echo | clang -v -E -x c++ - and look at the
paths under the #include <...> search starts here: heading. You should take
those paths, prepend -isystem to each individual path and append them all to
the list of flags you return from your FlagsForFile function in your
.ycm_extra_conf.py file. See issue #303 for details.",6
https://github.com/memorywarning/YouCompleteMe,### Install YCM with [NeoBundle][NeoBundle],"  NeoBundle can do the compilation for you; just add the following to your vimrc: NeoBundle 'Valloric/YouCompleteMe', {
     \ 'build'      : {
        \ 'mac'     : './install.py',
        \ 'unix'    : './install.py',
        \ 'windows' : 'install.py',
        \ 'cygwin'  : './install.py'
        \ }
     \ } But you could have problems with the time needed to get the sub modules and
compile the whole thing.
To increase the Neobundle timeout to 1500 seconds, add the following to your vimrc: let g:neobundle#install_process_timeout = 1500",6
https://github.com/memorywarning/YouCompleteMe,"### When I open a JavaScript file, I get an annoying warning about `.tern-project` file","  Take a look at the instructions for using the JavaScript
completer. If this is still really annoying, and you have a good reason not to have a
.tern-project file, create an empty .tern-config file in your home directory
and YCM will stop complaining.",6
https://github.com/memorywarning/YouCompleteMe,### When I start vim I get a runtime error saying `R6034 An application has made an attempt to load the C runtime library incorrectly.`,"  CMake and other things seem to screw up the PATH with their own msvcrXX.dll versions.
Add the following to the very top of your vimrc to remove these entries from the path. python << EOF
import os
import re
path = os.environ['PATH'].split(';')

def contains_msvcr_lib(folder):
    try:
        for item in os.listdir(folder):
            if re.match(r'msvcr\d+\.dll', item):
                return True
    except:
        pass
    return False

path = [folder for folder in path if not contains_msvcr_lib(folder)]
os.environ['PATH'] = ';'.join(path)
EOF",6
https://github.com/memorywarning/YouCompleteMe,"### I hear that YCM only supports Python 2, is that true?","  No. Both the Vim client and the ycmd server run on Python 2 or 3. If
you work on a Python 3 project, you may need to set g:ycm_python_binary_path
to the Python interpreter you use for your project to get completions for that
version of Python.",6
https://github.com/memorywarning/YouCompleteMe,## Contributor Code of Conduct,"  Please note that this project is released with a Contributor Code of
Conduct. By participating in this project you agree to abide by its
terms.",57
https://github.com/memorywarning/YouCompleteMe,## Contact,"  If you have questions about the plugin or need help, please use the
ycm-users mailing list. If you have bug reports or feature suggestions, please use the issue
tracker. The latest version of the plugin is available at
http://valloric.github.io/YouCompleteMe/. The author's homepage is http://val.markovic.io.",5
https://github.com/memorywarning/YouCompleteMe,## License,"  This software is licensed under the GPL v3 license.
© 2015-2016 YouCompleteMe contributors ",5
https://github.com/bissal/reveal.js,"# reveal.js [![Build Status](https://travis-ci.org/hakimel/reveal.js.svg?branch=master)](https://travis-ci.org/hakimel/reveal.js) <a href=https://slides.com?ref=github""><img src=""https://s3.amazonaws.com/static.slid.es/images/slides-github-banner-320x40.png?1"" alt=""Slides"" width=""160"" height=""20""></a>"""," A framework for easily creating beautiful presentations using HTML. Check out the live demo. reveal.js comes with a broad range of features including nested slides, Markdown contents, PDF export, speaker notes and a JavaScript API. There's also a fully featured visual editor and platform for sharing reveal.js presentations at slides.com.",13
https://github.com/bissal/reveal.js,## Table of contents,"  
Online Editor
Instructions

Markup
Markdown
Element Attributes
Slide Attributes


Configuration
Presentation Size
Dependencies
Ready Event
Auto-sliding
Keyboard Bindings
Touch Navigation
Lazy Loading
API

Slide Changed Event
Presentation State
Slide States
Slide Backgrounds
Parallax Background
Slide Transitions
Internal links
Fragments
Fragment events
Code syntax highlighting
Slide number
Overview mode
Fullscreen mode
Embedded media
Stretching elements
postMessage API


PDF Export
Theming
Speaker Notes

Share and Print Speaker Notes
Server Side Speaker Notes


Multiplexing

Master presentation
Client presentation
Socket.io server


MathJax
Installation

Basic setup
Full setup
Folder Structure


License
",6
https://github.com/bissal/reveal.js,#### More reading,"  
Changelog: Up-to-date version history.
Examples: Presentations created with reveal.js, add your own!
Browser Support: Explanation of browser support and fallbacks.
Plugins: A list of plugins that can be used to extend reveal.js.
",6
https://github.com/bissal/reveal.js,## Online Editor,  Presentations are written using HTML or Markdown but there's also an online editor for those of you who prefer a graphical interface. Give it a try at https://slides.com.,1
https://github.com/bissal/reveal.js,## Instructions, ,3
https://github.com/bissal/reveal.js,### Markup,"  Here's a barebones example of a fully working reveal.js presentation: <html>
	<head>
		<link rel=""stylesheet"" href=""css/reveal.css"">
		<link rel=""stylesheet"" href=""css/theme/white.css"">
	</head>
	<body>
		<div class=""reveal"">
			<div class=""slides"">
				<section>Slide 1</section>
				<section>Slide 2</section>
			</div>
		</div>
		<script src=""js/reveal.js""></script>
		<script>
			Reveal.initialize();
		</script>
	</body>
</html> The presentation markup hierarchy needs to be .reveal > .slides > section where the section represents one slide and can be repeated indefinitely. If you place multiple section elements inside of another section they will be shown as vertical slides. The first of the vertical slides is the ""root"" of the others (at the top), and will be included in the horizontal sequence. For example: <div class=""reveal"">
	<div class=""slides"">
		<section>Single Horizontal Slide</section>
		<section>
			<section>Vertical Slide 1</section>
			<section>Vertical Slide 2</section>
		</section>
	</div>
</div>",3
https://github.com/bissal/reveal.js,### Markdown,"  It's possible to write your slides using Markdown. To enable Markdown, add the data-markdown attribute to your <section> elements and wrap the contents in a <script type=""text/template""> like the example below. This is based on data-markdown from Paul Irish modified to use marked to support GitHub Flavored Markdown. Sensitive to indentation (avoid mixing tabs and spaces) and line breaks (avoid consecutive breaks). <section data-markdown>
	<script type=""text/template"">
		## Page title

		A paragraph with some text and a [link](http://hakim.se).
	</script>
</section>",3
https://github.com/bissal/reveal.js,#### External Markdown,"  You can write your content as a separate file and have reveal.js load it at runtime. Note the separator arguments which determine how slides are delimited in the external file. The data-charset attribute is optional and specifies which charset to use when loading the external file. When used locally, this feature requires that reveal.js runs from a local web server. <section data-markdown=""example.md""  
         data-separator=""^\n\n\n""  
         data-separator-vertical=""^\n\n""  
         data-separator-notes=""^Note:""  
         data-charset=""iso-8859-15"">
</section>",3
https://github.com/bissal/reveal.js,#### Element Attributes,"  Special syntax (in html comment) is available for adding attributes to Markdown elements. This is useful for fragments, amongst other things. <section data-markdown>
	<script type=""text/template"">
		- Item 1 <!-- .element: class=""fragment"" data-fragment-index=""2"" -->
		- Item 2 <!-- .element: class=""fragment"" data-fragment-index=""1"" -->
	</script>
</section>",3
https://github.com/bissal/reveal.js,#### Slide Attributes,"  Special syntax (in html comment) is available for adding attributes to the slide <section> elements generated by your Markdown. <section data-markdown>
	<script type=""text/template"">
	<!-- .slide: data-background=""#ff0000"" -->
		Markdown content
	</script>
</section>",3
https://github.com/bissal/reveal.js,### Configuration,"  At the end of your page you need to initialize reveal by running the following code. Note that all config values are optional and will default as specified below. Reveal.initialize({

	// Display controls in the bottom right corner
	controls: true,

	// Display a presentation progress bar
	progress: true,

	// Display the page number of the current slide
	slideNumber: false,

	// Push each slide change to the browser history
	history: false,

	// Enable keyboard shortcuts for navigation
	keyboard: true,

	// Enable the slide overview mode
	overview: true,

	// Vertical centering of slides
	center: true,

	// Enables touch navigation on devices with touch input
	touch: true,

	// Loop the presentation
	loop: false,

	// Change the presentation direction to be RTL
	rtl: false,

	// Randomizes the order of slides each time the presentation loads
	shuffle: false,

	// Turns fragments on and off globally
	fragments: true,

	// Flags if the presentation is running in an embedded mode,
	// i.e. contained within a limited portion of the screen
	embedded: false,

	// Flags if we should show a help overlay when the questionmark
	// key is pressed
	help: true,

	// Flags if speaker notes should be visible to all viewers
	showNotes: false,

	// Number of milliseconds between automatically proceeding to the
	// next slide, disabled when set to 0, this value can be overwritten
	// by using a data-autoslide attribute on your slides
	autoSlide: 0,

	// Stop auto-sliding after user input
	autoSlideStoppable: true,

	// Use this method for navigation when auto-sliding
	autoSlideMethod: Reveal.navigateNext,

	// Enable slide navigation via mouse wheel
	mouseWheel: false,

	// Hides the address bar on mobile devices
	hideAddressBar: true,

	// Opens links in an iframe preview overlay
	previewLinks: false,

	// Transition style
	transition: 'default', // none/fade/slide/convex/concave/zoom

	// Transition speed
	transitionSpeed: 'default', // default/fast/slow

	// Transition style for full page slide backgrounds
	backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom

	// Number of slides away from the current that are visible
	viewDistance: 3,

	// Parallax background image
	parallaxBackgroundImage: '', // e.g. ""'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'""

	// Parallax background size
	parallaxBackgroundSize: '', // CSS syntax, e.g. ""2100px 900px""

	// Number of pixels to move the parallax background per slide
	// - Calculated automatically unless specified
	// - Set to 0 to disable movement along an axis
	parallaxBackgroundHorizontal: null,
	parallaxBackgroundVertical: null

}); The configuration can be updated after initialization using the configure method: // Turn autoSlide off
Reveal.configure({ autoSlide: 0 });

// Start auto-sliding every 5s
Reveal.configure({ autoSlide: 5000 });",3
https://github.com/bissal/reveal.js,### Presentation Size,"  All presentations have a normal size, that is the resolution at which they are authored. The framework will automatically scale presentations uniformly based on this size to ensure that everything fits on any given display or viewport. See below for a list of configuration options related to sizing, including default values: Reveal.initialize({

	...

	// The ""normal"" size of the presentation, aspect ratio will be preserved
	// when the presentation is scaled to fit different resolutions. Can be
	// specified using percentage units.
	width: 960,
	height: 700,

	// Factor of the display size that should remain empty around the content
	margin: 0.1,

	// Bounds for smallest/largest possible scale to apply to content
	minScale: 0.2,
	maxScale: 1.5

});",3
https://github.com/bissal/reveal.js,### Dependencies,"  Reveal.js doesn't rely on any third party scripts to work but a few optional libraries are included by default. These libraries are loaded as dependencies in the order they appear, for example: Reveal.initialize({
	dependencies: [
		// Cross-browser shim that fully implements classList - https://github.com/eligrey/classList.js/
		{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },

		// Interpret Markdown in <section> elements
		{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
		{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },

		// Syntax highlight for <code> elements
		{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },

		// Zoom in and out with Alt+click
		{ src: 'plugin/zoom-js/zoom.js', async: true },

		// Speaker notes
		{ src: 'plugin/notes/notes.js', async: true },

		// MathJax
		{ src: 'plugin/math/math.js', async: true }
	]
}); You can add your own extensions using the same syntax. The following properties are available for each dependency object: 
src: Path to the script to load
async: [optional] Flags if the script should load after reveal.js has started, defaults to false
callback: [optional] Function to execute when the script has loaded
condition: [optional] Function which must return true for the script to be loaded
",3
https://github.com/bissal/reveal.js,### Ready Event,"  A 'ready' event is fired when reveal.js has loaded all non-async dependencies and is ready to start navigating. To check if reveal.js is already 'ready' you can call Reveal.isReady(). Reveal.addEventListener( 'ready', function( event ) {
	// event.currentSlide, event.indexh, event.indexv
} );",3
https://github.com/bissal/reveal.js,### Auto-sliding,"  Presentations can be configured to progress through slides automatically, without any user input. To enable this you will need to tell the framework how many milliseconds it should wait between slides: // Slide every five seconds
Reveal.configure({
  autoSlide: 5000
}); When this is turned on a control element will appear that enables users to pause and resume auto-sliding. Alternatively, sliding can be paused or resumed by pressing »a« on the keyboard. Sliding is paused automatically as soon as the user starts navigating. You can disable these controls by specifying autoSlideStoppable: false in your reveal.js config. You can also override the slide duration for individual slides and fragments by using the data-autoslide attribute: <section data-autoslide=""2000"">
	<p>After 2 seconds the first fragment will be shown.</p>
	<p class=""fragment"" data-autoslide=""10000"">After 10 seconds the next fragment will be shown.</p>
	<p class=""fragment"">Now, the fragment is displayed for 2 seconds before the next slide is shown.</p>
</section> To override the method used for navigation when auto-sliding, you can specify the autoSlideMethod setting. To only navigate along the top layer and ignore vertical slides, set this to Reveal.navigateRight. Whenever the auto-slide mode is resumed or paused the autoslideresumed and autoslidepaused events are fired.",3
https://github.com/bissal/reveal.js,### Keyboard Bindings,"  If you're unhappy with any of the default keyboard bindings you can override them using the keyboard config option: Reveal.configure({
  keyboard: {
    13: 'next', // go to the next slide when the ENTER key is pressed
    27: function() {}, // do something custom when ESC is pressed
    32: null // don't do anything when SPACE is pressed (i.e. disable a reveal.js default binding)
  }
});",3
https://github.com/bissal/reveal.js,### Touch Navigation,"  You can swipe to navigate through a presentation on any touch-enabled device. Horizontal swipes change between horizontal slides, vertical swipes change between vertical slides. If you wish to disable this you can set the touch config option to false when initializing reveal.js. If there's some part of your content that needs to remain accessible to touch events you'll need to highlight this by adding a data-prevent-swipe attribute to the element. One common example where this is useful is elements that need to be scrolled.",3
https://github.com/bissal/reveal.js,### Lazy Loading,"  When working on presentation with a lot of media or iframe content it's important to load lazily. Lazy loading means that reveal.js will only load content for the few slides nearest to the current slide. The number of slides that are preloaded is determined by the viewDistance configuration option. To enable lazy loading all you need to do is change your ""src"" attributes to ""data-src"" as shown below. This is supported for image, video, audio and iframe elements. Lazy loaded iframes will also unload when the containing slide is no longer visible. <section>
  <img data-src=""image.png"">
  <iframe data-src=""http://hakim.se""></iframe>
  <video>
    <source data-src=""video.webm"" type=""video/webm"" />
    <source data-src=""video.mp4"" type=""video/mp4"" />
  </video>
</section>",3
https://github.com/bissal/reveal.js,### API,"  The Reveal object exposes a JavaScript API for controlling navigation and reading state: // Navigation
Reveal.slide( indexh, indexv, indexf );
Reveal.left();
Reveal.right();
Reveal.up();
Reveal.down();
Reveal.prev();
Reveal.next();
Reveal.prevFragment();
Reveal.nextFragment();

// Randomize the order of slides
Reveal.shuffle();

// Toggle presentation states, optionally pass true/false to force on/off
Reveal.toggleOverview();
Reveal.togglePause();
Reveal.toggleAutoSlide();

// Change a config value at runtime
Reveal.configure({ controls: true });

// Returns the present configuration options
Reveal.getConfig();

// Fetch the current scale of the presentation
Reveal.getScale();

// Retrieves the previous and current slide elements
Reveal.getPreviousSlide();
Reveal.getCurrentSlide();

Reveal.getIndices(); // { h: 0, v: 0 } }
Reveal.getProgress(); // 0-1
Reveal.getTotalSlides();

// Returns the speaker notes for the current slide
Reveal.getSlideNotes();

// State checks
Reveal.isFirstSlide();
Reveal.isLastSlide();
Reveal.isOverview();
Reveal.isPaused();
Reveal.isAutoSliding();",3
https://github.com/bissal/reveal.js,### Slide Changed Event,"  A 'slidechanged' event is fired each time the slide is changed (regardless of state). The event object holds the index values of the current slide as well as a reference to the previous and current slide HTML nodes. Some libraries, like MathJax (see #226), get confused by the transforms and display states of slides. Often times, this can be fixed by calling their update or render function from this callback. Reveal.addEventListener( 'slidechanged', function( event ) {
	// event.previousSlide, event.currentSlide, event.indexh, event.indexv
} );",3
https://github.com/bissal/reveal.js,### Presentation State,"  The presentation's current state can be fetched by using the getState method. A state object contains all of the information required to put the presentation back as it was when getState was first called. Sort of like a snapshot. It's a simple object that can easily be stringified and persisted or sent over the wire. Reveal.slide( 1 );
// we're on slide 1

var state = Reveal.getState();

Reveal.slide( 3 );
// we're on slide 3

Reveal.setState( state );
// we're back on slide 1",3
https://github.com/bissal/reveal.js,### Slide States,"  If you set data-state=""somestate"" on a slide <section>, ""somestate"" will be applied as a class on the document element when that slide is opened. This allows you to apply broad style changes to the page based on the active slide. Furthermore you can also listen to these changes in state via JavaScript: Reveal.addEventListener( 'somestate', function() {
	// TODO: Sprinkle magic
}, false );",36
https://github.com/bissal/reveal.js,### Slide Backgrounds,"  Slides are contained within a limited portion of the screen by default to allow them to fit any display and scale uniformly. You can apply full page backgrounds outside of the slide area by adding a data-background attribute to your <section> elements. Four different types of backgrounds are supported: color, image, video and iframe.",36
https://github.com/bissal/reveal.js,##### Color Backgrounds,"  All CSS color formats are supported, like rgba() or hsl(). <section data-background-color=""#ff0000"">
	<h2>Color</h2>
</section>",36
https://github.com/bissal/reveal.js,##### Image Backgrounds,"  By default, background images are resized to cover the full page. Available options: 


Attribute
Default
Description




data-background-image

URL of the image to show. GIFs restart when the slide opens.


data-background-size
cover
See background-size on MDN.


data-background-position
center
See background-position on MDN.


data-background-repeat
no-repeat
See background-repeat on MDN.


 <section data-background-image=""http://example.com/image.png"">
	<h2>Image</h2>
</section>
<section data-background-image=""http://example.com/image.png"" data-background-size=""100px"" data-background-repeat=""repeat"">
	<h2>This background image will be sized to 100px and repeated</h2>
</section>",36
https://github.com/bissal/reveal.js,##### Video Backgrounds,"  Automatically plays a full size video behind the slide. 


Attribute
Default
Description




data-background-video

A single video source, or a comma separated list of video sources.


data-background-video-loop
false
Flags if the video should play repeatedly.


data-background-video-muted
false
Flags if the audio should be muted.


 <section data-background-video=""https://s3.amazonaws.com/static.slid.es/site/homepage/v1/homepage-video-editor.mp4,https://s3.amazonaws.com/static.slid.es/site/homepage/v1/homepage-video-editor.webm"" data-background-video-loop data-background-video-muted>
	<h2>Video</h2>
</section>",36
https://github.com/bissal/reveal.js,##### Iframe Backgrounds,"  Embeds a web page as a background. Note that since the iframe is in the background layer, behind your slides, it is not possible to interact with the embedded page. <section data-background-iframe=""https://slides.com"">
	<h2>Iframe</h2>
</section>",36
https://github.com/bissal/reveal.js,##### Background Transitions,  Backgrounds transition using a fade animation by default. This can be changed to a linear sliding transition by passing backgroundTransition: 'slide' to the Reveal.initialize() call. Alternatively you can set data-background-transition on any section with a background to override that specific transition.,36
https://github.com/bissal/reveal.js,### Parallax Background,"  If you want to use a parallax scrolling background, set the first two config properties below when initializing reveal.js (the other two are optional). Reveal.initialize({

	// Parallax background image
	parallaxBackgroundImage: '', // e.g. ""https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg""

	// Parallax background size
	parallaxBackgroundSize: '', // CSS syntax, e.g. ""2100px 900px"" - currently only pixels are supported (don't use % or auto)

	// Number of pixels to move the parallax background per slide
	// - Calculated automatically unless specified
	// - Set to 0 to disable movement along an axis
	parallaxBackgroundHorizontal: 200,
	parallaxBackgroundVertical: 50

}); Make sure that the background size is much bigger than screen size to allow for some scrolling. View example.",36
https://github.com/bissal/reveal.js,### Slide Transitions,"  The global presentation transition is set using the transition config value. You can override the global transition for a specific slide by using the data-transition attribute: <section data-transition=""zoom"">
	<h2>This slide will override the presentation transition and zoom!</h2>
</section>

<section data-transition-speed=""fast"">
	<h2>Choose from three transition speeds: default, fast or slow!</h2>
</section> You can also use different in and out transitions for the same slide: <section data-transition=""slide"">
    The train goes on ?</section>
<section data-transition=""slide"">
    and on ?</section>
<section data-transition=""slide-in fade-out"">
    and stops.
</section>
<section data-transition=""fade-in slide-out"">
    (Passengers entering and leaving)
</section>
<section data-transition=""slide"">
    And it starts again.
</section>",36
https://github.com/bissal/reveal.js,### Internal links,"  It's easy to link between slides. The first example below targets the index of another slide whereas the second targets a slide with an ID attribute (<section id=""some-slide"">): <a href=""#/2/2"">Link</a>
<a href=""#/some-slide"">Link</a> You can also add relative navigation links, similar to the built in reveal.js controls, by appending one of the following classes on any element. Note that each element is automatically given an enabled class when it's a valid navigation route based on the current slide. <a href=""#"" class=""navigate-left"">
<a href=""#"" class=""navigate-right"">
<a href=""#"" class=""navigate-up"">
<a href=""#"" class=""navigate-down"">
<a href=""#"" class=""navigate-prev""> <!-- Previous vertical or horizontal slide -->
<a href=""#"" class=""navigate-next""> <!-- Next vertical or horizontal slide -->",36
https://github.com/bissal/reveal.js,### Fragments,"  Fragments are used to highlight individual elements on a slide. Every element with the class fragment will be stepped through before moving on to the next slide. Here's an example: http://lab.hakim.se/reveal-js/#/fragments The default fragment style is to start out invisible and fade in. This style can be changed by appending a different class to the fragment: <section>
	<p class=""fragment grow"">grow</p>
	<p class=""fragment shrink"">shrink</p>
	<p class=""fragment fade-out"">fade-out</p>
	<p class=""fragment fade-up"">fade-up (also down, left and right!)</p>
	<p class=""fragment current-visible"">visible only once</p>
	<p class=""fragment highlight-current-blue"">blue only once</p>
	<p class=""fragment highlight-red"">highlight-red</p>
	<p class=""fragment highlight-green"">highlight-green</p>
	<p class=""fragment highlight-blue"">highlight-blue</p>
</section> Multiple fragments can be applied to the same element sequentially by wrapping it, this will fade in the text on the first step and fade it back out on the second. <section>
	<span class=""fragment fade-in"">
		<span class=""fragment fade-out"">I'll fade in, then out</span>
	</span>
</section> The display order of fragments can be controlled using the data-fragment-index attribute. <section>
	<p class=""fragment"" data-fragment-index=""3"">Appears last</p>
	<p class=""fragment"" data-fragment-index=""1"">Appears first</p>
	<p class=""fragment"" data-fragment-index=""2"">Appears second</p>
</section>",36
https://github.com/bissal/reveal.js,### Fragment events,"  When a slide fragment is either shown or hidden reveal.js will dispatch an event. Some libraries, like MathJax (see #505), get confused by the initially hidden fragment elements. Often times this can be fixed by calling their update or render function from this callback. Reveal.addEventListener( 'fragmentshown', function( event ) {
	// event.fragment = the fragment DOM element
} );
Reveal.addEventListener( 'fragmenthidden', function( event ) {
	// event.fragment = the fragment DOM element
} );",36
https://github.com/bissal/reveal.js,### Code syntax highlighting,"  By default, Reveal is configured with highlight.js for code syntax highlighting. Below is an example with clojure code that will be syntax highlighted. When the data-trim attribute is present, surrounding whitespace is automatically removed.  HTML will be escaped by default. To avoid this, for example if you are using <mark> to call out a line of code, add the data-noescape attribute to the <code> element. <section>
	<pre><code data-trim data-noescape>
(def lazy-fib
  (concat
   [0 1]
   <mark>((fn rfib [a b]</mark>
        (lazy-cons (+ a b) (rfib b (+ a b)))) 0 1)))
	</code></pre>
</section>",36
https://github.com/bissal/reveal.js,### Slide number,"  If you would like to display the page number of the current slide you can do so using the slideNumber configuration value. // Shows the slide number using default formatting
Reveal.configure({ slideNumber: true });

// Slide number formatting can be configured using these variables:
//  ""h.v"": 	horizontal . vertical slide number (default)
//  ""h/v"": 	horizontal / vertical slide number
//    ""c"": 	flattened slide number
//  ""c/t"": 	flattened slide number / total slides
Reveal.configure({ slideNumber: 'c/t' });",36
https://github.com/bissal/reveal.js,### Overview mode,"  Press ""Esc"" or ""o"" keys to toggle the overview mode on and off. While you're in this mode, you can still navigate between slides,
as if you were at 1,000 feet above your presentation. The overview mode comes with a few API hooks: Reveal.addEventListener( 'overviewshown', function( event ) { /* ... */ } );
Reveal.addEventListener( 'overviewhidden', function( event ) { /* ... */ } );

// Toggle the overview mode programmatically
Reveal.toggleOverview();",36
https://github.com/bissal/reveal.js,### Fullscreen mode,  Just press »F« on your keyboard to show your presentation in fullscreen mode. Press the »ESC« key to exit fullscreen mode.,36
https://github.com/bissal/reveal.js,### Embedded media,"  Embedded HTML5 <video>/<audio> and YouTube iframes are automatically paused when you navigate away from a slide. This can be disabled by decorating your element with a data-ignore attribute. Add data-autoplay to your media element if you want it to automatically start playing when the slide is shown: <video data-autoplay src=""http://clips.vorwaerts-gmbh.de/big_buck_bunny.mp4""></video> Additionally the framework automatically pushes two post messages to all iframes, slide:start when the slide containing the iframe is made visible and slide:stop when it is hidden.",36
https://github.com/bissal/reveal.js,### Stretching elements,"  Sometimes it's desirable to have an element, like an image or video, stretch to consume as much space as possible within a given slide. This can be done by adding the .stretch class to an element as seen below: <section>
	<h2>This video will use up the remaining space on the slide</h2>
    <video class=""stretch"" src=""http://clips.vorwaerts-gmbh.de/big_buck_bunny.mp4""></video>
</section> Limitations: 
Only direct descendants of a slide section can be stretched
Only one descendant per slide section can be stretched
",36
https://github.com/bissal/reveal.js,### postMessage API,"  The framework has a built-in postMessage API that can be used when communicating with a presentation inside of another window. Here's an example showing how you'd make a reveal.js instance in the given window proceed to slide 2: <window>.postMessage( JSON.stringify({ method: 'slide', args: [ 2 ] }), '*' ); When reveal.js runs inside of an iframe it can optionally bubble all of its events to the parent. Bubbled events are stringified JSON with three fields: namespace, eventName and state. Here's how you subscribe to them from the parent window: window.addEventListener( 'message', function( event ) {
	var data = JSON.parse( event.data );
	if( data.namespace === 'reveal' && data.eventName ==='slidechanged' ) {
		// Slide changed, see data.state for slide number
	}
} ); This cross-window messaging can be toggled on or off using configuration flags. Reveal.initialize({
	...,

	// Exposes the reveal.js API through window.postMessage
	postMessage: true,

	// Dispatches all reveal.js events to the parent window through postMessage
	postMessageEvents: false
});",36
https://github.com/bissal/reveal.js,## PDF Export,"  Presentations can be exported to PDF via a special print stylesheet. This feature requires that you use Google Chrome or Chromium.
Here's an example of an exported presentation that's been uploaded to SlideShare: http://www.slideshare.net/hakimel/revealjs-300. 
Open your presentation with print-pdf included anywhere in the query string. This triggers the default index HTML to load the PDF print stylesheet (css/print/pdf.css). You can test this with lab.hakim.se/reveal-js?print-pdf.
Open the in-browser print dialog (CTRL/CMD+P).
Change the Destination setting to Save as PDF.
Change the Layout to Landscape.
Change the Margins to None.
Enable the Background graphics option.
Click Save.
  Alternatively you can use the decktape project.",3
https://github.com/bissal/reveal.js,## Theming,"  The framework comes with a few different themes included: 
black: Black background, white text, blue links (default theme)
white: White background, black text, blue links
league: Gray background, white text, blue links (default theme for reveal.js < 3.0.0)
beige: Beige background, dark text, brown links
sky: Blue background, thin dark text, blue links
night: Black background, thick white text, orange links
serif: Cappuccino background, gray text, brown links
simple: White background, black text, blue links
solarized: Cream-colored background, dark green text, blue links
 Each theme is available as a separate stylesheet. To change theme you will need to replace black below with your desired theme name in index.html: <link rel=""stylesheet"" href=""css/theme/black.css"" id=""theme""> If you want to add a theme of your own see the instructions here: /css/theme/README.md.",13
https://github.com/bissal/reveal.js,## Speaker Notes,"  reveal.js comes with a speaker notes plugin which can be used to present per-slide notes in a separate browser window. The notes window also gives you a preview of the next upcoming slide so it may be helpful even if you haven't written any notes. Press the 's' key on your keyboard to open the notes window. Notes are defined by appending an <aside> element to a slide as seen below. You can add the data-markdown attribute to the aside element if you prefer writing notes using Markdown. Alternatively you can add your notes in a data-notes attribute on the slide. Like <section data-notes=""Something important""></section>. When used locally, this feature requires that reveal.js runs from a local web server. <section>
	<h2>Some Slide</h2>

	<aside class=""notes"">
		Oh hey, these are some notes. They'll be hidden in your presentation, but you can see them if you open the speaker notes window (hit 's' on your keyboard).
	</aside>
</section> If you're using the external Markdown plugin, you can add notes with the help of a special delimiter: <section data-markdown=""example.md"" data-separator=""^\n\n\n"" data-separator-vertical=""^\n\n"" data-separator-notes=""^Note:""></section>

# Title
## Sub-title

Here is some content...

Note:
This will only display in the notes window.",13
https://github.com/bissal/reveal.js,# Title,,-
https://github.com/bissal/reveal.js,## Sub-title,,-
https://github.com/bissal/reveal.js,#### Share and Print Speaker Notes,  Notes are only visible to the speaker inside of the speaker view. If you wish to share your notes with others you can initialize reveal.js with the showNotes config value set to true. Notes will appear along the bottom of the presentations. When showNotes is enabled notes are also included when you export to PDF.,3
https://github.com/bissal/reveal.js,## Server Side Speaker Notes,"  In some cases it can be desirable to run notes on a separate device from the one you're presenting on. The Node.js-based notes plugin lets you do this using the same note definitions as its client side counterpart. Include the required scripts by adding the following dependencies: Reveal.initialize({
	...

	dependencies: [
		{ src: 'socket.io/socket.io.js', async: true },
		{ src: 'plugin/notes-server/client.js', async: true }
	]
}); Then: 
Install Node.js (1.0.0 or later)
Run npm install
Run node plugin/notes-server
",3
https://github.com/bissal/reveal.js,## Multiplexing,"  The multiplex plugin allows your audience to view the slides of the presentation you are controlling on their own phone, tablet or laptop. As the master presentation navigates the slides, all client presentations will update in real time. See a demo at https://reveal-js-multiplex-ccjbegmaii.now.sh/. The multiplex plugin needs the following 3 things to operate: 
Master presentation that has control
Client presentations that follow the master
Socket.io server to broadcast events from the master to the clients
 More details:",3
https://github.com/bissal/reveal.js,#### Master presentation,"  Served from a static file server accessible (preferably) only to the presenter. This need only be on your (the presenter's) computer. (It's safer to run the master presentation from your own computer, so if the venue's Internet goes down it doesn't stop the show.) An example would be to execute the following commands in the directory of your master presentation: 
npm install node-static
static
 If you want to use the speaker notes plugin with your master presentation then make sure you have the speaker notes plugin configured correctly along with the configuration shown below, then execute node plugin/notes-server in the directory of your master presentation. The configuration below will cause it to connect to the socket.io server as a master, as well as launch your speaker-notes/static-file server. You can then access your master presentation at http://localhost:1947 Example configuration: Reveal.initialize({
	// other options...

	multiplex: {
		// Example values. To generate your own, see the socket.io server instructions.
		secret: '13652805320794272084', // Obtained from the socket.io server. Gives this (the master) control of the presentation
		id: '1ea875674b17ca76', // Obtained from socket.io server
		url: 'https://reveal-js-multiplex-ccjbegmaii.now.sh' // Location of socket.io server
	},

	// Don't forget to add the dependencies
	dependencies: [
		{ src: '//cdn.socket.io/socket.io-1.3.5.js', async: true },
		{ src: 'plugin/multiplex/master.js', async: true },

		// and if you want speaker notes
		{ src: 'plugin/notes-server/client.js', async: true }

		// other dependencies...
	]
});",3
https://github.com/bissal/reveal.js,#### Client presentation,"  Served from a publicly accessible static file server. Examples include: GitHub Pages, Amazon S3, Dreamhost, Akamai, etc. The more reliable, the better. Your audience can then access the client presentation via http://example.com/path/to/presentation/client/index.html, with the configuration below causing them to connect to the socket.io server as clients. Example configuration: Reveal.initialize({
	// other options...

	multiplex: {
		// Example values. To generate your own, see the socket.io server instructions.
		secret: null, // null so the clients do not have control of the master presentation
		id: '1ea875674b17ca76', // id, obtained from socket.io server
		url: 'https://reveal-js-multiplex-ccjbegmaii.now.sh' // Location of socket.io server
	},

	// Don't forget to add the dependencies
	dependencies: [
		{ src: '//cdn.socket.io/socket.io-1.3.5.js', async: true },
		{ src: 'plugin/multiplex/client.js', async: true }

		// other dependencies...
	]
});",3
https://github.com/bissal/reveal.js,#### Socket.io server,"  Server that receives the slideChanged events from the master presentation and broadcasts them out to the connected client presentations. This needs to be publicly accessible. You can run your own socket.io server with the commands: 
npm install
node plugin/multiplex
 Or you use the socket.io server at https://reveal-js-multiplex-ccjbegmaii.now.sh/. You'll need to generate a unique secret and token pair for your master and client presentations. To do so, visit http://example.com/token, where http://example.com is the location of your socket.io server. Or if you're going to use the socket.io server at https://reveal-js-multiplex-ccjbegmaii.now.sh/, visit https://reveal-js-multiplex-ccjbegmaii.now.sh/token. You are very welcome to point your presentations at the Socket.io server running at https://reveal-js-multiplex-ccjbegmaii.now.sh/, but availability and stability are not guaranteed. For anything mission critical I recommend you run your own server. It is simple to deploy to nodejitsu, heroku, your own environment, etc.",3
https://github.com/bissal/reveal.js,##### socket.io server as file static server,"  The socket.io server can play the role of static file server for your client presentation, as in the example at https://reveal-js-multiplex-ccjbegmaii.now.sh/. (Open https://reveal-js-multiplex-ccjbegmaii.now.sh/ in two browsers. Navigate through the slides on one, and the other will update to match.) Example configuration: Reveal.initialize({
	// other options...

	multiplex: {
		// Example values. To generate your own, see the socket.io server instructions.
		secret: null, // null so the clients do not have control of the master presentation
		id: '1ea875674b17ca76', // id, obtained from socket.io server
		url: 'example.com:80' // Location of your socket.io server
	},

	// Don't forget to add the dependencies
	dependencies: [
		{ src: '//cdn.socket.io/socket.io-1.3.5.js', async: true },
		{ src: 'plugin/multiplex/client.js', async: true }

		// other dependencies...
	] It can also play the role of static file server for your master presentation and client presentations at the same time (as long as you don't want to use speaker notes). (Open https://reveal-js-multiplex-ccjbegmaii.now.sh/ in two browsers. Navigate through the slides on one, and the other will update to match. Navigate through the slides on the second, and the first will update to match.) This is probably not desirable, because you don't want your audience to mess with your slides while you're presenting. ;) Example configuration: Reveal.initialize({
	// other options...

	multiplex: {
		// Example values. To generate your own, see the socket.io server instructions.
		secret: '13652805320794272084', // Obtained from the socket.io server. Gives this (the master) control of the presentation
		id: '1ea875674b17ca76', // Obtained from socket.io server
		url: 'example.com:80' // Location of your socket.io server
	},

	// Don't forget to add the dependencies
	dependencies: [
		{ src: '//cdn.socket.io/socket.io-1.3.5.js', async: true },
		{ src: 'plugin/multiplex/master.js', async: true },
		{ src: 'plugin/multiplex/client.js', async: true }

		// other dependencies...
	]
});",3
https://github.com/bissal/reveal.js,## MathJax,"  If you want to display math equations in your presentation you can easily do so by including this plugin. The plugin is a very thin wrapper around the MathJax library. To use it you'll need to include it as a reveal.js dependency, find our more about dependencies here. The plugin defaults to using LaTeX but that can be adjusted through the math configuration object. Note that MathJax is loaded from a remote server. If you want to use it offline you'll need to download a copy of the library and adjust the mathjax configuration value. Below is an example of how the plugin can be configured. If you don't intend to change these values you do not need to include the math config object at all. Reveal.initialize({

	// other options ...

	math: {
		mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
		config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
	},

	dependencies: [
		{ src: 'plugin/math/math.js', async: true }
	]

}); Read MathJax's documentation if you need HTTPS delivery or serving of specific versions for stability.",36
https://github.com/bissal/reveal.js,## Installation,  The basic setup is for authoring presentations only. The full setup gives you access to all reveal.js features and plugins such as speaker notes as well as the development tasks needed to make changes to the source.,3
https://github.com/bissal/reveal.js,### Basic setup,"  The core of reveal.js is very easy to install. You'll simply need to download a copy of this repository and open the index.html file directly in your browser. 

Download the latest version of reveal.js from https://github.com/hakimel/reveal.js/releases


Unzip and replace the example contents in index.html with your own


Open index.html in a browser to view it

",3
https://github.com/bissal/reveal.js,### Full setup,"  Some reveal.js features, like external Markdown and speaker notes, require that presentations run from a local web server. The following instructions will set up such a server as well as all of the development tasks needed to make edits to the reveal.js source code. 

Install Node.js (1.0.0 or later)


Clone the reveal.js repository
$ git clone https://github.com/hakimel/reveal.js.git


Navigate to the reveal.js folder
$ cd reveal.js


Install dependencies
$ npm install


Serve the presentation and monitor source files for changes
$ npm start


Open http://localhost:8000 to view your presentation
You can change the port by using npm start -- --port 8001.

",3
https://github.com/bissal/reveal.js,### Folder Structure,"  
css/ Core styles without which the project does not function
js/ Like above but for JavaScript
plugin/ Components that have been developed as extensions to reveal.js
lib/ All other third party assets (JavaScript, CSS, fonts)
",3
https://github.com/bissal/reveal.js,## License,"  MIT licensed Copyright (C) 2016 Hakim El Hattab, http://hakim.se",5
https://github.com/raphapassini/calendarjs,# calendarjs,A simple jquery events calendar plugin,1
https://github.com/raphapassini/calendarjs,## How to install,"Download the zip and extract it
Acess the index.html to see a demo
If you wanna run the tests suite run tests.html",3
https://github.com/raphapassini/calendarjs,## How to use it,"Basic usage

<!DOCTYPE html>
<html>
  <head>
    <title>CalendarJS</title>
    <meta charset=""utf-8"">
  </head>
  <body>
    <div class=""calendar""></div>

    <script src=""https://code.jquery.com/jquery.js""></script>
    <script src=""calendar.js"" charset=""UTF-8""></script>
    <script>$("".calendar"").calendarjs()</script>
  </body>
</html>",3
https://github.com/raphapassini/calendarjs,## How to translate,"// localization object in PT_BR
var pt_br = {
  month_names: ['Janeiro', 'Fevereiro', 'Mar?o', 'Abril', 'Maio', 'Junho',
           'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro'],
  weekdays: ['Segunda', 'Ter?a', 'Quarta', 'Quinta', 'Sexta', 'Sbado', 'Domingo'],
  weekdays_short: ['Dom', 'Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sab']
}

$("".calendar"").calendarjs({l10n: pt_br})",3
https://github.com/raphapassini/calendarjs,## Complete API,"set_date(dateObject) - set the calendar date

Ex:
$(""calendar"").calendarjs().set_date(new Date(2013, 1, 1))

set_events(eventList) - Set an event list

IMPORTANT: eventList should be ordered by date!

Ex:

evtList =  [
  {
    date: new Date('2013', '10', '01'),
    object: {'title': 'My first event', 'desc': 'First event'},
  },
  {
    date: new Date('2013', '10', '01'),
    object: {'title': 'Second event on day 01', 'desc': 'Second event on day 01'},
  },
  {
    date: new Date('2013', '10', '02'),
    object: {'title': 'Sencond Event', 'desc': 'Second event'},
  },
]

$cl = $('div.calendar').calendarjs()

$cl.set_events(evtList)
PS: Calendar will set the current display month to the month of the first event on list.",36
https://github.com/raphapassini/calendarjs,## Options,"width: 400 - The with of the calendar, always in px

height: 230 - The height of the calendar, always in px

auto_render: true - Should render calendar automatically when you cal $.calendarjs()

l10n: dflt_l10n - An object which have localized strings

date: new Date() - The calendar start date

short_weekdays: true - Which format of weekdays should calendar use

next_link: '<a href=""#""> >> </a>' - Link to the next month

prev_link: '<a href=""#"" class=""prev""> << </a>' - Link to the previous month

day_click_cb: function(cl, date, evtList){}

Callback function called when user click in a day, this function recieves:
the calendar object, the date in format dd/mm/yyyy and the list of events
or the Event object (if the clicked day have just 1 event)

month_change_cb: function(old, new){}

Callback function called when month change, this function recieves:
The old_date and the new_date",36
https://github.com/zhongdaojin/node-tesseract,# Tesseract for node.js,  A simple wrapper for the Tesseract OCR package for node.js,1
https://github.com/zhongdaojin/node-tesseract,## Requirements,"  
Tesseract 3.01 or higher is needed for this to work
",3
https://github.com/zhongdaojin/node-tesseract,## Installation,"  There is a hard dependency on the Tesseract project.  You can find installation instructions for various platforms on the project site. For Homebrew users, the installation is quick and easy. brew install tesseract --all-languages
 The above will install all of the language packages available, if you don't need them all you can remove the --all-languages flag and install them manually, by downloading them to your local machine and then exposing the TESSDATA_PREFIX variable into your path: export TESSDATA_PREFIX=~/Downloads/
 You can then go about installing the node-module to expose the JavaScript API: npm install node-tesseract
",3
https://github.com/zhongdaojin/node-tesseract,## Usage,"  var tesseract = require('node-tesseract');

// Recognize text of any language in any format
tesseract.process(__dirname + '/path/to/image.jpg',function(err, text) {
	if(err) {
		console.error(err);
	} else {
		console.log(text);
	}
});

// Recognize German text in a single uniform block of text and set the binary path

var options = {
	l: 'deu',
	psm: 6,
	binary: '/usr/local/bin/tesseract'
};

tesseract.process(__dirname + '/path/to/image.jpg', options, function(err, text) {
	if(err) {
		console.error(err);
	} else {
		console.log(text);
	}
});",3
https://github.com/zhongdaojin/node-tesseract,## Changelog,"  
0.2.7: Adds output file extension detection
0.2.6: Catches exception when deleting tmp files that do not exist
0.2.5: Preserves whitespace and replaces tmp module
0.2.4: Removes console logging for messaging
0.2.3: The ability to set the binary path via the config object.  Better installation documentation.
0.2.2: Adds test converage to utils module
0.2.1: Strips leading & trailing whitespace from output by default
0.2.0: Adds ability to pass options via a configuration object.
0.1.1: Updates tmp module.
0.1.0: Removes preprocessing functionatlity.  See #3.
0.0.3: Adds basic test coverage for process method
0.0.2: Pulls in changes by joscha including: refactored to support tesseract 3.01, added language parameter, config parameter, documentation, Added support for custom preprocessors, OTB Preprocessor using ImageMagick 'convert'
0.0.1: Initial version
",4
https://github.com/majestrate/go-multiaddr,# go-multiaddr, multiaddr implementation in Go.,1
https://github.com/majestrate/go-multiaddr,## Example, ,3
https://github.com/majestrate/go-multiaddr,### Simple,"  import ma ""github.com/jbenet/go-multiaddr""

// construct from a string (err signals parse failure)
m1, err := ma.NewMultiaddr(""/ip4/127.0.0.1/udp/1234"")

// construct from bytes (err signals parse failure)
m2, err := ma.NewMultiaddrBytes(m1.Bytes())

// true
strings.Equal(m1.String(), ""/ip4/127.0.0.1/udp/1234"")
strings.Equal(m1.String(), m2.String())
bytes.Equal(m1.Bytes(), m2.Bytes())
m1.Equal(m2)
m2.Equal(m1)",3
https://github.com/majestrate/go-multiaddr,### Protocols,"  // get the multiaddr protocol description objects
addr.Protocols()
// []Protocol{
//   Protocol{ Code: 4, Name: 'ip4', Size: 32},
//   Protocol{ Code: 17, Name: 'udp', Size: 16},
// }",3
https://github.com/majestrate/go-multiaddr,### En/decapsulate,"  m.Encapsulate(ma.NewMultiaddr(""/sctp/5678""))
// <Multiaddr /ip4/127.0.0.1/udp/1234/sctp/5678>
m.Decapsulate(ma.NewMultiaddr(""/udp"")) // up to + inc last occurrence of subaddr
// <Multiaddr /ip4/127.0.0.1>",3
https://github.com/majestrate/go-multiaddr,### Tunneling,"  Multiaddr allows expressing tunnels very nicely. printer, _ := ma.NewMultiaddr(""/ip4/192.168.0.13/tcp/80"")
proxy, _ := ma.NewMultiaddr(""/ip4/10.20.30.40/tcp/443"")
printerOverProxy := proxy.Encapsulate(printer)
// /ip4/10.20.30.40/tcp/443/ip4/192.168.0.13/tcp/80

proxyAgain := printerOverProxy.Decapsulate(printer)
// /ip4/10.20.30.40/tcp/443",3
https://github.com/ttyouare/angular-strap,# [AngularStrap](http://mgcrea.github.io/angular-strap),"       AngularStrap is a set of native directives that enables seamless integration of Bootstrap 3.0+ into your AngularJS 1.2+ app. 

With no external dependency except the Bootstrap CSS Styles, AngularStrap is lighter and faster than ever as it does leverage the power of ngAnimate from AngularJS 1.2+!


AngularStrap is tested against the latest patch release of the 1.2, 1.3 and 1.4 branches.


If you don't want to use ngAnimate, you will have to include a tiny ngAnimate mock.

",12
https://github.com/ttyouare/angular-strap,## Documentation and examples,"  
Check the documentation and changelog.
",6
https://github.com/ttyouare/angular-strap,## Communication,"  
If you need help, use Stack Overflow. (Tag 'angular-strap')
If you'd like to ask a general question, use Stack Overflow.
If you found a bug, open an issue.
If you have a feature request, open an issue.
If you want to contribute, submit a pull request.
",6
https://github.com/ttyouare/angular-strap,## Quick start,"  
Install AngularStrap with Bower.
 
 $ bower install angular-strap --save 
Include the required libraries in your index.html:
 
 <script src=""bower_components/angular/angular.js""></script>
<script src=""bower_components/angular-animate/angular-animate.js""></script>
<script src=""bower_components/angular-strap/dist/angular-strap.min.js""></script>
<script src=""bower_components/angular-strap/dist/angular-strap.tpl.min.js""></script> 
Inject the mgcrea.ngStrap module into your app:
 
 angular.module('myApp', ['ngAnimate', 'mgcrea.ngStrap']);",3
https://github.com/ttyouare/angular-strap,## Developers,"  Clone the repo, git clone git://github.com/mgcrea/angular-strap.git, download the latest release or install with bower bower install angular-strap --save. You will need to have bower installed globally into your node environment. 
 $ npm install -g bower AngularStrap is tested with karma against the latest stable release of AngularJS. 
AngularStrap uses gulp@4.0, you must use the local gulp instance with $(npm bin)/gulp for it to work (or use an alias).
 
 $ npm install
$ bower install
$ cd docs
$ bower install
$ cd ..
$ $(npm bin)/gulp test You can build the latest version using gulp. 
 $ $(npm bin)/gulp build You can quickly hack around (the docs) with: 
   $ $(npm bin)/gulp serve You can browse to http://localhost:9090/dev.html to work on a specific directive.",3
https://github.com/ttyouare/angular-strap,## Contributing,"  Please submit all pull requests the against master branch. If your pull request contains JavaScript patches or features, you should include relevant unit tests.
Please check the Contributing Guidelines for more details.
Thanks!",7
https://github.com/ttyouare/angular-strap,## Authors,"  Olivier Louvignes 
http://olouv.com
http://github.com/mgcrea
",5
https://github.com/ttyouare/angular-strap,## Copyright and license,"  The MIT License

Copyright (c) 2012 ?2015 Olivier Louvignes

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
",5
https://github.com/LookOut800/wdi_11_angular_token_auth_app,# Angular + Token Authentication,,1
https://github.com/LookOut800/wdi_11_angular_token_auth_app,## Objectives,"  By the end of this, students should be able to: 
Authenticate users on an AngularJS front end by consuming tokens delivered from a Rails API
Use localStorage for storing session information (as a JSON string)
Restrict access to any routes unless users are authorized
",1
https://github.com/LookOut800/wdi_11_angular_token_auth_app,## Instructions,"  
Fork/Clone
$ npm install && bower install
$ grunt serve
 The API endpoints look like this:  posts GET    /posts(.:format)     posts#index
       POST   /posts(.:format)     posts#create
  post GET    /posts/:id(.:format) posts#show
       PATCH  /posts/:id(.:format) posts#update
       PUT    /posts/:id(.:format) posts#update
       DELETE /posts/:id(.:format) posts#destroy
 users GET    /users(.:format)     users#index
       POST   /users(.:format)     users#create
  user GET    /users/:id(.:format) users#show
       PATCH  /users/:id(.:format) users#update
       PUT    /users/:id(.:format) users#update
       DELETE /users/:id(.:format) users#destroy
 login POST   /login(.:format)     users#login
logout GET    /logout(.:format)    users#logout We've seeded the db with two users: # User 1:
#———————————?username: tyriol
password: myjam

# User 2:
#———————————?username: dsquare
password: myjam To login a user, you must make a post request that looks like this: $http.post('http://localhost:3000/login', { username: 'tyriol', password: 'myjam' }); You will receive a response that looks like this: {""id"":5,""username"":""tyriol"",""first_name"":""Tyroil"",""last_name"":""Smoochie-Wallace"",""role"":""super_admin"",""email"":""tyriol@kp.com"",""token"":""ca63da06464f4c6f8f33c0ddf254195f"",""created_at"":""2015-03-26T23:37:19.670Z"",""updated_at"":""2015-03-26T23:37:19.670Z""} We will manipulate this object and store it in the browser's localStorage so that we may use this data to authorize the current user. At this point, follow along and we will code this together.",3
https://github.com/LookOut800/wdi_11_angular_token_auth_app,## Bonus (Optional Section),"Implement some of the concepts in this article: Techniques for authentication in AngularJS applications.

You might think about displaying some user data on the screen (maybe as a dropdown in the navbar).",6
https://github.com/LookOut800/wdi_11_angular_token_auth_app,## Additional,Read this article: Cookies vs Tokens. Getting auth right with Angular.JS,6
https://github.com/crisamdegracia/js-basics-online-shopping-lab-js-intro-000,# Online Shopping,,1
https://github.com/crisamdegracia/js-basics-online-shopping-lab-js-intro-000,## Objectives,"  
Create and manipulate hashes
Create and manipulate arrays
Create and call functions
Create and use variables
Use string methods
Use number methods
",12
https://github.com/crisamdegracia/js-basics-online-shopping-lab-js-intro-000,## Introduction,"  Before we dive into this lab, we need to tell you something: remember how easy it was to iterate over an array with a for or a while loop? Well, it's nearly as easy to iterate over an object in the same way. (Remember, arrays are essentially fancy objects ?it makes sense that iteration would be similar.) But objects don't have sequential indexes like arrays do, so we need another way of getting the keys. Luckily, that's exactly what Object.keys() is for! var meals = {
  breakfast: 'oatmeal',
  lunch: 'tuna',
  dinner: 'spaghetti'
}

var mealNames = Object.keys(meals)

for (var i = 0, l = mealNames.length; i < l; i++) {
  console.log(`I ate ${meals[mealNames[i]]} for ${mealNames[i]}!`)
}

// I ate oatmeal for breakfast!
// I ate tuna for lunch!
// I ate spaghetti for dinner! But this is a little verbose and sort of hard to read: we have to get the name of the meal using mealNames[i] and then use that name as a key in the object meals to get the food for that meal (meals[mealNames[i]]). Gross. There's a (slightly) better way! JavaScript has a special loop, called for...in, that makes iterating over objects a bit easier: var meals = {
  breakfast: 'oatmeal',
  lunch: 'tuna',
  dinner: 'spaghetti'
}

for (var mealName in meals) {
  console.log(`I ate ${meals[mealName]} for ${mealName}!`)
} Much better. NOTE: You can use for...in loops with arrays, too, but the variable that you get will just be the index (in order), so this particular loop is usually used with objects.",1
https://github.com/crisamdegracia/js-basics-online-shopping-lab-js-intro-000,## Instructions,"  

We've given you a function setCart() which takes one argument, an array, and sets cart (a variable that we've provided) to that array.


We've also given you a function total which does not accept any arguments. It iterates over the items in cart and adds up their prices, then returns the total.


Define a global variable (use var at the top level) called cart. Initialize it as an empty array.


Define a function getCart that takes no arguments and returns the cart.


Define a function addToCart. This function should accept one argument, the item the user wants to purchase.
This function should automatically set a price for this item by generating a random number between 0 and 100. (Hint: Math.random() generates a random number in [0, 1] (0 inclusive, 1 non-inclusive); Math.floor() rounds a number down to the nearest integer.)
This function should add the item and the price as an object ({item: price}) to the cart array. This function should print out to the console <item> has been added to your cart. and return the cart.


Define a function viewCart which does not accept any arguments. This function should loop over every item in cart to print out ""In your cart you have [item and price pairs]."". If there isn't anything in your cart, the function should print out ""Your shopping cart is empty."".


Define a function removeFromCart which accepts one argument, the name of the item you wish to remove. If the item isn't in the cart, the function should print out ""That item is not in your cart."". If the item is in your cart, it should remove the object from the cart array. Then return the cart. (HINT: Check each object's key to see if it matches the parameter, then remove it if it matches. You might find hasOwnProperty to be useful.)


Define a function placeOrder which accepts one argument, a credit card number. If no argument is received, then the function should print out ""We don't have a credit card on file for you to place your order."". If there is a credit card on file, the function should print out ""Your total cost is $${total()}, which will be charged to the card ${cardNumber}."". The function should empty the cart array.

 View Online Shopping Lab on Learn.co and start learning to code for free.",3
https://github.com/jakeheis/objc-TimesSquare,# TimesSquare, TimesSquare is a library to display a calendar in a view in your iPhone or iPad app. We wrote it after searching high and low for a better way and finding none.,1
https://github.com/jakeheis/objc-TimesSquare,## Usage,   Easy: create an instance of TSQCalendarView. Set its firstDate and lastDate properties to give yourself a range of dates.,3
https://github.com/jakeheis/objc-TimesSquare,## Calendars,"   While we fully expect you'll use it to display a Gregorian calendar most of the time, TimesSquare is just as happy displaying any of the calendars NSCalendar supports. The included test app shows you how to do this.",3
https://github.com/jakeheis/objc-TimesSquare,## Further documentation,"  If you install appledoc (""brew install appledoc"") you can build the ""TimesSquare Documentation"" target in Xcode and see (and search!) the full API in your documentation window.",6
https://github.com/jakeheis/objc-TimesSquare,## Contributing,"  We're glad you're interested in TimesSquare, and we'd love to see where you take it. Any contributors to the master TimesSquare repository must sign the Individual Contributor License Agreement (CLA). It's a short form that covers our bases and makes sure you're eligible to contribute. When you have a change you'd like to see in the master repository, send a pull request. Before we merge your request, we'll make sure you're in the list of people who have signed a CLA. Thanks, and happy date picking!",7
https://github.com/tfereyre/sonar-examples,## DEPRECATED," This repository is DEPRECATED and will be soon replaced by : 
https://github.com/SonarSource/sonar-scanning-examples : show how to use the SonarQube Scanners : In Progress
https://github.com/SonarSource/sonar-custom-rules-examples : show how to write custom rules : Done
https://github.com/SonarSource/sonar-custom-plugin-example : show how to write a SonarQube Plugin compatible with SQ LTS : Done
",4
https://github.com/tfereyre/sonar-examples,## Configuration of Projects,"  The directory '/projects' contains sample projects for: 
the different analyzers (SonarQube Scanner, SonarQube for Maven, SonarQube for MSBuild, ...)
the different languages (Java, JavaScript, Cobol, C#, ...)
the different ways to import unit tests and get code coverage data into SonarQube
",3
https://github.com/tfereyre/sonar-examples,## SonarQube Plugins,"  The directory '/plugins' contains the most frequent kinds of custom plugins: 
Custom Rules for Java, JavaScript and PHP Analyzers
New metric, computation of high level measures, post jobs
",3
https://github.com/tfereyre/sonar-examples,### License,"  Copyright 2011-2017 SonarSource. Licensed under the GNU Lesser General Public License, Version 3.0",5
https://github.com/e0003083/website,# Source Code for the CS2103 Module Website, This repo hosts the source code for the CS2103 (Software Engineering) module at SoC (NUS),1
https://github.com/e0003083/website,## Released version,"  The released version of this website is available here.
The released version may be behind the latest version in this repo.",4
https://github.com/e0003083/website,## Contributing,"  We welcome contributions from current/past CS2103 students. The easiest way to contribute is to post bugs and suggestion in our issue tracker. If you would like to contribute code, here is the procedure: 
Fork this repo.
Make sure what you want to contribute is already listed as an open issue in our issue tracker.
If it is not, post it as an issue first and wait for it to get accepted (an issue is considered
'accepted' when it is assigned a priority.* label).
You may choose an issue labeled forFirstTimers as your first issue, if there are any.
But do not do more than one forFirstTimers issues.
Clone your fork onto your Computer.
Create a branch. The branch name should be in the format issue-number-some-key-words
i.e. issue number followed by 2-4 key words related to the issue description
e.g. 12-broken-link-week1-schedule
Implement your fix in the new branch.

Use 2 spaces for indenting (not tab, not 4 or 8 spaces)
Minimize inline styles.
When in doubt, you can refer to these style guides from the
TEAMMATES project:
JavaScript,
CSS,
HTML


Test the code in your computer. 
Tip: When testing local html files, some JavaScripts might not work
in Firefox or Chrome. In that case you can use IE. Alternatively, you can start a web server
in your Computer
When the fix is ready,

Ensure that your fork has the latest code from this repo (the repo you forked from is called
the 'upstream` repo). The code in the upstream repo may have been updated while you were fixing the issue.
If that is the case, sync your fork with upstream repo
Stage your changes:
Your reviewer might want to see how your changes look like to a viewer of the website. To create a staging
site using GitHub Pages feature, create a branch called gh-pages, merge your branch to the gh-pages branch
and push the gh-pages branch to your fork. A running version of the website should now be available from
the corresponding github.io URL. Here is an example http://bobby-lin.github.io/website/.
Push the code to your fork and create a pull request (PR) against the master
branch of this repo.
When naming the PR, copy paste the name of the issue you are fixing, including the original issue number.
e.g. Handbook TOC links are not working in iPhone browser #19 
In the PR description, mention Fixes #IssueNumber (e.g. Fixes #24 so that the corresponding issue
is closed automatically when the PR is merged.
Remember to mention the URL of the staging site in your PR description. Here
is an example.
Check the diff view of the PR to ensure it contains the intended changes only.


Your code will be reviewed by someone from the dev team. If the reviewer requests changes,
revise the code, push the new commits to your branch, and post a comment to say the pull request
is ready for review again.
When your code is acceptable, it will be merged to this repo. Your fix will be included in the
next release of the website.
After your fix is merged, you may wish to create another PR to add your name to the CONTRIBUTORS.md file.
There is no need to create a corresponding issue for that PR.
",7
https://github.com/e0003083/website,## Acknowledgements,  Many thanks to our contributors.,5
https://github.com/merlincharlotte/search-github-users,# Angular QuickStart Source,"  This repository holds the TypeScript source code of the angular.io quickstart,
the foundation for most of the documentation samples and potentially a good starting point for your application. It's been extended with testing support so you can start writing tests immediately. This is not the perfect arrangement for your application. It is not designed for production.
It exists primarily to get you started quickly with learning and prototyping in Angular We are unlikely to accept suggestions about how to grow this QuickStart into something it is not.
Please keep that in mind before posting issues and PRs.",1
https://github.com/merlincharlotte/search-github-users,## Updating to a newer version of the Quickstart Repo,"  From time to time the QuickStart will be enhanced with support for new features or to reflect
changes to the official Style Guide. You can update your existing project to an up-to-date QuickStart by following these instructions: 
Create a new project using the instructions below
Copy the code you have in your project's main.ts file onto src/app/main.ts in the new project
Copy your old app folder into src/app
Delete src/app/main.ts if you have one (we now use src/main.ts instead)
Copy your old index.html, styles.css and tsconfig.json into src/
Install all your third party dependencies
Copy your old e2e/ folder into e2e/
Copy over any other files you added to your project
Copy your old .git folder into your new project's root
 Now you can continue working on the new project.",3
https://github.com/merlincharlotte/search-github-users,## Prerequisites,"  Node.js and npm are essential to Angular development. 
Get it now Verify that you are running at least node v4.x.x and npm 3.x.x
by running node -v and npm -v in a terminal/console window.
Older versions produce errors. We recommend nvm for managing multiple versions of node and npm.",3
https://github.com/merlincharlotte/search-github-users,## Create a new project based on the QuickStart,"  Clone this repo into new project folder (e.g., my-proj). git clone https://github.com/angular/quickstart  my-proj
cd my-proj We have no intention of updating the source on angular/quickstart.
Discard the .git folder.. rm -rf .git  # OS/X (bash)
rd .git /S/Q # windows",3
https://github.com/merlincharlotte/search-github-users,### Delete _non-essential_ files (optional),"  You can quickly delete the non-essential files that concern testing and QuickStart repository maintenance
(including all git-related artifacts such as the .git folder and .gitignore!)
by entering the following commands while in the project folder:",3
https://github.com/merlincharlotte/search-github-users,##### OS/X (bash),"  xargs rm -rf < non-essential-files.osx.txt
rm src/app/*.spec*.ts
rm non-essential-files.osx.txt",3
https://github.com/merlincharlotte/search-github-users,##### Windows,"  for /f %i in (non-essential-files.txt) do del %i /F /S /Q
rd .git /s /q
rd e2e /s /q",3
https://github.com/merlincharlotte/search-github-users,### Create a new git repo,"  You could start writing code now and throw it all away when you're done.
If you'd rather preserve your work under source control, consider taking the following steps. Initialize this project as a local git repo and make the first commit: git init
git add .
git commit -m ""Initial commit"" 
Recover the deleted .gitignore from the QuickStart repository
if you lost it in the Delete non-essential files step.
 Create a remote repository for this project on the service of your choice. Grab its address (e.g. https://github.com/<my-org>/my-proj.git) and push the local repo to the remote. git remote add origin <repo-address>
git push -u origin master",3
https://github.com/merlincharlotte/search-github-users,## Install npm packages,"  
See npm and nvm version notes above
 Install the npm packages described in the package.json and verify that it works: npm install
npm start 
Doesn't work in Bash for Windows which does not support servers as of January, 2017.
 The npm start command first compiles the application,
then simultaneously re-compiles and runs the lite-server.
Both the compiler and the server watch for file changes. Shut it down manually with Ctrl-C. You're ready to write your application.",3
https://github.com/merlincharlotte/search-github-users,### npm scripts,"  We've captured many of the most useful commands in npm scripts defined in the package.json: 
npm start - runs the compiler and a server at the same time, both in ""watch mode"".
npm run build - runs the TypeScript compiler once.
npm run build:w - runs the TypeScript compiler in watch mode; the process keeps running, awaiting changes to TypeScript files and re-compiling when it sees them.
npm run serve - runs the lite-server, a light-weight, static file server, written and maintained by
John Papa and
Christopher Martin
with excellent support for Angular apps that use routing.
 Here are the test related scripts: 
npm test - compiles, runs and watches the karma unit tests
npm run e2e - compiles and run protractor e2e tests, written in Typescript (*e2e-spec.ts)
",3
https://github.com/merlincharlotte/search-github-users,## Testing,"  The QuickStart documentation doesn't discuss testing.
This repo adds both karma/jasmine unit test and protractor end-to-end testing support. These tools are configured for specific conventions described below. It is unwise and rarely possible to run the application, the unit tests, and the e2e tests at the same time.
We recommend that you shut down one before starting another.",3
https://github.com/merlincharlotte/search-github-users,### Unit Tests,"  TypeScript unit-tests are usually in the src/app folder. Their filenames must end in .spec.ts. Look for the example src/app/app.component.spec.ts.
Add more .spec.ts files as you wish; we configured karma to find them. Run it with npm test That command first compiles the application, then simultaneously re-compiles and runs the karma test-runner.
Both the compiler and the karma watch for (different) file changes. Shut it down manually with Ctrl-C. Test-runner output appears in the terminal window.
We can update our app and our tests in real-time, keeping a weather eye on the console for broken tests.
Karma is occasionally confused and it is often necessary to shut down its browser or even shut the command down (Ctrl-C) and
restart it. No worries; it's pretty quick.",3
https://github.com/merlincharlotte/search-github-users,### End-to-end (E2E) Tests,"  E2E tests are in the e2e directory, side by side with the src folder.
Their filenames must end in .e2e-spec.ts. Look for the example e2e/app.e2e-spec.ts.
Add more .e2e-spec.js files as you wish (although one usually suffices for small projects);
we configured Protractor to find them. Thereafter, run them with npm run e2e. That command first compiles, then simultaneously starts the lite-server at localhost:8080
and launches Protractor. The pass/fail test results appear at the bottom of the terminal window.
A custom reporter (see protractor.config.js) generates a  ./_test-output/protractor-results.txt file
which is easier to read; this file is excluded from source control. Shut it down manually with Ctrl-C.",3
https://github.com/mgechev/nshahpazov.github.io,# Minimal Mistakes, Minimal Mistakes is a two column responsive Jekyll theme perfect for powering your GitHub hosted blog.,1
https://github.com/mgechev/nshahpazov.github.io,## Minimal Mistakes is all about:,"  
Responsive templates. Looking good on mobile, tablet, and desktop.
Gracefully degrading in older browsers. Compatible with Internet Explorer 8+ and all modern browsers.
Minimal embellishments -- content first.
Optional large feature images for posts and pages.
Simple and clear permalink structure.
Custom 404 page to get you started.
Support for Disqus Comments
  See a live version of Minimal Mistakes hosted on GitHub.",1
https://github.com/mgechev/nshahpazov.github.io,## Getting Started,  Minimal Mistakes takes advantage of Sass and data files to make customizing easier. These features require Jekyll 2.x and will not work with older versions of Jekyll. To learn how to install and use this theme check out the Setup Guide for more information.,36
https://github.com/sdtm1016/debugger.html,# debugger.html," debugger.html is a hackable debugger for modern times, built from the ground up using React and Redux.  It is designed to be approachable, yet powerful.  And it is engineered to be predictable, understandable, and testable. Mozilla created this debugger for use in the Firefox Developer Tools.  And we've purposely created this project in Github, using modern toolchains.  We hope to not only to create a great debugger that works with the Firefox and Chrome Debugging Protocol but development community that can embed this debugger in your own projects with tools like NPM.  

",12
https://github.com/sdtm1016/debugger.html,## Getting Started,"  Here are instructions to get the debugger.html application installed and running. 
npm install - Install dependencies
npm start - Start development web server
open http://localhost:8000 - Open in any modern browser
 Now you have the debugger.html web app running, follow the instructions shown on that page to start up debug target like a web browser or node.js. Please read Getting Started in our CONTRIBUTING document for more detailed instructions.",3
https://github.com/sdtm1016/debugger.html,## Getting Involved,"  This is an open source project and we would love your help. We have prepared a CONTRIBUTING guide to help you get started, here are some quick links to common questions. 
Reporting Bugs
Suggesting Enhancements
Your First Code Contribution
Pull Requests
Writing Code

Hot Reloading
Tests

Unit Tests
Integration Tests
Linting
Storybook




 We use the up for grabs label to indicate this work is open for anyone to take.  If you already know what you're doing and want to dive in, take a look at those issues. We strive for collaboration with mutual respect for each other.   Mozilla also has a set of participation guidelines which goes into greater detail specific to Mozilla employees and contributors.",7
https://github.com/sdtm1016/debugger.html,## Discussion,  We're all on Mozilla's IRC in the #devtools-html channel on irc.mozilla.org.,5
https://github.com/sdtm1016/debugger.html,## License,  MPL 2,5
https://github.com/pat/drumknott,# Drumknott CLI," Command line tool for the Drumknott search service. When invoked, it takes each of your compiled Jekyll pages and uploads them to Drumknott.",1
https://github.com/pat/drumknott,## Installation,"  $ gem install drumknott
",3
https://github.com/pat/drumknott,## Usage,"  From within the local Jekyll site directory, using the credentials provided by Drumknott: $ drumknott keys SITE_NAME SITE_KEY INCLUDE_PAGES
$ drumknott refresh
 The keys command will save your credentials to a .drumknott file in your site's directory. Do not commit this file to git! If you don't want to have that file saved, you can alternatively use the environment variables DRUMKNOTT_NAME and DRUMKNOTT_KEY respectively. By default, both posts and normal pages will be uploaded to Drumknott. If you only wish to include posts, the INCLUDE_PAGES argument in the keys command should be 'no'. This can also be managed via the DRUMKNOTT_PAGES environment variable. You can have visual output of the refresh if you also include the ruby-progressbar gem in your Gemfile (or, if you're not using a Gemfile, just have that gem installed). However, if you prefer quiet even though the gem's installed, set the DRUMKNOTT_SILENT environment variable to be 'true'.",3
https://github.com/pat/drumknott,## Development,"  After checking out the repo, run bin/setup to install dependencies. Then, run bin/console for an interactive prompt that will allow you to experiment.",3
https://github.com/pat/drumknott,## Contributing,"  Firstly, please note the Code of Conduct for all contributions to this project. If you accept that, then the steps for contributing are probably something along the lines of: 
Fork it ( https://github.com/pat/drumknott/fork )
Create your feature branch (git checkout -b my-new-feature)
Commit your changes (git commit -am 'Add some feature')
Push to the branch (git push origin my-new-feature)
Create a new Pull Request
",7
https://github.com/pat/drumknott,## Licence,"  Copyright (c) 2016-2020, Drumknott is developed and maintained by Pat Allan, and is released under the open MIT Licence.",5
https://github.com/jpbetz/prezto,# Prezto ?Instantly Awesome Zsh," For OSX, install: brew install coreutils
",1
https://github.com/jpbetz/prezto,## Installation,"Prezto will work with any recent release of Zsh, but the minimum required version is 4.3.11.

Launch Zsh:

zsh
Clone the repository:

git clone --recursive https://github.com/sorin-ionescu/prezto.git ""${ZDOTDIR:-$HOME}/.zprezto""
Create a new Zsh configuration by copying the Zsh configuration files provided:

setopt EXTENDED_GLOB
for rcfile in ""${ZDOTDIR:-$HOME}""/.zprezto/runcoms/^README.md(.N); do
  ln -s ""$rcfile"" ""${ZDOTDIR:-$HOME}/.${rcfile:t}""
done
Note: If you already have any of the given config files, ln will error. In simple cases you can add source ""${ZDOTDIR:-$HOME}/.zprezto/init.zsh"" to the bottom of your .zshrc to load prezto but keep your config intact. For more complicated setups, it is recommended that you back up your original configs and replace them with the provided prezto runcoms.

Set Zsh as your default shell:

chsh -s /bin/zsh
Open a new Zsh terminal window or tab.",3
https://github.com/jpbetz/prezto,### Troubleshooting,"  If you are not able to find certain commands after switching to Prezto,
modify the PATH variable in ~/.zprofile then open a new Zsh terminal
window or tab.",3
https://github.com/jpbetz/prezto,## Usage,"  Prezto has many features disabled by default. Read the source code and
accompanying README files to learn of what is available.",3
https://github.com/jpbetz/prezto,### Modules,"  
Browse /modules to see what is available.
Load the modules you need in ~/.zpreztorc then open a new Zsh terminal
window or tab.
",3
https://github.com/jpbetz/prezto,### Themes,"  

For a list of themes, type prompt -l.


To preview a theme, type prompt -p name.


Load the theme you like in ~/.zpreztorc then open a new Zsh terminal
window or tab.


",3
https://github.com/jpbetz/prezto,## Customization,"The project is managed via Git. It is highly recommended that you fork this project; so, that you can commit your changes and push them to GitHub to not lose them. If you do not know how to use Git, follow this tutorial and bookmark this reference.",3
https://github.com/jpbetz/prezto,## Resources,The Zsh Reference Card and the zsh-lovers man page are indispensable.,6
https://github.com/jpbetz/prezto,## License,This project is licensed under the MIT License.,5
https://github.com/hsugita/imas-producer_schedule,# Imas::ProducerSchedule," Welcome to your new gem! In this directory, you'll find the files you need to be able to package up your Ruby library into a gem. Put your Ruby code in the file lib/imas/producer_schedule. To experiment with that code, run bin/console for an interactive prompt. TODO: Delete this and the text above, and describe your gem",1
https://github.com/hsugita/imas-producer_schedule,## Installation,"  Add this line to your application's Gemfile: gem 'imas-producer_schedule' And then execute: $ bundle
 Or install it yourself as: $ gem install imas-producer_schedule
",3
https://github.com/hsugita/imas-producer_schedule,## Usage,  TODO: Write usage instructions here,3
https://github.com/hsugita/imas-producer_schedule,## Development,"  After checking out the repo, run bin/setup to install dependencies. You can also run bin/console for an interactive prompt that will allow you to experiment. To install this gem onto your local machine, run bundle exec rake install. To release a new version, update the version number in version.rb, and then run bundle exec rake release, which will create a git tag for the version, push git commits and tags, and push the .gem file to rubygems.org.",3
https://github.com/hsugita/imas-producer_schedule,## Contributing,  Bug reports and pull requests are welcome on GitHub at https://github.com/[USERNAME]/imas-producer_schedule.,7
https://github.com/hsugita/imas-producer_schedule,## License,  The gem is available as open source under the terms of the MIT License.,5
https://github.com/divampo/PHPStaticHelpers,# PHPStaticHelpers #, Static PHP classes-helpers Copyright (c) 2012 Dmitry Serpakov Licensed under the MIT license (http://www.opensource.org/licenses/mit-license.php),15
https://github.com/divampo/PHPStaticHelpers,## Dependence ##,  PHP 5.3+,3
https://github.com/divampo/PHPStaticHelpers,## Highlights: ##,"  
static usage
separate using
use own package name
",1
https://github.com/divampo/PHPStaticHelpers,## Usage ##,Include library:,3
https://github.com/divampo/PHPStaticHelpers,#!PHP,,-
https://github.com/divampo/PHPStaticHelpers,#!PHP,,-
https://github.com/divampo/PHPStaticHelpers,## Libraries ##,"HArray - working with arrays

createFromString - Get multilevel array from string, ignore nulls

createByKey - Create array with necessary structure

mergeReplace - Recursive merge and replace values in arrays

mapRecursive - Recursive call to each array value

addSlashes - Escape array values with addslashes

stripSlashes - Unescape array values with stripslashes

HClient - working with http client

getRealIP - Get real user IP-address

validateIP - IP validation

checkUserAgent - Check user agent for compliance

getBrowser - Get user browser name (use browsercap.ini)

HDate - working with dates

getRusWeekday - Get Russian weekday name

getRusMonth - Get Russian month name

convertToText - Convert date to Russian text format (ѧӧ, HH:mm) or to alternative format if unable

convert - Convert date to certain format

getDateDiff - Get time difference between dates (Russian)

parseDate - Parse date to array

getCalendar - Create array of days for input month

HFilesystem - working with filesystem

removeRecursive - Recursive directory delete

getImagePreview - Convert image path/url to certain format

HHeader - working with headers

location - Redirect to certain location

status404 - Send 404 headers

getStatusString - Get header by code

sendStatus - Send header by code

HString - working with strings

escape - Escape stings for output

bytes2Text - Calculate filesize to the smallest visualisation

getEvalResult - Get result of evaluated string (The eval() language construct is very dangerous!!!)

pluralForm - Get plural name of sth from input number (Russian)

crop - Cut the string to sertain length

shorten - Shorten the string

translit - Transliteration from Russian to English

transletter - Convert between Russian & English letters

ranking - Convert rating from one scale to another",3
https://github.com/manuelgu/discord-api-docs,# Discord Official API Documentation," This repo contains the official Discord API documentation, which can be viewed online HERE. Before submitting pull-requests, please remember to fully read the Contributing guidelines.",17
https://github.com/manuelgu/discord-api-docs,## Markdown Syntax,  This repository uses special markdown syntax that helps style the resulting web version of the documentation.,1
https://github.com/manuelgu/discord-api-docs,### H6 Headings,  H6 headings should be used above tables and code blocks to properly label them.,3
https://github.com/manuelgu/discord-api-docs,### Linking,"  Links between docs can be achieved by using a hash symbol (#), plus the markdown file name, plus another hash, and finally the dash-separated anchor. For instance, to link to the above H6 heading section: [Links to README.md H6](#README/h6-headings)",3
https://github.com/manuelgu/discord-api-docs,### Alert Boxes,"  Alert boxes are achieved by using a block quote that has one of 'warning', 'danger' or 'info' on the first line.",3
https://github.com/manuelgu/discord-api-docs,## Join the Unofficial Discord API Server,  The Unofficial Discord API server is a common hangout for library and bot developers alike. It's a great starting point for those looking to dive in and learn bot-creation with the Discord API. ,5
https://github.com/cloudfoundry/cf-mysql-release,# Cloud Foundry MySQL Service,,1
https://github.com/cloudfoundry/cf-mysql-release,### Table of contents," Components

Downloading a Stable Release

Development

Release notes & known issues

Deploying

Registering the Service Broker

Security Groups

Smoke Tests

Deregistering the Service Broker

CI",1
https://github.com/cloudfoundry/cf-mysql-release,## Components,"  A BOSH release of a MySQL database-as-a-service for Cloud Foundry using MariaDB Galera Cluster and a v2 Service Broker. 

ComponentDescription


CF MySQL Broker
Advertises the MySQL service and plans.  Creates and deletes MySQL databases and
    credentials (bindings) at the request of Cloud Foundry's Cloud Controller.
    


MySQL Server
The MySQL instances, either single or 3-node cluster. Currently using MariaDB 10 (versions vary by release).


Proxy
Switchboard; proxies to MySQL, severing connections on MySQL node failure.

 ",1
https://github.com/cloudfoundry/cf-mysql-release,### Proxy,"  Traffic to the MySQL cluster is routed through one or more proxy nodes. The current proxy implementation is Switchboard. This proxy acts as an intermediary between the client and the MySQL server, providing failover between MySQL nodes. The number of nodes is configured by the proxy job instance count in the deployment manifest. NOTE: If the number of proxy nodes is set to zero, apps will be bound to the IP address of the first MySQL node in the cluster. If that IP address should change for any reason (e.g. loss of a VM) or a proxy was subsequently added, one would need to re-bind all apps to the IP address of the new node. For more details see the proxy documentation. ",1
https://github.com/cloudfoundry/cf-mysql-release,### Dashboard,"  A user-facing service dashboard is provided by the service broker that displays storage utilization information for each service instance.
The dashboard is accessible by users via Single Sign-On (SSO) once authenticated with Cloud Foundry.
The dashboard URL can be found by running cf service MY_SERVICE_INSTANCE. Service authors interested in implementing a service dashboard accessible via SSO can follow documentation for Dashboard SSO.",1
https://github.com/cloudfoundry/cf-mysql-release,#### Prerequisites,"  

SSO is initiated when a user navigates to the URL found in the dashboard_url field. This value is returned to cloud controller by the broker in response to a provision request, and is exposed in the cloud controller API for the service instance. A users client must expose this field as a link, or it can be obtained via curl (cf curl /v2/service_instances/:guid) and copied into a browser.


SSO requires the following OAuth client to be configured in cf-release. This client is responsible for creating the OAuth client for the MySQL dashboard. Without this client configured in cf-release, the MySQL dashboard will not be accessible but the service will be otherwise functional. Registering the broker will display a warning to this effect.
properties:
  uaa:
    clients:
      cc-service-dashboards:
        secret: cc-broker-secret
        scope: cloud_controller.write,openid,cloud_controller.read,cloud_controller_service_permissions.read
        authorities: clients.read,clients.write,clients.admin
        authorized-grant-types: client_credentials


SSO was implemented in v169 of cf-release; if you are on an older version of cf-release you'll encounter an error when you register the service broker. If upgrading cf-release is not an option, try removing the following lines from the cf-mysql-release manifest and redeploy.
dashboard_client:
  id: p-mysql
  secret: yoursecret

",3
https://github.com/cloudfoundry/cf-mysql-release,#### Implementation Notes,"  The following links show how this release implements Dashboard SSO integration. 
Update the broker catalog with the dashboard client properties
Implement oauth workflow with the omniauth-uaa-oauth2 gem
Use the cf-uaa-lib gem to get a valid access token and request permissions on the instance
Before showing the user the dashboard, the broker checks to see if the user is logged-in and has permissions to view the usage details of the instance.
",3
https://github.com/cloudfoundry/cf-mysql-release,### Broker Configuration, ,3
https://github.com/cloudfoundry/cf-mysql-release,#### Require HTTPS when visiting Dashboard,"  The dashboard URL defaults to using the https scheme. This means any requests using http will automatically be redirected to https instead.
To override this, you can change jobs.cf-mysql-broker.ssl_enabled to false. Keep in mind that changing the ssl_enabled setting for an existing broker will not update previously advertised dashboard URLs.
Visiting the old URL may fail if you are using the SSO integration,
because the OAuth2 client registered with UAA will expect users to both come from and return to a URI using the scheme
implied by the ssl_enabled setting. Note:
If using https, the broker must be reached through an SSL termination proxy.
Connecting to the broker directly on https will result in a port 443: Connection refused error.",3
https://github.com/cloudfoundry/cf-mysql-release,#### Trust Self-Signed SSL Certificates,"  By default, the broker will not trust a self-signed SSL certificate when communicating with cf-release.
To trust self-signed SSL certificates, you can change jobs.cf-mysql-broker.skip_ssl_validation to true. ",3
https://github.com/cloudfoundry/cf-mysql-release,## Downloading a Stable Release,"  Stable releases, also known as final releases, are available for general use. Release notes and source code are available on github.
Instructions for uploading a final release to your BOSH director can be found on bosh.io. Note: If your BOSH director's able to access the Internet, you don't need to download and upload a release to your BOSH director. When using cf-mysql-deployment, the correct release is referenced in the manifest, and will be automatically retrieved by the BOSH director. ",3
https://github.com/cloudfoundry/cf-mysql-release,## Development,"  See our contributing docs for instructions on how to make a pull request. This BOSH release doubles as a $GOPATH. It will automatically be set up for
you if you have direnv installed. # fetch release repo
mkdir -p ~/workspace
cd ~/workspace
git clone https://github.com/cloudfoundry/cf-mysql-release.git
cd cf-mysql-release/

# switch to develop branch (not master!)
git checkout develop

# automate $GOPATH and $PATH setup
direnv allow

# initialize and sync submodules
./scripts/update
 If you do not wish to use direnv, you can simply source the .envrc file in the root
of the release repo.  You may manually need to update your $GOPATH and $PATH variables
as you switch in and out of the directory. ",37
https://github.com/cloudfoundry/cf-mysql-release,## Release Notes & Known Issues,"  Release Notes Known Issues For more information, check out the documentation. ",46
https://github.com/cloudfoundry/cf-mysql-release,## Deploying,See https://github.com/cloudfoundry/cf-mysql-deployment to deploy cf-mysql release.,6
https://github.com/D630/bds,##### Llist,"The double linked list gets a controlling associative array variable with the keys lname[type], lname[nodes] and lname[id] AND a second index array variable lname_idx, which indexes all nodes in the right order. (Of course, lname_idx isn't necessary. But iterating over the list is still slower.)

Each node of the list will get its own associative array variable with the following keys: lname_$((lname[id] + 1))=([prev]= [next]= [data]=).

set         lname [element ...]
unset       lname

insert      lname index [element ...]
append      lname [element ...]
prepend     lname [element ...]
replace     lname first last [element ...]

index       lname [index]
range       lname [-r] first last

length      lname [-t]

traverse    lname [-r] index",1
https://github.com/D630/bds,##### Queue," normal
One associative array variable is being used. Its keys are qname[type], qname[first] and qname[last].

set         qname
pushl       qname [element]
pushr       qname [element]
popl        qname
popr        qname
ext
One associative array variable + two indexed array variables for head and tail are being used. Keys are qname[type], qname[head], qname[tail], and qname[head_first], qname[tail_first]

set         qname
pushl       qname [element]
pushr       qname [element]
popl        qname
popr        qname",1
https://github.com/babyformula/shadowsocks,# shadowsocks," 

 A fast tunnel proxy that helps you bypass firewalls. Features: 
TCP & UDP support
User management API
TCP Fast Open
Workers and graceful restart
Destination IP blacklist
",1
https://github.com/babyformula/shadowsocks,## Server, ,13
https://github.com/babyformula/shadowsocks,### Install,"  Debian / Ubuntu: apt-get install python-pip
pip install shadowsocks
 CentOS: yum install python-setuptools && easy_install pip
pip install shadowsocks
 Windows: See Install Server on Windows",3
https://github.com/babyformula/shadowsocks,### Usage,"  ssserver -p 443 -k password -m aes-256-cfb
 To run in the background: sudo ssserver -p 443 -k password -m aes-256-cfb --user nobody -d start
 To stop: sudo ssserver -d stop
 To check the log: sudo less /var/log/shadowsocks.log
 Check all the options via -h. You can also use a Configuration file
instead.",3
https://github.com/babyformula/shadowsocks,## Client,"  
Windows / OS X
Android / iOS
OpenWRT
 Use GUI clients on your local PC/phones. Check the README of your client
for more information.",3
https://github.com/babyformula/shadowsocks,## Documentation,  You can find all the documentation in the Wiki.,6
https://github.com/babyformula/shadowsocks,## License,"  Copyright 2015 clowwindy Licensed under the Apache License, Version 2.0 (the ""License""); you may
not use this file except in compliance with the License. You may obtain
a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
License for the specific language governing permissions and limitations
under the License.",5
https://github.com/babyformula/shadowsocks,## Bugs and Issues,"  
Troubleshooting
Issue Tracker
Mailing list
",5
https://github.com/babyformula/shadowsocks,# shadowsocks, ,1
https://github.com/imlucas/node-forro,# forro," Encapsulate form validation definitions in objects, using the excellent
validator module
to handle the actual validation and casting. I missed the form definition pattern Python has adapted with libraries like
web.py and
wtforms.
Being able to declare form schema's in one place, and being able to trust
in your controller code that what you're dealing with has already been
validate and cast the way you want is pretty great.
forro adds these niceties to Javascript land. ",1
https://github.com/imlucas/node-forro,## Example,"  var express = require(""express""),
    app = express(),
    forro = require('forro'),
    StringField = forro.StringField,
    BooleanField = forro.BooleanField,
    DateField = forro.DateField;

// ... some code

var AuthForm = forro({
    'username': StringField.required().max(32),
    'password': StringField.required().length(4, 25),
    'remember_me': BooleanField
});


app.post(""/login"", AuthForm.middleware(), function(req, res){
    // Middleware already validated for us
    // and sent back a 400 error if validation failed.
    // now we can just call out authentication function with
    // req.form.val('username') and req.form.val('password')
});


 var BookmarkForm = forro({
    'url': StringField.required().url(),
    'tags': StringField.required().use(function tokenize(str){
        return str.split(',').map(function(s){
            return s.trim().toLowerCase();
        }).filter(function(s){
            return s.length > 0;
        });
    }),
    'created_on': DateField.default(DateField.now)
});

app.post(""/bookmark"", BookmarkForm.middleware(), function(req, res){
    saveBookmark(req.form.val('url'), req.form.val('tags'), req.form.val('created_on'), function(err, bookmark){
        if(err) return next(err);
        res.send(bookmark);
    });
});

// ... some more code
",3
https://github.com/imlucas/node-forro,## Install,"   npm install forro
",3
https://github.com/imlucas/node-forro,## Testing,"  git clone
npm install
mocha
",3
https://github.com/imlucas/node-forro,## License,  MIT,5
https://github.com/boumer/neocities,# Neocities.org," 
 The web site for Neocities! It's open source. Want a feature on the site? Send a pull request!",1
https://github.com/boumer/neocities,## Getting Started,"  Neocities can be quickly launched in development mode with Vagrant. Vagrant builds a virtual machine that automatically installs everything you need to run Neocities as a developer. Install Vagrant, then from the command line: vagrant up --provision
  vagrant ssh
cd /vagrant
bundle exec rackup
 Now you can access the running site from your browser: http://127.0.0.1:9292",3
https://github.com/boumer/neocities,## Want to contribute?,"  If you'd like to fix a bug, or make an improvement, or add a new feature, it's easy! Just send us a Pull Request. 
Fork it (http://github.com/YOURUSERNAME/neocities/fork)
Create your feature branch (git checkout -b my-new-feature)
Commit your changes (git commit -am 'Add some feature')
Push to the branch (git push origin my-new-feature)
Create new Pull Request
",7
https://github.com/att-bdpaas/webhdfs,"# webhdfs - A client library implementation for Hadoop WebHDFS, and HttpFs, for Ruby"," The webhdfs gem is to access Hadoop WebHDFS (EXPERIMENTAL: and HttpFs). WebHDFS::Client is a client class, and WebHDFS::FileUtils is utility like 'fileutils'.",1
https://github.com/att-bdpaas/webhdfs,## Installation,"  gem install webhdfs
",3
https://github.com/att-bdpaas/webhdfs,## Usage, ,3
https://github.com/att-bdpaas/webhdfs,### WebHDFS::Client,"  For client object interface: require 'webhdfs'
client = WebHDFS::Client.new(hostname, port)
# or with pseudo username authentication
client = WebHDFS::Client.new(hostname, port, username)
 To create/append/read files: client.create('/path/to/file', data)
client.create('/path/to/file', data, :overwrite => false, :blocksize => 268435456, :replication => 5, :permission => 0666)

#This does not require whole data in memory, and it can be read chunk by chunk, ex: File data
client.create('/path/to/file', file_IO_handle, :overwrite => false, :permission => 0666)

client.append('/path/to/existing/file', data)

client.read('/path/to/target') #=> data
client.read('/path/to/target' :offset => 2048, :length => 1024) #=> data
 To mkdir/rename/delete directories or files: client.mkdir('/hdfs/dirname')
client.mkdir('/hdfs/dirname', :permission => 0777)

client.rename(original_path, dst_path)

client.delete(path)
client.delete(dir_path, :recursive => true)
 To get status or list of files and directories: client.stat(file_path) #=> key-value pairs for file status
client.list(dir_path)  #=> list of key-value pairs for files in dir_path
 And, 'content_summary', 'checksum', 'homedir', 'chmod', 'chown', 'replication' and 'touch' methods available. For known errors, automated retries are available. Set retry_known_errors option as true. #### To retry for LeaseExpiredException automatically
client.retry_known_errors = true

# client.retry_interval = 1 # [sec], default: 1
# client.retry_times = 1 # [times], default: 1
",3
https://github.com/att-bdpaas/webhdfs,### WebHDFS::FileUtils,"  require 'webhdfs/fileutils'
WebHDFS::FileUtils.set_server(host, port)
# or
WebHDFS::FileUtils.set_server(host, port, username, doas)

WebHDFS::FileUtils.copy_from_local(localpath, hdfspath)
WebHDFS::FileUtils.copy_to_local(hdfspath, localpath)

WebHDFS::FileUtils.append(path, data)
",3
https://github.com/att-bdpaas/webhdfs,### For HttpFs,"  For HttpFs instead of WebHDFS: client = WebHDFS::Client.new('hostname', 14000)
client.httpfs_mode = true

client.read(path) #=> data

# or with webhdfs/filetuils
WebHDFS::FileUtils.set_server('hostname', 14000)
WebHDFS::FileUtils.set_httpfs_mode
WebHDFS::FileUtils.copy_to_local(remote_path, local_path)
",3
https://github.com/att-bdpaas/webhdfs,### For HTTP Proxy servers,"  client = WebHDFS::Client.new('hostname', 14000, 'proxy.server.local', 8080)
client.proxy_user = 'jack'   # if needed
client.proxy_pass = 'secret' # if needed
",3
https://github.com/att-bdpaas/webhdfs,### For SSL,"  Note that net/https and openssl libraries must be available: client = WebHDFS::Client.new('hostname', 4443)
client.ssl = true
client.ssl_ca_file = ""/path/to/ca_file.pem"" # if needed
client.ssl_varify_mode = :peer # if needed (:none or :peer)
",3
https://github.com/att-bdpaas/webhdfs,### For Kerberos Authentication,"  Note that gssapi library must be available: client = WebHDFS::Client.new('hostname', 14000)
client.kerberos = true
",3
https://github.com/att-bdpaas/webhdfs,## AUTHORS,"  
Kazuki Ohta kazuki.ohta@gmail.com
TAGOMORI Satoshi tagomoris@gmail.com
",5
https://github.com/att-bdpaas/webhdfs,## LICENSE,"  
Copyright: Copyright (c) 2012- Fluentd Project
License: Apache License, Version 2.0
",5
https://github.com/aforward-oss/chef-redis,# DESCRIPTION:," Installs Redis. Redis is an open source, advanced key-value store. It is often referred to as a data structure server since keys can contain strings, hashes, lists, sets and sorted sets. Details http://redis.io/ ",16
https://github.com/aforward-oss/chef-redis,# How to add to your cookbook repository #,"  Consider using our chef-solo bootstrap project (includes a simple deployment script for synching with your remote servers). More information at: https://github.com/aforward/chef-bootstrap git clone https://github.com/aforward/chef-bootstrap YOUR_REPO_ROOT
cd YOUR_REPO_ROOT
cp ~/.ssh/id_dsa.pub ./bootstrap/root_authorized_keys
bundle install
 Then, consider using a git submodule so that you can monitor changes in this cookbook separately. For more info, check out the Pro Git book. cd YOUR_REPO_ROOT
git submodule add https://github.com/aforward/chef-redis.git chef/cookbooks/redis
",36
https://github.com/aforward-oss/chef-redis,# REQUIREMENTS:,  None (please correct if you encounter issues). Currently tested on Ubuntu 10.04 and 12.04.,3
https://github.com/aforward-oss/chef-redis,# ATTRIBUTES:,"  ['redis']['bind']         			# ""127.0.0.1""
['redis']['port']         			# ""6379""
['redis']['config_path']  			# ""/etc/redis/redis.conf""
['redis']['daemonize']    			# ""yes""
['redis']['timeout']      			# ""300""
['redis']['loglevel']     		 	# ""notice""
['redis']['password']     		 	# nil
['redis']['include_monit']     	# nil

['redis']['source']['version']          # ""2.4.1""
['redis']['source']['prefix']           # ""/usr/local""
['redis']['source']['tar_url']          # ""http://redis.googlecode.com/files/redis-2.4.1.tar.gz""
['redis']['source']['tar_checksum']     # ""38e02...""
['redis']['source']['create_service']   # true
['redis']['source']['user']             # ""redis""
['redis']['source']['group']            # ""redis""
",3
https://github.com/aforward-oss/chef-redis,# USAGE:,"  
Add cookbook redis to your runlist. This will install redis on your machine.
Add cookbook redis::source to your runlist. This will build redis on your machine from source.
Add cookbook redis::gem to your runlist. This will install the redis Rubygem.
Add cookbook redis::remove to your runlist if you want to remove redis on your machine.
",3
https://github.com/Apentz49/django-movies-api,# Django Movie API,,1
https://github.com/Apentz49/django-movies-api,## Description,  Create a RESTful API that you can perform CRUD actions on a basic django model.,1
https://github.com/Apentz49/django-movies-api,## Learning Objectives,"  After completing this assignment, you should be able to: 
Create an API of CRUD views for the Movie model.
",12
https://github.com/Apentz49/django-movies-api,## Details, ,3
https://github.com/Apentz49/django-movies-api,### Deliverables,"  
A Git repo called django-movies-api containing at least:

a requirements.txt file
a README.md file
a Django project called crud containing an app with API views for the Movie model.


",3
https://github.com/Apentz49/django-movies-api,### Normal Mode,"  Included is a basic app where template driven views allow a user to create/read/delete new and existing
movies in the database.  Create an app called api that all API requests will use and correctly perform the verb
you are expecting. Required verbs to implement: 
GET
POST
PUT
DELETE
 Required functionality to implment: 
Query for all movies
Query for a specific movie
Create a new movie in the database
Update existing fields on an existing movie
Delete an existing movie
 How you choose to implement your API is up to you. The one hard requirement is that you do not rely on an external
API framework. Choices like class-based or function-based views are up to you. In fact for clarity you may find
function based views more of an optimal choice for this assignment.",13
https://github.com/Apentz49/django-movies-api,### Hard Mode,"  In addition to the normal mode requirements adapt your movie model to be able to load in your movielens dataset (use
a small dataset if you prefer) and adapt your views to be able to work with the new fields.",3
https://github.com/Apentz49/django-movies-api,### Additional Resources:,  Star Wars API Retrieving the method verb in a django view Naming RESTful resources,6
https://github.com/schmittjoh/jmsPaymentPlugin,# What the plugin does for you," jmsPaymentPlugin is designed to provide a generic persistence layer for processing payments. 
It is not coupled to any specific payment provider, or process flow.
It does not make assumptions about your domain model.
It has a flexible event system that allows you to hook into the payment process without altering payment classes.
It is easy to add new payment methods (support for PayPal, and Micropayment already built-in)
It is robust, and stable due to many unit tests.
",1
https://github.com/schmittjoh/jmsPaymentPlugin,# What's next?,  Getting started/Installation Working with Payments,6
https://github.com/schmittjoh/jmsPaymentPlugin,# Contributing,"  You can report bugs directly through github: Report Bug If you want to contribute new features, a post on the symfony mailing list would be appreciated, so we can discuss how to best implement the desired features.",7
https://github.com/jmorcos22/odoo,## Odoo," Odoo is a suite of web based open source business apps. The main Odoo Apps include an Open Source CRM, Website Builder, eCommerce, Project Management, Billing & Accounting, Point of Sale, Human Resources, Marketing, Manufacturing, Purchase Management, ... Odoo Apps can be used as stand-alone applications, but they also integrate seamlessly so you get
a full-featured Open Source ERP when you install several Apps.",1
https://github.com/jmorcos22/odoo,## Getting started with Odoo,"  For a standard installation please follow the Setup instructions
from the documentation. If you are a developer you may type the following command at your terminal: wget -O- https://raw.githubusercontent.com/odoo/odoo/master/odoo.py | python
 Then follow the developer tutorials",3
https://github.com/jmorcos22/odoo,## For Odoo employees,"  To add the odoo-dev remote use this command: $ ./odoo.py setup_git_dev
 To fetch odoo merge pull requests refs use this command: $ ./odoo.py setup_git_review
",3
https://github.com/henvic/pb,# Terminal progress bar for Go, Simple progress bar for console programs.,1
https://github.com/henvic/pb,## Installation,"  go get gopkg.in/cheggaaa/pb.v1
",3
https://github.com/henvic/pb,## Usage,"  package main

import (
	""gopkg.in/cheggaaa/pb.v1""
	""time""
)

func main() {
	count := 100000
	bar := pb.StartNew(count)
	for i := 0; i < count; i++ {
		bar.Increment()
		time.Sleep(time.Millisecond)
	}
	bar.FinishPrint(""The End!"")
} Result will be like this: > go run test.go
37158 / 100000 [================>_______________________________] 37.16% 1m11s
",3
https://github.com/henvic/pb,## Customization,"  // create bar
bar := pb.New(count)

// refresh info every second (default 200ms)
bar.SetRefreshRate(time.Second)

// show percents (by default already true)
bar.ShowPercent = true

// show bar (by default already true)
bar.ShowBar = true

// no counters
bar.ShowCounters = false

// show ""time left""
bar.ShowTimeLeft = true

// show average speed
bar.ShowSpeed = true

// sets the width of the progress bar
bar.SetWidth(80)

// sets the width of the progress bar, but if terminal size smaller will be ignored
bar.SetMaxWidth(80)

// convert output to readable format (like KB, MB)
bar.SetUnits(pb.U_BYTES)

// and start
bar.Start()",3
https://github.com/henvic/pb,## Progress bar for IO Operations,"  // create and start bar
bar := pb.New(myDataLen).SetUnits(pb.U_BYTES)
bar.Start()

// my io.Reader
r := myReader

// my io.Writer
w := myWriter

// create proxy reader
reader := bar.NewProxyReader(r)

// and copy from pb reader
io.Copy(w, reader) // create and start bar
bar := pb.New(myDataLen).SetUnits(pb.U_BYTES)
bar.Start()

// my io.Reader
r := myReader

// my io.Writer
w := myWriter

// create multi writer
writer := io.MultiWriter(w, bar)

// and copy
io.Copy(writer, r)",3
https://github.com/henvic/pb,## Custom Progress Bar Look-and-feel,"  bar.Format(""<.- >"")",3
https://github.com/henvic/pb,## Multiple Progress Bars (experimental and unstable),"  Do not print to terminal while pool is active. package main

import (
    ""math/rand""
    ""sync""
    ""time""

    ""gopkg.in/cheggaaa/pb.v1""
)

func main() {
    // create bars
    first := pb.New(200).Prefix(""First "")
    second := pb.New(200).Prefix(""Second "")
    third := pb.New(200).Prefix(""Third "")
    // start pool
    pool, err := pb.StartPool(first, second, third)
    if err != nil {
        panic(err)
    }
    // update bars
    wg := new(sync.WaitGroup)
    for _, bar := range []*pb.ProgressBar{first, second, third} {
        wg.Add(1)
        go func(cb *pb.ProgressBar) {
            for n := 0; n < 200; n++ {
                cb.Increment()
                time.Sleep(time.Millisecond * time.Duration(rand.Intn(100)))
            }
            cb.Finish()
            wg.Done()
        }(bar)
    }
    wg.Wait()
    // close pool
    pool.Stop()
} The result will be as follows: $ go run example/multiple.go 
First 141 / 1000 [===============>---------------------------------------] 14.10 % 44s
Second 139 / 1000 [==============>---------------------------------------] 13.90 % 44s
Third 152 / 1000 [================>--------------------------------------] 15.20 % 40s
",3
https://github.com/fredericletellier/udacity-xyzreader,#Project 5: Make Your App Material,"In this project, you will redesign an app to follow the Material Design guidelines and translate a set of static design mocks to a living and breathing app.",1
https://github.com/fredericletellier/udacity-xyzreader,##Why this Project,"This project gives you an opportunity to improve an apps design, a vital skill for building apps users will love. It also replicates a common developer task of updating and changing an app's design as new standards are released.",2
https://github.com/fredericletellier/udacity-xyzreader,##What Will I Learn?,"Through this project, you will:

Understand the fundamentals of Android design.
Apply Material Design guidelines to an mobile application.
Separate an interface into surfaces.
Effectively use transitions and motion.",1
https://github.com/fredericletellier/udacity-xyzreader,##How Do I Complete this Project?,"You will improve an app for this project:

XYZ Reader: A mock RSS feed reader featuring banner photos and shocking headlines!

Download the code here : https://www.udacity.com/api/nodes/4292653440/supplemental_media/xyzreaderzip/download?_ga=1.104131650.392489846.1464010250

The app is currently functional, and work in most cases for most users.

Your job will be to take the user feedback in the UI Review node, and implement changes that will improve the UI and make it conform to Material Design.",3
https://github.com/fredericletellier/udacity-xyzreader,###Supporting Courses,"You should have the skills you need to complete this app after completing:

Developing Android Apps https://classroom.udacity.com/courses/ud853
Advanced Android App Development https://classroom.udacity.com/courses/ud855
Material Design for Android Developers https://classroom.udacity.com/courses/ud862
You can also refer to the Material Design specification. http://www.google.com/design/spec/material-design/introduction.html",6
https://github.com/fredericletellier/udacity-xyzreader,###Required Tasks,"Download a zip file of the app.
Read the UI Review in the next node.
Spend time exploring the current state of the app, looking for ways it could be improved. The app will need multiple improvements. Be sure to look specifically at issues called out in the UI Review.
Execute the improvements!
Make a single GitHub repo with your code for the app and submit it through the Nanodegree portal. See the Submission and Evaluation node for detailed instructions.",3
https://github.com/fredericletellier/udacity-xyzreader,##User Feedback for XYZ Reader:,,6
https://github.com/fredericletellier/udacity-xyzreader,###Lyla says:,This app is starting to shape up but it feels a bit off in quite a few places. I can't put finger on it but it feels odd.,3
https://github.com/fredericletellier/udacity-xyzreader,###Jay says:,"Is the text supposed to be so wonky and unreadable? It is not accessible to those of us without perfect vision.""",3
https://github.com/fredericletellier/udacity-xyzreader,###Kagure says:,The color scheme is really sad and I shouldn't feel sad.,3
https://github.com/fredericletellier/udacity-xyzreader,# Rubric,,3
https://github.com/fredericletellier/udacity-xyzreader,### Required Components,"App uses the Design Support library and its provided widget types (FloatingActionButton, AppBarLayout, SnackBar, etc).
App uses CoordinatorLayout for the main Activity.
App theme extends from AppCompat.
App uses an AppBar and associated Toolbars.
App provides a Floating Action Button for the most common action(s).
App properly specifies elevations for app bars, FABs, and other elements specified in the Material Design specification.
App has a consistent color theme defined in styles.xml. Color theme does not impact usability of the app.
App provides sufficient space between text and surrounding elements.
App uses images that are high quality, specific, and full bleed.
App uses fonts that are either the Android defaults, are complementary, and aren't otherwise distracting.
App conforms to common standards found in the Android Nanodegree General Project Guidelines. http://udacity.github.io/android-nanodegree-guidelines/core.html",3
https://github.com/socialchorus/homebrew,# Homebrew Cookbook,"   This cookbook installs Homebrew and under Chef 11 and earlier versions, its package provider replaces MacPorts as the default package provider for the package resource on OS X systems.",1
https://github.com/socialchorus/homebrew,# Requirements,"  Chef 12: The package provider is not necessary on Chef 12, as the default OS X package provider is homebrew. Chef <= 11: The package provider will be set as the default provider for OS X.",3
https://github.com/socialchorus/homebrew,## Prerequisites,"  In order for this recipe to work, your userid must own /usr/local. This is outside the scope of the cookbook because it's possible that you'll run the cookbook as your own user, not root and you'd have to be root to take ownership of the directory. Easiest way to get started: sudo chown -R `whoami`:staff /usr/local Bear in mind that this will take ownership of the entire folder and its contents, so if you've already got stuff in there (eg MySQL owned by a mysql user) you'll need to be a touch more careful. This is a recommendation from the Homebrew project. Note This cookbook only supports installing in /usr/local. While the Homebrew project itself allows for alternative installations, this cookbook doesn't.",3
https://github.com/socialchorus/homebrew,## Platform,"  
Mac OS X (10.6+)
 The only platform supported by Homebrew itself at the time of this writing is Mac OS X. It should work fine on Server edition as well, and on platforms that Homebrew supports in the future.",3
https://github.com/socialchorus/homebrew,## Cookbooks,"  
build-essential: homebrew itself doesn't work well if XCode is not installed.
",3
https://github.com/socialchorus/homebrew,# Attributes,"  

node['homebrew']['owner'] - The user that will own the Homebrew installation and packages. Setting this will override the default behavior which is to use the non-privileged user that has invoked the Chef run (or the SUDO_USER if invoked with sudo). The default is nil.


node['homebrew']['auto-update'] - Whether the default recipe should automatically update homebrew each run or not. The default is true to maintain compatibility. Set to false or nil to disable. Note that disabling this feature may cause formula to not work.


node['homebrew']['formulas'] - An Array of formula that should be installed using homebrew by default, used only in the homebrew::install_formulas recipe.


To install the most recent version, include just the recipe name: - simple_formula


To install a specific version, specify both its name and version:
- name: special-version-formula
  version: 1.2.3



To install the HEAD of a formula, specify both its name and head: true:
- name: head-tracking-formula
  head: true





node['homebrew']['casks'] - An Array of casks that should be installed using brew cask by default, used only in the homebrew::install_casks recipe.


node['homebrew']['taps'] - An Array of taps that should be installed using brew tap by default, used only in the homebrew::install_taps recipe.

",3
https://github.com/socialchorus/homebrew,# Resources and Providers,"  This cookbook includes a package resource provider to use homebrew. Under Chef 12+, this is not necessary, and the code doesn't actually get used on Chef 12+. This was preserved to maintain backwards compatiblity with older versions of Chef.",3
https://github.com/socialchorus/homebrew,## package / homebrew\_package,"  This cookbook provides a package provider called homebrew_package which will install/remove packages using Homebrew. This becomes the default provider for package if your platform is Mac OS X. As this extends the built-in package resource/provider in Chef, it has all the resource attributes and actions available to the package resource. However, a couple notes: 
Homebrew itself doesn't have a notion of ""upgrade"" per se. The ""upgrade"" action will simply perform an install, and if the Homebrew Formula for the package is newer, it will upgrade.
Likewise, Homebrew doesn't have a purge, but the ""purge"" action will act like ""remove"".
",3
https://github.com/socialchorus/homebrew,### Examples,"  package 'mysql' do
  action :install
end

homebrew_package 'mysql'

package 'mysql' do
  provider Chef::Provider::Package::Homebrew
end

package 'wireshark' do
  options '--with-qt --devel'
end",3
https://github.com/socialchorus/homebrew,### homebrew\_tap,"  LWRP for brew tap, a Homebrew command used to add additional formula repositories. From the brew man page: tap [tap]
       Tap a new formula repository from GitHub, or list existing taps.

       tap is of the form user/repo, e.g. brew tap homebrew/dupes.
 Default action is :tap which enables the repository. Use :untap to disable a tapped repository.",3
https://github.com/socialchorus/homebrew,#### Examples,"  homebrew_tap 'homebrew/dupes'

homebrew_tap 'homebrew/dupes' do
  action :untap
end",3
https://github.com/socialchorus/homebrew,## homebrew\_cask,"  LWRP for brew cask, a Homebrew-style CLI workflow for the administration of Mac applications distributed as binaries. It's implemented as a homebrew ""external command"" called cask. homebrew-cask on GitHub",3
https://github.com/socialchorus/homebrew,### Prerequisites,"  You must have the homebrew-cask repository tapped. homebrew_tap 'caskroom/cask' And then install the homebrew cask package before using this LWRP. package ""brew-cask"" do
  action :install
  end You can include the homebrew::cask recipe to do this.",3
https://github.com/socialchorus/homebrew,### Examples,"  homebrew_cask ""google-chrome""

homebrew_cask ""google-chrome"" do
  action :uncask
end Default action is :cask which installs the Application binary . Use :uncask to uninstall a an Application. View the list of available Casks",3
https://github.com/socialchorus/homebrew,# Usage,"  We strongly recommend that you put ""recipe[homebrew]"" in your node's run list, to ensure that it is available on the system and that Homebrew itself gets installed. Putting an explicit dependency in the metadata will cause the cookbook to be downloaded and the library loaded, thus resulting in changing the package provider on Mac OS X, so if you have systems you want to use the default (Mac Ports), they would be changed to Homebrew. The default recipe also ensures that Homebrew is installed and up to date if the auto update attribute (above) is true (default).",3
https://github.com/socialchorus/homebrew,# License and Authors,"  This cookbook is maintained by CHEF. The original author, maintainer and copyright holder is Graeme Mathieson. The cookbook remains licensed under the Apache License version 2. Original blog post by Graeme Author:: Graeme Mathieson (mathie@woss.name) Author:: Joshua Timberman (joshua@chef.io) Copyright:: 2011, Graeme Mathieson
Copyright:: 2012-2015, Chef Software, Inc. <legal@chef.io>

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
",5
https://github.com/cambiata/android-midi-lib,# Android MIDI Library," This project is mainly for use with Android applications that do not have access to Java's javax.sound.midi library. However, it is a stand-alone Java library with no Android-specific dependencies or considerations. This code provides an interface to read, manipulate, and write MIDI files. ""Playback"" is supported as a real-time event dispatch system. This library does NOT include actual audio playback or device interfacing.",1
https://github.com/cambiata/android-midi-lib,## Example Usage:, ,3
https://github.com/cambiata/android-midi-lib,#### Reading and Writing a MIDI file:,"  File input = new File(""example.mid"");
MidiFile midi = new MidiFile(input);

...

File output = new File(""output.mid"");
midi.writeToFile(output);",3
https://github.com/cambiata/android-midi-lib,#### Manipulating a MIDI file's data:,"  Removing a track: midi.removeTrack(2); Removing any event that is not a note from track 1: MidiTrack track = midi.getTracks().get(1);

Iterator<MidiEvent> it = track.getEvents().iterator();
List<MidiEvent> eventsToRemove = new ArrayList<MidiEvent>();

while(it.hasNext())
{
    MidiEvent event = it.next();
    
    if(!(event instanceof NoteOn) && !(event instanceof NoteOff))
    {
        eventsToRemove.add(event);
    }
}

for(MidiEvent event : eventsToRemove)
{
    track.removeEvent(event);
} Reducing the tempo by half: MidiTrack tempoTrack = midi.getTracks().get(0);
Iterator<MidiEvent> it = tempoTrack.getEvents().iterator();

while(it.hasNext())
{
    MidiEvent event = it.next();
    
    if(event instanceof Tempo)
    {
        Tempo tempoEvent = (Tempo)event;
        tempoEvent.setBpm(tempo.getBpm() / 2);
    }
}",3
https://github.com/cambiata/android-midi-lib,#### Composing a new MIDI file:,"  // 1. Create some MidiTracks
MidiTrack tempoTrack = new MidiTrack();
MidiTrack noteTrack = new MidiTrack();

// 2. Add events to the tracks
// Track 0 is the tempo map
TimeSignature ts = new TimeSignature();
ts.setTimeSignature(4, 4, TimeSignature.DEFAULT_METER, TimeSignature.DEFAULT_DIVISION);

Tempo tempo = new Tempo();
tempo.setBpm(228);

tempoTrack.insertEvent(ts);
tempoTrack.insertEvent(tempo);

// Track 1 will have some notes in it
final int NOTE_COUNT = 80;

for(int i = 0; i < NOTE_COUNT; i++)
{
    int channel = 0;
    int pitch = 1 + i;
    int velocity = 100;
    long tick = i * 480;
    long duration = 120;
    
    noteTrack.insertNote(channel, pitch, velocity, tick, duration);
}

// 3. Create a MidiFile with the tracks we created
List<MidiTrack> tracks = new ArrayList<MidiTrack>();
tracks.add(tempoTrack);
tracks.add(noteTrack);

MidiFile midi = new MidiFile(MidiFile.DEFAULT_RESOLUTION, tracks);

// 4. Write the MIDI data to a file
File output = new File(""exampleout.mid"");
try
{
    midi.writeToFile(output);
}
catch(IOException e)
{
    System.err.println(e);
}",3
https://github.com/cambiata/android-midi-lib,#### Listening for and processing MIDI events,"  // Create a new MidiProcessor:
MidiProcessor processor = new MidiProcessor(midi);

// Register for the events you're interested in:
EventPrinter ep = new EventPrinter(""Individual Listener"");
processor.registerEventListener(ep, Tempo.class);
processor.registerEventListener(ep, NoteOn.class);

// or listen for all events:
EventPrinter ep2 = new EventPrinter(""Listener For All"");
processor.registerEventListener(ep2, MidiEvent.class);

// Start the processor:
processor.start(); // This class will print any event it receives to the console
public class EventPrinter implements MidiEventListener
{
    private String mLabel;

    public EventPrinter(String label)
    {
        mLabel = label;
    }

    @Override
    public void onStart(boolean fromBeginning)
    {
        if(fromBeginning)
        {
            System.out.println(mLabel + "" Started!"");
        }
        else
        {
            System.out.println(mLabel + "" resumed"");
        }
    }

    @Override
    public void onEvent(MidiEvent event, long ms)
    {
        System.out.println(mLabel + "" received event: "" + event);
    }

    @Override
    public void onStop(boolean finished)
    {
        if(finished)
        {
            System.out.println(mLabel + "" Finished!"");
        }
        else
        {
            System.out.println(mLabel + "" paused"");
        }
    }
}",3
https://github.com/connorworkman/LightWM,# LightWM," A lightweight window manager for the X window system. Dependencies:
The example xinitrc file provided makes calls to launch X clients within the window manager.  Therefore, these X clients need to be already installed on your system: xeyes, xclock, xterm.
In order to run the window manager as a client in your current window manager, you'll need xephyr and scons. There are two options for using this X window manager.
Option 1 is to compile the program by installing scons and running the ./build_and_run.sh file without xephyr by setting it as your native window manager (you can use the provided xinitrc file to replace ~/.xinitrc).
Option 2 is to install scons, and use xephyr to run the window manager from within your current X session.   It is assumed that the program will be tested before use, so this is the default setting for the build_and_run.sh script. Execution:
Execute the build_and_run.sh file to Make and connect the window manager to the X server as an X client. ./build_and_run.sh Once scons compiles our program, xephyr launches a few programs inside of the new window manager. Congratulations on making it this far! If you had problems installing LightWM see the toubleshooting section at the end of this readme. Commands: Close (kill) a window: ALT + Q Move a window: Hold ALT and select a window with the mouse. Drag to reposition. Release mouse to stop. Launch a new xterm window as a child process: ALT + Enter Cycle top window focus: ALT + Tab And of course, feel free to launch any program via xterm. Troubleshooting:
Make sure to install xorg-xeyes, xorg-xclock, xterm, xephyr (unless using lightWM as primary window manager), and scons with your operating system's package manager.
LightWM does not support multiple monitor X configurations, and may be unable to load xorg.conf configuration files with multiple screens.",13
https://github.com/fabianfh/QuantLib,# QuantLib: the free/open-source library for quantitative finance," 


 




  The QuantLib project (http://quantlib.org) is aimed at providing a
comprehensive software framework for quantitative finance. QuantLib is
a free/open-source library for modeling, trading, and risk management
in real-life. QuantLib is Non-Copylefted Free Software and OSI Certified Open Source
Software.",15
https://github.com/fabianfh/QuantLib,## Download and usage,"  QuantLib can be downloaded from http://quantlib.org/download.shtml;
installation instructions are available at
http://quantlib.org/install.shtml for most platforms. Documentation for the usage and the design of the QuantLib library is
available from http://quantlib.org/docs.shtml. A list of changes for each past versions of the library can be
browsed at http://quantlib.org/reference/history.html.",346
https://github.com/fabianfh/QuantLib,## Questions and feedback,"  The preferred channel for questions (and the one with the largest
audience) is the quantlib-users mailing list.  Instructions for
subscribing are at http://quantlib.org/mailinglists.shtml. Bugs can be reported as a GitHub issue at
https://github.com/lballabio/QuantLib/issues; if you have a patch
available, you can open a pull request instead (see ""Contributing""
below).",6
https://github.com/fabianfh/QuantLib,## Contributing,"  The preferred way to contribute is through pull requests on GitHub.
Get a GitHub account if you don't have it already and clone the
repository at https://github.com/lballabio/QuantLib with the ""Fork""
button in the top right corner of the page. Check out your clone to
your machine, code away, push your changes to your clone and submit a
pull request; instructions are available at
https://help.github.com/articles/fork-a-repo. In case you need them, more detailed instructions for creating pull
requests are at
https://help.github.com/articles/using-pull-requests, and a basic
guide to GitHub is at
https://guides.github.com/activities/hello-world/.  GitHub also
provides interactive learning at https://lab.github.com/. It's likely that we won't merge your code right away, and we'll ask
for some changes instead. Don't be discouraged! That's normal; the
library is complex, and thus it might take some time to become
familiar with it and to use it in an idiomatic way. We're looking forward to your contributions.",7
https://github.com/thekonz/piximgen,# PixImGen, Pixel graphics library for PHP.,1
https://github.com/thekonz/piximgen,## Installation,"  Add this to your composer.json: {
	""require"": {
		""thekonz/piximgen"": ""1.0.*@dev""
	}
} Then run composer install or composer update.",3
https://github.com/thekonz/piximgen,## Example app,  Wanna try it out? Take a look at the example app.,3
https://github.com/thekonz/piximgen,## General usage (salute!),"  
Load the composer autoloader.
 require_once 'vendor/autoload.php'; 
Create a new instance of PixImGen.
 $image = new \thekonz\PixImGen(); 
Set the settings for the image (the constructor also accepts settings as a parameter). You don't have to set the settings at all, there are default settings.
 $image->setSettings([
	'seed' => 'GitHub rocks!'
]); 
Set the header.
 header('content-type: image/png'); 
Display the image.
 echo $image->getImage(); 
Look at your image!
  If you play around with the settings (especially the saturation settings), you can get some pretty cool images.",3
https://github.com/thekonz/piximgen,## Complete list of settings,"  


Setting
Explanation
Default value




seed
Starting value for the random generator. Just like in Minecraft.
System time (time())


blocksize
The width of each block (pixel).
15


width
The amount of blocks on the X-axis of the image.
10


height
The amount of blocks on the Y-axis of the image.
10


minredsaturation
The minimum saturation of the color red.
0


maxredsaturation
The maximum saturation of the color red.
255


mingreensaturation
The minimum saturation of the color green.
0


maxgreensaturation
The maximum saturation of the color green.
255


minbluesaturation
The minimum saturation of the color blue.
0


maxbluesaturation
The maximum saturation of the color blue.
255


",3
https://github.com/thekonz/piximgen,## Further manipulation of the image,"  Since the method getImage() returns an Imagick object, you can use all of the Imagick methods.",3
https://github.com/gaopeng9090/IntentKit,# IntentKit [![Build Status](https://travis-ci.org/intentkit/IntentKit.png)](https://travis-ci.org/intentkit/IntentKit)," IntentKit is an easier way to handle third-party URL schemes in iOS apps.  Linking to third-party apps is essentially broken on iOS. Let's say that, as a developer, you want to allow users to open map links in Google Maps instead of the built-in Maps.app. You now need to write a whole bunch of custom code that determines whether Google Maps is installed, ask the user which they would prefer, and ideally remember that preference. If we take a more complex example, like Twitter clients, you're now potentially managing a dozen different third-party URL schemes that are all drastically different and quite possibly poorly-documented. As a result, very few apps link to external third-party apps for tasks handled by Apple's easier-to-link-to apps, even when users prefer third-party apps. IntentKit attempts to solve this problem. For users, it provides a beautiful selection interface to choose which third-party app to perform an action in. For developers, it provides: 

An elegant, cohesive API based on semantic actions. Instead of manually constructing URLs or creating modal view controllers to display, just tell it what you're trying to do. Instead of manually checking which applications a user has installed, let IntentKit automatically query the device for you to figure out what applications are available to perform a given action.


A unified, human-readable repository of third-party URL schemes. Every application's URL scheme is just a plaintext plist. You can add support for your application to IntentKit without writing a single line of code.

",123
https://github.com/gaopeng9090/IntentKit,## Installation,"  IntentKit is easiest to install using CocoaPods. Just add the following to your Podfile. pod ""IntentKit""
 After running pod install, you should be able to #import any INKHandler header file (e.g. #import <INKMailHandler.h>) and go to town. If you're concerned about the increase in your app bundle's size, you can choose to only include a subset of IntentKit's supported applications. Subspecs exist for each handler class. # Only includes web browsers
pod ""IntentKit/Browsers""
 For more information on what subspecs are available, refer to the project's Podspec.",3
https://github.com/gaopeng9090/IntentKit,## Usage,"  To use IntentKit, you start by instantiating a handler object. There are a handful of handler objects that come with IntentKit, each with domain knowledge of a specific type of application. For example, INKBrowserHandler, INKMapsHandler, and INKTwitterHandler handle opening links in web browsers, mapping applications, and Twitter clients, respectively. After creating a new handler object, you just tell it what action you want to perform. It will return you a special object called a presenter, which can be used to actually perform the action. Here's how you'd open an email compose screen on an iPhone: INKMailHandler *mailHandler = [[INKMailHandler alloc] init];
[[mailHandler sendMailTo:@""steve@apple.com""] presentModally]; If the user doesn't have any third-party mail apps installed (such as Mailbox or Google's native Gmail app), this will display an in-line MFMailComposeViewController, just as if you had created and presented one yourself. If the user does have other mail apps installed, this will display a modal sheet that looks like a UIActivityViewController listing each available application. It will also give them a switch they can tap to remember their choice for all future links of that type.",3
https://github.com/gaopeng9090/IntentKit,"### Convention Over Configuration"" mode""","  Depending on your application and userbase, that user experience might not be ideal. If 99% of your users want to use the Apple default, why should they have to go through an extra tap? Each INKHandler object has an useSystemDefault property. If you set it to YES, performing an INKHandler action will not result in a custom UI being shown. Instead, the system will silently pick an application to handle the request. Sensible defaults are picked for each handler type: all handlers that have an Apple-provided application will use that one, and handlers that are based on a third-party service (e.g. Twitter) will default to using the first-party application. If you use this method of presenting IntentKit, it's recommended that you give users a way to set their own defaults. IntentKit provides a view controller called INKDefaultsViewController that lets users set preferences. Just create a new INKDefaultsViewController object, optionally limit which handler types should be displayed, and present it on-screen: INKDefaultsViewController *defaultsController = [[INKDefaultsViewController alloc] init];
defaultsController.allowedHandlers = @[[INKBrowserHandler class], [INKMailHandler class]];
[self pushViewController:defaultsController animated:YES]; When you don't manually limit the handler types, it looks something like this:  If you'd rather more control over the user experience, IntentKit also offers API hooks to set your own defaults. Every INKHandler object has a promptToSetDefault method that will return an INKActivityPresenter object that handles prompting the user to select an application. For even lower-level control, the INKApplicationList and INKDefaultsManager classes can be used to fetch a list of available applications and manually set defaults.",3
https://github.com/gaopeng9090/IntentKit,### Optional Parameters,"  Some handlers have optional configuration parameters. For example, when linking to a map application, you can specify where the map should be centered and how zoomed-in it should be; these options will take effect whether you're searching for a location, getting turn-by-turn directions, or doing any other action supported by the handler. INKMapsHandler *mapsHandler = [[INKMapsHandler alloc] init];
mapsHandler.center = CLLocationCoordinate2DMake(42.523, -73.544);
mapsHandler.zoom = 14;
[mapsHandler directionsFrom:@""Washington Square Park"" to:@""Lincoln Center""]; This is where the real power of IntentKit shines through. This gives you a clean, semantic API to construct links rather than having to manually cobble together URLs, regardless of whether your user wants to use Apple Maps or a third-party app. An up-to-date list of available handlers and what methods and configuration options is available in the project's documentation.",3
https://github.com/gaopeng9090/IntentKit,### Explicitly specifying the view controller,"  If you're using presentModally, it will attempt to intelligently figure out which view controller to present itself on. It's possible it won't pick the correct one automatically; if that's the case, you probably want to explicitly specify the correct view controller. NSURL *url = [NSURL URLWithString:@""http://google.com""]
INKBrowserHandler *browserHandler = [[INKBrowserHandler alloc] init];
INKActivityPresenter *presenter = ][browserHandler openURL:url];
[presenter presentModalActivitySheetFromViewController:self];",3
https://github.com/gaopeng9090/IntentKit,### iPad and UIPopoverController,"  If your app is Universal or iPad-only, if you're displaying an IntentKit INKActivityViewController you probably want to display it as a popover instead of a modal sheet. The following code will automatically display itself modally on an iPhone and in a UIPopoverController on an iPad. NSURL *url = [NSURL URLWithString:@""http://google.com""]
INKBrowserHandler *browserHandler = [[INKBrowserHandler alloc] init];
INKActivityPresenter *presenter = [browserHandler openURL:url];
[presenter presentActivitySheetFromViewController:self
                                  popoverFromRect:someRect
                                           inView:self.view
                         permittedArrowDirections:UIPopoverArrowDirectionAny
                                         animated:YES]; All of those options will be passed directly into a UIPopoverController. Similarly, there exists a presentActivitySheetFromViewController:popoverFromBarButtonItem:permittedArrowDirections:animated: method that calls the equivalent UIPopoverController method if appropriate.",3
https://github.com/gaopeng9090/IntentKit,### Fallback URLs,"  If a user doesn't have any appropriate apps installed that can perform an action, IntentKit will try to use a web browser as a fallback. For example, if a user tries to do something involving Twitter but doesn't have a Twitter client installed, IntentKit will try to load the appropriate twitter.com URL. It does this by presenting an INKBrowserHandler so the user can still pick their preferred web browser. If you don't want this behavior, you can disable it by setting a handler's useFallback property to NO before invoking an action.",3
https://github.com/gaopeng9090/IntentKit,### Safari and UIWebViews,"  It's worth mentioning that IntentKit's default web browser is an in-app modal UIWebView. This is true both for actions triggered by an INKBrowserHandler and actions triggered by other handlers falling back to a web URL. If you don't want to do that, and would rather fall back on Safari for web actions, you can set your handler's disableInAppOption property to NO.",3
https://github.com/gaopeng9090/IntentKit,## Documentation,"  Documentation can be viewed online on CocoaDocs. Alternatively, documentation can be found in the docs directory by running script/generate-docs.sh from the root directory. If you do this, be aware that the documentation will be generated from your current copy of the code, which might differ from the most recent tagged version on CocoaPods.",6
https://github.com/gaopeng9090/IntentKit,## Example Project,"  A demo app has been provided so you can see IntentKit in action. 
Clone this repo.
Run pod install inside the project directory.
Open IntentKitDemo.xcworkspace.
Build and run the app.
 The demo lets you perform any of the actions supported by IntentKit. If you only have one app installed capable of performing a task, IntentKit will by default open up that app directly rather than prompt the user to pick. In the demo app, there is a toggle to always show the selection UI if there is at least one application available. It's recommended that you run the demo on an actual iOS device that has third-party apps installed, but if you must run it in the simulator that toggle will let you see what the selection UI looks like.",3
https://github.com/gaopeng9090/IntentKit,## Adding Your Own Actions,  Extending IntentKit is easy.,3
https://github.com/gaopeng9090/IntentKit,#### Including your own URL Scheme,"  

Inside the IntentKit/Apps/ directory, create a new directory with the name of your app.


Inside that directory, create a plist. Its name should be the app's (English) name, and its root object should be a dictionary.
Inside this dictionary, there should be a name key that represents the app's localized name(s). If your app's name does not change across locales, its value should be a string with that name.
<key>name</key>
<string>Safari</string>
If it does change, the value should be a dictionary mapping IETF BCP 47 language identifiers to localized names.
<key>name</key>
<dict>
  <key>en</key>
  <string>Sina Weibo</string>
  <key>zh-Hans</key>
  <string>新浪微博</string>
</dict>
Additionally, there should be an actions dictionary containing all of the actions your application can perform. This dictionary should map strings representing INKHandler methods to template strings used to generate URLs for those method. In these template strings, variables wrapped in Mustache-style curly braces will be interpolated at runtime. Just like Mustache, variables wrapped in double-braces ({{name}}) will be URL-escaped, whereas ones wrapped in triple-braces ({{{url}}}) will not be. For example:
<key>actions</key>
<dict>
    <key>searchForLocation:</key>
    <string>comgooglemaps://?q={{query}}</string>
</dict>
In general, the template variable keys are named the same as the argument names of the corresponding handler methods, but there is currently nothing enforcing that. It's recommended that you look at the plist files for other apps that respond to the same actions to see what the correct template keys are.

 If your application supports actions not currently represented in a handler, or is part of a class of applications that doesn't currently have a handler, you'll have to write code to add support. The current handler code is easy to read; refer to an existing handler subclass as a reference for creating your own handler methods or INKHandler subclasses. 

Your app's icon goes in the same directory. You will need four copies of the icon, all with the same root name as your plist file:

AppName.png: 60x60
AppName~ipad.png: 76x76
AppName@2x.png: 120x120
AppName@2x~ipad.png: 152x152

Use the same square icons you're using in your app's Xcode project; IntentKit will take care of masking them so they appear as iOS-style rounded rectangles/superellipses. The root filename (""AppName"" in those examples) must exactly match the filename of the plist.


In the root of your IntentKit codebase, run pod install. This will cause XCode to pick up any new files you've added. Next, run rake to run the test suite, which includes a linter to make sure that every action you've defined in your plist corresponds to a valid handler action. You'll also probably want to run the example app on an actual iOS device to make sure your links all work as expected.


In IntentKit.podspec, add your app to the subspec that corresponds to the handler your application responds to. Just add your app's folder name to the list of other application folder names in the appropriate resource bundle file glob.


Submit a pull request!

",3
https://github.com/gaopeng9090/IntentKit,#### Including Your Own In-App View Controller,"  Adding your own modal in-app action is very similar to adding your own URL scheme, with a few exceptions. All presentable IntentKit activities must conform to the INKPresentable protocol, which defines two methods: one which returns whether or not it can perform a given action, and tells it to actually perform an action. The latter method is passed a view controller to present your view controller modally on; it should both present your view controller, and take care of dismissing it once your action is complete. A few other changes must be made to your application's IntentKit plist file: 

actions should be an array of action names, rather than a dictionary.


There should be a field called className that lists the name of your INKPresententable class.


The name field should refer to whatever you want the activity to be listed as inside the app. For example, INKMailSheet (the activity that displays a MFMailComposeViewController) has a name of ""In App"".

",3
https://github.com/gaopeng9090/IntentKit,## Requirements,"  IntentKit requires Xcode 5, targeting iOS 7.0 and above.",3
https://github.com/gaopeng9090/IntentKit,## Contributing,"  All contributions are welcome! If you want to help but don't know where to begin, adding in support for a new third-party application can be a great way to get started (it typically doesn't require writing any code). Tests and documentation are heavily encouraged for new code. We use appledoc for documentation and Specta) for tests.",7
https://github.com/gaopeng9090/IntentKit,## Roadmap,"  The goal of the initial version of IntentKit was just to create a simple way to integrate third-party app linking without a lot of boilerplate code. Here's a non-exhaustive list of ways it could be extended in to the future. 
Downloading and caching plists at runtime, allowing an app to pull in the latest URL schemes without needing an App Store update
A web-based CMS to add and manage URL schemes without needing to manually edit plists or submit pull requests.
Saving user app preferences across all applications on a single device that use IntentKit
Optional downloading of app icons from Apple at runtime rather than requiring developers to upload them
",4
https://github.com/gaopeng9090/IntentKit,## Contact,"  Mike Walker 
https://github.com/lazerwalker
@lazerwalker
http://lazerwalker.com
 The initial version of IntentKit was built at Hacker School.",5
https://github.com/gaopeng9090/IntentKit,## License,  IntentKit is available under the MIT license. See the LICENSE file for more info.,5
https://github.com/kuyoska/embedio,## NuGet Installation:," PM> Install-Package EmbedIO
",3
https://github.com/kuyoska/embedio,## Basic Example:,"  Please note the comments are the important part here. More info is available in the samples. namespace Company.Project
{
    using System;
    using Unosquare.Labs.EmbedIO;
    using Unosquare.Labs.EmbedIO.Modules;

    class Program
    {
        /// <summary>
        /// Defines the entry point of the application.
        /// </summary>
        /// <param name=""args"">The arguments.</param>
        static void Main(string[] args)
        {
            var url = ""http://localhost:9696/"";
            if (args.Length > 0)
                url = args[0];

            // Our web server is disposable.
            using (var server = new WebServer(url))
            {
                // First, we will configure our web server by adding Modules.
                // Please note that order DOES matter.
                // ================================================================================================
                // If we want to enable sessions, we simply register the LocalSessionModule
                // Beware that this is an in-memory session storage mechanism so, avoid storing very large objects.
                // You can use the server.GetSession() method to get the SessionInfo object and manupulate it.
                // You could potentially implement a distributed session module using something like Redis
                server.RegisterModule(new LocalSessionModule());

                // Here we setup serving of static files
                server.RegisterModule(new StaticFilesModule(""c:/web""));
                // The static files module will cache small files in ram until it detects they have been modified.
                server.Module<StaticFilesModule>().UseRamCache = true;
                server.Module<StaticFilesModule>().DefaultExtension = "".html"";
                // We don't need to add the line below. The default document is always index.html.
                //server.Module<Modules.StaticFilesWebModule>().DefaultDocument = ""index.html"";

                // Once we've registered our modules and configured them, we call the RunAsync() method.
                server.RunAsync();

                // Fire up the browser to show the content if we are debugging!
#if DEBUG
                var browser = new System.Diagnostics.Process()
                {
                    StartInfo = new System.Diagnostics.ProcessStartInfo(url) { UseShellExecute = true }
                };
                browser.Start();
#endif
                // Wait for any key to be pressed before disposing of our web server.
                // In a service we'd manage the lifecycle of of our web server using
                // something like a BackgroundWorker or a ManualResetEvent.
                Console.ReadKey(true);
            }
        }
    }
}",3
https://github.com/kuyoska/embedio,#if DEBUG,,-
https://github.com/kuyoska/embedio,#endif,,-
https://github.com/kuyoska/embedio,## Fluent Example:,"  Many extension methods are available. This allows you to create a web server instance in a fluent style by dotting in configuration options. namespace Company.Project
{
    using System;
    using Unosquare.Labs.EmbedIO;

    internal class Program
    {
        /// <summary>
        /// Defines the entry point of the application.
        /// </summary>
        /// <param name=""args"">The arguments.</param>
        private static void Main(string[] args)
        {
            var url = ""http://localhost:9696/"";
            if (args.Length > 0)
                url = args[0];

            // Create Webserver and attach LocalSession and Static
            // files module and CORS enabled
            var server = WebServer
                .Create(url)
                .EnableCors()
                .WithLocalSession()
                .WithStaticFolderAt(""c:/web"");

			var cts = new CancellationTokenSource();
            var task = server.RunAsync(cts.Token);

            // Wait for any key to be pressed before disposing of our web server.
            // In a service we'd manage the lifecycle of of our web server using
            // something like a BackgroundWorker or a ManualResetEvent.
            Console.ReadKey(true);
			cts.Cancel();

			try
			{
				task.Wait();
			} catch (AggregateException)
			{
				// We'd also actually verify the exception cause was that the task
				// was cancelled.
				server.Dispose();
			}
        }
    }
}",3
https://github.com/kuyoska/embedio,## REST API Example:,"  The WebApi module supports two routing strategies: Wildcard and Regex. By default, and in order to maintain backwards compatibility, the WebApi module will use the Wildcard Routing Strategy and match routes using the asterisk * character in the route. For example: 
The route /api/people/* will match any request with a URL starting with the two first URL segments api and people and ending with anything. The route /api/people/hello will be matched.
You can also use wildcards in the middle of the route. The route /api/people/*/details will match requests starting with the two first URL segments api and people, and ending with a details segment. The route /api/people/hello/details will be matched.
 Note that most REST services can be designed with this simpler Wildcard routing startegy. However, the Regex matching strategy is the current recommended approach as we might be deprecating the Wildcard strategy altogether On the other hand, the Regex Routing Strategy will try to match and resolve the values from a route template, in a similar fashion to Microsoft's Web API 2. A method with the following route /api/people/{id} is going to match any request URL with three segments: the first two api and people and the last one is going to be parsed or converted to the type in the id argument of the handling method signature. Please read on if this was confusing as it is much simpler than it sounds. Additionally, you can put multiple values to match, for example /api/people/{mainSkill}/{age}, and receive the parsed values from the URL straight into the arguments of your handler method. During server setup: // The routing strategy is Wildcard by default, but you can change it to Regex as follows:
var server =  new WebServer(""http://localhost:9696/"", RoutingStrategy.Regex);

server.RegisterModule(new WebApiModule());
server.Module<WebApiModule>().RegisterController<PeopleController>(); And our controller class (using Regex Strategy) looks like: public class PeopleController : WebApiController
{
    [WebApiHandler(HttpVerbs.Get, ""/api/people/{id}"")]
    public bool GetPeople(WebServer server, HttpListenerContext context, int id)
    {
        try
        {
            if (People.Any(p => p.Key == id))
            {
                return context.JsonResponse(People.FirstOrDefault(p => p.Key == id));
            }
        }
        catch (Exception ex)
        {
            return HandleError(context, ex, (int)HttpStatusCode.InternalServerError);
        }
    }
    
    protected bool HandleError(HttpListenerContext context, Exception ex, int statusCode = 500)
    {
        var errorResponse = new
        {
            Title = ""Unexpected Error"",
            ErrorCode = ex.GetType().Name,
            Description = ex.ExceptionMessage(),
        };

        context.Response.StatusCode = statusCode;
        return context.JsonResponse(errorResponse);
    }
} Or if you want to use the Wildcard strategy (which is the default): public class PeopleController : WebApiController
{
    [WebApiHandler(HttpVerbs.Get, ""/api/people/*"")]
    public bool GetPeople(WebServer server, HttpListenerContext context)
    {
        try
        {
            var lastSegment = context.Request.Url.Segments.Last();
            if (lastSegment.EndsWith(""/""))
                return context.JsonResponse(People);

            int key = 0;
            if (int.TryParse(lastSegment, out key) && People.Any(p => p.Key == key))
            {
                return context.JsonResponse(People.FirstOrDefault(p => p.Key == key));
            }

            throw new KeyNotFoundException(""Key Not Found: "" + lastSegment);
        }
        catch (Exception ex)
        {
            return HandleError(context, ex, (int)HttpStatusCode.InternalServerError);
        }
    }
    
    protected bool HandleError(HttpListenerContext context, Exception ex, int statusCode = 500)
    {
        var errorResponse = new
        {
            Title = ""Unexpected Error"",
            ErrorCode = ex.GetType().Name,
            Description = ex.ExceptionMessage(),
        };

        context.Response.StatusCode = statusCode;
        return context.JsonResponse(errorResponse);
    }
}",3
https://github.com/kuyoska/embedio,## WebSockets Example:,"  During server setup: server.RegisterModule(new WebSocketsModule());
server.Module<WebSocketsModule>().RegisterWebSocketsServer<WebSocketsChatServer>(""/chat""); And our web sockets server class looks like: /// <summary>
/// Defines a very simple chat server
/// </summary>
public class WebSocketsChatServer : WebSocketsServer
{

    public WebSocketsChatServer()
        : base(true, 0)
    {
        // placeholder
    }

    /// <summary>
    /// Called when this WebSockets Server receives a full message (EndOfMessage) form a WebSockets client.
    /// </summary>
    /// <param name=""context"">The context.</param>
    /// <param name=""rxBuffer"">The rx buffer.</param>
    /// <param name=""rxResult"">The rx result.</param>
    protected override void OnMessageReceived(WebSocketContext context, byte[] rxBuffer, WebSocketReceiveResult rxResult)
    {
        var session = this.WebServer.GetSession(context);
        foreach (var ws in this.WebSockets)
        {
            if (ws != context)
                this.Send(ws, Encoding.UTF8.GetString(rxBuffer));
        }
    }

    /// <summary>
    /// Gets the name of the server.
    /// </summary>
    /// <value>
    /// The name of the server.
    /// </value>
    public override string ServerName
    {
        get { return ""Chat Server""; }
    }

    /// <summary>
    /// Called when this WebSockets Server accepts a new WebSockets client.
    /// </summary>
    /// <param name=""context"">The context.</param>
    protected override void OnClientConnected(WebSocketContext context)
    {
        this.Send(context, ""Welcome to the chat room!"");
        foreach (var ws in this.WebSockets)
        {
            if (ws != context)
                this.Send(ws, ""Someone joined the chat room."");
        }
    }

    /// <summary>
    /// Called when this WebSockets Server receives a message frame regardless if the frame represents the EndOfMessage.
    /// </summary>
    /// <param name=""context"">The context.</param>
    /// <param name=""rxBuffer"">The rx buffer.</param>
    /// <param name=""rxResult"">The rx result.</param>
    protected override void OnFrameReceived(WebSocketContext context, byte[] rxBuffer, WebSocketReceiveResult rxResult)
    {
        return;
    }

    /// <summary>
    /// Called when the server has removed a WebSockets connected client for any reason.
    /// </summary>
    /// <param name=""context"">The context.</param>
    protected override void OnClientDisconnected(WebSocketContext context)
    {
        this.Broadcast(string.Format(""Someone left the chat room.""));
    }
}",3
https://github.com/kuyoska/embedio,## Notes,  [1] - EmbedIO uses lowercase URL parts. In Windows systems this is the expected behaviour but in Unix systems using MONO please refer to Mono IOMap if you want to work with case insensitive URL parts.,3
https://github.com/sandu81/botframework,## QnAMakerDialog,,16
https://github.com/sandu81/botframework,## BestMatchDialog,,16
https://github.com/bran921007/react,# [React](https://facebook.github.io/react) [![Build Status](https://travis-ci.org/facebook/react.svg?branch=master)](https://travis-ci.org/facebook/react) [![npm version](https://badge.fury.io/js/react.svg)](http://badge.fury.io/js/react)," React is a JavaScript library for building user interfaces. 
Just the UI: Lots of people use React as the V in MVC. Since React makes no assumptions about the rest of your technology stack, it's easy to try it out on a small feature in an existing project.
Virtual DOM: React abstracts away the DOM from you, giving a simpler programming model and better performance. React can also render on the server using Node, and it can power native apps using React Native.
Data flow: React implements one-way reactive data flow which reduces boilerplate and is easier to reason about than traditional data binding.
 NEW! Check out our newest project React Native, which uses React and JavaScript to create native mobile apps. Learn how to use React in your own project.",16
https://github.com/bran921007/react,## Examples,"  We have several examples on the website. Here is the first one to get you started: var HelloMessage = React.createClass({
  render: function() {
    return <div>Hello {this.props.name}</div>;
  }
});

React.render(
  <HelloMessage name=""John"" />,
  document.getElementById('container')
); This example will render ""Hello John"" into a container on the page. You'll notice that we used an HTML-like syntax; we call it JSX. JSX is not required to use React, but it makes code more readable, and writing it feels like writing HTML. A simple transform is included with React that allows converting JSX into native JavaScript for browsers to digest.",3
https://github.com/bran921007/react,## Installation,"  The fastest way to get started is to serve JavaScript from the CDN (also available on cdnjs and jsdelivr): <!-- The core React library -->
<script src=""https://fb.me/react-0.13.3.js""></script>
<!-- In-browser JSX transformer, remove when pre-compiling JSX. -->
<script src=""https://fb.me/JSXTransformer-0.13.3.js""></script> We've also built a starter kit which might be useful if this is your first time using React. It includes a webpage with an example of using React with live code. If you'd like to use bower, it's as easy as: bower install --save react",3
https://github.com/bran921007/react,## Contribute,"  The main purpose of this repository is to continue to evolve React core, making it faster and easier to use. If you're interested in helping with that, then keep reading. If you're not interested in helping right now that's ok too. :) Any feedback you have about using React would be greatly appreciated.",7
https://github.com/bran921007/react,### Building Your Copy of React,"  The process to build react.js is built entirely on top of node.js, using many libraries you may already be familiar with.",3
https://github.com/bran921007/react,#### Prerequisites,"  
You have node installed at v0.10.0+ (it might work at lower versions, we just haven't tested).
You are familiar with npm and know whether or not you need to use sudo when installing packages globally.
You are familiar with git.
",3
https://github.com/bran921007/react,#### Build,"  Once you have the repository cloned, building a copy of react.js is really easy. # grunt-cli is needed by grunt; you might have this installed already
npm install -g grunt-cli
npm install
grunt build At this point, you should now have a build/ directory populated with everything you need to use React. The examples should all work.",3
https://github.com/bran921007/react,# grunt-cli is needed by grunt; you might have this installed already,,-
https://github.com/bran921007/react,### Grunt,"  We use grunt to automate many tasks. Run grunt -h to see a mostly complete listing. The important ones to know: # Build and run tests with PhantomJS
grunt test
# Build and run tests in your browser
grunt test --debug
# For speed, you can use fasttest and add --filter to only run one test
grunt fasttest --filter=ReactIdentity
# Lint the code with ESLint
grunt lint
# Wipe out build directory
grunt clean",3
https://github.com/bran921007/react,# Build and run tests with PhantomJS,,-
https://github.com/bran921007/react,# Build and run tests in your browser,,-
https://github.com/bran921007/react,"# For speed, you can use fasttest and add --filter to only run one test",,-
https://github.com/bran921007/react,# Lint the code with ESLint,,-
https://github.com/bran921007/react,# Wipe out build directory,,-
https://github.com/bran921007/react,### License,  React is BSD licensed. We also provide an additional patent grant. React documentation is Creative Commons licensed. Examples provided in this repository and in the documentation are separately licensed.,5
https://github.com/bran921007/react,"### More?,67"""," please read the Contributing document.""",
https://github.com/bran921007/react,## Troubleshooting,  See the Troubleshooting Guide,6
https://github.com/cliffparnitzky/TinyMceContextMenu,# Contao Extension: TinyMceContextMenu, Special TinyMCE plugin to add a context menu to the editor. The sources of this plugin could be found here. Now for TinyMCE 4.,1
https://github.com/cliffparnitzky/TinyMceContextMenu,## Installation,"  Install the extension via composer: cliffparnitzky/tiny-mce-context-menu. If you prefer to install it manually, download the latest release here: https://github.com/cliffparnitzky/TinyMceContextMenu/releases",3
https://github.com/cliffparnitzky/TinyMceContextMenu,## Tracker,  https://github.com/cliffparnitzky/TinyMceContextMenu/issues,6
https://github.com/cliffparnitzky/TinyMceContextMenu,## Compatibility,"  
Contao version >= 4.4.0
",3
https://github.com/cliffparnitzky/TinyMceContextMenu,## Dependency,"  
To load this plugin and add it to the configuration the extension [TinyMcePluginLoader] has to be installed.
",3
https://github.com/cliffparnitzky/TinyMceContextMenu,## Screenshot,  ,3
https://github.com/cliffparnitzky/TinyMceContextMenu,## Additional information, ,6
https://github.com/cliffparnitzky/TinyMceContextMenu,### Special notes,  There is nothing special to pay attention to.,6
https://github.com/cliffparnitzky/TinyMceContextMenu,### Information in the wiki, ,6
https://github.com/cliffparnitzky/TinyMceContextMenu,#### Create a new ...,"  
Creating a new plugin
Creating a new bundle
Creating a new setup
",6
https://github.com/cliffparnitzky/TinyMceContextMenu,#### Installation hints,"  
Install manually
",6
https://github.com/cliffparnitzky/TinyMceContextMenu,#### Bug report hints,"  
Report a bug
",6
https://github.com/Peplo/duckling,# Duckling,"  Duckling is a Clojure library that parses text into structured data: “the first Tuesday of October?=> {:value ""2014-10-07T00:00:00.000-07:00""
                                   :grain :day}
 You can try it out at https://duckling.wit.ai See our blog post announcement for more context.",16
https://github.com/Peplo/duckling,## Getting started,"  To use Duckling in your project, you just need two functions: load! to load the default configuration, and parse to parse a string. (ns myproject.core
  (:require [duckling.core :as p]))

(p/load!) ;; Load all languages

(p/parse :en$core ;; core configuration for English ; see also :fr$core, :es$core, :zh$core
         ""wake me up the last Monday of January 2015 at 6am""
         [:time]) ;; We are interested in :time expressions only ; see also :duration, :temperature, etc.

;; => [{:label :time
;;        :start 15
;;        :end 49
;;        :value {:type ""value"", :value ""2015-01-26T06:00:00.000-02:00"", :grain :hour}
;;        :body ""last Monday of January 2015 at 6am""}] See the documentation for more information.",36
https://github.com/niceguy-php/redis-windows,# Redis on Windows," This project contains the binary releases of MS Open Tech redis port of windows as well as a vagrant configuration for redis letting you run the native version of Redis in a Virtual Box VM. Whilst it's recommended to use Redis on Linux in production, it is often useful for developers on Windows platforms to have their own local version of redis running to develop with. The 2 most popular ways of running redis on windows is to use the binary releases of Microsoft's native port of redis, but as this is an unofficial port it always lags behind the latest official development of redis on linux/OSX. Thanks to Vagrant you can also run the latest linux version inside a Virutal Box Linux VM, which as it lets you run the official native version of redis, is our preferred approach:",1
https://github.com/niceguy-php/redis-windows,## Running the latest version of Redis with Vagrant, ,3
https://github.com/niceguy-php/redis-windows,#### 1. [Install Vagrant on Windows](http://docs.vagrantup.com/v2/getting-started/), ,3
https://github.com/niceguy-php/redis-windows,#### 2. Download the [vagrant-redis.zip](https://raw.github.com/ServiceStack/redis-windows/master/downloads/vagrant-redis.zip) vagrant configuration,"  wget https://raw.github.com/ServiceStack/redis-windows/master/downloads/vagrant-redis.zip
",3
https://github.com/niceguy-php/redis-windows,"#### 3. Extract `vagrant-redis.zip` in any folder, e.g. in `c:\vagrant-redis`", ,3
https://github.com/niceguy-php/redis-windows,#### 4. Launch the Virtual Box VM with `vagrant up`,"  cd c:\vagrant-redis
vagrant up
 This will launch a new Ubuntu VM instance inside Virtual Box that will automatically install and start the latest stable version of redis. The vagrant configuration was originally from JasonPunyon/redishobo and has been modified to use the latest stable release of Redis.",3
https://github.com/niceguy-php/redis-windows,## Running Microsoft's native port of Redis,"  These 64-bit binary releases are created by building the Microsoft's native port of redis which have also been published on NuGet, but as it's more convenient we provide a zip of the 64-bit binaries here.",3
https://github.com/niceguy-php/redis-windows,#### MS Open Announcements,"  
Redis on Windows release notes
MSOpenTech's Redis on Windows
Updates Released for Redis on Windows (2.8.4)
",6
https://github.com/niceguy-php/redis-windows,"### Current Version: 2.8.21 r01 (July 29, 2015)", ,4
https://github.com/niceguy-php/redis-windows,#### 1. Download the [redis64-latest.zip](https://github.com/ServiceStack/redis-windows/raw/master/downloads/redis-latest.zip) native 64bit Windows port of redis,"  wget https://raw.github.com/ServiceStack/redis-windows/master/downloads/redis64-latest.zip
",3
https://github.com/niceguy-php/redis-windows,"#### 2. Extract `redis64-latest.zip` in any folder, e.g. in `c:\redis`", ,3
https://github.com/niceguy-php/redis-windows,#### 3. Run the `redis-server.exe` using the local configuration,"  cd c:\redis
redis-server.exe redis.conf
",3
https://github.com/niceguy-php/redis-windows,#### 4. Run `redis-cli.exe` to connect to your redis instance,"  cd c:\redis
redis-cli.exe
",3
https://github.com/niceguy-php/redis-windows,#### 5. Start playing with redis :),"  redis 127.0.0.1:6379> SET foo bar
OK
redis 127.0.0.1:6379> KEYS *
1) ""foo""
redis 127.0.0.1:6379> GET foo
""bar""
redis 127.0.0.1:6379>
  The MSOpenTech of Redis adds some useful extensions for better integration with Windows:",3
https://github.com/niceguy-php/redis-windows,##,,-
https://github.com/niceguy-php/redis-windows,#### Running Redis as a Service,"  In order to better integrate with the Windows Services model, new command line arguments have been introduced to Redis. These service arguments require an elevated user context in order to connect to the service control manager. If these commands are invoked from a non-elevated context, Redis will attempt to create an elevated context in which to execute these commands. This will cause a User Account Control dialog to be displayed by Windows and may require Administrative user credentials in order to proceed.",3
https://github.com/niceguy-php/redis-windows,#### Installing the Service,"  --service-install
 This must be the first argument on the redis-server command line. Arguments after this are passed in the order they occur to Redis when the service is launched. The service will be configured as Autostart and will be launched as ""NT AUTHORITY\NetworkService"". Upon successful installation a success message will be displayed and Redis will exit.
This command does not start the service. For instance: redis-server --service-install redis.windows.conf --loglevel verbose
",3
https://github.com/niceguy-php/redis-windows,#### Uninstalling the Service,"  --service-uninstall
 This will remove the Redis service configuration information from the registry. Upon successful uninstallation a success message will be displayed and Redis will exit.
This does command not stop the service. For instance: redis-server --service-uninstall
",3
https://github.com/niceguy-php/redis-windows,#### Starting the Service,"  --service-start
 This will remove the Redis service configuration information from the registry. Upon successful uninstallation a success message will be displayed and Redis will exit. For instance: redis-server --service-start
",3
https://github.com/niceguy-php/redis-windows,#### Stopping the Service,"  --service-stop
 This will stop the Redis service. Upon successful termination a success message will be displayed and Redis will exit. For instance: redis-server --service-stop
",3
https://github.com/niceguy-php/redis-windows,#### Naming the Service,"  --service-name name
 This optional argument may be used with any of the preceding commands to set the name of the installed service. This argument should follow the service-install, service-start, service-stop or service-uninstall commands, and precede any arguments to be passed to Redis via the service-install command.
The following would install and start three separate instances of Redis as a service: redis-server --service-install –service-name redisService1 –port 10001
redis-server --service-start –service-name redisService1
redis-server --service-install –service-name redisService2 –port 10002
redis-server --service-start –service-name redisService2
redis-server --service-install –service-name redisService3 –port 10003
redis-server --service-start –service-name redisService3
",3
https://github.com/niceguy-php/redis-windows,## [Configure Redis Sentinel Servers](https://github.com/ServiceStack/redis-config),"   See the
redis config project for a quick way to setup up
the minimal
highly available Redis Sentinel configuration
including start/stop scripts for instantly running multiple redis instances on a single (or multiple)
Windows, OSX or Linux servers.",36
https://github.com/niceguy-php/redis-windows,## [Redis React Browser](https://servicestack.net/redis-react),"  Redis React is a simple user-friendly UI for browsing data in Redis servers which takes advantages of the complex
type conventions built in the ServiceStack.Redis Client to provide a rich, human-friendly UI for navigating related datasets, enabling a fast and fluid browsing experience for your Redis servers.",3
https://github.com/niceguy-php/redis-windows,#### [Live Demo](http://redisreact.servicestack.net/#/),  ,3
https://github.com/niceguy-php/redis-windows,"#### Windows, OSX and Linux downloads available from [Redis React Home Page](https://github.com/ServiceStackApps/RedisReact#download)", ,6
https://github.com/asmboom/Lizitt-Unity3D-Outfitter,# Lizitt Outfitter (Unity3D),,1
https://github.com/asmboom/Lizitt-Unity3D-Outfitter,## Notice,  This project is in flux as its undergoes a major redesign.  Components are checked-in as individual unit testing is completed. Changes will be frequent and proper integration testing is limited during this phase. Release v0.2.0 will be created once the design has stabilized and all testing completed.,4
https://github.com/asmboom/Lizitt-Unity3D-Outfitter,## Overview,"  API Status: Pre-release Alpha
Test Status: Beta
Language: C#
Target: Unity3D 5.3+ (Personal & Professional) The Outfitter helps a user to define prototypes (usually prefabs) that represent outfits and accessories.  These components are combined at run-time to represent an agent's body.  Certain parts of the outfits, such as materials can be overriden in order to support outfit variants.  At run-time the outfits and accessories are instantiated as needed to create a body.",14
https://github.com/asmboom/Lizitt-Unity3D-Outfitter,## Installation,"  Requires: Lizitt-Unity3D-Utilities Core & EasingCore
Unity3D v5.3+ 
Install Lizitt-Unity3D-Utilities Core & EasingCore
Download this project and drop the contents of the Source directory into the Unity Assets folder.
",3
https://github.com/asmboom/Lizitt-Unity3D-Outfitter,## Documentation,  There is some information over on the Wiki.  All code is documented using standard C# XML comments.,6
https://github.com/asmboom/Lizitt-Unity3D-Outfitter,### Videos,"  A Quick Introduction  (Outdated: v0.1.0.  Similar concepts, but outdated features and design.)",6
https://github.com/asmboom/Lizitt-Unity3D-Outfitter,## Miscellaneous,  All members are located under the com.lizitt.outfitter namespace.,6
https://github.com/igorT/khan-exercises,# Khan Academy Exercises, Copyright 2011 Khan Academy The exercise framework is MIT licensed. The exercises are under a Creative Commons by-nc-sa license.,5
https://github.com/igorT/khan-exercises,## Exercise Framework,"  Khan Academy has created a generic framework for building exercises. This framework, together with the exercises themselves, can be used completely independently of the Khan Academy application. The framework exists in two components: 
An HTML markup for specifying exercises.
A jQuery plugin for generating a usable, interactive, exercise from the HTML markup.
",1
https://github.com/igorT/khan-exercises,## Writing Exercises,"  The process for writing exercises is rather well documented. More information about this process can be found in the Khan Exercises wiki. Specifically: 
How to Get Involved
How to Write Exercises
How to Test Exercises
",36
https://github.com/omedbb/volume-leather-fill,# 2048," This is a derivative and the iOS version of the game 2048. In the very unlikely case that you don't know what it is, you can check it out here. Made just for fun! You can find it on the App Store. 

",1
https://github.com/omedbb/volume-leather-fill,## AI,"  An AI is added, thanks to DJBen! Tap ""Hint"" to show hint (e.g. Move left/right/up/down); tap ""Auto Run"" to run AI automatically. Check it out in the AI branch. You can also check out this demo video on YouTube. Thanks to ov3y's Javascript version that gave me (DJBen, that is) inspiration.",135
https://github.com/omedbb/volume-leather-fill,### Issues and pending improvements,"  Currently the searching depth is 2 and it fails sometimes. You can increase the number to 3 or more by changing the return value of - (NSInteger)maximumSearchingDepth in M2GlobalState+AI.h. Ideally, the AI should search from 0 depth to infinity and have a time out, it records the current best move when finish searching the current depth and stops immediately when timed out and return the best move so far. However, I have a little bit of trouble when dealing with NSOperationQueue so I didn't do it this way. Now the AI only searches at the specified -maximumSearchingDepth.",3
https://github.com/omedbb/volume-leather-fill,## The Game,"  Since it is a derivative of the original 2048, it is not the same. More explicitly, it has the following additions: 
Three board sizes: 3x3, 4x4 and 5x5. The smaller the board is, the fewer cells you have, and the harder the game is.*
Three game modes: The original Power of 2, i.e. combining two tiles of the same value to produce their sum. The Power of 3, i.e. combining three consecutive tiles of the same value to produce their sum. Not surprisingly, this is pretty hard with the 3x3 board, although I found it pretty easy to get 81. 243 is a different story... And the Fibonacci sequence, i.e. combining two adjacent numbers in the sequence 2, 3, 5, 8, 13... (I omitted the two 1's in the beginning) to produce the one next to the larger value. This is pretty tricky. Try it out and you will know what I mean.
Three themes: I made a bright theme and a 'joyful' theme in addition to the original one. In case you wonder how to do themes in iOS. (There may be a better way, but themes are verbose in nature, because you have to specify all the colors, fonts, etc.)
",1
https://github.com/omedbb/volume-leather-fill,## The Technology,"  This version of 2048 is built using SpriteKit, the new 2-D game engine Apple introduced to iOS 7. As a result, it requires iOS 7 to run. On the other hand, this app has the following two great properties: 
It does not rely on any third-party library. Not that Cocos-2D is not great, but the fact it's using SpriteKit means that it does not have any dependencies.
It does not have any images. That's right. The entire UI is done either via UIKit, or by Core Graphics. Check out the related files to see how that is done, if you are curious.
 You should be able to download the source, and build and run without problem. However, please note that you may not want to run it in the simulator unless you don't have an Apple Developer account. SpriteKit does use OpenGL, and simulating that using CPU will cause your computer to take off.",13
https://github.com/omedbb/volume-leather-fill,## The Code,"  First off, the best thing about the code is that it's pretty well documented. Most methods have the Apple-style documentation, which means that you can triple-click on the method name to get its documentation. The code started to resemble the structure of the original 2048. So for example, it has a game manager, a board class, a tile class, etc. I at least tried to stick to MVC as much as possible. Here is a brief summary to get you started: 
The M2GameManager class controls the game logic. There is only one action in the game: move. So the majority of that class is handling the move. The rest is checking whether you've won or died, etc.
The M2Grid class is the data structure for the board. The original 2048 used a 1-D array, but heck, 2-D array doesn't seem to be too bad here! ...except looping it is a bit ugly, so I made a forEach helper function.
The M2Cell class is the ""slot""s. They are not the tiles themselves. The benefit of having this class is that the cells never move, so they are good references and they don't mess stuff up.
The M2Tile class is the actual tile, and this is the actual SpriteKit class. If all you want is some sample code for SpriteKit, here it is. I believe my animations are smoother than the other 2048 on the App Store, and are closer to the original animation.
The M2GlobalState class is a global class accessible from anywhere in the universe. Well, global stuff is evil, right? At least so we are told. But, it is at least better to encapsulate the global stuff into one single object (namespace), and that's a singleton right there.
The M2Theme class and its subclasses control the theme.
There are also some controller classes and view classes. It's probably a better idea to do the Game Over scene in SpriteKit, but I was lazy so I faked it using a view. The M2GridView class is the one that draws the board, btw.
",3
https://github.com/omedbb/volume-leather-fill,### Contributing,"  If you'd like to contribute, great! That's more than welcome. If you do make improvements to it, remember to put yourself in the ""About 2048"" page to get yourself credit. If you'd like to fork and make your own version, that's also great! Feel free to tinker with it however you'd like. It may not be a terribly good idea to change the font, add some ads, and submit to Apple, though.",7
https://github.com/omedbb/volume-leather-fill,#### Contributors,"  
Danqing Liu (me)
Scott Matthewman
Sihao Lu
",5
https://github.com/omedbb/volume-leather-fill,## Licence and Other,"  2048 for iOS is licenced under the MIT license. If you find the source code somewhat useful, all I ask is to download it from the App Store, so I know that someone has seen it. Relax: It is free; it does not have any ads or weird stuff; it does not send you push notifications to ask you to go back and play it. You may also consider to donate to the maker of the original 2048 if you'd like, of course. (:",5
https://github.com/bikong2/rrc_detection,# Accurate Single Stage Detector Using Recurrent Rolling Convolution," By Jimmy Ren, Xiaohao Chen, Jianbo Liu, Wenxiu Sun, Jiahao Pang, Qiong Yan, Yu-Wing Tai, Li Xu.",15
https://github.com/bikong2/rrc_detection,### Introduction,"  High localization accuracy is crucial in many real-world applications. We propose a novel
single stage end-to-end object detection network (RRC) to produce high accuracy detection results. You can use the code to train/evaluate a network for object detection task. For more details, please refer to our paper (https://arxiv.org/abs/1704.05776). 


method
KITTI test mAP car (moderate)




Mono3D
88.66%


SDP+RPN
88.85%


MS-CNN
89.02%


Sub-CNN
89.04%


RRC (single model)
89.85%


 KITTI ranking",126
https://github.com/bikong2/rrc_detection,### Citing RRC,"  Please cite RRC in your publications if it helps your research: @inproceedings{Ren17CVPR,
author = {Jimmy Ren and Xiaohao Chen and Jianbo Liu and Wenxiu Sun and Jiahao Pang and Qiong Yan and Yu-Wing Tai and Li Xu},
title = {Accurate Single Stage Detector Using Recurrent Rolling Convolution},
booktitle = {CVPR},
year = {2017}
}",5
https://github.com/bikong2/rrc_detection,### Contents,"  
Installation
Preparation
Train/Eval
Models
Ackonwledge
",6
https://github.com/bikong2/rrc_detection,### Installation,"  
Get the code. We will call the directory that you cloned Caffe into $CAFFE_ROOT
https://github.com/xiaohaoChen/rrc_detection.git
cd rrc_detection

Build the code. Please follow Caffe instruction to install all necessary packages and build it.
Before build it, you should install CUDA and CUDNN(v5.0).
CUDA 7.5 and CUDNN v5.0 were adapted in our computer.
# Modify Makefile.config according to your Caffe installation.
cp Makefile.config.example Makefile.config
make -j8
# Make sure to include $CAFFE_ROOT/python to your PYTHONPATH.
make py
make test -j8
make runtest -j8

",3
https://github.com/bikong2/rrc_detection,### Preparation,"  

Download fully convolutional reduced (atrous) VGGNet.
By default, we assume the model is stored in $CAFFE_ROOT/models/VGGNet/.


Download the KITTI dataset(http://www.cvlibs.net/datasets/kitti/eval_object.php).
By default, we assume the data is stored in $HOME/data/KITTI/
  Unzip the training images, testing images and the labels in $HOME/data/KITTI/.


Create the LMDB file.
For training .
As only the images contain cars are adopted as training set for car detection,  the labels for cars should be extracted.
We have provided the list of images contain cars in $CAFFE_ROOT/data/KITTI-car/.
# extract the labels for cars
cd $CAFFE_ROOT/data/KITTI-car/
./extract_car_label.sh
Before create the LMDB files. The labels should be converted to VOC type. We provide some matlab scripts.
The scripts are in $CAFFE_ROOT/data/convert_labels/. Just modify converlabels.m.
line 4: root_dir = '/your/path/to/KITTI/';
VOC type labels will be generated in $KITTI_ROOT/training/labels_2car/xml/.
cd $CAFFE_ROOT/data/KITTI-car/
# Create the trainval.txt, test.txt, and test_name_size.txt in data/KITTI-car/
./create_list.sh
# You can modify the parameters in create_data.sh if needed.
# It will create lmdb files for trainval and test with encoded original image:
#   - $HOME/data/KITTI/lmdb/KITTI-car_training_lmdb/
#   - $HOME/data/KITTI/lmdb/KITTI-car_testing_lmdb/
# and make soft links at data/KITTI-car/lmdb
 ./data/KITTI-car/create_data.sh

",3
https://github.com/bikong2/rrc_detection,### Train/Eval,"  
Train your model and evaluate the model.
# It will create model definition files and save snapshot models in:
#   - $CAFFE_ROOT/models/VGGNet/KITTI/RRC_2560x768_kitti_car/
# and job file, log file in:
#   - $CAFFE_ROOT/jobs/VGGNet/KITIIT/RRC_2560x768_kitti_car/
# After 60k iterations, we can get the model as we said in the paper (mAP 89.*% in KITTI).
python examples/car/rrc_kitti_car.py
# Before run the testing script. You should modify [line 10: img_dir] to [your path to kitti testing images].
python examples/car/rrc_test.py
We train our models in a computer with 4 TITAN X(Maxwell) GPU cards. By default, we assume you train the models on mechines with 4 TITAN X GPUs.
If you only have one TITAN X card, you should modify the script rrc_kitti.py.
line 118: gpus = ""0,1,2,3"" -> gpus = ""0""
line 123: batch_size = 4   -> batch_size = 1
If you have two TITAN X cards, you should modify the script rrc_kitti.py as follow.
line 118: gpus = ""0,1,2,3"" -> gpus = ""0,1""
line 123: batch_size = 4   -> batch_size = 2
You can submit the result at kitti submit.
If you don't have time to train your model, you can download a pre-trained model from the link as follow.
Google Drive
Baidu Cloud
Unzip the files in $caffe_root/models/VGGNet/KITTI/, and run the testing script rrc_test.py, you will get the same result as the single model result we showed in the  paper.
# before run the script, you should modify the kitti_root at line 10.
# Make sure that the work directory is caffe_root
cd $caffe_root
python models/VGGNet/KITTI/RRC_2560x768_kitti_4r4b_max_size/rrc_test.py

Evaluate the most recent snapshot.
For testing a model you trained, you show modify the path in rrc_test.py.
",3
https://github.com/bikong2/rrc_detection,### Acknowledge,"  Thanks to Wei Liu, we have benifited a lot from his previous work SSD (Single Shot Multibox Detector) and his code.",5
https://github.com/bkachamakov/FreeCodeCamp,# Welcome to Free Code Camp's open source codebase!," Free Code Camp is an open-source community of busy people who learn to code, then build projects for nonprofits. Our campers (students) start by working through our free, self-paced, browser-based curriculum. Next, they build several practice projects. Finally, we pair two campers together with a stakeholder from a nonprofit organization, and help them build the solution the nonprofit has requested. We help our campers build job-worthy portfolios of real apps used by real people, while helping nonprofits. 80% of our campers are over 25, and nearly a fifth of our campers are women. This code is running live at FreeCodeCamp.com. We also have Gitter, a blog, and even a Twitch.tv channel. Join our community here. Note: We're currently very close to moving from Express to Loopback. As such, please keep in mind that the instructions here for setting up and running the project do not directly translate to the staging branch. Additionally, the file structure is quite a bit different. As always, the staging branch is the appropriate place to branch off of to fix/add something.",16
https://github.com/bkachamakov/FreeCodeCamp,## Wiki,  We would love your help expanding our wiki with more information about learning to code and getting a coding job.,6
https://github.com/bkachamakov/FreeCodeCamp,## Contributing,"  We welcome pull requests from Free Code Camp campers (our students) and seasoned JavaScript developers alike! Follow these steps to contribute: 
Check our public Waffle Board.
Pick an issue that nobody has claimed and start working on it. If your issue isn't on the board, open an issue. If you think you can fix it yourself, start working on it. Feel free to ask for help in our Gitter.
Fork the project (Need help with forking a project?). You'll do all of your work on your forked copy.
Create a branch specific to the issue or feature you are working on. Push your work to that branch. (Need help with branching?)
Name the branch something like  user-xxx where user is your username and xxx is the issue number you are addressing.
You should have ESLint running in your editor, and it will highlight anything doesn't conform to AirBnB's JavaScript Style Guide.  Please do not ignore any linting errors, as they are meant to help you. Make sure none of your JavaScript is longer than 80 characters per line.
Once your code is ready, submit a pull request from your branch to Free Code Camp's staging branch. We'll do a quick code review and give you feedback, then iterate from there.
Once we accept one of your pull requests, one of the project owners (currently @quincylarson, @terakilobyte, and @berkeleytrue) will add you to our camper contributor group.
",7
https://github.com/bkachamakov/FreeCodeCamp,## Prerequisites,"  
MongoDB
Node.js
",3
https://github.com/bkachamakov/FreeCodeCamp,## Getting Started,"  The easiest way to get started is to clone the repository: # Get the latest snapshot
git clone --depth=1 https://github.com/freecodecamp/freecodecamp.git freecodecamp

cd freecodecamp

# Install NPM dependencies
npm install

# Install Bower dependencies
bower install

# Create a .env file and populate it with the necessary API keys and secrets:
touch .env

# Install Gulp globally
npm install -g gulp Edit your .env file with the following API keys accordingly (if you only use email login, only the MONGOHQ_URL, SESSION_SECRET, MANDRILL_USER and MANDRILL_PASSWORD fields are necessary. Keep in mind if you want to use more services you'll have to get your own API keys for those services. 
MONGOHQ_URL='mongodb://localhost:27017/freecodecamp'

FACEBOOK_ID=stuff
FACEBOOK_SECRET=stuff

GITHUB_ID=stuff
GITHUB_SECRET=stuff

GOOGLE_ID=stuff
GOOGLE_SECRET=stuff

LINKEDIN_ID=stuff
LINKEDIN_SECRET=stuff

MANDRILL_PASSWORD=stuff
MANDRILL_USER=stuff

TRELLO_KEY=stuff
TRELLO_SECRET=stuff

TWITTER_KEY=stuff
TWITTER_SECRET=stuff
TWITTER_TOKEN=stuff
TWITTER_TOKEN_SECRET=stuff

BLOGGER_KEY=stuff

SESSION_SECRET=secretstuff
COOKIE_SECRET='this is a secret'

PEER=stuff
DEBUG=true

 # Start the mongo server
mongod

# Create your mongo database. 
# Type ""mongo"" in your terminal to access the mongo shell 
use freecodecamp
# Exit the mongo shell with control + d

# Seed your database with the challenges
node seed/

# start the application
gulp
",3
https://github.com/bkachamakov/FreeCodeCamp,## License,"  The BSD-3-Clause Copyright (c) 2015, Free Code Camp
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 

Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.


Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.


Neither the name of Free Code Camp nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

 THIS SOFTWARE IS PROVIDED BY FREE CODE CAMP AND CONTRIBUTORS ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.",5
https://github.com/abhilashkkumar/testapp_rails,# Test Rails App," (For this DigitalOcean guide) This Rails App has been fully configured with Nginx, Puma and Capistrano. This app isn't meant to be used
as a starting point for your Application, this is just an example to take help from.",16
https://github.com/abhilashkkumar/testapp_rails,## App Details,"  This app uses: 
Ruby Version: 2.2.1
Rails Version: 4.2.0
Web Server: Puma 2.11.1
Database: MongoDB
Database Driver: Mongoid 4.0.2
Automation Tool: Capistrano 3.4.0
",3
https://github.com/abhilashkkumar/testapp_rails,## Test Droplet Details,"  The Droplet where this App was hosted had: 
Server IP: 178.62.88.94
SSH Port: 7171
User: deploy
App Name (For Capistrano): testapp
 In the DB Installation Step, I installed MongoDB since this app uses Mongoid.",3
https://github.com/abhilashkkumar/testapp_rails,## Testing on Your own Droplet,"  If you'd like to test this app on your own droplet, fork
this repo and follow the DigitalOcean Guide step-by-step replacing parameters (such as Droplet IP, SSH Port, User, etc.)
with your Repo URL and Droplet's information.",3
https://github.com/ryam244/cdnjs-1,# cdnJS Script Repository," The repository mirroring all scripts on cdnjs.cloudflare.com, created and maintained by Thomas Davis, Ryan Kirkman and Lachlan Collins We will host any version of any library. Feel free to add a pull request for an older version of a library if your site still uses it. Libraries must have notable popularity. 100 watchers on GitHub is a good example, but as long as reasonably popularity can be demonstrated the library will be added.",15
https://github.com/ryam244/cdnjs-1,"## Extensions, Plugins, Resources","  Extensions, Plugins, Resources",6
https://github.com/ryam244/cdnjs-1,## Conventions,"  
Filenames should not include version number and be lowercase
Javascript & Css files should be minified, If the library doesn't already provide a minified version, our preferred minifier is UglifyJS
If updating an existing library, try to keep consistent with the existing structure
",3
https://github.com/ryam244/cdnjs-1,## Pull requests steps,"  
Fork this repository
 
Install all the needed dependencies locally (you will need node): npm install
 
Add your library (following the conventions of this repository)
 
1 commit per pull request
1 library per pull request
The pull request must be tagged in the original repository (some exceptions apply)
include a package.json in the npm format (see test/schemata/npm-package.json for details - it's very simple)
Run npm test to check everything is ok
 
Send us a pull request.
 
Make sure you include in the pull description:

Where you downloaded the script
If it isn't clear, how you found the version of the script


e.g. https://github.com/cdnjs/cdnjs/pull/541
 
If the library doesn't already provide a minified version, our preferred minifier is UglifyJS
",7
https://github.com/ryam244/cdnjs-1,## Running the validator,"  
Install all the needed dependencies locally (you will need node): npm install
Run the test suite: npm test
",3
https://github.com/melodysu83/AutoCircle_generater,# AutoCircle_generater, This software is a ROS node that generates RAVEN motion commands for it to follow a predefined circle trajectory. The circle RADIUS and orbitting speed are tunable. There are 2 ROS nodes in this folder: talkerAutoCircle and listenerAutoCircle.,1
https://github.com/melodysu83/AutoCircle_generater,## ROS topics :,"  The two ROS nodes talkerAutoCircle and listenerAutoCircle exchange information through ROS topics. Below are the two ROS topics that this software use in order to communicate with the main RAVEN software. This is the link to the .msg files. 
raven_state.msg : This topic stores current RAVEN position and orientation values.
raven_automove.msg : This topic stores the motion command for RAVEN to move accordingly.
",1
https://github.com/melodysu83/AutoCircle_generater,## ROS nodes :,"  
talkerAutoCircle : This ROS node is the command generator. It subscribes to raven_state.msg ROS topic to get current RAVEN status, then computes corresponding motion commands for the robot arm to follow circle trajectory. Finally, it publishes to raven_automove.msg ROS topic.
listenerAutoCircle : This ROS node is only for testing. It serves the same purpose as the main RAVEN software, and will be replaced during actual use. It communicates with the talkerAutoCircle by listening to the motion commands and sends out RAVEN position and orientation feedback after following the command. Thus, it subscribes to raven_automove.msg ROS topic, and updates RAVEN position and orientation accordingly, then publishes raven_state.msg ROS topic to show how the robot arm is currently posed.
",1
https://github.com/melodysu83/AutoCircle_generater,## Files :,"  This is the big picture of what files are in this AutoCircle_generater repository and what are each files are for. Note that only the ones specified as (original) are the original files created here, others are copied from the main RAVEN software and do NOT need to copy again to the main RAVEN software when combining. /msg folder: ----raven_automove.msg ----raven_state.msg /src folder: ----/raven_2 folder: --------raven_automove.h --------raven_state.h ----DS0.h ----DS1.h ----Raven_Controller.cpp --------------------- (original) ----Raven_Controller.h ----------------------- (original)This class controls the threads and workflow. ----Raven_PathPlanner.cpp -------------------- (original) ----Raven_PathPlanner.h ---------------------- (original)This class defines all the math and path planning. ----listener.cpp ----------------------------- (original)This will be replaced with main RAVEN software. ----talker.cpp ------------------------------- (original)This file is where main is. ----tools.h AutoCircle Generator flowchart.png ----------- (original)The ROS publish/subscribe flowchart for better understanding. CMakeLists.txt ------------------------------- (original)Should merge with CMakeLists.txt in main RAVEN software. README.md ------------------------------------ (original)This file! package.xml ---------------------------------- (original)The ROS package.xml file. The file talker.cpp is the heart of AutoCircle generater, it is where the main is. This file uses on methods defined in class Raven_Controller. Inside of class Raven_Contoller, there are two threads - ros_thread and console_thread, which takes charge of the ROS publishing/subscribing issues and user console inputs respectively. The class Raven_Contoller depends on class Raven_PathPlanner to compute and design circular trajectories. So, it is basically where all the math is! In the class Raven_Controller, there are two Raven_PathPlanner objects managing the motion of LEFT and RIGHT arm of RAVEN. (All these files belong to the talkerAutoCircle ROS node.)
And since we are NOT actually connected to the main RAVEN software yet, we have listener.cpp as the simplified version to simulate the main RAVEN software just so talker.cpp has someone to interact with. Thus, listener.cpp will be completely replaced when we actually combine it with the RAVEN code. (This file belongs to the listenerAutoCircle ROS node.)",6
https://github.com/melodysu83/AutoCircle_generater,## How To Use This Code:,"  This software design allows RAVEN to be controlled and follow predefined circular trajectory from any remote computer, so below is the instruction for hardware setup and terminal commands for it to work.
Computer A: The computer that downloads this AutoCircle_generater software and runsroscore from here.
Computer B: This is the computer that RAVEN main software runs on. (This should be already setup and ready to go.) 

Find out hostname and IP : On both computer A and computer B, open up a terminal, type in ""hostname"" to find out the hostname of that computer and type in ""ifconfig"" to find out the IP address. Note that it will be better and more stable connection-wise if both computers are connected to wired internet. Because wireless connections does not have static IP, and can cause floating IP problem which may cause us to lose connection midway through your control.
Up to this point, we should have: IP for computer A and B (denoted as IP_A and IP_B later on in the instruction),as well as the hostname for computer A and B  (denoted as hostname_A and hostname_B later on in the instruction).


Download AutoCircle_generater code : On computer A, type in ""git clone git://github.com/melodysu83/AutoCircle_generater.git"" to download this repository to the directory you desire. It should create a AutoCircle_generater folder under that directory. Note that this should be a directory under the your ROS workspace. Then go back to your ROS workspace directory, type in ""catkin_make_isolated --pkg AutoCircle_generater"", and this should build the software. Now this part of the software is done.


ssh : On computer A, open up another terminal and type in ""ssh -X hostname_A@IP_B"", it should allow you to control computer B from this terminal. Assume you already have RAVEN running on this computer, type in ""pwd"", and then ""roscd raven_2"". Note that this RAVEN code should be the RAVEN 10.16 release version in October 2016, because there is a pedal down/pedal up switch where you can control by pressing 'd' and 'u' keys respectively. And this feature is required for the AutoCircle_generater to work. If you don't have the version yet, you can download it from here, and use the indigo branch.


Up and running : On computer A, open up another terminal and run ""roscore"". Use ths terminal is step 3, type in ""sudo roslaunch raven_2 raven_2.launch"". Next, initialize RAVEN. After it is initialized, press 'd' and it holds the pedal down state for 5 seconds. If no commend is sent within the time range, it will automatically switch back to pedal up state. If you are constantantly sending commends, then RAVEN will be in pedal down state all the time until you press 'u' manually. But you can always re-press 'd' again if you need to. Within the 5 second, use the terminal in step 2, type in ""rosrun AutoCircle_genetater talkerAutoCircle"" under the main ROS workspace directory, and you sill need to press ""Enter"" to start. At this point, you should see RAVEN moving slowly in very small circles already if everything is good.

",3
https://github.com/melodysu83/AutoCircle_generater,## Trouble Shooting :,"  These are the problems that may occur to you. Basically if you are running AutoCircle_generater code, and still the pedal down state in RAVEN holds for 5 seconds then jumps back to pedal up, that means there is something wrong with the connection. Try doing the following to identify the problem . If you cannot even run the RAVEN code from terminal in step 2, then it is not even sensing the ""roscore"" on computer A. 

Internet Connection Issue : (If you cannot run RAVEN code) On the terminal in step 2, where you ssh to computer B, type in ""ping hostname_A"", and make sure it works well. If not, try ""ping IP_A"". If hostname_A fails but IP_A works, that means computer B does not know the name of computer A. Do it by typing in ""gedit /etc/hosts"" and add in hostname_A IP_A to the list of hosts. If even ""ping IP_A"" does not work, then there is some internet issue, try checking your internet connection and double check the IP address. Do the same process for computer A on any other terminal, only to change by typing ""ping hostname_B"" and ""ping IP_B"". If both sides are working good,


ROS_MASTER_URL : Make sure you set the ROS_MASTER_URL correctly. It should be the following: On regular terminal on computer A, type in ""gedit ~/.bashrc"", then set ROS_MASTER_URL = host_A (or IP_A), ROS_IP = host_A (or IP_A). On the terminal you ssh to computer B, type in ""gedit ~/.bashrc"", then set ROS_MASTER_URL = host_A (or IP_A), ROS_IP = host_B (or IP_B). This can be a tricky part, so be sure to set it correctly. This should ensure the ROS topic publishing and subscribing to be bidirectional.


rostopic monitoring : You can type in ""rostoppic echo topicname -c"" this on each side to monitor the publishing and subscribing condition and check if it's the problem of receiving ravenstate or sending raven_automove.

",3
https://github.com/melodysu83/AutoCircle_generater,## Selection Menu :,"  User can choose the circle speed, radius, direction(clockwise or counter-clockwise), base plane(Y-Z plane, X-Z plane, X-Y plane), center of the circle, as well as whether or not to display motion status on console.
Note that only the Y-Z base plane will generate horizontal circle motion, the other two are vertical. There are 60 levels of speed and 6 levels of radius. In horizontal circles (Y-Z base plane) under radius level 1 and 2, we can only increase the speed up to level 50, while larger radius (level 3 ~ 6) allows max speed to be level 60. In vertical circles (Y-Z and X-Z base plane), it requires more torque so we set max speed to be level 40 under all radius.",3
https://github.com/melodysu83/AutoCircle_generater,## Spec :,"  These are the constraints we set for our physical device - RAVEN surgical robot arm to function normally. These are mostly defined in PathPlanner.h file under /src folder. Be careful when tuning these values! 

publish rate : The raven_automove.msg is being sent at 1000 Hz.


feedback rate : The raven_state.msg is being sent at 100 Hz in listener.cpp. But in actual RAVEN software, raven_state.msg is updated at 1000 Hz.


DEL_POS_THRESHOLD : This is the motion translation threshold for RAVEN to move. It is set as 180 micro meter (=0.18 mm = 0.018 cm). That being said, the maximum speed that RAVEN will be moving is 1000 Hz * 0.018 cm = 18 (cm/sec).


DEL_ROT_THRESHOLD : This is the motion rotation threshold for RAVEN to move. It is set to be 0.25 degrees. That being said, the maximum rotational speed for RAVEN will be is 1000 Hz * 0.25 degrees = 250 (degrees/sec). This is currently unused because the circle trajectoy we have now does NOT include orientation motion.


RADIUS levels : There are ten levels of RADIUS to choose from. Level 1 ~ 6 corresponds to 3000 micro meter (=3 mm = 0.3cm) ~ 100000 micro meter (=18 mm = 1.8cm). Yet that is the desired radius. From our experiments, the relation between desired radius and actual radius are listed as follows:  actual radius = desired radius * 2/3 + 1.0


SPEED levels : There are sixty levels of SPEED to choose from, with each level increasing 0.3 cm/sec from the previous level. So level 1 ~ 60 corresponds to moving 0.3 cm/sec (= 3mm/sec = 0.003 mm per command) all the way up to 18 cm/sec (= 180mm/sec = 0.18 mm per command, which is exactly DEL_POS_THRESHOLD).

",3
https://github.com/melodysu83/AutoCircle_generater,## Relative links:,"  
uw-biorobotics/raven2 : This is the main RAVEN software that this AutoCircle generater software is going to connect to. And this code will replace the ROS node listenerAutoCircle that we temporarily have for now.
raven_absolute_controller : This is the extended work for RAVEN absolute position control done by Imperial College London. We were originally intended to implement the AutoCircle generater based on their work. But since we want it to be a ROS node instead of teleoperating and sending UDP packages to communicate, we eventually didn't apply their code.
",6
https://github.com/caomm/angularjs-springmvc-sample,# angularjs-springmvc-sample," An example application using AnguarJS/Bootstrap as frontend and Spring MVC as REST API producer.  ##Contribution I appreciate any contribution for this project, including suggestions, documentation improvements, reporting issues, forks and bugfixs,  etc. I have found there are some unrelated issues added, before you file an issue, please READ THE STEPS IN THIS README.md  carefully. 在你提交 ISSUE 前，请务必确认已经严格完成了本文中描述的操作步骤?Thank the DevFactory team member @misgersameer for sending several PRs to improve the code quaulity according to the sonar rules. ##Requirements 

JDK 8
Oracle Java 8 is required, go to Oracle Java website to download it and install into your system.
Optionally, you can set JAVA_HOME environment variable and add <JDK installation dir>/bin in your PATH environment variable.


Apache Maven
Download the latest Apache Maven from http://maven.apache.org, and uncompress it into your local system.
Optionally, you can set M2_HOME environment varible, and also do not forget to append <Maven Installation dir>/bin your PATH environment variable.

",1
https://github.com/caomm/angularjs-springmvc-sample,##Contribution,"I appreciate any contribution for this project, including suggestions, documentation improvements, reporting issues, forks and bugfixs, etc. I have found there are some unrelated issues added, before you file an issue, please READ THE STEPS IN THIS README.md carefully.

ύ ISSUE ǰȷѾϸ˱Ĳ衣

Thank the DevFactory team member @misgersameer for sending several PRs to improve the code quaulity according to the sonar rules.",7
https://github.com/caomm/angularjs-springmvc-sample,##Requirements,"JDK 8

Oracle Java 8 is required, go to Oracle Java website to download it and install into your system.

Optionally, you can set JAVA_HOME environment variable and add <JDK installation dir>/bin in your PATH environment variable.

Apache Maven

Download the latest Apache Maven from http://maven.apache.org, and uncompress it into your local system.

Optionally, you can set M2_HOME environment varible, and also do not forget to append <Maven Installation dir>/bin your PATH environment variable.",3
https://github.com/caomm/angularjs-springmvc-sample,## Run this project,"  
Clone the codes.
 <pre>
git clone https://github.com/hantsy/angularjs-springmvc-sample
</pre>
 
And enter the root folder, run mvn tomcat7:run to start up an embedded tomcat7 to serve this application.
 <pre>
mvn tomcat7:run
</pre>
 
Go to http://localhost:8080/angularjs-springmvc-sample/ to test it. If you want to explore the REST API docs online, there is a Swagger UI configured for visualizing the REST APIs, just go to http://localhost:8080/angularjs-springmvc-sample/swagger-ui.html.
",3
https://github.com/caomm/angularjs-springmvc-sample,## Spring Boot,"  If you are interested in Spring Boot, I have moved the boot branch into a new project angularjs-springmvc-sample-boot.",6
https://github.com/manuelbrand/WeatherPage,# angular-seed ?the seed for AngularJS apps," This project is an application skeleton for a typical AngularJS web app.
You can use it to quickly bootstrap your angular webapp projects and dev environment for these
projects. The seed contains a sample AngularJS application and is preconfigured to install the Angular
framework and a bunch of development and testing tools for instant web development gratification. The seed app doesn't do much, just shows how to wire two controllers and views together.",12
https://github.com/manuelbrand/WeatherPage,## Getting Started,  To get you started you can simply clone the angular-seed repository and install the dependencies:,3
https://github.com/manuelbrand/WeatherPage,### Prerequisites,"  You need git to clone the angular-seed repository. You can get git from
http://git-scm.com/. We also use a number of node.js tools to initialize and test angular-seed. You must have node.js and
its package manager (npm) installed.  You can get them from http://nodejs.org/.",3
https://github.com/manuelbrand/WeatherPage,### Clone angular-seed,"  Clone the angular-seed repository using git: git clone https://github.com/angular/angular-seed.git
cd angular-seed
 If you just want to start a new project without the angular-seed commit history then you can do: git clone --depth=1 https://github.com/angular/angular-seed.git <your-project-name> The depth=1 tells git to only pull down one commit worth of historical data.",3
https://github.com/manuelbrand/WeatherPage,### Install Dependencies,"  We have two kinds of dependencies in this project: tools and angular framework code.  The tools help
us manage and test the application. 
We get the tools we depend upon via npm, the node package manager.
We get the angular code via bower, a client-side code package manager.
 We have preconfigured npm to automatically run bower so we can simply do: npm install
 Behind the scenes this will also call bower install.  You should find that you have two new
folders in your project. 
node_modules - contains the npm packages for the tools we need
app/bower_components - contains the angular framework files
 Note that the bower_components folder would normally be installed in the root folder but
angular-seed changes this location through the .bowerrc file.  Putting it in the app folder makes
it easier to serve the files by a webserver.",3
https://github.com/manuelbrand/WeatherPage,### Run the Application,"  We have preconfigured the project with a simple development web server.  The simplest way to start
this server is: npm start
 Now browse to the app at http://localhost:8000/index.html.",3
https://github.com/manuelbrand/WeatherPage,## Directory Layout,"  app/                    --> all of the source files for the application
  app.css               --> default stylesheet
  components/           --> all app specific modules
    version/              --> version related components
      version.js                 --> version module declaration and basic ""version"" value service
      version_test.js            --> ""version"" value service tests
      version-directive.js       --> custom directive that returns the current app version
      version-directive_test.js  --> version directive tests
      interpolate-filter.js      --> custom interpolation filter
      interpolate-filter_test.js --> interpolate filter tests
  view1/                --> the view1 view template and logic
    view1.html            --> the partial template
    view1.js              --> the controller logic
    view1_test.js         --> tests of the controller
  view2/                --> the view2 view template and logic
    view2.html            --> the partial template
    view2.js              --> the controller logic
    view2_test.js         --> tests of the controller
  app.js                --> main application module
  index.html            --> app layout file (the main html template file of the app)
  index-async.html      --> just like index.html, but loads js files asynchronously
karma.conf.js         --> config file for running unit tests with Karma
e2e-tests/            --> end-to-end tests
  protractor-conf.js    --> Protractor config file
  scenarios.js          --> end-to-end scenarios to be run by Protractor
",3
https://github.com/manuelbrand/WeatherPage,## Testing,  There are two kinds of tests in the angular-seed application: Unit tests and end-to-end tests.,3
https://github.com/manuelbrand/WeatherPage,### Running Unit Tests,"  The angular-seed app comes preconfigured with unit tests. These are written in
Jasmine, which we run with the Karma Test Runner. We provide a Karma
configuration file to run them. 
the configuration is found at karma.conf.js
the unit tests are found next to the code they are testing and are named as ..._test.js.
 The easiest way to run the unit tests is to use the supplied npm script: npm test
 This script will start the Karma test runner to execute the unit tests. Moreover, Karma will sit and
watch the source and test files for changes and then re-run the tests whenever any of them change.
This is the recommended strategy; if your unit tests are being run every time you save a file then
you receive instant feedback on any changes that break the expected code functionality. You can also ask Karma to do a single run of the tests and then exit.  This is useful if you want to
check that a particular version of the code is operating as expected.  The project contains a
predefined script to do this: npm run test-single-run
",3
https://github.com/manuelbrand/WeatherPage,### End to end testing,"  The angular-seed app comes with end-to-end tests, again written in Jasmine. These tests
are run with the Protractor End-to-End test runner.  It uses native events and has
special features for Angular applications. 
the configuration is found at e2e-tests/protractor-conf.js
the end-to-end tests are found in e2e-tests/scenarios.js
 Protractor simulates interaction with our web app and verifies that the application responds
correctly. Therefore, our web server needs to be serving up the application, so that Protractor
can interact with it. npm start
 In addition, since Protractor is built upon WebDriver we need to install this.  The angular-seed
project comes with a predefined script to do this: npm run update-webdriver
 This will download and install the latest version of the stand-alone WebDriver tool. Once you have ensured that the development web server hosting our application is up and running
and WebDriver is updated, you can run the end-to-end tests using the supplied npm script: npm run protractor
 This script will execute the end-to-end tests against the application being hosted on the
development server. Note:
Under the hood, Protractor uses the Selenium Standalone Server, which in turn requires
the Java Development Kit (JDK) to be installed on your local machine. Check this by running
java -version from the command line. If JDK is not already installed, you can download it here.",3
https://github.com/manuelbrand/WeatherPage,## Updating Angular,"  Previously we recommended that you merge in changes to angular-seed into your own fork of the project.
Now that the angular framework library code and tools are acquired through package managers (npm and
bower) you can use these tools instead to update the dependencies. You can update the tool dependencies by running: npm update
 This will find the latest versions that match the version ranges specified in the package.json file. You can update the Angular dependencies by running: bower update
 This will find the latest versions that match the version ranges specified in the bower.json file.",3
https://github.com/manuelbrand/WeatherPage,## Loading Angular Asynchronously,"  The angular-seed project supports loading the framework and application scripts asynchronously.  The
special index-async.html is designed to support this style of loading.  For it to work you must
inject a piece of Angular JavaScript into the HTML page.  The project has a predefined script to help
do this. npm run update-index-async
 This will copy the contents of the angular-loader.js library file into the index-async.html page.
You can run this every time you update the version of Angular that you are using.",3
https://github.com/manuelbrand/WeatherPage,## Serving the Application Files,"  While angular is client-side-only technology and it's possible to create angular webapps that
don't require a backend server at all, we recommend serving the project files using a local
webserver during development to avoid issues with security restrictions (sandbox) in browsers. The
sandbox implementation varies between browsers, but quite often prevents things like cookies, xhr,
etc to function properly when an html page is opened via file:// scheme instead of http://.",3
https://github.com/manuelbrand/WeatherPage,### Running the App during Development,"  The angular-seed project comes preconfigured with a local development webserver.  It is a node.js
tool called http-server.  You can start this webserver with npm start but you may choose to
install the tool globally: sudo npm install -g http-server
 Then you can start your own development web server to serve static files from a folder by
running: http-server -a localhost -p 8000
 Alternatively, you can choose to configure your own webserver, such as apache or nginx. Just
configure your server to serve the files under the app/ directory.",3
https://github.com/manuelbrand/WeatherPage,### Running the App in Production,"  This really depends on how complex your app is and the overall infrastructure of your system, but
the general rule is that all you need in production are all the files under the app/ directory.
Everything else should be omitted. Angular apps are really just a bunch of static html, css and js files that just need to be hosted
somewhere they can be accessed by browsers. If your Angular app is talking to the backend server via xhr or other means, you need to figure
out what is the best way to host the static files to comply with the same origin policy if
applicable. Usually this is done by hosting the files by the backend server or through
reverse-proxying the backend server(s) and webserver(s).",3
https://github.com/manuelbrand/WeatherPage,## Continuous Integration, ,3
https://github.com/manuelbrand/WeatherPage,### Travis CI,"  Travis CI is a continuous integration service, which can monitor GitHub for new commits
to your repository and execute scripts such as building the app or running tests. The angular-seed
project contains a Travis configuration file, .travis.yml, which will cause Travis to run your
tests when you push to GitHub. You will need to enable the integration between Travis and GitHub. See the Travis website for more
instruction on how to do this.",3
https://github.com/manuelbrand/WeatherPage,### CloudBees,"  CloudBees have provided a CI/deployment setup: 
 If you run this, you will get a cloned version of this repo to start working on in a private git repo,
along with a CI service (in Jenkins) hosted that will run unit and end to end tests in both Firefox and Chrome.",3
https://github.com/manuelbrand/WeatherPage,## Contact,  For more information on AngularJS please check out http://angularjs.org/,5
https://github.com/zhly0/LightGBM,"# LightGBM, Light Gradient Boosting Machine","  LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages: 
Faster training speed and higher efficiency
Lower memory usage
Better accuracy
Parallel learning supported
Capable of handling large-scale data
 For more details, please refer to Features. Experiments on public datasets show that LightGBM can outperform other existing boosting framework on both efficiency and accuracy, with significant lower memory consumption. What's more, the experiments show that LightGBM can achieve a linear speed-up by using multiple machines for training in specific settings.",126
https://github.com/zhly0/LightGBM,## News,"  12/05/2016 : Categorical Features as input directly(without one-hot coding). Experiment on Expo data shows about 8x speed-up with same accuracy compared with one-hot coding (refer to categorical log and one-hot log).
For the setting details, please refer to IO Parameters. 12/02/2016 : Release python-package beta version, welcome to have a try and provide issues and feedback.",4
https://github.com/zhly0/LightGBM,## Get Started And Documents,"  To get started, please follow the Installation Guide and Quick Start. 
Wiki
Installation Guide
Quick Start
Examples
Features
Parallel Learning Guide
Configuration
Document Indexer
",36
https://github.com/zhly0/LightGBM,## How to Contribute,"  LightGBM has been developed and used by many active community members. Your help is very valuable to make it better for everyone. 
Check out call for contributions to see what can be improved, or open an issue if you want something.
Contribute to the tests to make it more reliable.
Contribute to the documents to make it clearly for everyone.
Contribute to the examples to share your experience with other users.
Check out Development Guide.
Open issue if you met problems during development.
",7
https://github.com/zhly0/LightGBM,## Microsoft Open Source Code of Conduct,  This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.,5
https://github.com/RubenPHP/cookieconsent,## What is Cookie Consent?," Cookie Consent is a lightweight JavaScript plugin for alerting users about the use of cookies on your website. It is designed to help you comply with the hideous EU Cookie Law and not make you want to kill yourself in the process. So we made it fast, free, and relatively painless.",12
https://github.com/RubenPHP/cookieconsent,## Version 3.0,"  Version 3.0 is a complete rewrite from version 2. The most substantial new features are: 
the ability to GeoLocate and only show the addon to people in the relevant countries
callback hooks for showing/accepting/revoking the banner
support for different types of compliance, giving you the flexibility to obey even the strictest cookie laws
easy no-fuss themes and customisable styles
",4
https://github.com/RubenPHP/cookieconsent,## Installation,  The easiest way to get up and running is to use our wizard. You can also install this project through npm: npm install cookieconsent Or through Bower: bower install cookieconsent,3
https://github.com/RubenPHP/cookieconsent,## Documentation,  See our full documentation.,6
https://github.com/RubenPHP/cookieconsent,## Contributing,  Feel free to improve the plugin and send us a pull request. The easiest way to develop is to host the files with a local webserver. e.g. python -m SimpleHTTPServer We use Gulp to compile the SCSS and minify the JavaScript. You can run a build with: gulp build,7
https://github.com/RubenPHP/cookieconsent,## License,  Code released under the MIT licence.,5
https://github.com/RubenPHP/cookieconsent,## Credits,"  Cookie Consent v3 
Alex Morley-Finch - JavaScript
Piiu Pilt - JavaScript
Oliver Emberton (@oliveremberton) - a couple of lines of CSS, maybe
 Cookie Consent v2 
David Ball (@drball) - CSS / themes
Adam Hutchinson (@adjohu) - JavaScript
",5
https://github.com/peteryunkim/javascript-intro-to-functions-lab-web-031317,## JavaScript Intro to Functions Lab,,1
https://github.com/peteryunkim/javascript-intro-to-functions-lab-web-031317,## Objectives,"  
Practice writing functions
Explain basics of working with strings
Explain the difference between return and logging
Practice using return and console.log()
",12
https://github.com/peteryunkim/javascript-intro-to-functions-lab-web-031317,## Introduction,"  Welcome to the JavaScript functions lab! You'll notice a few new things in this lesson that we haven't encountered before. Don't worry, we'll walk you through them. Even if you've walked through some of this material before, it's a good idea to review as we code-along ?we're writing functions now, after all.",1
https://github.com/peteryunkim/javascript-intro-to-functions-lab-web-031317,### Code-along,"  For now, open up index.js in your text editor. You should see, well, nothing. We'll fix that soon. Now open up test/index-test.js. Hey, there's something! What's all of this stuff doing? At the very top of the file, you'll see global.expect = require('expect');

const babel = require('babel-core');
const jsdom = require('jsdom');
const path = require('path'); This might be a bit bewildering, but all we're doing is referencing different libraries that help us run your tests. A library is code that someone else (usually multiple someone elses) wrote for our use. Note that require won't work out of the box in the browser. We're actually running our tests in a different environment. (Remember the sandbox analogy from earlier? It's just like that.) If you go to test/index-test.js, you'll see describe('shout(string)', () => {
  // there's stuff in here, too
}) describe is a function provided by our test runner (in this case, we're using Mocha) ?it's basically a container for our tests. Let's take a closer look at that describe(): describe('shout(string)', () => {
  it('receives one argument and returns it in all caps', () => {
    // we'll get to this in a sec
  })
}) These internal describe() calls are used for describing the functions that you're going to write. In this case, the test is saying, ""Okay, I think there's going to be a function called shout, and it should take one argument (it doesn't actually matter what the argument is called, but string, is nice and specific, don't you think?). It should return that argument in all caps. Finally, we have expect(shout('hello')).toEqual('HELLO') which says that it expects a call to shout() with the string 'hello' will equal the string 'HELLO'. This is the actual test ?otherwise called a spec, expectation, or assertion ?for this function. We can have more than one test per function, but let's start with this one.",3
https://github.com/peteryunkim/javascript-intro-to-functions-lab-web-031317,### Running the Tests,"  To run the tests, run learn test in the terminal in your Learn IDE. The first output you'll see will look like  Hm, that's kind of disappointing. Let's see if we can get that first test to pass. Open up index.js. When we write our code, we follow the guidance of the tests. Remember the line, describe('shout(string)', () => { ... }). Well, we know that we need a function called shout that accepts an argument ?let's add that first. In index.js: function shout(string) {
} And what should that function do? Well, the it() description tells us that it ""receives one argument and returns it in all caps"". Okay, so with that information, we know that our function should look like function shout(string) {
  return string
} But how do we make string all caps? JavaScript has a method for that! It's called toUpperCase(). We can call it on any string: 'Hello!'.toUpperCase() // 'HELLO!' So let's try it with our shout() function: function shout(string) {
  return string.toUpperCase()
} And run our tests again: learn test  Hey! We got one to pass!",3
https://github.com/peteryunkim/javascript-intro-to-functions-lab-web-031317,## Your turn,"  Now it's your turn to get the rest of the tests to pass. Note that some of them require you to use console.log() instead of return ?follow the guidance of the tests! In this lab, we're writing functions that ""speak"" at different volumes ?they whisper or they shout. We're going to use what we learn practicing speaking in this way to write another function, sayHiToGrandma(), which takes our new-found speaking ability to greet our grandmother. She's not exactly deaf, but whispering can be a bit difficult. But she'll always hear you if you say, ""I love you, Grandma."" Note that just like .toUpperCase() changes any string to all uppercase in JavaScript, .toLowerCase() (e.g., 'HELLO'.toLowerCase()) changes any string to all lowercase. Additionally, how do we check if a string is all lowercase or all uppercase? var uppercase = ""HELLO!""

uppercase.toUpperCase() === uppercase // true

var lowercase = 'hello!'

lowercase.toLowerCase() === lowercase // true

var mixedCase = 'Hi there!'

mixedCase.toLowerCase() === mixedCase // false

mixedCase.toUpperCase() === mixedCase // false We can simply check whether the string is the same when we convert it to uppercase or lowercase! If it's the same, then it was already in that case; if not, then it's either in the other case or it's mixed case. Good luck! When you're finished, be sure to run learn submit! View Intro to Functions Lab on Learn.co and start learning to code for free.",3
https://github.com/lindes/vrptools,# vrptools - tools for Vision Research's Phantom cameras and their data,,1
https://github.com/lindes/vrptools,## What is this?,"  Vision Research is a company that
makes some pretty amazing high-speed video cameras, which generally
have the word Phantom in their name.  Their products run the gamut
from doing 4K video at
140 frames per second (fps) with the
Phantom 65,
all the way to an unbelievable 1,400,000 (yes, 1.4 million) fps
(though at a mere 128x8 pixels, no M, no K) on the
Phantom v710
-- with, of course, a whole breadth of in-between speeds and
resolutions, including some pretty impressive frame-rates at
1080p on some models (e.g. 2,560
fps on the
v641,
to name but one). This project, then, is an attempt to have a set of open-source
utilities for getting data out of the proprietary (though publicly
documented) ""CINE"" files.  There are, of course, a number of software
packages out there already that will read these files, including the
ones from Vision Research, other tools from
Glue Tools, and
others, but I was unable to find an open-source/free-software one,
so... here is this (though note the See Also; I've since discovered
other projects doing similar things). The cameras are fairly expensive, so I imagine their availability is
limited.  Still, there seem to be more and more people shooting with
them (as evidenced by a
video search;
I got 4110 results as of 2011-02-23, and over 7 million as of
2013-10-08).  Add to this the fact that I happen to occassionaly have
had access to one, and I have some files here that I want to read, so,
here we are.",12
https://github.com/lindes/vrptools,## Status,"  These tools are currently in their infancy. Please keep your expectations low for this software, for now. That said, cineinfo is starting to provide some vaguely-useful
information about a CINE file, and cine-extract will now generate a
series of PPM files (in cine-extract.d by default; changeable with
-d option) from one, one per frame. There's also a ""magic"" file (a la /etc/magic).  I haven't yet taken
the time to figure out how one would go about installing it on one's
system, but you can run file -M magic foo.cine and it will give some
info.  Probably still needs more content there, and probably also
needs to have some of it removed (or migrated to 'magic.verbose' or
something), as the output is really verbose at the moment.",4
https://github.com/lindes/vrptools,## Technical Docs:,"  This tooling is based on documentation which, at the time of this
writing, was available for public download at either of: 
www.visionresearch.com/devzonedownloads/cine640.pdf
(original version used, dated 2007)
www.visionresearch.com/devzonedownloads/cine705.pdf
(updated version -- dated 2011, found 2013)
",6
https://github.com/lindes/vrptools,## Contributing:,"  If you'd like to contribute, please feel free to fork this project
from it's primary repository:
github/lindes/vrptools Then, create a topic
branch,
do your work, push it to your github fork, and send me a pull request.
I'll try to be prompt at taking a look. You're also welcome to submit ""Issues"" via GitHub.  I'd be happy to
give a shot at fixing bugs and adding features that are requested that
way. Or drop me a private message (via GitHub, or wherever) with any
questions, requests, etc.",7
https://github.com/lindes/vrptools,## License information:,"  Copyright 2011, 2013 by David Lindes.  All rights reserved. The canonical source for this project is
github.com/lindes/vrptools. This program is
free software: you can
redistribute it and/or modify it under the terms of the
GNU General Public License as
published by the Free Software Foundation, either version 3 of the
License, or (at your option) any later version. This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details. You should have received a copy of the GNU General Public License
along with this program.  If not, see http://www.gnu.org/licenses/. If you have reason to need a different license, please contact me.
It's possible that I could accomodate that, especially for other
free-software licenses.",5
https://github.com/lindes/vrptools,## Example commands:,"  To get a bit of information about a file (note: add a -v option
before filename to get (much) more verbose output): ./cineinfo myfile.cine
 To extract each frame as a PPM image:  ./cine-extract -d myfile.ppms.d myfile.cine
",3
https://github.com/lindes/vrptools,## TODO,"  
Create other output formats, including something suitable for
streaming into ffmpeg or similar, for
conversion to other formats.
Find a way to emit (SMPTE-compliant, if
possible -- for the framerates we have, it may not make sense)
timecode information
(or its functional equivalent) in some way (either in sidecar files,
or directly encoded into the output stream, where applicable).
Allow input-file-based output-directory(/file) naming.
Clean up various aspects of the code, to be more modular,
expandable, etc.
Handle a new ""packed"" format that exists in more recent cameras.
Optimization for speed of rendering.
",4
https://github.com/lindes/vrptools,## Imagined Possibilities,"  (Like TODO, but more a ""this is one way things could go"" list.  If you
want things from this list, please let me know.) 
Add bindings for other languages (python, ruby, perl)?
",4
https://github.com/lindes/vrptools,## See Also,"  There's a related project called
pycine, which uses native
Python code to read CINE files.",6
https://github.com/adrian907/neuraltalk2,# NeuralTalk2," Recurrent Neural Network captions your images. Now much faster and better than the original NeuralTalk. Compared to the original NeuralTalk this implementation is batched, uses Torch, runs on a GPU, and supports CNN finetuning. All of these together result in quite a large increase in training speed for the Language Model (~100x), but overall not as much because we also have to forward a VGGNet. However, overall very good models can be trained in 2-3 days, and they show a much better performance. This is an early code release that works great but is slightly hastily released and probably requires some code reading of inline comments (which I tried to be quite good with in general). I will be improving it over time but wanted to push the code out there because I promised it to too many people. This current code (and the pretrained model) gets ~0.9 CIDEr, which would place it around spot #8 on the codalab leaderboard. I will submit the actual result soon.  You can find a few more example results on the demo page. These results will improve a bit more once the last few bells and whistles are in place (e.g. beam search, ensembling, reranking). There's also a fun video by @kcimc, where he runs a neuraltalk2 pretrained model in real time on his laptop during a walk in Amsterdam.",12
https://github.com/adrian907/neuraltalk2,### Requirements, ,3
https://github.com/adrian907/neuraltalk2,#### For evaluation only,"  This code is written in Lua and requires Torch. If you're on Ubuntu, installing Torch in your home directory may look something like: $ curl -s https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bash
$ git clone https://github.com/torch/distro.git ~/torch --recursive
$ cd ~/torch; 
$ ./install.sh      # and enter ""yes"" at the end to modify your bashrc
$ source ~/.bashrc See the Torch installation documentation for more details. After Torch is installed we need to get a few more packages using LuaRocks (which already came with the Torch install). In particular: $ luarocks install nn
$ luarocks install nngraph 
$ luarocks install image  We're also going to need the cjson library so that we can load/save json files. Follow their download link and then look under their section 2.4 for easy luarocks install. If you'd like to run on an NVIDIA GPU using CUDA (which you really, really want to if you're training a model, since we're using a VGGNet), you'll of course need a GPU, and you will have to install the CUDA Toolkit. Then get the cutorch and cunn packages: $ luarocks install cutorch
$ luarocks install cunn If you'd like to use the cudnn backend (the pretrained checkpoint does), you also have to install cudnn. First follow the link to NVIDIA website, register with them and download the cudnn library. Then make sure you adjust your LD_LIBRARY_PATH to point to the lib64 folder that contains the library (e.g. libcudnn.so.7.0.64). Then git clone the cudnn.torch repo, cd inside and do luarocks make cudnn-scm-1.rockspec to build the Torch bindings.",3
https://github.com/adrian907/neuraltalk2,#### For training,"  If you'd like to train your models you will need loadcaffe, since we are using the VGGNet. First, make sure you follow their instructions to install protobuf and everything else (e.g. sudo apt-get install libprotobuf-dev protobuf-compiler), and then install via luarocks: luarocks install loadcaffe Finally, you will also need to install torch-hdf5, and h5py, since we will be using hdf5 files to store the preprocessed data. Phew! Quite a few dependencies, sorry no easy way around it :\",3
https://github.com/adrian907/neuraltalk2,### I just want to caption images,"  In this case you want to run the evaluation script on a pretrained model checkpoint.
I trained a decent one on the MS COCO dataset that you can run on your images.
The pretrained checkpoint can be downloaded here: pretrained checkpoint link (600MB). It's large because it contains the weights of a finetuned VGGNet. Now place all your images of interest into a folder, e.g. blah, and run
the eval script: $ th eval.lua -model /path/to/model -image_folder /path/to/image/directory -num_images 10  This tells the eval script to run up to 10 images from the given folder. If you have a big GPU you can speed up the evaluation by increasing batch_size (default = 1). Use -num_images -1 to process all images. The eval script will create an vis.json file inside the vis folder, which can then be visualized with the provided HTML interface: $ cd vis
$ python -m SimpleHTTPServer Now visit localhost:4000 in your browser and you should see your predicted captions. You can see an example visualization demo page here. ""I only have CPU"". Okay, in that case download the cpu model checkpoint. Make sure you run the eval script with -gpuid -1 to tell the script to run on CPU. On my machine it takes a bit less than 1 second per image to caption in CPU mode. Beam Search. Beam search is enabled by default because it increases the performance of the search for argmax decoding sequence. However, this is a little more expensive, so if you'd like to evaluate images faster, but at a cost of performance, use -beam_size 1. For example, in one of my experiments beam size 2 gives CIDEr 0.922, and beam size 1 gives CIDEr 0.886. Running on MSCOCO images. If you train on MSCOCO (see how below), you will have generated preprocessed MSCOCO images, which you can use directly in the eval script. In this case simply leave out the image_folder option and the eval script and instead pass in the input_h5, input_json to your preprocessed files. This will make more sense once you read the section below :)",3
https://github.com/adrian907/neuraltalk2,### I'd like to train my own network on MS COCO,"  Great, first we need to some preprocessing. Head over to the coco/ folder and run the IPython notebook to download the dataset and do some very simple preprocessing. The notebook will combine the train/val data together and create a very simple and small json file that contains a large list of image paths, and raw captions for each image, of the form: [{ file_path: 'path/img.jpg', captions: ['a caption', ...] }, ...]
 Once we have this, we're ready to invoke the prepro.py script, which will read all of this in and create a dataset (an hdf5 file and a json file) ready for consumption in the Lua code. For example, for MS COCO we can run the prepro file as follows: $ python prepro.py --input_json coco/coco_raw.json --num_val 5000 --num_test 5000 --images_root coco/images --word_count_threshold 5 --output_json coco/cocotalk.json --output_h5 coco/cocotalk.h5 This is telling the script to read in all the data (the images and the captions), allocate 5000 images for val/test splits respectively, and map all words that occur <= 5 times to a special UNK token. The resulting json and h5 files are about 30GB and contain everything we want to know about the dataset. Warning: the prepro script will fail with the default MSCOCO data because one of their images is corrupted. See this issue for the fix, it involves manually replacing one image in the dataset. The last thing we need is the VGG-16 Caffe checkpoint, (under Models section, ""16-layer model"" bullet point). Put the two files (the prototxt configuration file and the proto binary of weights) somewhere (e.g. a model directory), and we're ready to train! $ th train.lua -input_h5 coco/cocotalk.h5 -input_json coco/cocotalk.json The train script will take over, and start dumping checkpoints into the folder specified by checkpoint_path (default = current folder). You also have to point the train script to the VGGNet protos (see the options inside train.lua). If you'd like to evaluate BLEU/METEOR/CIDEr scores during training in addition to validation cross entropy loss, use -language_eval 1 option, but don't forget to download the coco-caption code into coco-caption directory. A few notes on training. To give you an idea, with the default settings one epoch of MS COCO images is about 7500 iterations. 1 epoch of training (with no finetuning - notice this is the default) takes about 1 hour and results in validation loss ~2.7 and CIDEr score of ~0.4. By iteration 70,000 CIDEr climbs up to about 0.6 (validation loss at about 2.5) and then will top out at a bit below 0.7 CIDEr. After that additional improvements are only possible by turning on CNN finetuning. I like to do the training in stages, where I first train with no finetuning, and then restart the train script with -finetune_cnn_after 0 to start finetuning right away, and using -start_from flag to continue from the previous model checkpoint. You'll see your score rise up to about 0.9 CIDEr over ~2 days or so (on MS COCO).",3
https://github.com/adrian907/neuraltalk2,### I'd like to train on my own data,"  No problem, create a json file in the exact same form as before: [{ file_path: 'path/img.jpg', captions: ['a caption', ...] }, ...]
 and invoke the prepro.py script to preprocess all the images and data into and hdf5 file and json file. Then invoke train.lua (see detailed options inside code).",3
https://github.com/adrian907/neuraltalk2,### I'd like to distribute my GPU trained checkpoints for CPU,"  Use the script convert_checkpoint_gpu_to_cpu.lua to convert your GPU checkpoints to be usable on CPU. See inline documentation for why this separate script is needed. For example: th convert_checkpoint_gpu_to_cpu.lua gpu_checkpoint.t7 write the file gpu_checkpoint.t7_cpu.t7, which you can now run with -gpuid -1 in the eval script.",3
https://github.com/adrian907/neuraltalk2,### License,  BSD License.,5
https://github.com/adrian907/neuraltalk2,### Acknowledgements,  Parts of this code were written in collaboration with my labmate Justin Johnson. I'm very grateful for NVIDIA's support in providing GPUs that made this work possible. I'm also very grateful to the maintainers of Torch for maintaining a wonderful deep learning library.,5
https://github.com/MHarrison72/ircdd,## Documentation:, You can read the documentation at: readthedocs In addition to that the project's wiki might contain further useful information.,6
https://github.com/MHarrison72/ircdd,## Contributing:,  Contributions are welcome once initial development is complete. Keep an eye for the 1.0 tag.,7
https://github.com/MHarrison72/ircdd,## Authors:,  Michael J. Harrison Daniel McGinnis Kevin K. Rothenberger Roman Senyszyn Kiril Zvezdarov,5
https://github.com/harvard-crimson/django-select2,# Django-Select2 [![Build Status](https://travis-ci.org/applegrew/django-select2.svg?branch=master)](https://travis-ci.org/applegrew/django-select2),"This is a Django integration of Select2.

The app includes Select2 driven Django Widgets and Form Fields.",1
https://github.com/harvard-crimson/django-select2,# Installation,"Install django_select2

 pip install django_select2
Add django_select2 to your INSTALLED_APPS in your project settings.

When deploying on production server, run :-

 python manage.py collectstatic
Add django_select to your urlconf if you use any 'Auto' fields.

 url(r'^select2/', include('django_select2.urls')),",3
https://github.com/harvard-crimson/django-select2,# Documentation,Documentation available at http://django-select2.readthedocs.org/.,6
https://github.com/harvard-crimson/django-select2,# More details,More details can be found on my blog at - http://blog.applegrew.com/2012/08/django-select2/.,6
https://github.com/harvard-crimson/django-select2,# External Dependencies,"Django - This is obvious.
jQuery - This is not included in the package since it is expected that in most scenarios this would already be available.
Memcached (python-memcached) - If you plan on running multiple python processes with GENERATE_RANDOM_SELECT2_ID enabled, then you need to turn on ENABLE_SELECT2_MULTI_PROCESS_SUPPORT. In that mode it is highly recommended that you use Memcached, to minimize DB hits.",3
https://github.com/harvard-crimson/django-select2,# Example Application,"Please see testapp application. This application is used to manually test the functionalities of this package. This also serves as a good example.

You need only Django 1.4 or above to run that. It might run on older versions but that is not tested.",3
https://github.com/harvard-crimson/django-select2,# Special Thanks,"Samuel Goldszmidt (@ouhouhsami) for reporting many fundamental issues with the code, because of which versions 2.0 and 2.0.1 were released.",5
https://github.com/harvard-crimson/django-select2,# Official Contributors,Johannes Hoppe (@codingjoe),5
https://github.com/harvard-crimson/django-select2,# Changelog Summary,,4
https://github.com/harvard-crimson/django-select2,### v4.3.0,"Now the package supports both Python2 and Python3.
Django 1.8 support added.
Many bug fixes.",4
https://github.com/harvard-crimson/django-select2,### v4.2.2,"Misc fixes and enhancements - 61, 64.",4
https://github.com/harvard-crimson/django-select2,### v4.2.1,Finally fixed performance issue#54 (and issue#41) in widgets when backing field is based on models and the field has an initial value.,4
https://github.com/harvard-crimson/django-select2,### v4.2.0,"Updated Select2 to version 3.4.2. Please note, that if you need any of the Select2 locale files, then you need to download them yourself from http://ivaynberg.github.com/select2/ and add to your project.
Tagging support added. See Field API reference in documentation.",4
https://github.com/harvard-crimson/django-select2,### v4.1.0,"Updated Select2 to version 3.4.1. Please note, that if you need any of the Select2 locale files, then you need to download them yourself from http://ivaynberg.github.com/select2/ and add to your project.
Address isssue#36 - Fix importerror under django1.6.
Fixed the way setup.py handles Unicode files while minifying them during package build.
Address isssue#39 - MultipleSelect2HiddenInput.render() should use mark_safe().
Address isssue#45 - MultipleSelect2HiddenInput returns bad has_changed value.",4
https://github.com/harvard-crimson/django-select2,### v4.0.0,Main version number bumped to bring your attention to the fact that the default Id generation scheme has now changed. Now Django Select2 will use hashed paths of fields to generate their Ids. The old scheme of generating random Ids are still there. You can enable that by setting GENERATE_RANDOM_SELECT2_ID to True.,4
https://github.com/harvard-crimson/django-select2,### v3.3.1,"Addressed issue#30.
Merged pull request#31.
Added light parameter to import_django_select2_js, import_django_select2_css and import_django_select2_js_css template tags. Please see doc's ""Getting Started"", for more details.",4
https://github.com/harvard-crimson/django-select2,### v3.3.0,"Updated Select2 to version 3.3.1.
Added multi-process support. (Issue#28).
Addressed issue#26.
Addressed issue#24.
Addressed issue#23.
Addressed some typos.",4
https://github.com/harvard-crimson/django-select2,### v3.2.0,"Fixed issue#20. Infact while fixing that I realised that heavy components do not need the help of cookies, infact due to a logic error in previous code the cookies were not being used anyway. Now Django Select2 does not use cookies etc.
Few more bugs fixed in heav_data.js.
Now production code will use minimized versions of js and css files.
Codes added in setup.py to automate the task of minimizing js and css files, using a web service.",4
https://github.com/harvard-crimson/django-select2,### v3.1.5,"Merged pull request (issue#17). Which allows the user to pass some extra data to Select2 clients-side component.
Updated License. The previous one was inadequently worded. Now this project use Apache 2.0 license.",4
https://github.com/harvard-crimson/django-select2,### v3.1.4,"
Manually merged changes from pull request (issue#16).
Django Select2 widgets now allow passing of any Select2 Js options. Previously it used to allow only white-listed options. Now it will block only black-listed options. For example, Light Select2 widgets won't allow you to set multiple option, since it is an error to set them when Select2 Js is bound to <select> fields.",4
https://github.com/harvard-crimson/django-select2,### v3.1.3,"Addressed enhancement issue#12.
Addressed enhancement issue#11.
Addressed performance issue#8.",4
https://github.com/harvard-crimson/django-select2,### v3.1.2,Fixed issue#7.,4
https://github.com/harvard-crimson/django-select2,### v3.1.1,"Bumping up minor version since Select2 JS has been updated to version 3.2. It seems Select2 JS now includes new higher resolution icons for Retina displays.
Fixed an issue in setup.py because of which templatetags directory was not included in last PIP releases' tar file.",4
https://github.com/harvard-crimson/django-select2,### v3.0.2,"Added AUTO_RENDER_SELECT2_STATICS settings. This, when specified and set to False in settings.py then Django_Select2 widgets won't automatically include the required scripts and stylesheets. When this setting is True (default) then every Select2 field on the page will output <script> and <link> tags to include the required JS and CSS files. This is convinient but will output the same JS and CSS files multiple times if there are more than one Select2 fields on the page.
Added django_select2_tags template tags to manually include the required JS and CSS files, when AUTO_RENDER_SELECT2_STATICS is turned off.",4
https://github.com/harvard-crimson/django-select2,### v3.0.1,"Revised the design of heavy fields. The previous design didn't quite make it easy to back heavy fields by big data sources. See fields.HeavyChoiceField class and its methods' docs for more info.
Updated docs.
Some more fixes for issue#4.
Updated Select2 JS to version 3.1.",4
https://github.com/harvard-crimson/django-select2,### v3.0,"Added docs.
Some bug fixes. See issue#4.
widgets.Select2Mixin.__init__ now accepts select2_options kwarg to override its options settings. Previously attrs were being used for this too. This means backward compatibility has been broken here. attrs will no longer override options values. The major release version has been changed to 3, because of this backward incompatible change.",4
https://github.com/harvard-crimson/django-select2,### v2.0.1,Auto id registration fixes.,4
https://github.com/harvard-crimson/django-select2,### v2.0,"Mostly major bug fixes in code and design. The changes were many, raising the possibility of backward incompatibility. However, the backward incompatibility would be subtle.

Auto fields (sub-classes of AutoViewFieldMixin) now accepts auto_id parameter. This can be used to provide custom id for the field. The default is 'module.field_class_name'. Ideally only the first instance of an auto field is registered. This parameter can be used to force registration of additional instances by passing a unique value.",4
https://github.com/harvard-crimson/django-select2,# License,"Copyright 2012 Nirupam Biswas

Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this project except in compliance with the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",5
https://github.com/m4rm0k/matter-js,# Matter.js," 
Matter.js is a JavaScript 2D rigid body physics engine for the web
 brm.io/matter-js Features - Status - Install - Usage -  Docs - Implementation - References - License ",1
https://github.com/m4rm0k/matter-js,### Demos,"  



Mixed Shapes
Solid Shapes
Newton's Cradle
Wrecking Ball
Slingshot Game
Rounded Corners
Views
Time Scaling
Raycasting
Sprites
Pyramid
Car
Catapult
Reverse Gravity
Bridge
Avalanche




Basic Soft Bodies
Cloth
Events
Chains
Ball Pool
Stack
Circle Stack
Restitution
Friction
Air Friction
Sleeping
Grid Broadphase
Beach Balls
Stress 1
Stress 2




",3
https://github.com/m4rm0k/matter-js,### Features,"  
Physical properties (mass, area, density etc.)
Rigid bodies of any convex polygon
Stable stacking and resting
Collisions (broad-phase, mid-phase and narrow-phase)
Restitution (elastic and inelastic collisions)
Conservation of momentum
Friction and resistance
Constraints
Gravity
Composite bodies
Sleeping and static bodies
Events
Rounded corners (chamfering)
Views (translate, zoom)
Collision queries (raycasting, region tests)
Time scaling (slow-mo, speed-up)
Canvas renderer (supports vectors and textures)
WebGL renderer (requires pixi.js)
MatterTools for creating, testing and debugging worlds
World state serialisation (requires resurrect.js)
Cross-browser (Chrome, Firefox, Safari, IE8+)
Mobile-compatible (touch, responsive)
An original JavaScript physics implementation (not a port)
",1
https://github.com/m4rm0k/matter-js,### Install,"  Download the edge build (master) or get a stable release and include the script in your web page: <script src=""matter.js"" type=""text/javascript""></script>
 You can also install using the package managers Bower and NPM. bower install matter-js
npm install matter-js
",3
https://github.com/m4rm0k/matter-js,### Usage,"  See the Getting started wiki page for a minimal usage example. Matter.js includes a sample renderer, but this is optional and it's easy to use your own.
See the Rendering wiki page for information, including on how to use your own custom game loop. Check out the demo page for more examples and then refer to Demo.js to see how they work. Some of the demos are also available on codepen, where you can easily experiment with them.",36
https://github.com/m4rm0k/matter-js,### Documentation,"  Edge build documentation is at Matter.js API Docs (master)
Stable release documentation is at Matter.js API Docs (v0.8.0)",6
https://github.com/m4rm0k/matter-js,### Status,"  Matter.js is currently in alpha status, meaning the API is still in development and may change occasionally.
The library is reasonably stable as-is, but it is not yet feature complete.",4
https://github.com/m4rm0k/matter-js,### Building and Contributing,"  To build you must first install node.js and grunt, then run npm install
 This will install the required build dependencies, then run grunt dev
 which is a task that builds the matter-dev.js file, spawns a connect and watch server, then opens demo/dev.html in your browser. Any changes you make to the source will automatically rebuild matter-dev.js and reload your browser for quick and easy testing. Contributions are welcome, please ensure they follow the same style and architecture as the rest of the code. You should run grunt test to ensure jshint gives no errors. Please do not include any changes to the files in the build directory. If you'd like to contribute but not sure what to work on, feel free to message me. Thanks!",37
https://github.com/m4rm0k/matter-js,### Changelog,"  To see what's new or changed in the latest version, see the changelog.",4
https://github.com/m4rm0k/matter-js,### Implementation,"  The technical details for physics nerds and game devs.
This engine is using the following techniques: 
Time-corrected position Verlet integrator
Adaptive grid broad-phase detection
AABB mid-phase detection
SAT narrow-phase detection
Iterative sequential impulse solver and position solver
Resting collisions with resting constraints ala Erin Catto's method
(GDC08)
Temporal coherence impulse caching and warming
Collision pairs, contacts and impulses maintained with a pair
manager
Approximate Coulomb friction model using friction constraints
Constraints solved with the Gauss-Siedel method
Semi-variable time step, synced with rendering
A basic sleeping strategy
HTML5 Canvas / WebGL renderer
",1
https://github.com/m4rm0k/matter-js,### References,  See my post on Game physics for beginners.,6
https://github.com/m4rm0k/matter-js,### License,"  Matter.js is licensed under The MIT License (MIT)
Copyright (c) 2014 Liam Brummitt This license is also supplied with the release and source code.
As stated in the license, absolutely no warranty is provided.",5
https://github.com/SCDesigns/web-auth-readme-v-000,# Using OAuth With APIs,,1
https://github.com/SCDesigns/web-auth-readme-v-000,## Objectives,"  
Understand what OAuth is and why we use it.
Use OAuth with the Foursquare API.
",12
https://github.com/SCDesigns/web-auth-readme-v-000,## Lesson,  We're going to expand on our Coffee Shop example to use OAuth with the Foursquare API to perform actions on behalf of an individual user.,1
https://github.com/SCDesigns/web-auth-readme-v-000,### API User Authentication,"  Until now, we've been authenticating to APIs at the application level using a Client ID/Secret pair with each request. As we learned, this level of application authentication is important in that it allows the API provider to ensure good behavior by any client application. Application-level authentication like this gives us access to application-level functions, for instance, venue search. This is an application-level function because you don't need to be any particular user to search for a coffee shop. In fact, if we look at the venue search API documentation, we see an entry: Requires Acting User: No at the top. Compare that to the documentation for list friends, and we see that this function does require an acting user, which makes sense, because the application doesn't have friends, an individual user does. So, if we want to show our user what their friends are doing, we need a way of authenticating the user to Foursquare through our application. It's not enough for a user to be logged in to Foursquare and use our app, because Foursquare needs to know that we are acting on behalf of a user and that the user has allowed that action. We could write some code to log in on behalf of the user, but that would require us to ask the user for their Foursquare login credentials. Think about that as if you're the user. Are you going to give some random website your login and password for Foursquare? The very thought should make you very suspicious of our motives.  Beyond the security issues, there's the problem of keeping things up to date. If we ask the user to log in to Foursquare on every request, that's a horrible experience. However, if we store the user's Foursquare login info, we have whole other problems. The first is that we'd have to store them unencrypted, in plain text, because Fourquare expects a person to log in with their unencrypted credentials. So we have another security problem. Now we have a database full of unencrypted Foursquare credentials waiting for anyone to get in there and grab them all. Beyond the security issue is a logistical one. If the user changes her password on Foursquare, we'll never know about it, and our app will break. Now she has to update her Foursquare credentials in two places, which is cumbersome to say the least.",3
https://github.com/SCDesigns/web-auth-readme-v-000,### Enter OAuth,"  Okay, how do we authenticate a user without them entering their username and password into our application? OAuth. OAuth provides a way for one application to authenticate to another on behalf of a user by means of a revokable, expirable token. If our application has a Foursquare token for the user, and someone gets access to our database of tokens, all of them can be revoked and a hacker never gets access to individual user credentials. An OAuth token also provides a standard way for our application to tell Foursquare ""hey, this user says we can do things for her"", because part of implementing OAuth requires the user to take action on the provider (Foursquare, in this case), explicitly authorizing our application.",3
https://github.com/SCDesigns/web-auth-readme-v-000,### OAuth Authentication Flow,"  OAuth authentication workflow involved three steps at a high level. 
Request access from the provider site (often via redirect to a
special form)
Redirect back to our site with a code
Request a token from the provider using the code
 Take a look at the Access token section of the Foursquare API Documentation, specifically the second subsection, under Code (preferred). It describes how to do those three steps with Foursquare.",3
https://github.com/SCDesigns/web-auth-readme-v-000,#### Checking Authentication,"  The first thing we want to do is figure out if a user has already authenticated to Foursquare in this session. Ultimately, users will be considered ""logged in"" if they have an access token stored in their session. So, let's create a private method #logged_in? in your ApplicationController that will return false if session[:token] is nil and true otherwise: # application_controller.rb

private
  def logged_in?
    !!session[:token]
  end",3
https://github.com/SCDesigns/web-auth-readme-v-000,# application_controller.rb,,-
https://github.com/SCDesigns/web-auth-readme-v-000,#### Redirect Users To Request Foursquare Access,"  The first step in the OAuth flow is to direct the user to Foursquare to request access if we haven't already. According to the docs, that URL looks like this: https://foursquare.com/oauth2/authenticate
    ?client_id=YOUR_CLIENT_ID
    &response_type=code
    &redirect_uri=YOUR_REGISTERED_REDIRECT_URI
 Part of our URL includes passing a redirect_uri parameter, so we'll need to set that up. Update your Foursquare app and add a Redirect URI. Let's set it to http://localhost:3000/auth and save the app. Because we're going to be using our client ID/secret a lot, instead of always typing it in, let's use a .env file to hold our FOURSQUARE_CLIENT_ID and FOURSQUARE_SECRET values. Once that's set up, we'll be able to access these values as ENV['FOURSQUARE_CLIENT_ID'] and ENV['FOURSQUARE_SECRET'], which is much easier to keep track of. Follow the instructions to set up Dotenv and add your app's client ID and secret. Don't forget to restart your server after you change any values in .env! Top-tip: Dotenv is a great way to keep configuration variables for development, but always remember to add .env to your .gitignore so you don't share your secrets with everyone else! Okay, that should handle everything we need to make this first request, so now we need to set up the redirect. Write another private method #authenticate_user that will redirect the user to https://foursquare.com/oauth2/authenticate if the user is not already logged in. Then we'll set up a before_action to check authentication. # application_controller.rb
before_action :authenticate_user

private

  def authenticate_user
    client_id = ENV['FOURSQUARE_CLIENT_ID']
    redirect_uri = CGI.escape(""http://localhost:3000/auth"")
    foursquare_url = ""https://foursquare.com/oauth2/authenticate?client_id=#{client_id}&response_type=code&redirect_uri=#{redirect_uri}""
    redirect_to foursquare_url unless logged_in?
  end

  def logged_in?
    !!session[:token]
  end Once you've implemented #authenticate_user, set the authentication as a before_action in your ApplicationController. In your SessionsController, skip the before_action with skip_before_action :authenticate_user, only: :create. Now, whenever users do not have an access token stored in their session, they will be redirected to the Foursquare authorization URL. Let's try it out. Start your Rails server and try to hit the /search page. You should get redirected to Foursquare! Hit the ""Allow"" button and let's see what happens. Error. Okay. That's good. That means it's working so far. Now we need to implement step two.",3
https://github.com/SCDesigns/web-auth-readme-v-000,# application_controller.rb,,-
https://github.com/SCDesigns/web-auth-readme-v-000,#### Foursquare Redirects Back To Our Site With A Code,"  When you registered your application, you set your redirect URL to http://localhost:3000/auth. This is where Foursquare is sending users after the login process. Now we need to handle that request. In your routes.rb file, add a route for get '/auth', to: 'sessions#create'. This will route that redirect to our SessionsController and a create action, which is where we'll get the token. So now let's implement that.",3
https://github.com/SCDesigns/web-auth-readme-v-000,#### Request A Token From Foursquare With The Code,"  Back to our handy documentation! Foursquare redirects users with a code that can be accessed through params and exchanged for an access token with a second GET request. We'll need to provide our ID, secret, and the code we just got. We're going to use Faraday to send this request in our controller action. If all goes well, according to the docs we can expect a JSON response with an access_token, so we'll parse that and put it in our session[:token]. # sessions_controller.rb
skip_before_action :authenticate_user

def create
  resp = Faraday.get(""https://foursquare.com/oauth2/access_token"") do |req|
    req.params['client_id'] = ENV['FOURSQUARE_CLIENT_ID']
    req.params['client_secret'] = ENV['FOURSQUARE_SECRET']
    req.params['grant_type'] = 'authorization_code'
    req.params['redirect_uri'] = ""http://localhost:3000/auth""
    req.params['code'] = params[:code]
  end

  body = JSON.parse(resp.body)
  session[:token] = body[""access_token""]
  redirect_to root_path
end Top-tip: Make sure to skip the authenticate_user before_action when you're creating a session, otherwise you'll end up in an infinite loop of trying to figure out who the user is, which is a very existential bug.",3
https://github.com/SCDesigns/web-auth-readme-v-000,# sessions_controller.rb,,-
https://github.com/SCDesigns/web-auth-readme-v-000,#### Use the access token to access the API,"  Now that users have their API tokens, they can make calls to all of the API endpoints as long as those tokens are included in the request. Back in our Foursquare auth docs, under the Requests section, we see that all we have to do now is add a oauth_token parameter to any request with the user's token. Let's look again at the friends documentation and add a friends list to our application. First, let's add a route to /friends: # routes.rb
# ...
get '/friends', to: 'searches#friends' And then handle that in our controller: # searches_controller.rb

def friends
  resp = Faraday.get(""https://api.foursquare.com/v2/users/self/friends"") do |req|
    req.params['oauth_token'] = session[:token]
    # don't forget that pesky v param for versioning
    req.params['v'] = '20160201'
  end
  @friends = JSON.parse(resp.body)[""response""][""friends""][""items""]
end Top-tip: Like many API providers, Foursquare gives you a way to try API calls right from the documentation. Try it with the friends list to examine the response JSON. Finally, let's set up our view: # views/searches/friends.html.erb
<ul>
  <% @friends.each do |friend| %>
    <li><%= ""#{friend['firstName']} #{friend['lastName']}"" %></li>
  <% end %>
</ul> Now load /friends and, just like that, they'll be there for you!  View Working with APIs on Learn.co and start learning to code for free. View Using OAuth With APIs on Learn.co and start learning to code for free. View Using OAuth With APIs on Learn.co and start learning to code for free.",3
https://github.com/SCDesigns/web-auth-readme-v-000,# routes.rb,,-
https://github.com/SCDesigns/web-auth-readme-v-000,# ...,,-
https://github.com/SCDesigns/web-auth-readme-v-000,# searches_controller.rb,,-
https://github.com/SCDesigns/web-auth-readme-v-000,# views/searches/friends.html.erb,,-
https://github.com/MasazI/dropzone,## Main features," 
Image thumbnail previews. Simply register the callback thumbnail(file, data) and display the image wherever you like
Retina enabled
Multiple files and synchronous uploads
Progress updates
Support for large files
Complete theming. The look and feel of Dropzone is just the default theme. You
can define everything yourself by overwriting the default event listeners.
Well tested
",1
https://github.com/MasazI/dropzone,## Documentation,  For the full documentation and installation please visit www.dropzonejs.com Please also refer to the FAQ.,6
https://github.com/MasazI/dropzone,## Examples,"  For examples, please see the GitHub wiki.",6
https://github.com/MasazI/dropzone,## Usage,"  Implicit creation: <form id=""my-awesome-dropzone"" action=""/target"" class=""dropzone""></form> That's it. Really! Dropzone will automatically attach to it, and handle file drops. Want more control? You can configure dropzones like this: // ""myAwesomeDropzone"" is the camelized version of the ID of your HTML element
Dropzone.options.myAwesomeDropzone = { maxFilesize: 1 }; ...or instantiate dropzone manually like this: new Dropzone(""div#my-dropzone"", { /* options */ }); 
Note that dropzones don't have to be forms. But if you choose another element you have to pass the url parameter in the options.
 For configuration options please look at the documentation on the website
or at the source.",3
https://github.com/MasazI/dropzone,### Register for events,"  If you want to register to some event you can do so on the dropzone object itself: Dropzone.options.myDropzone({
  init: function() {
    this.on(""error"", function(file, message) { alert(message); });
  }
});
// or if you need to access a Dropzone somewhere else:
var myDropzone = Dropzone.forElement(""div#my-dropzone"");
myDropzone.on(""error"", function(file, message) { alert(message); }); For a list of all events, please look at the chapter
»listen to events« in the documentation
or at the source.",3
https://github.com/MasazI/dropzone,## Browser support,"  
Chrome 7+
Firefox 4+
IE 10+
Opera 12+ (Version 12 for MacOS is disabled because their API is buggy)
Safari 6+
 For all the other browsers, dropzone provides an oldschool file input fallback.",3
https://github.com/MasazI/dropzone,## Why another library?,"  I realize that there are already other libraries out there but the reason I decided to write my own are the following: 
I didn't want it to be too big, and to cumbersome to dive into.
I want to design my own elements. I only want to register callbacks so I can update my elements accordingly.
Big files should get uploaded without a problem.
I wanted a callback for image previews, that don't kill the browser if too many too big images are viewed.
I want to use the latest API of browsers. I don't care if it falls back to the normal upload form if the browser is too old.
I don't think that it's necessary anymore to depend on libraries such as jQuery (especially when providing functionality that isn't available in old browsers anyway).
",2
https://github.com/MasazI/dropzone,## MIT License,  See LICENSE file,5
https://github.com/petems/puppet-splunk,# Splunk module for Puppet," 




",1
https://github.com/petems/puppet-splunk,#### Table of Contents,"  
Overview
Module Description - What the module does and why it is useful
Setup - The basics of getting started with splunk

What splunk affects
Setup requirements
Beginning with splunk


Usage - Configuration options and additional functionality
Reference - An under-the-hood peek at what the module is doing and how
Limitations - OS compatibility, etc.
Development - Guide for contributing to the module
",6
https://github.com/petems/puppet-splunk,## Overview,"  This module provides a method to deploy Splunk Server or Splunk Universal Forwarder
with common configurations and ensure the services maintain a running
state. It provides types/providers to interact with the various Splunk/Forwarder
configuration files.",1
https://github.com/petems/puppet-splunk,## Module Description,"  This module does not configure firewall rules. Firewall rules will need to be
configured separately in order to allow for correct operation of Splunk and the
Splunk Universal Forwarder. Additionally, this module does not supply Splunk or
Splunk Universal Forwarder installation media. Installation media will need to
be aquired seperately, and the module configured to use it. Users can use yum
or apt to install these components if they're self-hosted.",13
https://github.com/petems/puppet-splunk,## Setup, ,3
https://github.com/petems/puppet-splunk,### What splunk affects,"  
Installs the Splunk/Forwarder package and manages their config files. It does
not purge them by default.
The module will set up both Splunk and Splunkforwarder to run as the 'root'
user on POSIX platforms.
",3
https://github.com/petems/puppet-splunk,### Setup Requirements,"  To begin using this module, use the Puppet Module Tool (PMT) from the command
line to install this module: puppet module install puppet-splunk This will place the module into your primary module path if you do not utilize
the --target-dir directive. You can also use r10k or code-manager to deploy the module so ensure that you
have the correct entry in your Puppetfile. Once the module is in place, there is just a little setup needed. First, you will need to place your downloaded splunk installers into the files
directory, <module_path>/splunk/files/. If you're using r10k or code-manager
you'll need to override the splunk::params::src_root parameter to point at a
modulepath outside of the Splunk module because each deploy will overwrite the
files. The files must be placed according to directory structure example given below. The expected directory structure is:   `-- files
      |-- splunk
      |   `-- $platform
      |       `-- splunk-${version}-${build}-${additl}
      `-- universalforwarder
          `-- $platform
              `-- splunkforwarder-${version}-${build}-${additl}
 A semi-populated example files directory might then contain:   `-- files
      |-- splunk
      |   `-- linux
      |       |-- splunk-6.3.3-f44afce176d0-linux-2.6-amd64.deb
      |       |-- splunk-6.3.3-f44afce176d0-linux-2.6-intel.deb
      |       `-- splunk-6.3.3-f44afce176d0-linux-2.6-x86_64.rpm
      `-- universalforwarder
          |-- linux
          |   |-- splunkforwarder-6.3.3-f44afce176d0-linux-2.6-amd64.deb
          |   |-- splunkforwarder-6.3.3-f44afce176d0-linux-2.6-intel.deb
          |   `-- splunkforwarder-6.3.3-f44afce176d0-linux-2.6-x86_64.rpm
          |-- solaris
          |   `-- splunkforwarder-6.3.3-f44afce176d0-solaris-9-intel.pkg
          `-- windows
              |-- splunkforwarder-6.3.3-f44afce176d0-x64-release.msi
              `-- splunkforwarder-6.3.3-f44afce176d0-x86-release.msi
 Second, you will need to supply the splunk::params class with three critical
pieces of information. 
The version of Splunk you are using
The build of Splunk you are using
The root URL to use to retrieve the packages
 In the example given above, the version is 6.3.3, the build is f44afce176d0,
and the root URL is puppet:///modules/splunk. See the splunk::params class
documentation for more information.",3
https://github.com/petems/puppet-splunk,### Beginning with splunk,"  Once the Splunk packages are hosted in the users repository or hosted by the
Puppet Server in the modulepath the module is ready to deploy.",3
https://github.com/petems/puppet-splunk,## Usage,"  If a user is installing Splunk with packages provided from their modulepath,
this is the most basic way of installing Splunk Server with default settings: include ::splunk This is the most basic way of installing the Splunk Universal Forwarder with
default settings: class { '::splunk::params':
    server => $my_splunk_server,
}

include ::splunk::forwarder Once both Splunk and Splunk Universal Forwarder have been deployed on their
respective nodes, the Forwarder is ready to start sending logs. In order to start sending some log data, users can take advantage of the
Splunkforwarder_input type. Here is a basic example of adding an input to
start sending Puppet Server logs: @splunkforwarder_input { 'puppetserver-sourcetype':
  section => 'monitor:///var/log/puppetlabs/puppetserver/puppetserver.log',
  setting => 'sourcetype',
  value   => 'puppetserver',
  tag     => 'splunk_forwarder'
} This virtual resource will get collected by the ::splunk::forwarder class if
it is tagged with splunk_forwarder and will add the appropriate setting to
the inputs.conf file and refresh the service.",3
https://github.com/petems/puppet-splunk,## Reference, ,6
https://github.com/petems/puppet-splunk,### Types,"  

splunk_config: This is a meta resource used to configur defaults for all the
splunkforwarder and splunk types. This type should not be declared directly as
it is declared in splunk::params and used internally by the types and providers.


splunk_authentication: Used to manage ini settings in authentication.conf


splunk_authorize: Used to manage ini settings in authorize.conf


splunk_distsearch: Used to manage ini settings in distsearch.conf


splunk_indexes: Used to manage ini settings in indexes.conf


splunk_input: Used to manage ini settings in inputs.ocnf


splunk_limits: Used to mange ini settings in limits.conf


splunk_output: Used to manage ini settings in outputs.conf


splunk_props: Used to manage ini settings in props.conf


splunk_server: Used to mangage ini settings in server.conf


splunk_transforms: Used to manage ini settings in transforms.conf


splunk_web: Used to manage ini settings in web.conf


splunkforwarder_input: Used to manage ini settings in inputs.ocnf


splunkforwarder_output:Used to manage ini settings in outputs.conf


splunkforwarder_props: Used to manage ini settings in props.conf


splunkforwarder_transforms: Used to manage ini settings in transforms.conf


splunkforwarder_web: Used to manage ini settings in web.conf

 All of the above types use puppetlabs/ini_file as a parent and are declared in
an identical way, and accept the following parameters: 
section:  The name of the section in the configuration file
setting:  The setting to be managed
value: The value of the setting
 Both section and setting are namevars for the types.  Specifying a single string
as the title without a forward slash implies that the title is the section to be
managed (if the section attribute is not defined).  You can also specify the
resource title as section/setting and ommit both section and setting params
for a more shortform way of declaring the resource.   Eg: splunkforwarder_output { 'useless title':
  section => 'default',
  setting => 'defaultGroup',
  value   => 'splunk_9777',
}

splunkforwarder_output { 'default':
  setting => 'defaultGroup',
  value   => 'splunk_9777',
}

splunkforwarder_output { 'default/defaultGroup':
  value   => 'splunk_9777',
} The above resource declarations will all configure the following entry in outputs.conf [default]
defaultGroup=splunk_9997
 Note: if the section contains forward slashes you should not use it as the resource
title and should explicitly declare it with the section attribute.",6
https://github.com/petems/puppet-splunk,## Parameters, ,6
https://github.com/petems/puppet-splunk,### Class: ::splunk::params, ,6
https://github.com/petems/puppet-splunk,#### `version`,  Optional Specifies the version of Splunk Enterprise that the module should install.,6
https://github.com/petems/puppet-splunk,#### `build`,  Optional Specifies the build of Splunk Enterprise that the module should use.,6
https://github.com/petems/puppet-splunk,#### `src_root`,"  Optional The root path that the staging module will use to find packages for
splunk and splunk::forwarder.",6
https://github.com/petems/puppet-splunk,#### `splunkd_port`,  Optional The splunkd port. Used as a default for both splunk and splunk::forwarder.,6
https://github.com/petems/puppet-splunk,#### `logging_port`,"  Optional The port on which to send and listen for logs. Used as a default for
both splunk and splunk::forwarder.",6
https://github.com/petems/puppet-splunk,#### `server`,"  Optional The fqdn or IP address of the Splunk server. Used for setting up the
default TCP output and input.",6
https://github.com/petems/puppet-splunk,### Class: ::splunk Parameters, ,6
https://github.com/petems/puppet-splunk,#### `package_source`,"  The source URL for the splunk installation media (typically an RPM, MSI,
etc). If a $src_root parameter is set in splunk::params, this will be
automatically supplied. Otherwise it is required. The URL can be of any
protocol supported by the nanliu/staging module.",6
https://github.com/petems/puppet-splunk,#### `package_name`,  The name of the package(s) Puppet will use to install Splunk.,6
https://github.com/petems/puppet-splunk,#### `package_ensure`,"  Ensure parameter which will get passed to the Splunk package resource.
Default to the value in splunk::params",6
https://github.com/petems/puppet-splunk,#### `logging_port`,"  The port to receive TCP logs on. Default to the port specified in
splunk::params.",6
https://github.com/petems/puppet-splunk,#### `splunk_user`,  The user to run Splunk as. Default to the value set in splunk::params.,6
https://github.com/petems/puppet-splunk,#### `splunkd_port`,  The management port for Splunk. Default to the value set in splunk::params.,6
https://github.com/petems/puppet-splunk,#### `web_port`,  The port on which to service the Splunk Web interface. Default to 8000.,6
https://github.com/petems/puppet-splunk,#### `purge_inputs`,"  Optional If set to true, inputs.conf will be purged of configuration that is
no longer managed by the splunk_input type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_outputs`,"  Optional If set to true, outputs.conf will be purged of configuration that is
no longer managed by the splunk_output type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_authentication`,"  Optional If set to true, authentication.conf will be purged of configuration
that is no longer managed by the splunk_authentication type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_authorize`,"  Optional If set to true, authorize.conf will be purged of configuration that
is no longer managed by the splunk_authorize type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_distsearch`,"  Optional If set to true, distsearch.conf will be purged of configuration that
is no longer managed by the splunk_distsearch type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_indexes`,"  Optional If set to true, indexes.conf will be purged of configuration that is
no longer managed by the splunk_indexes type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_limits`,"  Optional If set to true, limits.conf will be purged of configuration that is
no longer managed by the splunk_limits type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_props`,"  Optional If set to true, props.conf will be purged of configuration that is
no longer managed by the splunk_props type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_server`,"  Optional If set to true, server.conf will be purged of configuration that is
no longer managed by the splunk_server type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_transforms`,"  Optional If set to true, transforms.conf will be purged of configuration that
is no longer managed by the splunk_transforms type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_web`,"  Optional If set to true, web.conf will be purged of configuration that is no
longer managed by the splunk_web type. Default to false.",6
https://github.com/petems/puppet-splunk,### Class ::splunk::forwarder Parameters, ,6
https://github.com/petems/puppet-splunk,#### `server`,  Optional The fqdn or IP address of the Splunk server. Default to the value in ::splunk::params.,6
https://github.com/petems/puppet-splunk,#### `package_source`,"  The source URL for the splunk installation media (typically an RPM, MSI,
etc). If a $src_root parameter is set in splunk::params, this will be
automatically supplied. Otherwise it is required. The URL can be of any
protocol supported by the nanliu/staging module.",6
https://github.com/petems/puppet-splunk,#### `package_name`,  The name of the package(s) Puppet will use to install Splunk Universal Forwarder.,6
https://github.com/petems/puppet-splunk,#### `package_ensure`,"  Ensure parameter which will get passed to the Splunk package resource.
Default to the value in ::splunk::params",6
https://github.com/petems/puppet-splunk,#### `logging_port`,"  Optional The port on which to send and listen for logs. Default to the value
in ::splunk::params.",6
https://github.com/petems/puppet-splunk,#### `splunkd_port`,  The management port for Splunk. Default to the value set in splunk::params.,6
https://github.com/petems/puppet-splunk,#### `install_options`,"  This variable is passed to the package resources' install_options parameter.
Default to the value in ::splunk::params.",6
https://github.com/petems/puppet-splunk,#### `splunk_user`,  The user to run Splunk as. Default to the value set in splunk::params.,6
https://github.com/petems/puppet-splunk,#### `splunkd_listen`,  The address on which splunkd should listen. Defaults to 127.0.0.1.,6
https://github.com/petems/puppet-splunk,#### `purge_inputs`,"  Optional If set to true, inputs.conf will be purged of configuration that is
no longer managed by the splunkforwarder_input type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_outputs`,"  Optional If set to true, outputs.conf will be purged of configuration that is
no longer managed by the splunk_output type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_props`,"  Optional If set to true, props.conf will be purged of configuration that is
no longer managed by the splunk_props type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_transforms`,"  Optional If set to true, transforms.conf will be purged of configuration that is
no longer managed by the splunk_transforms type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `purge_web`,"  Optional If set to true, web.conf will be purged of configuration that is
no longer managed by the splunk_web type. Default to false.",6
https://github.com/petems/puppet-splunk,#### `pkg_provider`,"  Optional This will override the default package provider for the package
resource. Default to undef.",6
https://github.com/petems/puppet-splunk,#### `forwarder_confdir`,"  The root directory where Splunk Universal Forwarder is installed. Default to
the value in ::splunk::params.",6
https://github.com/petems/puppet-splunk,#### `forwarder_input`,  Used to override the default forwarder_input type defined in ::splunk::params.,6
https://github.com/petems/puppet-splunk,#### `forwarder_output`,  Used to override the default forwarder_output type defined in ::splunk::params.,6
https://github.com/petems/puppet-splunk,#### `create_password`,  Not yet implemented.,6
https://github.com/petems/puppet-splunk,## Limitations,"  
Currently tested manually on Centos 7, but we will eventually add automated
testing and are targeting compatibility with other platforms.
Tested with Puppet 4.x
",4
https://github.com/petems/puppet-splunk,## Development,  TBD,4
https://github.com/petems/puppet-splunk,## Release Notes/Contributors/Etc,  TBD,4
https://github.com/savethefails/gcloud-node,# Google Cloud Node.js Client," 
Node.js idiomatic client for Google Cloud Platform services.
 

 
Homepage
API Documentation
 This client supports the following Google Cloud Platform services: 
Google BigQuery
Google Cloud Datastore
Google Cloud DNS
Google Cloud Pub/Sub
Google Cloud Storage
Google Compute Engine
Google Prediction API
Google Translate API
Google Cloud Logging (Beta)
Google Cloud Resource Manager (Beta)
Google Cloud Vision (Beta)
Google Cloud Search (Alpha)
 If you need support for other Google APIs, check out the Google Node.js API Client library.",16
https://github.com/savethefails/gcloud-node,## Quick Start,  $ npm install --save gcloud,3
https://github.com/savethefails/gcloud-node,## Example Applications,"  
nodejs-getting-started - A sample and tutorial that demonstrates how to build a complete web application using Cloud Datastore, Cloud Storage, and Cloud Pub/Sub and deploy it to Google App Engine or Google Compute Engine.
gcloud-node-todos - A TodoMVC backend using gcloud-node and Datastore.
gitnpm - Easily lookup an npm package's GitHub repo using gcloud-node and Google App Engine.
gcloud-kvstore - Use Datastore as a simple key-value store.
hya-wave - Cloud-based web sample editor. Part of the hya-io family of products.
",36
https://github.com/savethefails/gcloud-node,## Authentication,  With gcloud-node it's incredibly easy to get authenticated and start using Google's APIs. You can set your credentials on a global basis as well as on a per-API basis. See each individual API section below to see how you can auth on a per-API-basis. This is useful if you want to use different accounts for different Google Cloud services.,3
https://github.com/savethefails/gcloud-node,### On Google Compute Engine,"  If you are running this client on Google Compute Engine, we handle authentication for you with no configuration. You just need to make sure that when you set up the GCE instance, you add the correct scopes for the APIs you want to access. // Authenticating on a global basis.
var projectId = process.env.GCLOUD_PROJECT_ID; // E.g. 'grape-spaceship-123'
var gcloud = require('gcloud')({
  projectId: projectId
});

// ...you're good to go! See the next section to get started using the APIs.",36
https://github.com/savethefails/gcloud-node,### Elsewhere,"  If you are not running this client on Google Compute Engine, you need a Google Developers service account. To create a service account: 
Visit the Google Developers Console.
Create a new project or click on an existing project.
Navigate to  APIs & auth > APIs section and turn on the following APIs (you may need to enable billing in order to use these services):
 
Google Cloud Datastore API
Google Cloud Storage
Google Cloud Storage JSON API
 
Navigate to APIs & auth >  Credentials and then:
 
If you want to use a new service account, click on Create new Client ID and select Service account. After the account is created, you will be prompted to download the JSON key file that the library uses to authenticate your requests.
If you want to generate a new key for an existing service account, click on Generate new JSON key and download the JSON key file.
 // Authenticating on a global basis.
var projectId = process.env.GCLOUD_PROJECT_ID; // E.g. 'grape-spaceship-123'

var gcloud = require('gcloud')({
  projectId: projectId,
  keyFilename: '/path/to/keyfile.json'
});

// ...you're good to go! See the next section to get started using the APIs. You can also set auth on a per-API-instance basis. The examples below show you how.",3
https://github.com/savethefails/gcloud-node,## Google BigQuery,"  
API Documentation
Official Documentation
",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authenticating on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authentication section above).
var bigquery = gcloud.bigquery({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

// Access an existing dataset and table.
var schoolsDataset = bigquery.dataset('schools');
var schoolsTable = schoolsDataset.table('schoolsData');

// Import data into a table.
schoolsTable.import('/local/file.json', function(err, job) {});

// Get results from a query job.
var job = bigquery.job('job-id');

// Use a callback.
job.getQueryResults(function(err, rows) {});

// Or get the same results as a readable stream.
job.getQueryResults().on('data', function(row) {});",3
https://github.com/savethefails/gcloud-node,## Google Cloud Datastore,"  
API Documentation
Official Documentation
 Follow the activation instructions to use the Google Cloud Datastore API with your project.",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authenticating on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authentication section above).

var dataset = gcloud.datastore.dataset({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

dataset.get(dataset.key(['Product', 'Computer']), function(err, entity) {
  console.log(err || entity);
});

// Save data to your dataset.
var blogPostData = {
  title: 'How to make the perfect homemade pasta',
  author: 'Andrew Chilton',
  isDraft: true
};

var blogPostKey = dataset.key('BlogPost');

dataset.save({
  key: blogPostKey,
  data: blogPostData
}, function(err) {
  // `blogPostKey` has been updated with an ID so you can do more operations
  // with it, such as an update.
  blogPostData.isDraft = false;

  dataset.save({
    key: blogPostKey,
    data: blogPostData
  }, function(err) {
    if (!err) {
      // The blog post is now published!
    }
  });
});",3
https://github.com/savethefails/gcloud-node,## Google Cloud DNS,"  
API Documentation
Official Documentation
",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authenticating on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authentication section above).

var dns = gcloud.dns({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

// Create a managed zone.
dns.createZone('my-new-zone', {
  dnsName: 'my-domain.com.'
}, function(err, zone) {});

// Reference an existing zone.
var zone = dns.zone('my-existing-zone');

// Create an NS record.
var nsRecord = zone.record('ns', {
  ttl: 86400,
  name: 'my-domain.com.',
  data: 'ns-cloud1.googledomains.com.'
});

zone.addRecord(nsRecord, function(err, change) {});

// Create a zonefile from the records in your zone.
zone.export('/zonefile.zone', function(err) {});",3
https://github.com/savethefails/gcloud-node,## Google Cloud Pub/Sub,"  
API Documentation
Official Documentation
",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authenticating on a per-API-basis. You don't need to do this if you
// auth on a global basis (see Authentication section above).

var pubsub = gcloud.pubsub({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

// Reference a topic that has been previously created.
var topic = pubsub.topic('my-topic');

// Publish a message to the topic.
topic.publish({
  data: 'New message!'
}, function(err) {});

// Subscribe to the topic.
topic.subscribe('new-subscription', function(err, subscription) {
  // Register listeners to start pulling for messages.
  function onError(err) {}
  function onMessage(message) {}
  subscription.on('error', onError);
  subscription.on('message', onMessage);

  // Remove listeners to stop pulling for messages.
  subscription.removeListener('message', onMessage);
  subscription.removeListener('error', onError);
});",3
https://github.com/savethefails/gcloud-node,## Google Cloud Storage,"  
API Documentation
Official Documentation
",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var fs = require('fs');
var gcloud = require('gcloud');

// Authenticating on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authentication section above).

var gcs = gcloud.storage({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

// Create a new bucket.
gcs.createBucket('my-new-bucket', function(err, bucket) {
  if (!err) {
    // ""my-new-bucket"" was successfully created.
  }
});

// Reference an existing bucket.
var bucket = gcs.bucket('my-existing-bucket');

// Upload a local file to a new file to be created in your bucket.
bucket.upload('/photos/zoo/zebra.jpg', function(err, file) {
  if (!err) {
    // ""zebra.jpg"" is now in your bucket.
  }
});

// Download a file from your bucket.
bucket.file('giraffe.jpg').download({
  destination: '/photos/zoo/giraffe.jpg'
}, function(err) {});

// Streams are also supported for reading and writing files.
var remoteReadStream = bucket.file('giraffe.jpg').createReadStream();
var localWriteStream = fs.createWriteStream('/photos/zoo/giraffe.jpg');
remoteReadStream.pipe(localWriteStream);

var localReadStream = fs.createReadStream('/photos/zoo/zebra.jpg');
var remoteWriteStream = bucket.file('zebra.jpg').createWriteStream();
localReadStream.pipe(remoteWriteStream);",3
https://github.com/savethefails/gcloud-node,## Google Compute Engine,"  
API Documentation
Official Documentation
",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authenticating on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authentication section above).

var gce = gcloud.compute({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

// Create a new VM using the latest OS image of your choice.
var zone = gce.zone('us-central1-a');
var name = 'ubuntu-http';

zone.createVM(name, { os: 'ubuntu' }, function(err, vm, operation) {
  // `operation` lets you check the status of long-running tasks.

  operation.onComplete(function(err, metadata) {
    if (!err) {
      // Virtual machine created!
    }
  });
});",3
https://github.com/savethefails/gcloud-node,## Google Prediction API,"  
API Documentation
Official Documentation
",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authenticating on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authentication section above).

var prediction = gcloud.prediction({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

// Get all of the trained models in your project.
prediction.getModels(function(err, models) {
  if (!err) {
    // `models` is an array of Model objects.
  }
});

// Reference an existing trained model.
var model = prediction.model('my-existing-model');

// Train a model.
model.train('english', 'Hello from your friends at Google!', function(err) {});

// Query a model.
model.query('Hello', function(err, results) {
  if (!err) {
    // results.winner == 'english'
    // results.scores == [
    //   {
    //     label: 'english',
    //     score: 1
    //   },
    //   {
    //     label: 'spanish',
    //     score: 0
    //   }
    // ]
  }
});",3
https://github.com/savethefails/gcloud-node,## Google Translate API,"  
API Documentation
Official Documentation
 An API key is required for Translate. See Identifying your application to Google.",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authenticating on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authentication section above).
var translate = gcloud.translate({
  key: 'API Key'
});

// Translate a string of text.
translate.translate('Hello', 'es', function(err, translation) {
  if (!err) {
    // translation = 'Hola'
  }
});

// Detect a language from a string of text.
translate.detect('Hello', function(err, results) {
  if (!err) {
    // results = {
    //   language: 'en',
    //   confidence: 1,
    //   input: 'Hello'
    // }
  }
});

// Get a list of supported languages.
translate.getLanguages(function(err, languages) {
  if (!err) {
    // languages = [
    //   'af',
    //   'ar',
    //   'az',
    //   ...
    // ]
  }
});",3
https://github.com/savethefails/gcloud-node,## Google Cloud Logging (Beta),"  
This is a Beta release of Google Cloud Logging. This API is not covered by any SLA or deprecation policy and may be subject to backward-incompatible changes.
 
API Documentation
Official Documentation
 // Authenticating on a global-basis. You can also authenticate on a per-API-
// basis (see Authentication section above).

var gcloud = require('gcloud')({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

var logging = gcloud.logging();

// Create a sink using a Bucket as a destination.
var gcs = gcloud.storage();

logging.createSink('my-new-sink', {
  destination: gcs.bucket('my-sink')
}, function(err, sink) {});

// Write a critical entry to a log.
var syslog = logging.log('syslog');

var resource = {
  type: 'gce_instance',
  labels: {
    zone: 'global',
    instance_id: 3
  }
};

var entry = syslog.entry(resource, {
  delegate: process.env.user
});

syslog.critical(entry, function(err) {});

// Get all entries in your project.
logging.getEntries(function(err, entries) {
  if (!err) {
    // `entries` contains all of the entries from the logs in your project.
  }
});",36
https://github.com/savethefails/gcloud-node,## Google Cloud Resource Manager (Beta),"  
This is a Beta release of Google Cloud Resource Manager. This feature is not covered by any SLA or deprecation policy and may be subject to backward-incompatible changes.
 
API Documentation
Official Documentation
",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authorizing on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authorization section above).

var resource = gcloud.resource({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

// Get all of the projects you maintain.
resource.getProjects(function(err, projects) {
  if (!err) {
    // `projects` contains all of your projects.
  }
});

// Get the metadata from your project. (defaults to `my-project`)
var project = resource.project();

project.getMetadata(function(err, metadata) {
  // `metadata` describes your project.
});",3
https://github.com/savethefails/gcloud-node,## Google Cloud Vision (Beta),"  
This is a Beta release of Google Cloud Vision. This feature is not covered by any SLA or deprecation policy and may be subject to backward-incompatible changes.
 
API Documentation
Official Documentation
",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authorizing on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authorization section above).

var vision = gcloud.vision({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

// Read the text from an image.
vision.detectText('./image.jpg', function(err, text) {
  // text = [
  //   'This was text found in the image',
  //   'This was more text found in the image'
  // ]
});

// Detect faces and the locations of their features in an image.
vision.detectFaces('./image.jpg', function(err, faces) {
  // faces = [
  //   {
  //     angles: {pan,tilt,roll},
  //     bounds: {
  //       head: [{x,y},{x,y},{x,y},{x,y}],
  //       face: [{x,y},{x,y},{x,y},{x,y}]
  //     },
  //     features: {
  //       confidence: 34.489909,
  //       chin: {
  //         center: {x,y,z},
  //         left: {x,y,z},
  //         right: {x,y,z}
  //       },
  //       ears: {
  //         left: {x,y,z},
  //         right: {x,y,z}
  //       },
  //       eyebrows: {
  //         left: {
  //           left: {x,y,z},
  //           right: {x,y,z},
  //           top: {x,y,z}
  //         },
  //         right: {
  //           left: {x,y,z},
  //           right: {x,y,z},
  //           top: {x,y,z}
  //         }
  //       },
  //       eyes: {
  //         left: {
  //           bottom: {x,y,z},
  //           center: {x,y,z},
  //           left: {x,y,z},
  //           pupil: {x,y,z},
  //           right: {x,y,z},
  //           top: {x,y,z}
  //         },
  //         right: {
  //           bottom: {x,y,z},
  //           center: {x,y,z},
  //           left: {x,y,z},
  //           pupil: {x,y,z},
  //           right: {x,y,z},
  //           top: {x,y,z}
  //         }
  //       },
  //       forehead: {x,y,z},
  //       lips: {
  //         bottom: {x,y,z},
  //         top: {x,y,z}
  //       },
  //       mouth: {
  //         center: {x,y,z},
  //         left: {x,y,z},
  //         right: {x,y,z}
  //       },
  //       nose: {
  //         bottom: {
  //           center: {x,y,z},
  //           left: {x,y,z},
  //           right: {x,y,z}
  //         },
  //         tip: {x,y,z},
  //         top: {x,y,z}
  //       }
  //     },
  //     confidence: 56.748849,
  //     blurry: false,
  //     dark: false,
  //     happy: false,
  //     hat: false,
  //     mad: false,
  //     sad: false,
  //     surprised: false
  //   }
  // ]
});",3
https://github.com/savethefails/gcloud-node,## Google Cloud Search (Alpha),"  
This is an Alpha release of Google Cloud Search. This feature is not covered by any SLA or deprecation policy and may be subject to backward-incompatible changes.
 
API Documentation
Official Documentation - If you are not a tester, this documentation is unavailable.
",36
https://github.com/savethefails/gcloud-node,#### Preview,"  var gcloud = require('gcloud');

// Authenticating on a per-API-basis. You don't need to do this if you auth on a
// global basis (see Authentication section above).

var search = gcloud.search({
  projectId: 'my-project',
  keyFilename: '/path/to/keyfile.json'
});

// Create a document in a new index.
var index = search.index('memberData');

var document = index.document('member-id-34211');
document.addField('preferredContactForm').addTextValue('phone');

index.createDocument(document, function(err, document) {
  console.log(err || document);
});

// Search an index and get the results as a readable object stream.
var index = search.index('memberData');

index.search('preferredContactForm:phone')
  .on('error', console.error)
  .on('data', function(document) {
    // document.id = 'member-id-34211';
  })
  .on('end', function() {
    // All results consumed.
  });",3
https://github.com/savethefails/gcloud-node,## Contributing,  Contributions to this library are always welcome and highly encouraged. See CONTRIBUTING for more information on how to get started.,7
https://github.com/savethefails/gcloud-node,## License,  Apache 2.0 - See COPYING for more information.,5
https://github.com/tmandal/CarND-Transfer-Learning-Lab,"# Transfer Learning Lab with VGG, Inception and ResNet","  In this lab, you will continue exploring transfer learning. You've already explored feature extraction with AlexNet and TensorFlow. Next, you will use Keras to explore feature extraction with the VGG, Inception and ResNet architectures. The models you will use were trained for days or weeks on the ImageNet dataset. Thus, the weights encapsulate higher-level features learned from training on thousands of classes. We'll use two datasets in this lab: 
German Traffic Sign Dataset
Cifar10
 Unless you have a powerful GPU, running feature extraction on these models will take a significant amount of time. To make things we precomputed bottleneck features for each (network, dataset) pair, this will allow you experiment with feature extraction even on a modest CPU. You can think of bottleneck features as feature extraction but with caching.  Because the base network weights are frozen during feature extraction, the output for an image will always be the same. Thus, once the image has already been passed once through the network we can cache and reuse the output. The files are encoded as such: 
{network}_{dataset}_bottleneck_features_train.p
{network}_{dataset}_bottleneck_features_validation.p
 network can be one of 'vgg', 'inception', or 'resnet' dataset can be on of 'cifar10' or 'traffic' How will the pretrained model perform on the new datasets?",1
https://github.com/ld000/decent,# decent," A Ghost blog theme, modified from Casper. The main design is inspired by Aquila. Demo: my blog ",13
https://github.com/ld000/decent,## Screenshot,  Moved to docs/screenshot.md,3
https://github.com/ld000/decent,## Features,"  
Ajax powered page loading.
Minimalist design, less is more.
Syntax highlighting.
Responsive deign.
Quote with author supported.
Image caption supported.
Image alignment supported.
Image gallery supported.
Google Analytics service.
Duoshuo comment service.
Disqus comment service.
All Optional services can be configured in the Ghost admin page, you don't have to manually modify the code.
",1
https://github.com/ld000/decent,## Installation,"  
Download this theme from Github release page, and extract the files to the Ghost's theme folder: content/themes.
Restart Ghost: pm2 restart ghost (assuming you're using pm2)
In the Ghost admin page, navigate to General section, change the theme to decent
In the Ghost admin page, navigate to Code Injection section, add some configurations, for example, add Google Analytics service or Duoshuo comment service.
Everything is done. Just visit your blog's home page to enjoy the theme.
",3
https://github.com/ld000/decent,## Writing markdown,"  This theme support some custom styles, it enable you to write some cool styles in markdown, such as image caption, image alignment and so on. The detailed documentation can be found at docs/writing-markdown.md.",136
https://github.com/ld000/decent,## Configuration,  See docs/configuration.md.,36
https://github.com/ld000/decent,## Compatibility,  decent theme works great with Ghost >= v0.8 && < v1.0. The frontend code works great in modern browser.,3
https://github.com/ld000/decent,## Development,"  
Fork this project, and clone it to Ghost theme's folder.
Run npm install to install dependencies.
Run gulp to start development(make sure your Ghost is running, and you have set decent as your Ghost's theme.)
 Gulp will watch your files' changes, and automatically generate the bundle file, like screen.css and bundle.min.js. So you don't need to build these files by yourself. And when the bundle file changes, the browser will automatically reload itself, to see the latest changes.",3
https://github.com/ld000/decent,## Thanks to,"  
Ghost
Casper
Aquila
Prism.js
Photoswipe
Duoshuo
Disqus
Progress.js
",56
https://github.com/ld000/decent,## License,  MIT,5
https://github.com/zzl81cn/avalon-server-render-example,# avalon-server-render-example," avalon2+koa2的后端渲染例?npm install npm start  后端渲染的流?
引入最新版 avalon 这里用avalon.modern体积少些
引入avalon仓库下的serve下的文件serveRender.js
引入你定义VM的文?(所有DOM操作要在回调里进?不要出现 window, document, 方便能在nodejs环境中运?
对你的VM使用webpack进行打包 (目的是处理module.exports, require)
引入你该页面的模?将VM与模板放进serveRender方法,得到一个对?里面包含渲染好的HTML(A) ?一个包括所有模板的对象(B)
创建一个script标签, 里面定义一个avalon.serverTemplates对象, 将B对象赋给?将上面的标签与A页面,  赋给ctx.body发往前端
  //1. 引入avalon
var vm = require('./src/avalon')
//2. 引入avalon的后端渲染器
var serveRender = require('./dist/serverRender')
//3. 当前页面VM
var vm = require('./src/vm')
//4. 当前页面模板
var test = fs.readFileSync('./src/aaa.html', 'utf-8');

//5. 
var obj = serveRender(vm, test)

//6. 
var files = JSON.stringify(obj.templates)
var script = '<script src=""./avalon.js""><\/script>' +
        '<script> avalon.serverTemplates= ' + files + '<\/script>' +
        '<script src=""./test.js""><\/script>'
//7. render
app.use(async function(ctx){
     await (ctx.body = script + obj.html)
})

",-
https://github.com/zzl81cn/avalon-server-render-example,##,,-
https://github.com/zzl81cn/avalon-server-render-example,##,,-
https://github.com/ahmadassaf/dynamic-json-resume,# dynamic-json-resume,"Create your resume easily using json, and add some dynamism to it, or export it as pdf.

This started as a small weekend project. In the end, it took me 2/3 afternoons to finish it and have it published on npm.",12
https://github.com/ahmadassaf/dynamic-json-resume,##Inspiration:,"json-resume
This blog post, as I really liked the content loaded as you scroll on the right. I wanted to have the same, in a simple way for my resume.",16
https://github.com/ahmadassaf/dynamic-json-resume,##Installation:,npm install (--save) json-resume-dynamic,3
https://github.com/ahmadassaf/dynamic-json-resume,##Usage:,"You will have to fill out your resume following a specific json schema.
This assumes that you are using express for the server part if you want to display your resume on your website.
If you are not interested in showcasing your resume on your website, you can just export it as a PDF and skip directly to How to generate a PDF from my json file?",3
https://github.com/ahmadassaf/dynamic-json-resume,##JSON Schema:,"Your resume will be divided into 6 sections, all englobed into a resume JSON object.",3
https://github.com/ahmadassaf/dynamic-json-resume,####Contact section:,"""contact"" : {
        ""first_name"": """",
        ""last_name"": """",
        ""website"": """",
        ""email"": """",
        ""github"": """",
        ""city"": """"
    }",3
https://github.com/ahmadassaf/dynamic-json-resume,####Education section:," This will be composed of an array of item-education englobed into an education JSON object.

An item-education has this form:

  ""item-education"": {
    ""start-date"": """",
    ""end-date"": """",
    ""institution"": {
        ""name"": """",
        ""city"": """",
        ""country"": """"
    },
    ""description"": """",
    ""additional-info"": """"
  }",3
https://github.com/ahmadassaf/dynamic-json-resume,#### Work section:," This will be composed of an array of item-work englobed into a work JSON object.

""item-work"": {
    ""start-date"": """",
    ""end-date"": """",
    ""position"": """",
    ""company"": {
        ""name"": """",
        ""city"": """",
        ""country"": """"
     },
    ""achievements"": """",
    ""technologies"": ["""", """"]
}",3
https://github.com/ahmadassaf/dynamic-json-resume,#### Project section:,"This will be composed of an array of item-projects englobed into a projects JSON object.

""item-projects"": {
    ""title"": """",
    ""description"":"""",
    ""technologies"": []
}",3
https://github.com/ahmadassaf/dynamic-json-resume,#### Skills section:,"his is just an array of strings with the key ""skills""

""skills"" : [""skill1"", ""skill2""]",3
https://github.com/ahmadassaf/dynamic-json-resume,#### Languages and Hobbies sections:,"This will be composed of an array of item-languages englobed into a languages and an array of item-hobbies into a hobbies JSON object respectively.


""item-languages"": {
    ""name"": """",
    ""additional-info"": """"
}

{
""item-hobbies"": {
    ""name"": """",
    ""additional-info"": """"
}",3
https://github.com/ahmadassaf/dynamic-json-resume,##How to add extra content for your resume?,"This is done by adding two properties only to the items of your JSON's schema:

You need to add an id attribute
You need to add an extra JSON object having two properties:
""extra"" {
  ""type"": ""text"" || ""images""
  ""extraContent"": <html string> || <string> if type == ""text"" 
                  [<url-image>] or <url-image> if type == ""images""
}
You can find an empty schema in resume-schema.json at the root of the module or a working schema in examples/my-resume.json.",3
https://github.com/ahmadassaf/dynamic-json-resume,##API:,"Two methods only:

getResumeWithExtras(strResumeAsJson) returns an object containing the resume section as result.resume and the extras section as result.extraContent

It will parse the JSON string provided and verify that:

all the mandatory fields are declared.
each extra object has an id.
If something is wrong, the error message should give you a good indication on how fix your issue!

getTemplatePath(nameTemplate) returns the template location within the module",36
https://github.com/ahmadassaf/dynamic-json-resume,## How to generate a PDF for my resume?,"Go into the module folder
Run ./cli.js export <json_path> [output_location] [css_file_location]
By default it will generate a resume.pdf file in the current directory.

You can also generate an html file containing your resume:

Go into the module folder
Run ./cli.js exportToHtml <json_path> [output_location] [css_file_location]
And as a plain text file (as it is sometimes the only solution for some job posts hmhm):

Go into the module folder
Run ./cli.js exportToPlainText <json_path> [output_location]",3
https://github.com/ahmadassaf/dynamic-json-resume,## Generate your dynamic resume from your [json-resume](https://jsonresume.org/),"Go into the module folder
Run ./cli.js generateFromJsonResume <json_path> [output_location]",3
https://github.com/ahmadassaf/dynamic-json-resume,## Example,"Complete example to integrate this into your node app (assuming you use node-express and mustache-express):
var express = require('express');
var path = require('path');
var fs = require('fs');
var mustacheExpress = require('mustache-express');
var dynamicJsonResume = require('json-resume-dynamic');
var app = express()

app.use(express.static(path.join(__dirname, 'static')));
app.use(express.static(path.join(__dirname, 'node_modules/json-resume-dynamic/static')));

app.engine('html', mustacheExpress());
app.set('view engine', 'html');
app.set('views', __dirname + '/templates');


app.get('/', function(request, response) {
    var resumeJsonFile = fs.readFileSync(__dirname + ""/my-resume.json"", 'utf-8', function (err, data) {
    });

    var resume = dynamicJsonResume.getResumeWithExtras(resumeJsonFile);
    if (resume) {
        response.render(dynamicJsonResume.getTemplatePath('cv'), resume);
    }
});

var port = process.env.PORT || 5000;

app.listen(port, function() {
console.log(""Listening on "" + port);
}); ",3
https://github.com/ahmadassaf/dynamic-json-resume,##### Complete example to integrate this into your node app (assuming you use node-express and mustache-express):,,3
https://github.com/ahmadassaf/dynamic-json-resume,##Tests,"You can run the tests by executing: npm test ##Mentions:

Marc Bachmann for the nice to use node-html-pdf
You can find a quickly done example here: http://resume-jeremydagorn.herokuapp.com/. You can of course modify the theme/style of your resume by playing around with those files.",3
https://github.com/ahmadassaf/dynamic-json-resume,##Mentions:,,56
https://github.com/envs/javascript,# Airbnb JavaScript Style Guide() {," A mostly reasonable approach to JavaScript 

 Other Style Guides 
ES5 (Deprecated)
React
CSS-in-JavaScript
CSS & Sass
Ruby
",16
https://github.com/envs/javascript,## Table of Contents,"  
Types
References
Objects
Arrays
Destructuring
Strings
Functions
Arrow Functions
Classes & Constructors
Modules
Iterators and Generators
Properties
Variables
Hoisting
Comparison Operators & Equality
Blocks
Control Statements
Comments
Whitespace
Commas
Semicolons
Type Casting & Coercion
Naming Conventions
Accessors
Events
jQuery
ECMAScript 5 Compatibility
ECMAScript 6+ (ES 2015+) Styles
Testing
Performance
Resources
In the Wild
Translation
The JavaScript Style Guide Guide
Chat With Us About JavaScript
Contributors
License
",6
https://github.com/envs/javascript,## Types,"   

1.1 Primitives: When you access a primitive type you work directly on its value.

string
number
boolean
null
undefined

const foo = 1;
let bar = foo;

bar = 9;

console.log(foo, bar); // => 1, 9

  

1.2 Complex: When you access a complex type you work on a reference to its value.

object
array
function

const foo = [1, 2];
const bar = foo;

bar[0] = 9;

console.log(foo[0], bar[0]); // => 9, 9

 ?back to top",3
https://github.com/envs/javascript,## References,"   

2.1 Use const for all of your references; avoid using var. eslint: prefer-const, no-const-assign

Why? This ensures that you can't reassign your references, which can lead to bugs and difficult to comprehend code.

// bad
var a = 1;
var b = 2;

// good
const a = 1;
const b = 2;

  

2.2 If you must reassign references, use let instead of var. eslint: no-var jscs: disallowVar

Why? let is block-scoped rather than function-scoped like var.

// bad
var count = 1;
if (true) {
  count += 1;
}

// good, use the let.
let count = 1;
if (true) {
  count += 1;
}

  

2.3 Note that both let and const are block-scoped.
// const and let only exist in the blocks they are defined in.
{
  let a = 1;
  const b = 1;
}
console.log(a); // ReferenceError
console.log(b); // ReferenceError

 ?back to top",3
https://github.com/envs/javascript,## Objects,"   

3.1 Use the literal syntax for object creation. eslint: no-new-object
// bad
const item = new Object();

// good
const item = {};

  

3.2 Use computed property names when creating objects with dynamic property names.

Why? They allow you to define all the properties of an object in one place.

function getKey(k) {
  return `a key named ${k}`;
}

// bad
const obj = {
  id: 5,
  name: 'San Francisco',
};
obj[getKey('enabled')] = true;

// good
const obj = {
  id: 5,
  name: 'San Francisco',
  [getKey('enabled')]: true,
};

  

3.3 Use object method shorthand. eslint: object-shorthand jscs: requireEnhancedObjectLiterals
// bad
const atom = {
  value: 1,

  addValue: function (value) {
    return atom.value + value;
  },
};

// good
const atom = {
  value: 1,

  addValue(value) {
    return atom.value + value;
  },
};

  

3.4 Use property value shorthand. eslint: object-shorthand jscs: requireEnhancedObjectLiterals

Why? It is shorter to write and descriptive.

const lukeSkywalker = 'Luke Skywalker';

// bad
const obj = {
  lukeSkywalker: lukeSkywalker,
};

// good
const obj = {
  lukeSkywalker,
};

  

3.5 Group your shorthand properties at the beginning of your object declaration.

Why? It's easier to tell which properties are using the shorthand.

const anakinSkywalker = 'Anakin Skywalker';
const lukeSkywalker = 'Luke Skywalker';

// bad
const obj = {
  episodeOne: 1,
  twoJediWalkIntoACantina: 2,
  lukeSkywalker,
  episodeThree: 3,
  mayTheFourth: 4,
  anakinSkywalker,
};

// good
const obj = {
  lukeSkywalker,
  anakinSkywalker,
  episodeOne: 1,
  twoJediWalkIntoACantina: 2,
  episodeThree: 3,
  mayTheFourth: 4,
};

  

3.6 Only quote properties that are invalid identifiers. eslint: quote-props jscs: disallowQuotedKeysInObjects

Why? In general we consider it subjectively easier to read. It improves syntax highlighting, and is also more easily optimized by many JS engines.

// bad
const bad = {
  'foo': 3,
  'bar': 4,
  'data-blah': 5,
};

// good
const good = {
  foo: 3,
  bar: 4,
  'data-blah': 5,
};

  

3.7 Do not call Object.prototype methods directly, such as hasOwnProperty, propertyIsEnumerable, and isPrototypeOf.

Why? These methods may be shadowed by properties on the object in question - consider { hasOwnProperty: false } - or, the object may be a null object (Object.create(null)).

// bad
console.log(object.hasOwnProperty(key));

// good
console.log(Object.prototype.hasOwnProperty.call(object, key));

// best
const has = Object.prototype.hasOwnProperty; // cache the lookup once, in module scope.
/* or */
import has from 'has';
// ...
console.log(has.call(object, key));

  

3.8 Prefer the object spread operator over Object.assign to shallow-copy objects. Use the object rest operator to get a new object with certain properties omitted.
// very bad
const original = { a: 1, b: 2 };
const copy = Object.assign(original, { c: 3 }); // this mutates `original` ಠ_?delete copy.a; // so does this

// bad
const original = { a: 1, b: 2 };
const copy = Object.assign({}, original, { c: 3 }); // copy => { a: 1, b: 2, c: 3 }

// good
const original = { a: 1, b: 2 };
const copy = { ...original, c: 3 }; // copy => { a: 1, b: 2, c: 3 }

const { a, ...noA } = copy; // noA => { b: 2, c: 3 }

 ?back to top",3
https://github.com/envs/javascript,## Arrays,"   

4.1 Use the literal syntax for array creation. eslint: no-array-constructor
// bad
const items = new Array();

// good
const items = [];

  

4.2 Use Array#push instead of direct assignment to add items to an array.
const someStack = [];

// bad
someStack[someStack.length] = 'abracadabra';

// good
someStack.push('abracadabra');

  

4.3 Use array spreads ... to copy arrays.
// bad
const len = items.length;
const itemsCopy = [];
let i;

for (i = 0; i < len; i += 1) {
  itemsCopy[i] = items[i];
}

// good
const itemsCopy = [...items];

  

4.4 To convert an array-like object to an array, use Array.from.
const foo = document.querySelectorAll('.foo');
const nodes = Array.from(foo);

  

4.5 Use return statements in array method callbacks. It's ok to omit the return if the function body consists of a single statement following 8.2. eslint: array-callback-return
// good
[1, 2, 3].map((x) => {
  const y = x + 1;
  return x * y;
});

// good
[1, 2, 3].map(x => x + 1);

// bad
const flat = {};
[[0, 1], [2, 3], [4, 5]].reduce((memo, item, index) => {
  const flatten = memo.concat(item);
  flat[index] = flatten;
});

// good
const flat = {};
[[0, 1], [2, 3], [4, 5]].reduce((memo, item, index) => {
  const flatten = memo.concat(item);
  flat[index] = flatten;
  return flatten;
});

// bad
inbox.filter((msg) => {
  const { subject, author } = msg;
  if (subject === 'Mockingbird') {
    return author === 'Harper Lee';
  } else {
    return false;
  }
});

// good
inbox.filter((msg) => {
  const { subject, author } = msg;
  if (subject === 'Mockingbird') {
    return author === 'Harper Lee';
  }

  return false;
});

 ?back to top  
4.6 Use line breaks after open and before close array brackets if an array has multiple lines
 // bad
const arr = [
  [0, 1], [2, 3], [4, 5],
];

const objectInArray = [{
  id: 1,
}, {
  id: 2,
}];

const numberInArray = [
  1, 2,
];

// good
const arr = [[0, 1], [2, 3], [4, 5]];

const objectInArray = [
  {
    id: 1,
  },
  {
    id: 2,
  },
];

const numberInArray = [
  1,
  2,
]; ?back to top",3
https://github.com/envs/javascript,## Destructuring,"   

5.1 Use object destructuring when accessing and using multiple properties of an object. jscs: requireObjectDestructuring

Why? Destructuring saves you from creating temporary references for those properties.

// bad
function getFullName(user) {
  const firstName = user.firstName;
  const lastName = user.lastName;

  return `${firstName} ${lastName}`;
}

// good
function getFullName(user) {
  const { firstName, lastName } = user;
  return `${firstName} ${lastName}`;
}

// best
function getFullName({ firstName, lastName }) {
  return `${firstName} ${lastName}`;
}

  

5.2 Use array destructuring. jscs: requireArrayDestructuring
const arr = [1, 2, 3, 4];

// bad
const first = arr[0];
const second = arr[1];

// good
const [first, second] = arr;

  

5.3 Use object destructuring for multiple return values, not array destructuring. jscs: disallowArrayDestructuringReturn

Why? You can add new properties over time or change the order of things without breaking call sites.

// bad
function processInput(input) {
  // then a miracle occurs
  return [left, right, top, bottom];
}

// the caller needs to think about the order of return data
const [left, __, top] = processInput(input);

// good
function processInput(input) {
  // then a miracle occurs
  return { left, right, top, bottom };
}

// the caller selects only the data they need
const { left, top } = processInput(input);

 ?back to top",3
https://github.com/envs/javascript,## Strings,"   

6.1 Use single quotes '' for strings. eslint: quotes jscs: validateQuoteMarks
// bad
const name = ""Capt. Janeway"";

// bad - template literals should contain interpolation or newlines
const name = `Capt. Janeway`;

// good
const name = 'Capt. Janeway';

  

6.2 Strings that cause the line to go over 100 characters should not be written across multiple lines using string concatenation.

Why? Broken strings are painful to work with and make code less searchable.

// bad
const errorMessage = 'This is a super long error that was thrown because \
of Batman. When you stop to think about how Batman had anything to do \
with this, you would get nowhere \
fast.';

// bad
const errorMessage = 'This is a super long error that was thrown because ' +
  'of Batman. When you stop to think about how Batman had anything to do ' +
  'with this, you would get nowhere fast.';

// good
const errorMessage = 'This is a super long error that was thrown because of Batman. When you stop to think about how Batman had anything to do with this, you would get nowhere fast.';

  

6.3 When programmatically building up strings, use template strings instead of concatenation. eslint: prefer-template template-curly-spacing jscs: requireTemplateStrings

Why? Template strings give you a readable, concise syntax with proper newlines and string interpolation features.

// bad
function sayHi(name) {
  return 'How are you, ' + name + '?';
}

// bad
function sayHi(name) {
  return ['How are you, ', name, '?'].join();
}

// bad
function sayHi(name) {
  return `How are you, ${ name }?`;
}

// good
function sayHi(name) {
  return `How are you, ${name}?`;
}

  
6.4 Never use eval() on a string, it opens too many vulnerabilities.
  

6.5 Do not unnecessarily escape characters in strings. eslint: no-useless-escape

Why? Backslashes harm readability, thus they should only be present when necessary.

// bad
const foo = '\'this\' \i\s \""quoted\""';

// good
const foo = '\'this\' is ""quoted""';
const foo = `my name is '${name}'`;

 ?back to top",3
https://github.com/envs/javascript,## Functions,"   

7.1 Use named function expressions instead of function declarations. eslint: func-style jscs: disallowFunctionDeclarations

Why? Function declarations are hoisted, which means that it’s easy - too easy - to reference the function before it is defined in the file. This harms readability and maintainability. If you find that a function’s definition is large or complex enough that it is interfering with understanding the rest of the file, then perhaps it’s time to extract it to its own module! Don’t forget to name the expression - anonymous functions can make it harder to locate the problem in an Error's call stack. (Discussion)

// bad
function foo() {
  // ...
}

// bad
const foo = function () {
  // ...
};

// good
const foo = function bar() {
  // ...
};

  

7.2 Wrap immediately invoked function expressions in parentheses. eslint: wrap-iife jscs: requireParenthesesAroundIIFE

Why? An immediately invoked function expression is a single unit - wrapping both it, and its invocation parens, in parens, cleanly expresses this. Note that in a world with modules everywhere, you almost never need an IIFE.

// immediately-invoked function expression (IIFE)
(function () {
  console.log('Welcome to the Internet. Please follow me.');
}());

  
7.3 Never declare a function in a non-function block (if, while, etc). Assign the function to a variable instead. Browsers will allow you to do it, but they all interpret it differently, which is bad news bears. eslint: no-loop-func
  

7.4 Note: ECMA-262 defines a block as a list of statements. A function declaration is not a statement. Read ECMA-262's note on this issue.
// bad
if (currentUser) {
  function test() {
    console.log('Nope.');
  }
}

// good
let test;
if (currentUser) {
  test = () => {
    console.log('Yup.');
  };
}

  

7.5 Never name a parameter arguments. This will take precedence over the arguments object that is given to every function scope.
// bad
function foo(name, options, arguments) {
  // ...
}

// good
function foo(name, options, args) {
  // ...
}

  

7.6 Never use arguments, opt to use rest syntax ... instead. eslint: prefer-rest-params

Why? ... is explicit about which arguments you want pulled. Plus, rest arguments are a real Array, and not merely Array-like like arguments.

// bad
function concatenateAll() {
  const args = Array.prototype.slice.call(arguments);
  return args.join('');
}

// good
function concatenateAll(...args) {
  return args.join('');
}

  

7.7 Use default parameter syntax rather than mutating function arguments.
// really bad
function handleThings(opts) {
  // No! We shouldn't mutate function arguments.
  // Double bad: if opts is falsy it'll be set to an object which may
  // be what you want but it can introduce subtle bugs.
  opts = opts || {};
  // ...
}

// still bad
function handleThings(opts) {
  if (opts === void 0) {
    opts = {};
  }
  // ...
}

// good
function handleThings(opts = {}) {
  // ...
}

  

7.8 Avoid side effects with default parameters.

Why? They are confusing to reason about.

var b = 1;
// bad
function count(a = b++) {
  console.log(a);
}
count();  // 1
count();  // 2
count(3); // 3
count();  // 3

  

7.9 Always put default parameters last.
// bad
function handleThings(opts = {}, name) {
  // ...
}

// good
function handleThings(name, opts = {}) {
  // ...
}

  

7.10 Never use the Function constructor to create a new function. eslint: no-new-func

Why? Creating a function in this way evaluates a string similarly to eval(), which opens vulnerabilities.

// bad
var add = new Function('a', 'b', 'return a + b');

// still bad
var subtract = Function('a', 'b', 'return a - b');

  

7.11 Spacing in a function signature. eslint: space-before-function-paren space-before-blocks

Why? Consistency is good, and you shouldn’t have to add or remove a space when adding or removing a name.

// bad
const f = function(){};
const g = function (){};
const h = function() {};

// good
const x = function () {};
const y = function a() {};

  

7.12 Never mutate parameters. eslint: no-param-reassign

Why? Manipulating objects passed in as parameters can cause unwanted variable side effects in the original caller.

// bad
function f1(obj) {
  obj.key = 1;
}

// good
function f2(obj) {
  const key = Object.prototype.hasOwnProperty.call(obj, 'key') ? obj.key : 1;
}

  

7.13 Never reassign parameters. eslint: no-param-reassign

Why? Reassigning parameters can lead to unexpected behavior, especially when accessing the arguments object. It can also cause optimization issues, especially in V8.

// bad
function f1(a) {
  a = 1;
  // ...
}

function f2(a) {
  if (!a) { a = 1; }
  // ...
}

// good
function f3(a) {
  const b = a || 1;
  // ...
}

function f4(a = 1) {
  // ...
}

  

7.14 Prefer the use of the spread operator ... to call variadic functions. eslint: prefer-spread

Why? It's cleaner, you don't need to supply a context, and you can not easily compose new with apply.

// bad
const x = [1, 2, 3, 4, 5];
console.log.apply(console, x);

// good
const x = [1, 2, 3, 4, 5];
console.log(...x);

// bad
new (Function.prototype.bind.apply(Date, [null, 2016, 8, 5]));

// good
new Date(...[2016, 8, 5]);

  

7.15 Functions with multiline signatures, or invocations, should be indented just like every other multiline list in this guide: with each item on a line by itself, with a trailing comma on the last item.
// bad
function foo(bar,
             baz,
             quux) {
  // ...
}

// good
function foo(
  bar,
  baz,
  quux,
) {
  // ...
}

// bad
console.log(foo,
  bar,
  baz);

// good
console.log(
  foo,
  bar,
  baz,
);

 ?back to top",3
https://github.com/envs/javascript,## Arrow Functions,"   

8.1 When you must use function expressions (as when passing an anonymous function), use arrow function notation. eslint: prefer-arrow-callback, arrow-spacing jscs: requireArrowFunctions

Why? It creates a version of the function that executes in the context of this, which is usually what you want, and is a more concise syntax.


Why not? If you have a fairly complicated function, you might move that logic out into its own function declaration.

// bad
[1, 2, 3].map(function (x) {
  const y = x + 1;
  return x * y;
});

// good
[1, 2, 3].map((x) => {
  const y = x + 1;
  return x * y;
});

  

8.2 If the function body consists of a single expression, omit the braces and use the implicit return. Otherwise, keep the braces and use a return statement. eslint: arrow-parens, arrow-body-style jscs:  disallowParenthesesAroundArrowParam, requireShorthandArrowFunctions

Why? Syntactic sugar. It reads well when multiple functions are chained together.

// bad
[1, 2, 3].map(number => {
  const nextNumber = number + 1;
  `A string containing the ${nextNumber}.`;
});

// good
[1, 2, 3].map(number => `A string containing the ${number}.`);

// good
[1, 2, 3].map((number) => {
  const nextNumber = number + 1;
  return `A string containing the ${nextNumber}.`;
});

// good
[1, 2, 3].map((number, index) => ({
  [index]: number,
}));

  

8.3 In case the expression spans over multiple lines, wrap it in parentheses for better readability.

Why? It shows clearly where the function starts and ends.

// bad
['get', 'post', 'put'].map(httpMethod => Object.prototype.hasOwnProperty.call(
    httpMagicObjectWithAVeryLongName,
    httpMethod,
  )
);

// good
['get', 'post', 'put'].map(httpMethod => (
  Object.prototype.hasOwnProperty.call(
    httpMagicObjectWithAVeryLongName,
    httpMethod,
  )
));

  

8.4 If your function takes a single argument and doesn’t use braces, omit the parentheses. Otherwise, always include parentheses around arguments for clarity and consistency. Note: it is also acceptable to always use parentheses, in which case use the ""always"" option for eslint or do not include disallowParenthesesAroundArrowParam for jscs. eslint: arrow-parens jscs:  disallowParenthesesAroundArrowParam

Why? Less visual clutter.

// bad
[1, 2, 3].map((x) => x * x);

// good
[1, 2, 3].map(x => x * x);

// good
[1, 2, 3].map(number => (
  `A long string with the ${number}. It’s so long that we don’t want it to take up space on the .map line!`
));

// bad
[1, 2, 3].map(x => {
  const y = x + 1;
  return x * y;
});

// good
[1, 2, 3].map((x) => {
  const y = x + 1;
  return x * y;
});

  

8.5 Avoid confusing arrow function syntax (=>) with comparison operators (<=, >=). eslint: no-confusing-arrow
// bad
const itemHeight = item => item.height > 256 ? item.largeSize : item.smallSize;

// bad
const itemHeight = (item) => item.height > 256 ? item.largeSize : item.smallSize;

// good
const itemHeight = item => (item.height > 256 ? item.largeSize : item.smallSize);

// good
const itemHeight = (item) => {
  const { height, largeSize, smallSize } = item;
  return height > 256 ? largeSize : smallSize;
};

 ?back to top",3
https://github.com/envs/javascript,## Classes & Constructors,"   

9.1 Always use class. Avoid manipulating prototype directly.

Why? class syntax is more concise and easier to reason about.

// bad
function Queue(contents = []) {
  this.queue = [...contents];
}
Queue.prototype.pop = function () {
  const value = this.queue[0];
  this.queue.splice(0, 1);
  return value;
};


// good
class Queue {
  constructor(contents = []) {
    this.queue = [...contents];
  }
  pop() {
    const value = this.queue[0];
    this.queue.splice(0, 1);
    return value;
  }
}

  

9.2 Use extends for inheritance.

Why? It is a built-in way to inherit prototype functionality without breaking instanceof.

// bad
const inherits = require('inherits');
function PeekableQueue(contents) {
  Queue.apply(this, contents);
}
inherits(PeekableQueue, Queue);
PeekableQueue.prototype.peek = function () {
  return this.queue[0];
};

// good
class PeekableQueue extends Queue {
  peek() {
    return this.queue[0];
  }
}

  

9.3 Methods can return this to help with method chaining.
// bad
Jedi.prototype.jump = function () {
  this.jumping = true;
  return true;
};

Jedi.prototype.setHeight = function (height) {
  this.height = height;
};

const luke = new Jedi();
luke.jump(); // => true
luke.setHeight(20); // => undefined

// good
class Jedi {
  jump() {
    this.jumping = true;
    return this;
  }

  setHeight(height) {
    this.height = height;
    return this;
  }
}

const luke = new Jedi();

luke.jump()
  .setHeight(20);

  

9.4 It's okay to write a custom toString() method, just make sure it works successfully and causes no side effects.
class Jedi {
  constructor(options = {}) {
    this.name = options.name || 'no name';
  }

  getName() {
    return this.name;
  }

  toString() {
    return `Jedi - ${this.getName()}`;
  }
}

  

9.5 Classes have a default constructor if one is not specified. An empty constructor function or one that just delegates to a parent class is unnecessary. eslint: no-useless-constructor
// bad
class Jedi {
  constructor() {}

  getName() {
    return this.name;
  }
}

// bad
class Rey extends Jedi {
  constructor(...args) {
    super(...args);
  }
}

// good
class Rey extends Jedi {
  constructor(...args) {
    super(...args);
    this.name = 'Rey';
  }
}

  

9.6 Avoid duplicate class members. eslint: no-dupe-class-members

Why? Duplicate class member declarations will silently prefer the last one - having duplicates is almost certainly a bug.

// bad
class Foo {
  bar() { return 1; }
  bar() { return 2; }
}

// good
class Foo {
  bar() { return 1; }
}

// good
class Foo {
  bar() { return 2; }
}

 ?back to top",3
https://github.com/envs/javascript,## Modules,"   

10.1 Always use modules (import/export) over a non-standard module system. You can always transpile to your preferred module system.

Why? Modules are the future, let's start using the future now.

// bad
const AirbnbStyleGuide = require('./AirbnbStyleGuide');
module.exports = AirbnbStyleGuide.es6;

// ok
import AirbnbStyleGuide from './AirbnbStyleGuide';
export default AirbnbStyleGuide.es6;

// best
import { es6 } from './AirbnbStyleGuide';
export default es6;

  

10.2 Do not use wildcard imports.

Why? This makes sure you have a single default export.

// bad
import * as AirbnbStyleGuide from './AirbnbStyleGuide';

// good
import AirbnbStyleGuide from './AirbnbStyleGuide';

  

10.3 And do not export directly from an import.

Why? Although the one-liner is concise, having one clear way to import and one clear way to export makes things consistent.

// bad
// filename es6.js
export { es6 as default } from './AirbnbStyleGuide';

// good
// filename es6.js
import { es6 } from './AirbnbStyleGuide';
export default es6;

  

10.4 Only import from a path in one place.
eslint: no-duplicate-imports

Why? Having multiple lines that import from the same path can make code harder to maintain.

// bad
import foo from 'foo';
// ?some other imports ?//
import { named1, named2 } from 'foo';

// good
import foo, { named1, named2 } from 'foo';

// good
import foo, {
  named1,
  named2,
} from 'foo';

  

10.5 Do not export mutable bindings.
eslint: import/no-mutable-exports

Why? Mutation should be avoided in general, but in particular when exporting mutable bindings. While this technique may be needed for some special cases, in general, only constant references should be exported.

// bad
let foo = 3;
export { foo };

// good
const foo = 3;
export { foo };

  

10.6 In modules with a single export, prefer default export over named export.
eslint: import/prefer-default-export
// bad
export function foo() {}

// good
export default function foo() {}

  

10.7 Put all imports above non-import statements.
eslint: import/first

Why? Since imports are hoisted, keeping them all at the top prevents surprising behavior.

// bad
import foo from 'foo';
foo.init();

import bar from 'bar';

// good
import foo from 'foo';
import bar from 'bar';

foo.init();

  

10.8 Multiline imports should be indented just like multiline array and object literals.

Why? The curly braces follow the same indentation rules as every other curly brace block in the style guide, as do the trailing commas.

// bad
import {longNameA, longNameB, longNameC, longNameD, longNameE} from 'path';

// good
import {
  longNameA,
  longNameB,
  longNameC,
  longNameD,
  longNameE,
} from 'path';

  

10.9 Disallow Webpack loader syntax in module import statements.
eslint: import/no-webpack-loader-syntax

Why? Since using Webpack syntax in the imports couples the code to a module bundler. Prefer using the loader syntax in webpack.config.js.

// bad
import fooSass from 'css!sass!foo.scss';
import barCss from 'style!css!bar.css';

// good
import fooSass from 'foo.scss';
import barCss from 'bar.css';

 ?back to top",3
https://github.com/envs/javascript,## Iterators and Generators,"   

11.1 Don't use iterators. Prefer JavaScript's higher-order functions instead of loops like for-in or for-of. eslint: no-iterator no-restricted-syntax

Why? This enforces our immutable rule. Dealing with pure functions that return values is easier to reason about than side effects.


Use map() / every() / filter() / find() / findIndex() / reduce() / some() / ... to iterate over arrays, and Object.keys() / Object.values() / Object.entries() to produce arrays so you can iterate over objects.

const numbers = [1, 2, 3, 4, 5];

// bad
let sum = 0;
for (let num of numbers) {
  sum += num;
}
sum === 15;

// good
let sum = 0;
numbers.forEach(num => sum += num);
sum === 15;

// best (use the functional force)
const sum = numbers.reduce((total, num) => total + num, 0);
sum === 15;

// bad
const increasedByOne = [];
for (let i = 0; i < numbers.length; i++) {
  increasedByOne.push(numbers[i] + 1);
}

// good
const increasedByOne = [];
numbers.forEach(num => increasedByOne.push(num + 1));

// best (keeping it functional)
const increasedByOne = numbers.map(num => num + 1);

  

11.2 Don't use generators for now.

Why? They don't transpile well to ES5.


  

11.3 If you must use generators, or if you disregard our advice, make sure their function signature is spaced properly. eslint: generator-star-spacing

Why? function and * are part of the same conceptual keyword - * is not a modifier for function, function* is a unique construct, different from function.

// bad
function * foo() {
  // ...
}

// bad
const bar = function * () {
  // ...
};

// bad
const baz = function *() {
  // ...
};

// bad
const quux = function*() {
  // ...
};

// bad
function*foo() {
  // ...
}

// bad
function *foo() {
  // ...
}

// very bad
function
*
foo() {
  // ...
}

// very bad
const wat = function
*
() {
  // ...
};

// good
function* foo() {
  // ...
}

// good
const foo = function* () {
  // ...
};

 ?back to top",3
https://github.com/envs/javascript,## Properties,"   

12.1 Use dot notation when accessing properties. eslint: dot-notation jscs: requireDotNotation
const luke = {
  jedi: true,
  age: 28,
};

// bad
const isJedi = luke['jedi'];

// good
const isJedi = luke.jedi;

  

12.2 Use bracket notation [] when accessing properties with a variable.
const luke = {
  jedi: true,
  age: 28,
};

function getProp(prop) {
  return luke[prop];
}

const isJedi = getProp('jedi');

 ?back to top",3
https://github.com/envs/javascript,## Variables,"   

13.1 Always use const or let to declare variables. Not doing so will result in global variables. We want to avoid polluting the global namespace. Captain Planet warned us of that. eslint: no-undef prefer-const
// bad
superPower = new SuperPower();

// good
const superPower = new SuperPower();

  

13.2 Use one const or let declaration per variable. eslint: one-var jscs: disallowMultipleVarDecl

Why? It's easier to add new variable declarations this way, and you never have to worry about swapping out a ; for a , or introducing punctuation-only diffs. You can also step through each declaration with the debugger, instead of jumping through all of them at once.

// bad
const items = getItems(),
    goSportsTeam = true,
    dragonball = 'z';

// bad
// (compare to above, and try to spot the mistake)
const items = getItems(),
    goSportsTeam = true;
    dragonball = 'z';

// good
const items = getItems();
const goSportsTeam = true;
const dragonball = 'z';

  

13.3 Group all your consts and then group all your lets.

Why? This is helpful when later on you might need to assign a variable depending on one of the previous assigned variables.

// bad
let i, len, dragonball,
    items = getItems(),
    goSportsTeam = true;

// bad
let i;
const items = getItems();
let dragonball;
const goSportsTeam = true;
let len;

// good
const goSportsTeam = true;
const items = getItems();
let dragonball;
let i;
let length;

  

13.4 Assign variables where you need them, but place them in a reasonable place.

Why? let and const are block scoped and not function scoped.

// bad - unnecessary function call
function checkName(hasName) {
  const name = getName();

  if (hasName === 'test') {
    return false;
  }

  if (name === 'test') {
    this.setName('');
    return false;
  }

  return name;
}

// good
function checkName(hasName) {
  if (hasName === 'test') {
    return false;
  }

  const name = getName();

  if (name === 'test') {
    this.setName('');
    return false;
  }

  return name;
}

  

13.5 Don't chain variable assignments.

Why? Chaining variable assignments creates implicit global variables.

// bad
(function example() {
  // JavaScript interprets this as
  // let a = ( b = ( c = 1 ) );
  // The let keyword only applies to variable a; variables b and c become
  // global variables.
  let a = b = c = 1;
}());

console.log(a); // undefined
console.log(b); // 1
console.log(c); // 1

// good
(function example() {
  let a = 1;
  let b = a;
  let c = a;
}());

console.log(a); // undefined
console.log(b); // undefined
console.log(c); // undefined

// the same applies for `const`

  

13.6 Avoid using unary increments and decrements (++, --). eslint no-plusplus

Why? Per the eslint documentation, unary increment and decrement statements are subject to automatic semicolon insertion and can cause silent errors with incrementing or decrementing values within an application. It is also more expressive to mutate your values with statements like num += 1 instead of num++ or num ++. Disallowing unary increment and decrement statements also prevents you from pre-incrementing/pre-decrementing values unintentionally which can also cause unexpected behavior in your programs.

// bad

const array = [1, 2, 3];
let num = 1;
num++;
--num;

let sum = 0;
let truthyCount = 0;
for (let i = 0; i < array.length; i++) {
  let value = array[i];
  sum += value;
  if (value) {
    truthyCount++;
  }
}

// good

const array = [1, 2, 3];
let num = 1;
num += 1;
num -= 1;

const sum = array.reduce((a, b) => a + b, 0);
const truthyCount = array.filter(Boolean).length;

 ?back to top",3
https://github.com/envs/javascript,## Hoisting,"   

14.1 var declarations get hoisted to the top of their scope, their assignment does not. const and let declarations are blessed with a new concept called Temporal Dead Zones (TDZ). It's important to know why typeof is no longer safe.
// we know this wouldn't work (assuming there
// is no notDefined global variable)
function example() {
  console.log(notDefined); // => throws a ReferenceError
}

// creating a variable declaration after you
// reference the variable will work due to
// variable hoisting. Note: the assignment
// value of `true` is not hoisted.
function example() {
  console.log(declaredButNotAssigned); // => undefined
  var declaredButNotAssigned = true;
}

// the interpreter is hoisting the variable
// declaration to the top of the scope,
// which means our example could be rewritten as:
function example() {
  let declaredButNotAssigned;
  console.log(declaredButNotAssigned); // => undefined
  declaredButNotAssigned = true;
}

// using const and let
function example() {
  console.log(declaredButNotAssigned); // => throws a ReferenceError
  console.log(typeof declaredButNotAssigned); // => throws a ReferenceError
  const declaredButNotAssigned = true;
}

  

14.2 Anonymous function expressions hoist their variable name, but not the function assignment.
function example() {
  console.log(anonymous); // => undefined

  anonymous(); // => TypeError anonymous is not a function

  var anonymous = function () {
    console.log('anonymous function expression');
  };
}

  

14.3 Named function expressions hoist the variable name, not the function name or the function body.
function example() {
  console.log(named); // => undefined

  named(); // => TypeError named is not a function

  superPower(); // => ReferenceError superPower is not defined

  var named = function superPower() {
    console.log('Flying');
  };
}

// the same is true when the function name
// is the same as the variable name.
function example() {
  console.log(named); // => undefined

  named(); // => TypeError named is not a function

  var named = function named() {
    console.log('named');
  };
}

  

14.4 Function declarations hoist their name and the function body.
function example() {
  superPower(); // => Flying

  function superPower() {
    console.log('Flying');
  }
}


For more information refer to JavaScript Scoping & Hoisting by Ben Cherry.

 ?back to top",3
https://github.com/envs/javascript,## Comparison Operators & Equality,"   
15.1 Use === and !== over == and !=. eslint: eqeqeq
  

15.2 Conditional statements such as the if statement evaluate their expression using coercion with the ToBoolean abstract method and always follow these simple rules:

Objects evaluate to true
Undefined evaluates to false
Null evaluates to false
Booleans evaluate to the value of the boolean
Numbers evaluate to false if +0, -0, or NaN, otherwise true
Strings evaluate to false if an empty string '', otherwise true

if ([0] && []) {
  // true
  // an array (even an empty one) is an object, objects will evaluate to true
}

  

15.3 Use shortcuts for booleans, but explicit comparisons for strings and numbers.
// bad
if (isValid === true) {
  // ...
}

// good
if (isValid) {
  // ...
}

// bad
if (name) {
  // ...
}

// good
if (name !== '') {
  // ...
}

// bad
if (collection.length) {
  // ...
}

// good
if (collection.length > 0) {
  // ...
}

  
15.4 For more information see Truth Equality and JavaScript by Angus Croll.
  

15.5 Use braces to create blocks in case and default clauses that contain lexical declarations (e.g. let, const, function, and class).

Why? Lexical declarations are visible in the entire switch block but only get initialized when assigned, which only happens when its case is reached. This causes problems when multiple case clauses attempt to define the same thing.

eslint rules: no-case-declarations.
// bad
switch (foo) {
  case 1:
    let x = 1;
    break;
  case 2:
    const y = 2;
    break;
  case 3:
    function f() {
      // ...
    }
    break;
  default:
    class C {}
}

// good
switch (foo) {
  case 1: {
    let x = 1;
    break;
  }
  case 2: {
    const y = 2;
    break;
  }
  case 3: {
    function f() {
      // ...
    }
    break;
  }
  case 4:
    bar();
    break;
  default: {
    class C {}
  }
}

  

15.6 Ternaries should not be nested and generally be single line expressions.
eslint rules: no-nested-ternary.
// bad
const foo = maybe1 > maybe2
  ? ""bar""
  : value1 > value2 ? ""baz"" : null;

// better
const maybeNull = value1 > value2 ? 'baz' : null;

const foo = maybe1 > maybe2
  ? 'bar'
  : maybeNull;

// best
const maybeNull = value1 > value2 ? 'baz' : null;

const foo = maybe1 > maybe2 ? 'bar' : maybeNull;

  

15.7 Avoid unneeded ternary statements.
eslint rules: no-unneeded-ternary.
// bad
const foo = a ? a : b;
const bar = c ? true : false;
const baz = c ? false : true;

// good
const foo = a || b;
const bar = !!c;
const baz = !c;

 ?back to top",3
https://github.com/envs/javascript,## Blocks,"   

16.1 Use braces with all multi-line blocks.
// bad
if (test)
  return false;

// good
if (test) return false;

// good
if (test) {
  return false;
}

// bad
function foo() { return false; }

// good
function bar() {
  return false;
}

  

16.2 If you're using multi-line blocks with if and else, put else on the same line as your if block's closing brace. eslint: brace-style jscs:  disallowNewlineBeforeBlockStatements
// bad
if (test) {
  thing1();
  thing2();
}
else {
  thing3();
}

// good
if (test) {
  thing1();
  thing2();
} else {
  thing3();
}

 ?back to top",3
https://github.com/envs/javascript,## Control Statements,"   

17.1 In case your control statement (if, while etc.) gets too long or exceeds the maximum line length, each (grouped) condition could be put into a new line. It's up to you whether the logical operator should begin or end the line.
// bad
if ((foo === 123 || bar === 'abc') && doesItLookGoodWhenItBecomesThatLong() && isThisReallyHappening()) {
  thing1();
}

// bad
if (foo === 123 &&
  bar === 'abc') {
  thing1();
}

// bad
if (foo === 123
  && bar === 'abc') {
  thing1();
}

// good
if (
  (foo === 123 || bar === ""abc"") &&
  doesItLookGoodWhenItBecomesThatLong() &&
  isThisReallyHappening()
) {
  thing1();
}

// good
if (foo === 123 && bar === 'abc') {
  thing1();
}

// good
if (
  foo === 123 &&
  bar === 'abc'
) {
  thing1();
}

// good
if (
  foo === 123
  && bar === 'abc'
) {
  thing1();
}

 ?back to top",3
https://github.com/envs/javascript,## Comments,"   

18.1 Use /** ... */ for multi-line comments.
// bad
// make() returns a new element
// based on the passed in tag name
//
// @param {String} tag
// @return {Element} element
function make(tag) {

  // ...

  return element;
}

// good
/**
 * make() returns a new element
 * based on the passed-in tag name
 */
function make(tag) {

  // ...

  return element;
}

  

18.2 Use // for single line comments. Place single line comments on a newline above the subject of the comment. Put an empty line before the comment unless it's on the first line of a block.
// bad
const active = true;  // is current tab

// good
// is current tab
const active = true;

// bad
function getType() {
  console.log('fetching type...');
  // set the default type to 'no type'
  const type = this.type || 'no type';

  return type;
}

// good
function getType() {
  console.log('fetching type...');

  // set the default type to 'no type'
  const type = this.type || 'no type';

  return type;
}

// also good
function getType() {
  // set the default type to 'no type'
  const type = this.type || 'no type';

  return type;
}


18.3 Start all comments with a space to make it easier to read. eslint: spaced-comment
// bad
//is current tab
const active = true;

// good
// is current tab
const active = true;

// bad
/**
 *make() returns a new element
 *based on the passed-in tag name
 */
function make(tag) {

  // ...

  return element;
}

// good
/**
 * make() returns a new element
 * based on the passed-in tag name
 */
function make(tag) {

  // ...

  return element;
}

  
18.4 Prefixing your comments with FIXME or TODO helps other developers quickly understand if you're pointing out a problem that needs to be revisited, or if you're suggesting a solution to the problem that needs to be implemented. These are different than regular comments because they are actionable. The actions are FIXME: -- need to figure this out or TODO: -- need to implement.
  

18.5 Use // FIXME: to annotate problems.
class Calculator extends Abacus {
  constructor() {
    super();

    // FIXME: shouldn't use a global here
    total = 0;
  }
}

  

18.6 Use // TODO: to annotate solutions to problems.
class Calculator extends Abacus {
  constructor() {
    super();

    // TODO: total should be configurable by an options param
    this.total = 0;
  }
}

 ?back to top",3
https://github.com/envs/javascript,## Whitespace,"   

19.1 Use soft tabs (space character) set to 2 spaces. eslint: indent jscs: validateIndentation
// bad
function foo() {
∙∙∙∙let name;
}

// bad
function bar() {
∙let name;
}

// good
function baz() {
∙∙let name;
}

  

19.2 Place 1 space before the leading brace. eslint: space-before-blocks jscs: requireSpaceBeforeBlockStatements
// bad
function test(){
  console.log('test');
}

// good
function test() {
  console.log('test');
}

// bad
dog.set('attr',{
  age: '1 year',
  breed: 'Bernese Mountain Dog',
});

// good
dog.set('attr', {
  age: '1 year',
  breed: 'Bernese Mountain Dog',
});

  

19.3 Place 1 space before the opening parenthesis in control statements (if, while etc.). Place no space between the argument list and the function name in function calls and declarations. eslint: keyword-spacing jscs: requireSpaceAfterKeywords
// bad
if(isJedi) {
  fight ();
}

// good
if (isJedi) {
  fight();
}

// bad
function fight () {
  console.log ('Swooosh!');
}

// good
function fight() {
  console.log('Swooosh!');
}

  

19.4 Set off operators with spaces. eslint: space-infix-ops jscs: requireSpaceBeforeBinaryOperators, requireSpaceAfterBinaryOperators
// bad
const x=y+5;

// good
const x = y + 5;

  

19.5 End files with a single newline character. eslint: eol-last
// bad
import { es6 } from './AirbnbStyleGuide';
  // ...
export default es6;
// bad
import { es6 } from './AirbnbStyleGuide';
  // ...
export default es6;??// good
import { es6 } from './AirbnbStyleGuide';
  // ...
export default es6;?
  

19.6 Use indentation when making long method chains (more than 2 method chains). Use a leading dot, which
emphasizes that the line is a method call, not a new statement. eslint: newline-per-chained-call no-whitespace-before-property
// bad
$('#items').find('.selected').highlight().end().find('.open').updateCount();

// bad
$('#items').
  find('.selected').
    highlight().
    end().
  find('.open').
    updateCount();

// good
$('#items')
  .find('.selected')
    .highlight()
    .end()
  .find('.open')
    .updateCount();

// bad
const leds = stage.selectAll('.led').data(data).enter().append('svg:svg').classed('led', true)
    .attr('width', (radius + margin) * 2).append('svg:g')
    .attr('transform', `translate(${radius + margin},${radius + margin})`)
    .call(tron.led);

// good
const leds = stage.selectAll('.led')
    .data(data)
  .enter().append('svg:svg')
    .classed('led', true)
    .attr('width', (radius + margin) * 2)
  .append('svg:g')
    .attr('transform', `translate(${radius + margin},${radius + margin})`)
    .call(tron.led);

// good
const leds = stage.selectAll('.led').data(data);

  

19.7 Leave a blank line after blocks and before the next statement. jscs: requirePaddingNewLinesAfterBlocks
// bad
if (foo) {
  return bar;
}
return baz;

// good
if (foo) {
  return bar;
}

return baz;

// bad
const obj = {
  foo() {
  },
  bar() {
  },
};
return obj;

// good
const obj = {
  foo() {
  },

  bar() {
  },
};

return obj;

// bad
const arr = [
  function foo() {
  },
  function bar() {
  },
];
return arr;

// good
const arr = [
  function foo() {
  },

  function bar() {
  },
];

return arr;

  

19.8 Do not pad your blocks with blank lines. eslint: padded-blocks jscs:  disallowPaddingNewlinesInBlocks
// bad
function bar() {

  console.log(foo);

}

// also bad
if (baz) {

  console.log(qux);
} else {
  console.log(foo);

}

// good
function bar() {
  console.log(foo);
}

// good
if (baz) {
  console.log(qux);
} else {
  console.log(foo);
}

  

19.9 Do not add spaces inside parentheses. eslint: space-in-parens jscs: disallowSpacesInsideParentheses
// bad
function bar( foo ) {
  return foo;
}

// good
function bar(foo) {
  return foo;
}

// bad
if ( foo ) {
  console.log(foo);
}

// good
if (foo) {
  console.log(foo);
}

  

19.10 Do not add spaces inside brackets. eslint: array-bracket-spacing jscs: disallowSpacesInsideArrayBrackets
// bad
const foo = [ 1, 2, 3 ];
console.log(foo[ 0 ]);

// good
const foo = [1, 2, 3];
console.log(foo[0]);

  

19.11 Add spaces inside curly braces. eslint: object-curly-spacing jscs: requireSpacesInsideObjectBrackets
// bad
const foo = {clark: 'kent'};

// good
const foo = { clark: 'kent' };

  

19.12 Avoid having lines of code that are longer than 100 characters (including whitespace). Note: per above, long strings are exempt from this rule, and should not be broken up. eslint: max-len jscs: maximumLineLength

Why? This ensures readability and maintainability.

// bad
const foo = jsonData && jsonData.foo && jsonData.foo.bar && jsonData.foo.bar.baz && jsonData.foo.bar.baz.quux && jsonData.foo.bar.baz.quux.xyzzy;

// bad
$.ajax({ method: 'POST', url: 'https://airbnb.com/', data: { name: 'John' } }).done(() => console.log('Congratulations!')).fail(() => console.log('You have failed this city.'));

// good
const foo = jsonData
  && jsonData.foo
  && jsonData.foo.bar
  && jsonData.foo.bar.baz
  && jsonData.foo.bar.baz.quux
  && jsonData.foo.bar.baz.quux.xyzzy;

// good
$.ajax({
  method: 'POST',
  url: 'https://airbnb.com/',
  data: { name: 'John' },
})
  .done(() => console.log('Congratulations!'))
  .fail(() => console.log('You have failed this city.'));

 ?back to top",3
https://github.com/envs/javascript,## Commas,"   

20.1 Leading commas: Nope. eslint: comma-style jscs: requireCommaBeforeLineBreak
// bad
const story = [
    once
  , upon
  , aTime
];

// good
const story = [
  once,
  upon,
  aTime,
];

// bad
const hero = {
    firstName: 'Ada'
  , lastName: 'Lovelace'
  , birthYear: 1815
  , superPower: 'computers'
};

// good
const hero = {
  firstName: 'Ada',
  lastName: 'Lovelace',
  birthYear: 1815,
  superPower: 'computers',
};

  

20.2 Additional trailing comma: Yup. eslint: comma-dangle jscs: requireTrailingComma

Why? This leads to cleaner git diffs. Also, transpilers like Babel will remove the additional trailing comma in the transpiled code which means you don't have to worry about the trailing comma problem in legacy browsers.

// bad - git diff without trailing comma
const hero = {
     firstName: 'Florence',
-    lastName: 'Nightingale'
+    lastName: 'Nightingale',
+    inventorOf: ['coxcomb chart', 'modern nursing']
};

// good - git diff with trailing comma
const hero = {
     firstName: 'Florence',
     lastName: 'Nightingale',
+    inventorOf: ['coxcomb chart', 'modern nursing'],
};
// bad
const hero = {
  firstName: 'Dana',
  lastName: 'Scully'
};

const heroes = [
  'Batman',
  'Superman'
];

// good
const hero = {
  firstName: 'Dana',
  lastName: 'Scully',
};

const heroes = [
  'Batman',
  'Superman',
];

// bad
function createHero(
  firstName,
  lastName,
  inventorOf
) {
  // does nothing
}

// good
function createHero(
  firstName,
  lastName,
  inventorOf,
) {
  // does nothing
}

// good (note that a comma must not appear after a ""rest"" element)
function createHero(
  firstName,
  lastName,
  inventorOf,
  ...heroArgs
) {
  // does nothing
}

// bad
createHero(
  firstName,
  lastName,
  inventorOf
);

// good
createHero(
  firstName,
  lastName,
  inventorOf,
);

// good (note that a comma must not appear after a ""rest"" element)
createHero(
  firstName,
  lastName,
  inventorOf,
  ...heroArgs
);

 ?back to top",3
https://github.com/envs/javascript,## Semicolons,"   

21.1 Yup. eslint: semi jscs: requireSemicolons
// bad
(function () {
  const name = 'Skywalker'
  return name
})()

// good
(function () {
  const name = 'Skywalker';
  return name;
}());

// good, but legacy (guards against the function becoming an argument when two files with IIFEs are concatenated)
;((() => {
  const name = 'Skywalker';
  return name;
})());
Read more.

 ?back to top",3
https://github.com/envs/javascript,## Type Casting & Coercion,"   
22.1 Perform type coercion at the beginning of the statement.
  

22.2  Strings:
// => this.reviewScore = 9;

// bad
const totalScore = this.reviewScore + ''; // invokes this.reviewScore.valueOf()

// bad
const totalScore = this.reviewScore.toString(); // isn't guaranteed to return a string

// good
const totalScore = String(this.reviewScore);

  

22.3 Numbers: Use Number for type casting and parseInt always with a radix for parsing strings. eslint: radix
const inputValue = '4';

// bad
const val = new Number(inputValue);

// bad
const val = +inputValue;

// bad
const val = inputValue >> 0;

// bad
const val = parseInt(inputValue);

// good
const val = Number(inputValue);

// good
const val = parseInt(inputValue, 10);

  

22.4 If for whatever reason you are doing something wild and parseInt is your bottleneck and need to use Bitshift for performance reasons, leave a comment explaining why and what you're doing.
// good
/**
 * parseInt was the reason my code was slow.
 * Bitshifting the String to coerce it to a
 * Number made it a lot faster.
 */
const val = inputValue >> 0;

  

22.5 Note: Be careful when using bitshift operations. Numbers are represented as 64-bit values, but bitshift operations always return a 32-bit integer (source). Bitshift can lead to unexpected behavior for integer values larger than 32 bits. Discussion. Largest signed 32-bit Int is 2,147,483,647:
2147483647 >> 0; // => 2147483647
2147483648 >> 0; // => -2147483648
2147483649 >> 0; // => -2147483647

  

22.6 Booleans:
const age = 0;

// bad
const hasAge = new Boolean(age);

// good
const hasAge = Boolean(age);

// best
const hasAge = !!age;

 ?back to top",3
https://github.com/envs/javascript,## Naming Conventions,"   

23.1 Avoid single letter names. Be descriptive with your naming. eslint: id-length
// bad
function q() {
  // ...
}

// good
function query() {
  // ...
}

  

23.2 Use camelCase when naming objects, functions, and instances. eslint: camelcase jscs: requireCamelCaseOrUpperCaseIdentifiers
// bad
const OBJEcttsssss = {};
const this_is_my_object = {};
function c() {}

// good
const thisIsMyObject = {};
function thisIsMyFunction() {}

  

23.3 Use PascalCase only when naming constructors or classes. eslint: new-cap jscs: requireCapitalizedConstructors
// bad
function user(options) {
  this.name = options.name;
}

const bad = new user({
  name: 'nope',
});

// good
class User {
  constructor(options) {
    this.name = options.name;
  }
}

const good = new User({
  name: 'yup',
});

  

23.4 Do not use trailing or leading underscores. eslint: no-underscore-dangle jscs: disallowDanglingUnderscores

Why? JavaScript does not have the concept of privacy in terms of properties or methods. Although a leading underscore is a common convention to mean “private? in fact, these properties are fully public, and as such, are part of your public API contract. This convention might lead developers to wrongly think that a change won't count as breaking, or that tests aren't needed. tl;dr: if you want something to be “private? it must not be observably present.

// bad
this.__firstName__ = 'Panda';
this.firstName_ = 'Panda';
this._firstName = 'Panda';

// good
this.firstName = 'Panda';

  

23.5 Don't save references to this. Use arrow functions or Function#bind. jscs: disallowNodeTypes
// bad
function foo() {
  const self = this;
  return function () {
    console.log(self);
  };
}

// bad
function foo() {
  const that = this;
  return function () {
    console.log(that);
  };
}

// good
function foo() {
  return () => {
    console.log(this);
  };
}

  

23.6 A base filename should exactly match the name of its default export.
// file 1 contents
class CheckBox {
  // ...
}
export default CheckBox;

// file 2 contents
export default function fortyTwo() { return 42; }

// file 3 contents
export default function insideDirectory() {}

// in some other file
// bad
import CheckBox from './checkBox'; // PascalCase import/export, camelCase filename
import FortyTwo from './FortyTwo'; // PascalCase import/filename, camelCase export
import InsideDirectory from './InsideDirectory'; // PascalCase import/filename, camelCase export

// bad
import CheckBox from './check_box'; // PascalCase import/export, snake_case filename
import forty_two from './forty_two'; // snake_case import/filename, camelCase export
import inside_directory from './inside_directory'; // snake_case import, camelCase export
import index from './inside_directory/index'; // requiring the index file explicitly
import insideDirectory from './insideDirectory/index'; // requiring the index file explicitly

// good
import CheckBox from './CheckBox'; // PascalCase export/import/filename
import fortyTwo from './fortyTwo'; // camelCase export/import/filename
import insideDirectory from './insideDirectory'; // camelCase export/import/directory name/implicit ""index""
// ^ supports both insideDirectory.js and insideDirectory/index.js

  

23.7 Use camelCase when you export-default a function. Your filename should be identical to your function's name.
function makeStyleGuide() {
  // ...
}

export default makeStyleGuide;

  

23.8 Use PascalCase when you export a constructor / class / singleton / function library / bare object.
const AirbnbStyleGuide = {
  es6: {
  },
};

export default AirbnbStyleGuide;

  

23.9 Acronyms and initialisms should always be all capitalized, or all lowercased.

Why? Names are for readability, not to appease a computer algorithm.

// bad
import SmsContainer from './containers/SmsContainer';

// bad
const HttpRequests = [
  // ...
];

// good
import SMSContainer from './containers/SMSContainer';

// good
const HTTPRequests = [
  // ...
];

// best
import TextMessageContainer from './containers/TextMessageContainer';

// best
const Requests = [
  // ...
];

 ?back to top",3
https://github.com/envs/javascript,## Accessors,"   
24.1 Accessor functions for properties are not required.
  

24.2 Do not use JavaScript getters/setters as they cause unexpected side effects and are harder to test, maintain, and reason about. Instead, if you do make accessor functions, use getVal() and setVal('hello').
// bad
class Dragon {
  get age() {
    // ...
  }

  set age(value) {
    // ...
  }
}

// good
class Dragon {
  getAge() {
    // ...
  }

  setAge(value) {
    // ...
  }
}

  

24.3 If the property/method is a boolean, use isVal() or hasVal().
// bad
if (!dragon.age()) {
  return false;
}

// good
if (!dragon.hasAge()) {
  return false;
}

  

24.4 It's okay to create get() and set() functions, but be consistent.
class Jedi {
  constructor(options = {}) {
    const lightsaber = options.lightsaber || 'blue';
    this.set('lightsaber', lightsaber);
  }

  set(key, val) {
    this[key] = val;
  }

  get(key) {
    return this[key];
  }
}

 ?back to top",3
https://github.com/envs/javascript,## Events,"   

25.1 When attaching data payloads to events (whether DOM events or something more proprietary like Backbone events), pass a hash instead of a raw value. This allows a subsequent contributor to add more data to the event payload without finding and updating every handler for the event. For example, instead of:
// bad
$(this).trigger('listingUpdated', listing.id);

// ...

$(this).on('listingUpdated', (e, listingId) => {
  // do something with listingId
});
prefer:
// good
$(this).trigger('listingUpdated', { listingId: listing.id });

// ...

$(this).on('listingUpdated', (e, data) => {
  // do something with data.listingId
});

 ?back to top",3
https://github.com/envs/javascript,## jQuery,"   

26.1 Prefix jQuery object variables with a $. jscs: requireDollarBeforejQueryAssignment
// bad
const sidebar = $('.sidebar');

// good
const $sidebar = $('.sidebar');

// good
const $sidebarBtn = $('.sidebar-btn');

  

26.2 Cache jQuery lookups.
// bad
function setSidebar() {
  $('.sidebar').hide();

  // ...

  $('.sidebar').css({
    'background-color': 'pink',
  });
}

// good
function setSidebar() {
  const $sidebar = $('.sidebar');
  $sidebar.hide();

  // ...

  $sidebar.css({
    'background-color': 'pink',
  });
}

  
26.3 For DOM queries use Cascading $('.sidebar ul') or parent > child $('.sidebar > ul'). jsPerf
  

26.4 Use find with scoped jQuery object queries.
// bad
$('ul', '.sidebar').hide();

// bad
$('.sidebar').find('ul').hide();

// good
$('.sidebar ul').hide();

// good
$('.sidebar > ul').hide();

// good
$sidebar.find('ul').hide();

 ?back to top",3
https://github.com/envs/javascript,## ECMAScript 5 Compatibility,"   
27.1 Refer to Kangax's ES5 compatibility table.
 ?back to top ",6
https://github.com/envs/javascript,## ECMAScript 6+ (ES 2015+) Styles,"   
28.1 This is a collection of links to the various ES6 features.
 
Arrow Functions
Classes
Object Shorthand
Object Concise
Object Computed Properties
Template Strings
Destructuring
Default Parameters
Rest
Array Spreads
Let and Const
Iterators and Generators
Modules
  

28.2 Do not use TC39 proposals that have not reached stage 3.

Why? They are not finalized, and they are subject to change or to be withdrawn entirely. We want to use JavaScript, and proposals are not JavaScript yet.


 ?back to top",6
https://github.com/envs/javascript,## Testing,"   

29.1 Yup.
function foo() {
  return true;
}

  
29.2 No, but seriously:
Whichever testing framework you use, you should be writing tests!
Strive to write many small pure functions, and minimize where mutations occur.
Be cautious about stubs and mocks - they can make your tests more brittle.
We primarily use mocha at Airbnb. tape is also used occasionally for small, separate modules.
100% test coverage is a good goal to strive for, even if it's not always practical to reach it.
Whenever you fix a bug, write a regression test. A bug fixed without a regression test is almost certainly going to break again in the future.
 ?back to top",3
https://github.com/envs/javascript,## Performance,"  
On Layout & Web Performance
String vs Array Concat
Try/Catch Cost In a Loop
Bang Function
jQuery Find vs Context, Selector
innerHTML vs textContent for script text
Long String Concatenation
Are Javascript functions like map(), reduce(), and filter() optimized for traversing arrays?
Loading...
 ?back to top",6
https://github.com/envs/javascript,## Resources,"  Learning ES6 
Draft ECMA 2015 (ES6) Spec
ExploringJS
ES6 Compatibility Table
Comprehensive Overview of ES6 Features
 Read This 
Standard ECMA-262
 Tools 
Code Style Linters

ESlint - Airbnb Style .eslintrc
JSHint - Airbnb Style .jshintrc
JSCS - Airbnb Style Preset (Deprecated, please use ESlint)


Neutrino preset - neutrino-preset-airbnb-base
 Other Style Guides 
Google JavaScript Style Guide
jQuery Core Style Guidelines
Principles of Writing Consistent, Idiomatic JavaScript
 Other Styles 
Naming this in nested functions - Christian Johansen
Conditional Callbacks - Ross Allen
Popular JavaScript Coding Conventions on GitHub - JeongHoon Byun
Multiple var statements in JavaScript, not superfluous - Ben Alman
 Further Reading 
Understanding JavaScript Closures - Angus Croll
Basic JavaScript for the impatient programmer - Dr. Axel Rauschmayer
You Might Not Need jQuery - Zack Bloom & Adam Schwartz
ES6 Features - Luke Hoban
Frontend Guidelines - Benjamin De Cock
 Books 
JavaScript: The Good Parts - Douglas Crockford
JavaScript Patterns - Stoyan Stefanov
Pro JavaScript Design Patterns  - Ross Harmes and Dustin Diaz
High Performance Web Sites: Essential Knowledge for Front-End Engineers - Steve Souders
Maintainable JavaScript - Nicholas C. Zakas
JavaScript Web Applications - Alex MacCaw
Pro JavaScript Techniques - John Resig
Smashing Node.js: JavaScript Everywhere - Guillermo Rauch
Secrets of the JavaScript Ninja - John Resig and Bear Bibeault
Human JavaScript - Henrik Joreteg
Superhero.js - Kim Joar Bekkelund, Mads Mobæk, & Olav Bjorkoy
JSBooks - Julien Bouquillon
Third Party JavaScript - Ben Vinegar and Anton Kovalyov
Effective JavaScript: 68 Specific Ways to Harness the Power of JavaScript - David Herman
Eloquent JavaScript - Marijn Haverbeke
You Don't Know JS: ES6 & Beyond - Kyle Simpson
 Blogs 
JavaScript Weekly
JavaScript, JavaScript...
Bocoup Weblog
Adequately Good
NCZOnline
Perfection Kills
Ben Alman
Dmitry Baranovskiy
Dustin Diaz
nettuts
 Podcasts 
JavaScript Air
JavaScript Jabber
 ?back to top",6
https://github.com/envs/javascript,## In the Wild,"  This is a list of organizations that are using this style guide. Send us a pull request and we'll add you to the list. 
3blades: 3Blades/javascript
4Catalyzer: 4Catalyzer/javascript
Aan Zee: AanZee/javascript
Adult Swim: adult-swim/javascript
Airbnb: airbnb/javascript
AltSchool: AltSchool/javascript
Apartmint: apartmint/javascript
Ascribe: ascribe/javascript
Avalara: avalara/javascript
Avant: avantcredit/javascript
Axept: axept/javascript
BashPros: BashPros/javascript
Billabong: billabong/javascript
Bisk: bisk/javascript
Bonhomme: bonhommeparis/javascript
Brainshark: brainshark/javascript
CaseNine: CaseNine/javascript
Chartboost: ChartBoost/javascript-style-guide
ComparaOnline: comparaonline/javascript
Compass Learning: compasslearning/javascript-style-guide
DailyMotion: dailymotion/javascript
DoSomething: DoSomething/eslint-config
Digitpaint digitpaint/javascript
Ecosia: ecosia/javascript
Evernote: evernote/javascript-style-guide
Evolution Gaming: evolution-gaming/javascript
EvozonJs: evozonjs/javascript
ExactTarget: ExactTarget/javascript
Expensify Expensify/Style-Guide
Flexberry: Flexberry/javascript-style-guide
Gawker Media: gawkermedia/javascript
General Electric: GeneralElectric/javascript
Generation Tux: GenerationTux/javascript
GoodData: gooddata/gdc-js-style
Grooveshark: grooveshark/javascript
Honey: honeyscience/javascript
How About We: howaboutwe/javascript
Huballin: huballin/javascript
HubSpot: HubSpot/javascript
Hyper: hyperoslo/javascript-playbook
InterCity Group: intercitygroup/javascript-style-guide
Jam3: Jam3/Javascript-Code-Conventions
JeopardyBot: kesne/jeopardy-bot
JSSolutions: JSSolutions/javascript
KickorStick: kickorstick/javascript
Kinetica Solutions: kinetica/javascript
Lonely Planet: lonelyplanet/javascript
M2GEN: M2GEN/javascript
Mighty Spring: mightyspring/javascript
MinnPost: MinnPost/javascript
MitocGroup: MitocGroup/javascript
ModCloth: modcloth/javascript
Money Advice Service: moneyadviceservice/javascript
Muber: muber/javascript
National Geographic: natgeo/javascript
Nimbl3: nimbl3/javascript
Nulogy: nulogy/javascript
Orange Hill Development: orangehill/javascript
Orion Health: orionhealth/javascript
OutBoxSoft: OutBoxSoft/javascript
Peerby: Peerby/javascript
Razorfish: razorfish/javascript-style-guide
reddit: reddit/styleguide/javascript
React: facebook.github.io/react/contributing/how-to-contribute.html#style-guide
REI: reidev/js-style-guide
Ripple: ripple/javascript-style-guide
SeekingAlpha: seekingalpha/javascript-style-guide
Shutterfly: shutterfly/javascript
Sourcetoad: sourcetoad/javascript
Springload: springload/javascript
StratoDem Analytics: stratodem/javascript
SteelKiwi Development: steelkiwi/javascript
StudentSphere: studentsphere/javascript
SwoopApp: swoopapp/javascript
SysGarage: sysgarage/javascript-style-guide
Syzygy Warsaw: syzygypl/javascript
Target: target/javascript
TheLadders: TheLadders/javascript
The Nerdery: thenerdery/javascript-standards
T4R Technology: T4R-Technology/javascript
VoxFeed: VoxFeed/javascript-style-guide
WeBox Studio: weboxstudio/javascript
Weggo: Weggo/javascript
Zillow: zillow/javascript
ZocDoc: ZocDoc/javascript
 ?back to top",6
https://github.com/envs/javascript,## Translation,"  This style guide is also available in other languages: 
 Brazilian Portuguese: armoucar/javascript-style-guide
 Bulgarian: borislavvv/javascript
 Catalan: fpmweb/javascript-style-guide
 Chinese (Simplified): sivan/javascript-style-guide
 Chinese (Traditional): jigsawye/javascript
 French: nmussy/javascript-style-guide
 German: timofurrer/javascript-style-guide
 Italian: sinkswim/javascript-style-guide
 Japanese: mitsuruog/javascript-style-guide
 Korean: tipjs/javascript-style-guide
 Polish: mjurczyk/javascript
 Russian: leonidlebedev/javascript-airbnb
 Spanish: paolocarrasco/javascript-style-guide
 Thai: lvarayut/javascript-style-guide
 Ukrainian: ivanzusko/javascript
 Vietnam: hngiang/javascript-style-guide
",6
https://github.com/envs/javascript,## The JavaScript Style Guide Guide,"  
Reference
",6
https://github.com/envs/javascript,## Chat With Us About JavaScript,"  
Find us on gitter.
",5
https://github.com/envs/javascript,## Contributors,"  
View Contributors
",5
https://github.com/envs/javascript,## License,"  (The MIT License) Copyright (c) 2014-2017 Airbnb Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
'Software'), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions: The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ?back to top",5
https://github.com/envs/javascript,## Amendments,"  We encourage you to fork this guide and change the rules to fit your team's style guide. Below, you may list some amendments to the style guide. This allows you to periodically update your style guide without having to deal with merge conflicts.",57
https://github.com/envs/javascript,# };, ,-
https://github.com/FleetCarma/embedC-Challenge,# embedC-Challenge," The following problem is a (heavily simplified) version of a feature implemented in our vehicle telematics devices. A vehicle telematics device needs to read a set of signals over a period of time and compile a ""trip event summary"". For an electric vehicle, this summary may include: 
Trip Start Time [seconds since unix epoch]
Trip Duration [seconds]
Trip Distance Travelled [meters]
Trip Total Energy Consumed [Watt-hours]
Trip Starting Battery State-of-Charge (SOC) Value [%]
Trip Ending Battery State-of-Charge (SOC) Value [%]
 Someone has already written the code to retrieve signals from the vehicle and make each one available as a vehicle_signal_t. This data structure contains the signal type, the time when the signal was received, and the signal value. typedef enum {
    VEHICLE_SIGNAL_TYPE_VEHICLE_SPEED,		// unsigned vehicle speed in kilometers per hour
    VEHICLE_SIGNAL_TYPE_HV_BATTERY_VOLTAGE,	// unsigned battery voltage in volts
    VEHICLE_SIGNAL_TYPE_HV_BATTERY_CURRENT,	// signed battery current in amps
    VEHICLE_SIGNAL_TYPE_HV_BATTERY_SOC		// unsigned battery state of charge in percent
}vehicle_signal_type_t;

typedef struct {
    vehicle_signal_type_t signal_type;
    uint64_t unix_timestamp_milliseconds;
    float value;
}vehicle_signal_t; Your job is to write a small code library, in C, to receive each signal and maintain the following trip event summary: typedef struct {
    uint32_t start_time_since_unix_epoch_seconds;
    uint32_t duration_seconds;
    uint32_t distance_travelled_meters;
    uint32_t total_energy_consumed_wh;
    float starting_soc;
    float ending_soc;
}trip_event_summary_t;",1
https://github.com/FleetCarma/embedC-Challenge,"# Specifically, you must:","  

Create a code library containing one or more functions that receive a vehicle_signal_t and update the appropriate fields of a trip_event_summary_t.

the start time is the time that the first signal of any type is received
the duration is the difference in time between the first signal (of any type) received and the last signal (of any type) received
the distance travelled is the numerical integration of the VEHICLE_SIGNAL_TYPE_VEHICLE_SPEED signal
the total energy consumed is the numerical integration of the product of VEHICLE_SIGNAL_TYPE_HV_BATTERY_VOLTAGE and VEHICLE_SIGNAL_TYPE_HV_BATTERY_CURRENT
the starting SOC is the first VEHICLE_SIGNAL_TYPE_HV_BATTERY_SOC signal received
the ending SOC is the last VEHICLE_SIGNAL_TYPE_HV_BATTERY_SOC signal received



Write (at least one) unit test that feeds your library a set of vehicle_signal_t and checks that the resulting trip_event_summary_t is correct.

The included CSV file contains data from one of our employee's vehicles. Use this data to generate a set of vehicle_signal_t for your unit test(s).
A good unit test asserts a result that was derived from an independent source. Document how you determined the ""correct value"" for each field in trip_event_summary_t.
Note that VEHICLE_SIGNAL_TYPE_HV_BATTERY_CURRENT is signed. An electric vehicle generally discharges the battery (positive current) when driving, but can also charge the battery via regenerative braking (negative current) during deceleration. The total energy to be computed is the NET POSITIVE energy drawn from the battery.


",3
https://github.com/FleetCarma/embedC-Challenge,# What you'll find to get started:,"  

Two (essentially empty) source files are found in the trip_calculator directory. Use them to use to implement your library.


A main.c exists for you to call your unit test(s). If you have a favourite C unit test library then by all means import it.


vehicle_signal_t.h can be included where knowledge of this data type is needed.


A CSV file with sample data should be used as the basis for your unit test(s).

",3
https://github.com/FleetCarma/embedC-Challenge,# Things to keep in mind:,"  

There isn't a lot of code to get you started. In fact, the included files are missing some important elements. Please demonstrate best practices when updating these files.


We don't care what integration method you choose to use.


Use comments to describe what your code does (and, more importantly, why).


Feel free to add more source files if you feel that they will benefit the project.


You may create new types and variables as needed to support your calculations. Try to keep your code library file(s) from containing any state, so that they are safe to use in a multi-threaded environment.


Although you will likely test your code in a desktop environment, it will ultimately execute in an embedded environment (a low-cost 32-bit micro-controller). Be aware of this when choosing the data types and mathematical operations for your calculations.

",3
https://github.com/fewd-sg/fewd-3-homework-week-2,#FEWD Week #2: Styling with CSS,,1
https://github.com/fewd-sg/fewd-3-homework-week-2,##,,-
https://github.com/fewd-sg/fewd-3-homework-week-2,###Description,"A hot, new NY Tech Startup, Relaxr, has approached you to help them develop a new landing page for their company. They've handed you the design file for the site, along with the copy and assets. You need to take these files and turn it into a landing page.",1
https://github.com/fewd-sg/fewd-3-homework-week-2,##,,-
https://github.com/fewd-sg/fewd-3-homework-week-2,###Real-World Applications,"Build a website from a design file
Integrate advanced CSS properties
Use HTML5 structural elements
Use CSS Resets to ""normalize"" the rendering of your page across different browsers
Use the Box Model to style element borders and structure your page",1
https://github.com/fewd-sg/fewd-3-homework-week-2,##,,-
https://github.com/fewd-sg/fewd-3-homework-week-2,###Technical Requirements,"Use HTML5 structural elements (nav, header, footer)
Use a CSS Reset file in addition to your style.css file to style the page
Use IDs and Classes to to select and style elements on the page
Style your text with the Google Fonts provided by your style guide
Follow naming conventions, maintain consistency across .html and .css files and use best practices for naming IDs and Classes
Indent nested elements to increase your code's readability",3
https://github.com/fewd-sg/fewd-3-homework-week-2,##,,-
https://github.com/fewd-sg/fewd-3-homework-week-2,###Resources,"Starter code can be found inside of the ""starter_code"" folder for this assignment.
Box Model explanation from Mozilla
Box Model Breakdown
CSS Tricks difference between IDs and Classes
What is a CSS Reset?
Relaxr's design file",6
https://github.com/CASunday2003/jquery,# [jQuery](https://jquery.com/) ?New Wave JavaScript,,1
https://github.com/CASunday2003/jquery,## Contribution Guides,"  In the spirit of open source software development, jQuery always encourages community code contribution. To help you get started and before you jump into writing code, be sure to read these important contribution guidelines thoroughly: 
Getting Involved
Core Style Guide
Writing Code for jQuery Foundation Projects
",7
https://github.com/CASunday2003/jquery,## Environments in which to use jQuery,"  
Browser support
jQuery also supports Node, browser extensions, and other non-browser environments.
",3
https://github.com/CASunday2003/jquery,## What you need to build your own jQuery,"  In order to build jQuery, you need to have the latest Node.js/npm and git 1.7 or later. Earlier versions might work, but are not supported. For Windows, you have to download and install git and Node.js. OS X users should install Homebrew. Once Homebrew is installed, run brew install git to install git,
and brew install node to install Node.js. Linux/BSD users should use their appropriate package managers to install git and Node.js, or build from source
if you swing that way. Easy-peasy.",3
https://github.com/CASunday2003/jquery,## How to build your own jQuery,"  Clone a copy of the main jQuery git repo by running: git clone git://github.com/jquery/jquery.git Enter the jquery directory and run the build script: cd jquery && npm run build The built version of jQuery will be put in the dist/ subdirectory, along with the minified copy and associated map file. If you want to create custom build or help with jQuery development, it would be better to install grunt command line interface as a global package: npm install -g grunt-cli
 Make sure you have grunt installed by testing: grunt -V
 Now by running the grunt command, in the jquery directory, you can build a full version of jQuery, just like with an npm run build command: grunt
 There are many other tasks available for jQuery Core: grunt -help
",3
https://github.com/CASunday2003/jquery,### Modules,"  Special builds can be created that exclude subsets of jQuery functionality.
This allows for smaller custom builds when the builder is certain that those parts of jQuery are not being used.
For example, an app that only used JSONP for $.ajax() and did not need to calculate offsets or positions of elements could exclude the offset and ajax/xhr modules. Any module may be excluded except for core, and selector. To exclude a module, pass its path relative to the src folder (without the .js extension). Some example modules that can be excluded are: 
ajax: All AJAX functionality: $.ajax(), $.get(), $.post(), $.ajaxSetup(), .load(), transports, and ajax event shorthands such as .ajaxStart().
ajax/xhr: The XMLHTTPRequest AJAX transport only.
ajax/script: The <script> AJAX transport only; used to retrieve scripts.
ajax/jsonp: The JSONP AJAX transport only; depends on the ajax/script transport.
css: The .css() method. Also removes all modules depending on css (including effects, dimensions, and offset).
css/showHide:  Non-animated .show(), .hide() and .toggle(); can be excluded if you use classes or explicit .css() calls to set the display property. Also removes the effects module.
deprecated: Methods documented as deprecated but not yet removed.
dimensions: The .width() and .height() methods, including inner- and outer- variations.
effects: The .animate() method and its shorthands such as .slideUp() or .hide(""slow"").
event: The .on() and .off() methods and all event functionality. Also removes event/alias.
event/alias: All event attaching/triggering shorthands like .click() or .mouseover().
event/focusin: Cross-browser support for the focusin and focusout events.
event/trigger: The .trigger() and .triggerHandler() methods. Used by alias and focusin modules.
offset: The .offset(), .position(), .offsetParent(), .scrollLeft(), and .scrollTop() methods.
wrap: The .wrap(), .wrapAll(), .wrapInner(), and .unwrap() methods.
core/ready: Exclude the ready module if you place your scripts at the end of the body. Any ready callbacks bound with jQuery() will simply be called immediately. However, jQuery(document).ready() will not be a function and .on(""ready"", ...) or similar will not be triggered.
deferred: Exclude jQuery.Deferred. This also removes jQuery.Callbacks. Note that modules that depend on jQuery.Deferred(AJAX, effects, core/ready) will not be removed and will still expect jQuery.Deferred to be there. Include your own jQuery.Deferred implementation or exclude those modules as well (grunt custom:-deferred,-ajax,-effects,-core/ready).
exports/global: Exclude the attachment of global jQuery variables ($ and jQuery) to the window.
exports/amd: Exclude the AMD definition.
 As a special case, you may also replace Sizzle by using a special flag grunt custom:-sizzle. 
sizzle: The Sizzle selector engine. When this module is excluded, it is replaced by a rudimentary selector engine based on the browser's querySelectorAll method that does not support jQuery selector extensions or enhanced semantics. See the selector-native.js file for details.
 Note: Excluding Sizzle will also exclude all jQuery selector extensions (such as effects/animatedSelector and css/hiddenVisibleSelectors). The build process shows a message for each dependent module it excludes or includes.",3
https://github.com/CASunday2003/jquery,##### AMD name,"  As an option, you can set the module name for jQuery's AMD definition. By default, it is set to ""jquery"", which plays nicely with plugins and third-party libraries, but there may be cases where you'd like to change this. Simply set the ""amd"" option: grunt custom --amd=""custom-name"" Or, to define anonymously, set the name to an empty string. grunt custom --amd=""""",3
https://github.com/CASunday2003/jquery,#### Custom Build Examples,"  To create a custom build, first check out the version: git pull; git checkout VERSION Where VERSION is the version you want to customize. Then, make sure all Node dependencies are installed: npm install Create the custom build using the grunt custom option, listing the modules to be excluded. Exclude all ajax functionality: grunt custom:-ajax Excluding css removes modules depending on CSS: effects, offset, dimensions. grunt custom:-css Exclude a bunch of modules: grunt custom:-ajax,-css,-deprecated,-dimensions,-effects,-event/alias,-offset,-wrap For questions or requests regarding custom builds, please start a thread on the Developing jQuery Core section of the forum. Due to the combinatorics and custom nature of these builds, they are not regularly tested in jQuery's unit test process. The non-Sizzle selector engine currently does not pass unit tests because it is missing too much essential functionality.",3
https://github.com/CASunday2003/jquery,## Running the Unit Tests,"  Make sure you have the necessary dependencies: npm install Start grunt watch or npm start to auto-build jQuery as you work: grunt watch Run the unit tests with a local server that supports PHP. Ensure that you run the site from the root directory, not the ""test"" directory. No database is required. Pre-configured php local servers are available for Windows and Mac. Here are some options: 
Windows: WAMP download
Mac: MAMP download
Linux: Setting up LAMP
Mongoose (most platforms)
",3
https://github.com/CASunday2003/jquery,## Building to a different directory,"  To copy the built jQuery files from /dist to another directory: grunt && grunt dist:/path/to/special/location/ With this example, the output files would be: /path/to/special/location/jquery.js
/path/to/special/location/jquery.min.js To add a permanent copy destination, create a file in dist/ called "".destination.json"". Inside the file, paste and customize the following: {
  ""/Absolute/path/to/other/destination"": true
} Additionally, both methods can be combined.",3
https://github.com/CASunday2003/jquery,## Essential Git,"  As the source code is handled by the Git version control system, it's useful to know some features used.",3
https://github.com/CASunday2003/jquery,### Cleaning ###,"  If you want to purge your working directory back to the status of upstream, the following commands can be used (remember everything you've worked on is gone after these): git reset --hard upstream/master
git clean -fdx",3
https://github.com/CASunday2003/jquery,### Rebasing ###,"  For feature/topic branches, you should always use the --rebase flag to git pull, or if you are usually handling many temporary ""to be in a github pull request"" branches, run the following to automate this: git config branch.autosetuprebase local (see man git-config for more information)",3
https://github.com/CASunday2003/jquery,### Handling merge conflicts ###,"  If you're getting merge conflicts when merging, instead of editing the conflicted files manually, you can use the feature
git mergetool. Even though the default tool xxdiff looks awful/old, it's rather useful. The following are some commands that can be used there: 
Ctrl + Alt + M - automerge as much as possible
b - jump to next merge conflict
s - change the order of the conflicted lines
u - undo a merge
left mouse button - mark a block to be the winner
middle mouse button - mark a line to be the winner
Ctrl + S - save
Ctrl + Q - quit
",3
https://github.com/CASunday2003/jquery,## [QUnit](https://api.qunitjs.com) Reference, ,6
https://github.com/CASunday2003/jquery,### Test methods ###,"  expect( numAssertions );
stop();
start(); Note: QUnit's eventual addition of an argument to stop/start is ignored in this test suite so that start and stop can be passed as callbacks without worrying about their parameters.",3
https://github.com/CASunday2003/jquery,### Test assertions ###,"  ok( value, [message] );
equal( actual, expected, [message] );
notEqual( actual, expected, [message] );
deepEqual( actual, expected, [message] );
notDeepEqual( actual, expected, [message] );
strictEqual( actual, expected, [message] );
notStrictEqual( actual, expected, [message] );
throws( block, [expected], [message] );",3
https://github.com/CASunday2003/jquery,## Test Suite Convenience Methods Reference (See [test/data/testinit.js](https://github.com/jquery/jquery/blob/master/test/data/testinit.js)), ,36
https://github.com/CASunday2003/jquery,### Returns an array of elements with the given IDs ###,"  q( ... ); Example: q(""main"", ""foo"", ""bar"");

=> [ div#main, span#foo, input#bar ]",36
https://github.com/CASunday2003/jquery,### Asserts that a selection matches the given IDs ###,"  t( testName, selector, [ ""array"", ""of"", ""ids"" ] ); Example: t(""Check for something"", ""//[a]"", [""foo"", ""bar""]);",36
https://github.com/CASunday2003/jquery,### Fires a native DOM event without going through jQuery ###,"  fireNative( node, eventType ) Example: fireNative( jQuery(""#elem"")[0], ""click"" );",36
https://github.com/CASunday2003/jquery,### Add random number to url to stop caching ###,"  url( ""some/url.php"" ); Example: url(""data/test.html"");

=> ""data/test.html?10538358428943""


url(""data/test.php?foo=bar"");

=> ""data/test.php?foo=bar&10538358345554""",36
https://github.com/CASunday2003/jquery,### Run tests in an iframe ###,"  Some tests may require a document other than the standard test fixture, and
these can be run in a separate iframe. The actual test code and assertions
remain in jQuery's main test files; only the minimal test fixture markup
and setup code should be placed in the iframe file. testIframe( testName, fileName,
  function testCallback(
      assert, jQuery, window, document,
	  [ additional args ] ) {
	...
  } ); This loads a page, constructing a url with fileName ""./data/"" + fileName.
The iframed page determines when the callback occurs in the test by
including the ""/test/data/iframeTest.js"" script and calling
startIframeTest( [ additional args ] ) when appropriate. Often this
will be after either document ready or window.onload fires. The testCallback receives the QUnit assert object created by testIframe
for this test, followed by the global jQuery, window, and document from
the iframe. If the iframe code passes any arguments to startIframeTest,
they follow the document argument.",36
https://github.com/CASunday2003/jquery,## Questions?,"  If you have any questions, please feel free to ask on the
Developing jQuery Core forum or in #jquery on irc.freenode.net.",56
https://github.com/ibarrick/web-animations-js,## What is Web Animations?," A new JavaScript API for driving animated content on the web. By unifying
the animation features of SVG and CSS, Web Animations unlocks features
previously only usable declaratively, and exposes powerful, high-performance
animation capabilities to developers.",12
https://github.com/ibarrick/web-animations-js,## What is in this repository?,"  A JavaScript implementation of the Web Animations API that provides Web
Animation features in browsers that do not support it natively. The polyfill
falls back to the native implementation when one is available.",1
https://github.com/ibarrick/web-animations-js,## Quick start,"  Here's a simple example of an animation that fades and scales a <div>.
Try it as a live demo. <!-- Include the polyfill -->
<script src=""web-animations.min.js""></script>

<!-- Set up a target to animate -->
<div class=""pulse"" style=""width: 150px;"">Hello world!</div>

<!-- Animate! -->
<script>
    var elem = document.querySelector('.pulse');
    var animation = elem.animate({
        opacity: [0.5, 1],
        transform: ['scale(0.5)', 'scale(1)'],
    }, {
        direction: 'alternate',
        duration: 500,
        iterations: Infinity,
    });
</script>",3
https://github.com/ibarrick/web-animations-js,## Documentation,"  
Codelab tutorial
Examples of usage
Live demos
MDN reference
W3C specification
",6
https://github.com/ibarrick/web-animations-js,## We love feedback!,"  

For feedback on the API and the specification:

File an issue on GitHub: https://github.com/w3c/web-animations/issues/new
Alternatively, send an email to public-fx@w3.org with subject line
""[web-animations] ... message topic ...""
(archives).



For issues with the polyfill, report them on GitHub:
https://github.com/web-animations/web-animations-js/issues/new.

",5
https://github.com/ibarrick/web-animations-js,## Keep up-to-date,"  Breaking polyfill changes will be announced on this low-volume mailing list:
web-animations-changes@googlegroups.com.",5
https://github.com/ibarrick/web-animations-js,## More info,"  
Technical details about the polyfill

Browser support
Fallback to native
Feature list
Feature deprecation and removal processes


To test experimental API features, try one of the
experimental targets
",6
https://github.com/abricot/foxmote,# Foxmote," Yet another XBMC remote for firefox os,
built using AngularJS, Node and Grunt. ",1
https://github.com/abricot/foxmote,## Purpose,"  Foxmote is an XBMC remote that let you control XBMC with your firefox os phone. It is powered with some of the most trendy, popular frameworks around.",12
https://github.com/abricot/foxmote,## Stack,"  
AngularJS power the application
Beautiful styles using LESS css and Font-Awesome
",1
https://github.com/abricot/foxmote,### Build,"  Build system focused on AngularJS apps and tightly integrated with other tools commonly used in the AngularJS community: 
powered by Grunt.js
build supporting JS, CSS and AngularJS templates minification
",1
https://github.com/abricot/foxmote,## Installation, ,3
https://github.com/abricot/foxmote,### Platform & tools,"  You need to install Node.js and then the development tools. Node.js comes with a package manager called npm for installing NodeJS applications and libraries. 

Install node.js (requires node.js version >= 0.8.4)


Install Grunt-CLI as global npm modules:
npm install -g grunt-cli


",3
https://github.com/abricot/foxmote,### Application Server,"  When testing with your browser (Chrome, Firefox) you will need to use our backend application server (using nodejs).  Please follow the below steps : 

Install local dependencies:
cd server
npm install
cd ..


",3
https://github.com/abricot/foxmote,### Client Application,"  Our client application is a straight HTML/Javascript application but our development process uses a Node.js build tool
Grunt.js and Bower to retrieve 3rd party dependencies. Grunt relies upon some 3rd party libraries that we need to install as local dependencies using npm. 

Install local dependencies:
cd client
npm install
cd ..


",3
https://github.com/abricot/foxmote,## Building,"  The application made up of a number of javascript, css and html files that need to be merged into a final distribution for running.  We use the Grunt build tool to do this.
Build client application with: ```
cd client
grunt build
```
 Note : It is important to build again if you change files in under client directory.
You can avoid this painful process by using continuous building see dedicated section.",3
https://github.com/abricot/foxmote,## Running, ,3
https://github.com/abricot/foxmote,### Start the Server,"  Run the server with : ```
cd server
node server.js
```
 Your browser should automatically open at the following URL [http://localhost:8082] letting you use the application. Of course you can manually navigate to this URL at any time.*",3
https://github.com/abricot/foxmote,## Development, ,3
https://github.com/abricot/foxmote,### Folders structure,"  At the top level, the repository is split into a client folder and a server folder.  The client folder contains all the client-side AngularJS application.  The server folder contains a very basic webserver that delivers and supports the application while using a desktop browse (not needed when app is added to the firefox os emulator).
Within the client folder you have the following structure: 
dist contains build results
src contains application's sources
vendor contains external dependencies for the application
",3
https://github.com/abricot/foxmote,### Default Build,"  The default grunt task will build the application. ```
cd client
grunt
```
",3
https://github.com/abricot/foxmote,### Continuous Building,"  The watch grunt task will monitor the source files and run the default build task every time a file changes. ```
cd client
grunt watch
```
",3
https://github.com/abricot/foxmote,"### Building release code, aka create a zip file ready for firefox os marketplace upload","  You can build a zipped release version of the app, with minified files using a dedicated grunt task. ```
cd client
grunt marketplace
```
",3
https://github.com/abricot/foxmote,### Using Firefox OS Simulator,"  Once application is build you can add it to firefox os simulator. To do so : 
Be sure firefox os simulator is installed. Instruction here
Open firefox and navigate to Firefox > Web Developer >  Firefox os Simulator
On the Firefox os Simulator page click on add directory
Navigate to the dist folder under client directory
Select manifest.webapp
Emulator should start and application run
",3
https://github.com/HugoTamaki/flisol-api,# Simple node server, This is a simple implementation of a node server for who is starting to learn Angular JS and needs API comsumption. To use this server:,1
https://github.com/HugoTamaki/flisol-api,### First install the dependencies,"  
Run npm install. It will create a node_modules folder with express, bodyparser and mongoose
",3
https://github.com/HugoTamaki/flisol-api,### Install Mongodb,"  If you don't have mongodb installed, you will need it to save data. To install: 
http://docs.mongodb.org/manual/installation/
 Once installed, create a database called flisol-dogs, or call it what you want (don't forget to change it on server.js)
Run the server with mongod and be sure that the server port and address is the same on server.js",3
https://github.com/HugoTamaki/flisol-api,## Create a user,"  Add a user with bcrypted password. To get a hashed password, run: var bcrypt = require('bcrypt')
bcrypt.hash('teste123', 10, function(err, hash){ console.log(hash) })
 then at mongo console, run select the db with use flisol-dogs and then: db.users.insert({email: 'teste@email.com', password: <hashed_password_here>});
",3
https://github.com/HugoTamaki/flisol-api,### To make the requisitions,"  You can use Postman, or any other way. I like to test it with HTTParty (ruby gem).
You can make requisitions in this way. Post: HTTParty.post('http://localhost:8080/api/contatos', :body => {name: 'Robson', phone: '8888-9999', operator: {name: 'Oi', code: '21', category: 'Celular'}, date: DateTime.now}.to_json, :headers => {'content-type' => 'application/json'}) Get: HTTParty.get('http://localhost:8080/api/contatos/557cad4954d5940710000001') Put: HTTParty.put('http://localhost:8080/api/contatos/557cad4954d5940710000001', :body => {name: 'Robson', phone: '8888-9999', operator: {name: 'Claro', code: '15', category: 'Celular'}, date: DateTime.now}.to_json, :headers => {'content-type' => 'application/json'}) Delete: HTTParty.delete.('http://localhost:8080/api/contatos/557cad4954d5940710000001')",3
https://github.com/HugoTamaki/flisol-api,### Create new models,"  Just create new models at /models folder, don't forget to call it on server js like this var Dog = require('./models/dog'); and don't forget to add the new routes. Now run it and be happy :)",3
https://github.com/crh19970307/android-training-course-in-chinese,# Android官方培训课程中文?v0.9.5),  Google Android团队?012年的时候开设了Android Training板块 - http://developer.android.com/training/index.html，这些课程是学习Android应用开发的绝佳资料。我们通过Github发起开源协作翻译的项目，完成中文版的输出，欢迎大家传阅学习?文章中难免会有很多写的不对不好的地方，欢迎读者加入此协作项目，进行纠错，为完善这份教程贡献一点力?,-
https://github.com/crh19970307/android-training-course-in-chinese,## Github托管主页,  https://github.com/kesenhoo/android-training-course-in-chinese 请读者点击Star进行关注并支持！,-
https://github.com/crh19970307/android-training-course-in-chinese,## 在线阅读,  http://hukai.me/android-training-course-in-chinese/index.html,-
https://github.com/crh19970307/android-training-course-in-chinese,### 更新记录,"  
v0.9.5 - 2015/12/15
v0.9.4 - 2015/06/11
v0.9.3 - 2015/05/18
v0.9.2 - 2015/03/30
v0.9.1 - 2015/03/14
v0.9.0 - 2015/03/09
v0.8.0 - 2015/02/12
v0.7.0 - 2014/11/30
v0.6.0 - 2014/11/02
v0.5.0 - 2014/10/18
v0.4.0 - 2014/09/11
v0.3.0 - 2014/08/31
v0.2.0 - 2014/08/14
v0.1.0 - 2014/08/05
",-
https://github.com/crh19970307/android-training-course-in-chinese,## 参与方式,"  你可以选择以下的方式帮忙修改纠正这份教程（推荐使用方法1）： 
通过在线阅读课程的页面，找到Github仓库对应的章节文件，直接在线编辑修改提交即可?在线阅读的文章底部留言，提出问题与修改意见，我们会及时处理?写邮件给发起人：胡凯，邮箱是kesenhoo at gmail.com，邮件内容注明需要纠正的章节段落位置，并给出纠正的建议? 你也可以选择加入QQ群和学习Training课程的小伙伴一起讨论交流： 
Android Training基础群，适合刚接触Android Training课程的同学?
基础?1)?63415744，已?基础?2)?99077455，已?基础?3)?58929573


Android Training进阶群：适合实际Android开发经?-3年的同学?
进阶?1)?14115939，已?进阶?2)?86059229


Android Training高级群：399096506，理论上Android开发经验至?年以上，部分能力突出的也可以申请，请在申请入群的时候填写能力举?例如，XXX公司Android高级开?个人博客/Github账号等等)，未填写的不予通过，谢谢配合！
",-
https://github.com/crh19970307/android-training-course-in-chinese,## 课程结构,"  
序言
Android入门基础：从这里开?
建立你的第一个App - @yuanfentiank789
添加ActionBar - @vincent4j
兼容不同的设?- @Lin-H
管理Activity的生命周?- @kesenhoo
使用Fragment建立动态的UI - @fastcome1985
数据保存 - @kesenhoo
与其他应用的交互 - @kesenhoo


Android分享操作

分享简单的数据 - @kesenhoo
分享文件 - @jdneo
使用NFC分享文件 - @jdneo


Android多媒?
管理音频播放 - @kesenhoo
拍照 - @kesenhoo
打印 - @jdneo


Android图像与动?
高效显示Bitmap - @kesenhoo
使用OpenGL ES显示图像 - @jdneo
添加动画 - @XizhiXu


Android网络连接与云服务

无线连接设备 - @naizhengtan
网络连接操作 - @kesenhoo
传输数据时避免消耗大量电?- @kesenhoo
使用Sync Adapter传输数据 - @jdneo
使用Volley执行网络数据传输 - @kesenhoo
云同?- @kesenhoo，@jdneo
解决云同步的保存冲突 - @jdneo


Android联系人与位置信息

Android联系人信?- @spencer198711
Android位置信息 - @penkzhou


Android可穿戴应?
赋予Notification可穿戴的特?- @wangyachen
创建可穿戴的应用 - @kesenhoo
创建自定义的UI - @Roya
发送并同步数据 - @wly2014
创建表盘 - @heray1990
位置检?- @heray1990


Android企业级应?
Ensuring Compatibility with Managed Profiles - @2015/03/14 - 待认?Implementing App Restrictions - @2015/03/14 - 待认?Building a Work Policy Controller - @2015/03/14 - 待认?

Android TV应用

创建TV应用 - @awong1900
创建TV播放应用 - @huanglizhuo
帮助用户在TV上探索内?- @awong1900
创建TV游戏应用 - @dupengwei
创建TV直播应用 - @dupengwei
TV应用清单 - @awong1900


Android交互设计

设计高效的导?- @XizhiXu
实现高效的导?- @Lin-H
通知提示用户 - @fastcome1985
增加搜索功能 - @Lin-H
使得你的App内容可被Google搜索 - @Lin-H


Android界面设计

为多屏幕设计 - @riverfeng
创建自定义View - @kesenhoo
创建向后兼容的UI - @spencer198711
实现辅助功能 - @K0ST
管理系统UI - @K0ST
创建Material Design的应?- @allenlsy


Android用户输入

使用触摸手势 - @Andrwyw
处理键盘输入 - @zhaochunqi
支持游戏控制?- @heray1990


Android后台任务

在IntentService中执行后台任?- @kesenhoo
在后台加载数?- @kesenhoo
管理设备的唤醒状?- @jdneo,@lltowq


Android性能优化

管理应用的内?- @kesenhoo
性能优化Tips - @kesenhoo
提升Layout的性能 - @allenlsy
优化电池寿命 - @kesenhoo
多线程操?- @AllenZheng1991
避免程序无响应ANR - @kesenhoo
JNI Tips - @pedant
优化多核处理?SMP)下的Android程序 - @kesenhoo - 20%


Android安全与隐?
Security Tips - @craftsmanBai
使用HTTPS与SSL - @craftsmanBai


Android测试程序

测试你的Activity - @huanglizhuo


",-
https://github.com/crh19970307/android-training-course-in-chinese,## 致谢,"  发起这个项目之后，得到很多人的支持，有经验丰富的Android开发者，也有刚接触Android的爱好者。他们有些已经上班，有些还是学生，有些在国内，还有的在国外！感谢所有参与或者关注这个项目的小伙? 下面是参与翻译的小伙?Github ID按照课程结构排序)?


0
1
2




@yuanfentiank789
@vincent4j
@Lin-H


@kesenhoo
@fastcome1985
@jdneo


@XizhiXu
@naizhengtan
@spencer198711


@penkzhou
@wangyachen
@wly2014


@fastcome1985
@riverfeng
@xrayzh


@K0ST
@Andrwyw
@zhaochunqi


@lltowq
@allenlsy
@AllenZheng1991


@pedant
@craftsmanBai
@huanglizhuo


@Roya
@awong1900
@dupengwei


0:10
1:10
2:10


 @发起?胡凯，博客：http://hukai.me，Github：https://github.com/kesenhoo，微博：http://weibo.com/kesenhoo 还有众多参与纠错校正的同学名字就不一一列举了，谢谢所有关注这个项目的小伙伴！特别感谢安卓巴士社区，爱开发社区，码农周刊对项目的宣传?,-
3175,https://github.com/crh19970307/android-training-course-in-chinese,License,  本站作品由https://github.com/kesenhoo/android-training-course-in-chinese创作，采用知识共?署名-非商业性使?相同方式共享 4.0 国际 许可协议进行许可?-
3176,https://github.com/vanloswang/cpprestsdk,Welcome!, The C++ REST SDK is a Microsoft project for cloud-based client-server communication in native code using a modern asynchronous C++ API design. This project aims to help C++ developers connect to and interact with services.,1
3177,https://github.com/vanloswang/cpprestsdk,Getting Started,  Are you new to the C++ Rest SDK? To get going we recommend you start by taking a look at our tutorial to use the http_client. It walks through how to setup a project to use the C++ Rest SDK and make a basic Http request. Other important information",-
https://github.com/crh19970307/android-training-course-in-chinese,## License,"  
Features - HTTP client/server, JSON, URI, asynchronous streams, WebSockets client, oAuth
PPL Tasks - A powerful model for composing asynchronous operations based on C++ 11 features
Platforms - Windows desktop, Windows Store, Windows Phone, Ubuntu, OS X, iOS, and Android
Support for Visual Studio 2012, 2013, and 2015 with debugger visualizers
NuGet package with binaries for Windows and Android platforms
",-
https://github.com/vanloswang/cpprestsdk,## Welcome!,The C++ REST SDK is a Microsoft project for cloud-based client-server communication in native code using a modern asynchronous C++ API design. This project aims to help C++ developers connect to and interact with services.,1
https://github.com/vanloswang/cpprestsdk,## Getting Started,"Are you new to the C++ Rest SDK? To get going we recommend you start by taking a look at our tutorial to use the http_client. It walks through how to setup a project to use the C++ Rest SDK and make a basic Http request. Other important information, like how to build the C++ Rest SDK from source, can be located on the documentation page.",36
https://github.com/vanloswang/cpprestsdk,## What's in the SDK:,"Features - HTTP client/server, JSON, URI, asynchronous streams, WebSockets client, oAuth
PPL Tasks - A powerful model for composing asynchronous operations based on C++ 11 features
Platforms - Windows desktop, Windows Store, Windows Phone, Ubuntu, OS X, iOS, and Android
Support for Visual Studio 2012, 2013, and 2015 with debugger visualizers
NuGet package with binaries for Windows and Android platforms",1
https://github.com/vanloswang/cpprestsdk,## Contribute Back!,"  Is there a feature missing that you'd like to see, or found a bug that you have a fix for? Or do you have an idea or just interest in helping out in building the library? Let us know and we'd love to work with you. For a good starting point on where we are headed and feature ideas, take a look at our requested features and bugs. Big or small we'd like to take your contributions back to help improve the C++ Rest SDK for everyone. If interested contact us askcasablanca at Microsoft dot com.",7
https://github.com/vanloswang/cpprestsdk,## Having Trouble?,"  We'd love to get your review score, whether good or bad, but even more than that, we want to fix your problem. If you submit your issue as a Review, we won't be able to respond to your problem and ask any follow-up questions that may be necessary. The most efficient way to do that is to open a an issue in our issue tracker.",6
https://github.com/vanloswang/cpprestsdk,### Quick Links,"  
FAQ
Documentation
Issue Tracker
Directly contact us: askcasablanca@microsoft.com
",6
https://github.com/Fu2k/Seccubus_v2,# Seccubus V2 Read Me," Seccubus automates regular vulnerability scans with vrious tools and aids
security people in the fast analysis of its output, both on the first scan and
on repeated scans. On repeated scan delta reporting ensures that findings only need to be judged
when they first appear in the scan results or when their output changes. Seccubus 2.x is the only actively developed and maintained branch and all support
for Seccubus V1 has officially been dropped. Seccubus V2 works with the following scanners: 
Nessus 4.x and 5.x (professional and home feed)
Skipfish
OpenVAS
Medusa (local and remote)
Nikto (local and remote)
NMap (local and remote)
SSLyze
Medusa
Burp Suite
Qualys SSL labs
 For more information visit [www.seccubus.com] ",14
https://github.com/Fu2k/Seccubus_v2,##, ,-
https://github.com/Fu2k/Seccubus_v2,# Release notes,,4
https://github.com/Fu2k/Seccubus_v2,# 24-02-2015 - 2.14 - SSL labs API,  The SSL labs scanner now uses the SSL labs API (see https://github.com/ssllabs/ssllabs-scan/blob/master/ssllabs-api-docs.md) to check the SSL configuration of your website in stead of scraping the site.,4
https://github.com/Fu2k/Seccubus_v2,# Bug Fixes,"  
No additional bugfixes
",4
https://github.com/EgoistTheBest/monodroid-samples,# MonoDroid Samples,,1
https://github.com/EgoistTheBest/monodroid-samples,## License," This repository contains Mono for Android samples, showing usage of various
Android API wrappers from C#.",5
https://github.com/EgoistTheBest/monodroid-samples,## Contributing,"  The Apache License 2.0 applies to all samples in this repository. Copyright 2011 Xamarin Inc Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.",7
https://github.com/EgoistTheBest/monodroid-samples,# Samples Submission Guidelines,"  Before adding a sample to the repository, please run either install-hook.bat
or install-hook.sh depending on whether you're on Windows or a POSIX system.
This will install a Git hook that runs the Xamarin code sample validator before
a commit, to ensure that all samples are good to go.",3
https://github.com/EgoistTheBest/monodroid-samples,## Galleries,"  We love samples! Application samples show off our platform and provide a great way for people to learn our stuff. And we even promote them as a first-class feature of the docs site. You can find our two sample galleries here: 

Xamarin Forms Samples


iOS Samples


Mac Samples


Android Samples

",6
https://github.com/EgoistTheBest/monodroid-samples,## Sample GitHub Repositories,"  These sample galleries are populated by samples in our six sample GitHub repos: 

https://github.com/xamarin/xamarin-forms-samples


https://github.com/xamarin/mobile-samples


https://github.com/xamarin/monotouch-samples


https://github.com/xamarin/mac-samples


https://github.com/xamarin/monodroid-samples


https://github.com/xamarin/mac-ios-samples

 The mobile-samples repository is for samples that are cross-platform.
The mac-ios-samples repository is for samples that are Mac/iOS only.",6
https://github.com/EgoistTheBest/monodroid-samples,## Sample Requirements,"  We welcome sample submissions. Please ping Nat or Miguel for repo commit access. However, because the sample galleries are powered by the github sample repos, each sample needs to have the following things: 

Screenshots - a folder called Screenshots that has at least one screen shot of the sample (preferably a screen shot for every page or every major functionality piece, people really key off these things). for the xplat samples, the folder should be split into platform folders, e.g. iOS, Android, Windows. see https://github.com/xamarin/mobile-samples/tree/master/Tasky/Screenshots for an example of this.


Readme - a README.md file that has the name of the sample, a description, and author attribution. sample here: https://github.com/xamarin/mobile-samples/blob/master/Tasky/README.md


Metadata - Finally, it needs a Metadata.xml file (https://github.com/xamarin/mobile-samples/blob/master/Tasky/Metadata.xml) that has some information:


ID - A GUID for the sample. You can generate this in MD under Tools menu : Insert GUID. we need this to key between articles and their associated samples


IsFullApplication - Boolean flag (true or false): whether or not this is a full application such as the MWC App, Tasky, etc., or it's just a feature sample, such as, how to use 'x' feature. the basic test here is, if you would submit this to the app store because it's useful, then it's a full app, otherwise it's just a feature sample.


Brief - Short description or what your sample does. This allows us to display a nice and clean vignette on the sample page.


Level - Beginning, Intermediate, or Advanced: this is the intended audience level for the sample. only the getting started samples are Beginning, as they are intended for people who are just starting with the platform. most samples are Intermediate, and a few, that dive deep into difficult APIs, should be Advanced.


Minimum License Requirement - Starter, Indie, Business, or Enterprise: denotes the license that a user has to have in order to build/run the sample.


Tags: a list of relevant tags for the app. These are:


Data


Games


Graphics (CoreDrawing, Animation, OpenGL...)


Media (Video, Sound, recording, photos)


Platform Features (Photo Library, Contacts, Calendars, etc.)


Device Features (NFC, Accelerometer, Compass, Magnemometer, Bluetooth, RFID)


Cloud (Web Services, Networking, etc.)


Backgrounding


Maps + Location


Binding + Interop (Projections)


Notifications


Touch


Getting Started


Async


FSharp


SupportedPlatforms: this is only for cross plat samples. It's a comma-separated list, and the valid values are iOS, Android, and Windows.


Gallery: This tag must contain a value of true if you want the sample to show up in the samples gallery on the developer portal.




Buildable Sln and CSProj file - the project must build and have the appropriate project scaffolding (solution + proj).

 A good example of this stuff is here in the drawing sample: https://github.com/xamarin/monotouch-samples/tree/master/Drawing For a x-platform sample, please see: https://github.com/xamarin/mobile-samples/tree/master/Tasky",36
https://github.com/EgoistTheBest/monodroid-samples,## GitHub Integration,"  We integrate tightly with Git to make sure we always provide working samples to our customers. This is achieved through a pre-commit hook that runs before your commit goes through, as well as a post-receive hook on GitHub's end that notifies our samples gallery server when changes go through. To you, as a sample committer, this means that before you push to the repos, you should run the ""install-hook.bat"" or ""install-hook.sh"" (depending on whether you're on Windows or OS X/Linux, respectively). These will install the Git pre-commit hook. Now, whenever you try to make a Git commit, all samples in the repo will be validated. If any sample fails to validate, the commit is aborted; otherwise, your commit goes through and you can go ahead and push. This strict approach is put in place to ensure that the samples we present to our customers are always in a good state, and to ensure that all samples integrate correctly with the sample gallery (README.md, Metadata.xml, etc). Note that the master branch of each sample repo is what we present to our customers for our stable releases, so they must always Just Work. Should you wish to invoke validation of samples manually, simply run ""validate.windows"" or ""validate.posix"" (again, Windows vs OS X/Linux, respectively). These must be run from a Bash shell (i.e. a terminal on OS X/Linux or the Git Bash terminal on Windows). If you have any questions, don't hesitate to ask!",6
https://github.com/Chen0831/rallets-android,## Shadowsocks for Android," A shadowsocks client for Android, written in Scala. ",1
https://github.com/Chen0831/rallets-android,### CI STATUS,  ,4
https://github.com/Chen0831/rallets-android,### PREREQUISITES,"  
JDK 1.8
SBT 0.13.0+
Go 1.4+
Android SDK

Build Tools 25+
Android Support Repository and Google Repository (see build.sbt for version)


Android NDK r12b+
",3
https://github.com/Chen0831/rallets-android,### BUILD,"  
Set environment variable ANDROID_HOME to /path/to/android-sdk
Set environment variable ANDROID_NDK_HOME to /path/to/android-ndk
Set environment variable GOROOT_BOOTSTRAP to /path/to/go
Create your key following the instructions at https://developer.android.com/studio/publish/app-signing.html
Create local.properties from local.properties.example with your own key information
Invoke the building like this
     git submodule update --init

    # Build the App
    sbt native-build clean android:package-release",3
https://github.com/Chen0831/rallets-android,### TRANSLATE,"  Translators can go to POEditor to help translate shadowsocks-android. Guidelines: 
It's okay to leave some strings untranslated if you think it should use the same string as English (US).
faq_url should not be changed. If you'd like to translate FAQ, submit a pull request with the translated faq.md (it should be named properly, e.g. .github/faq.zh-CN.md). Administrators will take care of the rest.
Do not add/edit/remove comments.
",7
https://github.com/Chen0831/rallets-android,## DEVELOPE & DEBUG,"  
clean and install: sbt clean android:install
list database tables: adb -e shell ""run-as com.github.rallets ls /data/data/com.github.rallets/databases/""
",3
https://github.com/Chen0831/rallets-android,## OPEN SOURCE LICENSES,"  
redsocks: APL 2.0
mbed TLS: APL 2.0
libevent: BSD
tun2socks: BSD
pcre: BSD
libancillary: BSD
shadowsocks-libev: GPLv3
pdnsd: GPLv3
libev: GPLv2
kcptun: MIT
libsodium: ISC
",5
https://github.com/Chen0831/rallets-android,### Signing,"  
keytool -genkey -v -keystore .keystore -alias rallets -keyalg RSA -keysize 2048 -validity 10000
zipalign -p 4 my.apk ~/Desktop/Rallets-VERSION.apk
jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore .keystore ~/Desktop/Rallets-VERSION.apk rallets
",3
https://github.com/rivieragug/groovy-core,# ﻿Groovy," [Groovy][Groovy] is an agile and dynamic language for the Java Virtual Machine. It builds upon the strengths of Java, but has additional power features inspired by languages like Python, Ruby and Smalltalk. Groovy makes modern programming features available to Java developers with almost-zero learning curve as well as supports Domain-Specific Languages and other compact syntax so your code becomes easy to read and maintain. Groovy makes writing shell and build scripts easy with its powerful processing primitives, OO abilities and an Ant DSL. It also increases developer productivity by reducing scaffolding code when developing web, GUI, database or console applications. Groovy simplifies testing by supporting unit testing and mocking out-of-the-box. Groovy also seamlessly integrates with all existing Java classes and libraries and compiles straight to Java bytecode so you can use it anywhere you can use Java.
[Groovy]: http://groovy.codehaus.org/",12
https://github.com/rivieragug/groovy-core,## Building,"  To build you will need: 
JDK 1.7+
 To build everything using Gradle (the command below will download Gradle automatically, you do not need to download it first). ./gradlew clean dist
 This will generate a distribution similar to the zip you can download on the Groovy download page. To build everything and launch unit tests, use ./gradlew test
 To build from IntelliJ IDEA ./gradlew jarAll idea
 Then open the generated project in IDEA. To build from Eclipse ./gradlew jarAll eclipse
 Then open the generated project and the generated subprojects in Eclipse.",3
https://github.com/rivieragug/groovy-core,## InvokeDynamic support,"  The Groovy build supports the new Java 7 JVM instruction invokedynamic. If you want to build Groovy with invokedynamic, you can use the project property indy: ./gradlew -Pindy=true clean test
 Please note that the following Gradle tasks generate both indy and non indy variants of the jars, so you don't need to use the system property: 
dist
install
uploadArchives
",3
https://github.com/rivieragug/groovy-core,## Continuous Integration,  The official CI server runs here.,6
https://github.com/rivieragug/groovy-core,## License,"  Groovy is licensed under the terms of the [Apache License, Version 2.0][Apache License, Version 2.0].
[Apache License, Version 2.0]: http://www.apache.org/licenses/LICENSE-2.0.html",5
https://github.com/Parisson/loaders,## loaders," 
AudioBuffer loader and other loader utilities module
",1
https://github.com/Parisson/loaders,### Example,"  Load loaders.js in your html file by using:     <script src=""loaders.js""></script>   // We need an audio context to decode the file
  // By default,the loaders search for audioContext in the window.
  var audioContext = new AudioContext();

  // Load the file passing the path
  var myAudioBufferLoader = new loaders.AudioBufferLoader();
  myAudioBufferLoader.progressCallback = function(obj){
    // Do something with the progress value obj
    // obj: {value:.., total:..., loaded:...}
    // value is loaded/total
  }
  myAudioBufferLoader.load('sound/file/url').then(
      function(buffer){
        // Do something with the loaded audio buffer
      },
      function(error){
        // Catch an error during the loading or decodeAudioData process
      }
  ); Use the same load method to load multiple files, by passing
an array of urls ['url/to/file1', 'url/to/file2', ...].
The progress is then an object, eg. {index: 4, value: 0.2, total:999, loaded:1},
where index corresponds to the file index in the array of files,
and value, between 0.0 and 1, corresponds to the file loading progress.",3
https://github.com/Parisson/loaders,### Tests,"  Install all dependencies in the module folder $ npm install Run the test suite $ npm test It should launch a browser, run the tests in it, and generate the coverage report in the coverage folder.",3
https://github.com/Parisson/loaders,### Status,"  This library is under heavy development and subject to change.
Every new API breaking change we will be adding snapshots to the repository so you can always fetch a working copy.",4
https://github.com/Parisson/loaders,## License,  This module is released under the BSD-3-Clause license.,5
https://github.com/Parisson/loaders,## Acknowledgments,"  This code is part of the WAVE project,
funded by ANR (The French National Research Agency),
ContInt program,
2012-2015.",5
https://github.com/Lodin/broccoli-pug-plugin,# broccoli-pug-plugin," 

  A Broccoli plugin which
compiles pug code to html.",1
https://github.com/Lodin/broccoli-pug-plugin,## How to install?,  $ npm install --save-dev broccoli-pug-plugin ,3
https://github.com/Lodin/broccoli-pug-plugin,## How to use?,"  In your Brocfile.js: var Pug = require('broccoli-pug-plugin');
var nodes = new Pug(inputNodes, options, locals); Locals are the compile-time variables used in pug code. You can find options at the pug site.",36
https://github.com/jimlester/thoughtworks-email-signature-generator,# ThoughtWorks Email Signature Generator," Generate an on-brand and cross-client email signature personalized with your details and preferences.  



",1
https://github.com/jimlester/thoughtworks-email-signature-generator,## Deployment, ,3
https://github.com/jimlester/thoughtworks-email-signature-generator,### Prerequisites,  This project is deployed with Docker. The easiest way to setup a Docker environment is by installing the Docker Toolbox.,3
https://github.com/jimlester/thoughtworks-email-signature-generator,### Docker Compose,"  
docker-compose up
",3
https://github.com/kleopatra999/ca-bundle,# composer/ca-bundle," Small utility library that lets you find a path to the system CA bundle,
and includes a fallback to the Mozilla CA bundle. Originally written as part of composer/composer,
now extracted and made available as a stand-alone library.",16
https://github.com/kleopatra999/ca-bundle,## Installation,  Install the latest version with: $ composer require composer/ca-bundle,3
https://github.com/kleopatra999/ca-bundle,## Requirements,"  
PHP 5.3.2 is required but using the latest version of PHP is highly recommended.
",3
https://github.com/kleopatra999/ca-bundle,## Basic usage, ,3
https://github.com/kleopatra999/ca-bundle,# `Composer\CaBundle\CaBundle`,"  
CaBundle::getSystemCaRootBundlePath(): Returns the system CA bundle path, or a path to the bundled one as fallback
CaBundle::getBundledCaBundlePath(): Returns the path to the bundled CA file
CaBundle::validateCaFile($filename): Validates a CA file using opensl_x509_parse only if it is safe to use
CaBundle::isOpensslParseSafe(): Test if it is safe to use the PHP function openssl_x509_parse()
CaBundle::reset(): Resets the static caches
",3
https://github.com/kleopatra999/ca-bundle,## To use with curl,"  $curl = curl_init(""https://example.org/"");
curl_setopt($curl, CURLOPT_CAINFO, \Composer\CaBundle\CaBundle::getSystemCaRootBundlePath());
$result = curl_exec($curl);",3
https://github.com/kleopatra999/ca-bundle,## To use with php streams,"  $opts = array(
    'http' => array(
        'method' => ""GET""
    )
);

$caPath = \Composer\CaBundle\CaBundle::getSystemCaRootBundlePath();
if (is_dir($caPath)) {
    $opts['ssl']['capath'] = $caPath;
} else {
    $opts['ssl']['cafile'] = $caPath;
}

$context = stream_context_create($opts);
$result = file_get_contents('https://example.com', false, $context);",3
https://github.com/kleopatra999/ca-bundle,## License,"  composer/ca-bundle is licensed under the MIT License, see the LICENSE file for details.",5
https://github.com/abhinav1592/PruneCluster,# ![PruneCluster](http://medias.master-bridge.eu/e30525b1a92f01204ac69039a642e370c85bf906.png)," PruneCluster is a fast and realtime marker clustering library. It's working with Leaflet as an alternative to Leaflet.markercluster. The library is designed for large datasets or live situations. The memory consumption is kept low and the library is fast on mobile devices, thanks to a new algorithm inspired by collision detection in physical engines. 
Some tweets over the world",12
https://github.com/abhinav1592/PruneCluster,### Features, ,1
https://github.com/abhinav1592/PruneCluster,#### Realtime,  The clusters can be updated in realtime. It's perfect for live situations.,1
https://github.com/abhinav1592/PruneCluster,#### Fast,"  


Number of markers
First step
Update (low zoom level)
Update (high zoom level)




100
instant
instant
instant


1 000
instant
instant
instant


10 000
14ms
3ms
2ms


60 000
70ms
23ms
9ms


150 000
220ms
60ms
20ms


1 000 000
1.9s
400ms
135ms


 These values are tested with random positions, on a recent laptop, using Chrome 38. One half of markers is moving randomly and the other half is static. It is also fast enough for mobile devices. If you prefer real world data, the 50k Leaflet.markercluster example is computed in 60ms (original).",1
https://github.com/abhinav1592/PruneCluster,#### Weight,"  You can specify the weight of each marker. For example, you may want to add more importance to a marker representing an incident, than a marker representing a tweet.",1
https://github.com/abhinav1592/PruneCluster,#### Categories,"  You can specify a category for the markers. Then a small object representing the number of markers for each category is attached to the clusters. This way, you can create cluster icons adapted to their content.  ",1
https://github.com/abhinav1592/PruneCluster,#### Dynamic cluster size,  The size of a cluster can be adjusted on the fly (Example),1
https://github.com/abhinav1592/PruneCluster,#### Filtering,  The markers can be filtered easily with no performance cost.,1
https://github.com/abhinav1592/PruneCluster,### Usage,"  	<!-- In <head> -->
	<link rel=""stylesheet"" href=""http://cdn.leafletjs.com/leaflet-0.7.3/leaflet.css""/>

	<!-- In <head> or before </body> -->
	<script src=""http://cdn.leafletjs.com/leaflet-0.7.3/leaflet.js""></script>
	<script src=""PruneCluster/dist/PruneCluster.js""></script> var pruneCluster = new PruneClusterForLeaflet();

...
var marker = new PruneCluster.Marker(latitude, longitude);
pruneCluster.RegisterMarker(marker);
...

leafletMap.addLayer(pruneCluster);",3
https://github.com/abhinav1592/PruneCluster,### PruneClusterForLeaflet constructor,"  PruneClusterForLeaflet(size, margin) You can specify the size and margin which affect when your clusters and markers will be merged. size defaults to 120 and margin to 20.",3
https://github.com/abhinav1592/PruneCluster,#### Update a position,"  marker.Move(lat, lng);",3
https://github.com/abhinav1592/PruneCluster,#### Deletions,"  // Remove all the markers
pruneCluster.RemoveMarkers();

// Remove a list of markers
pruneCluster.RemoveMarkers([markerA,markerB,...]);",3
https://github.com/abhinav1592/PruneCluster,#### Set the category,"  The category can be a number or a string, but in order to minimize the performance cost, it is recommended to use numbers between 0 and 7. marker.category = 5;",3
https://github.com/abhinav1592/PruneCluster,#### Set the weight,  marker.weight = 4;,3
https://github.com/abhinav1592/PruneCluster,#### Filtering,  marker.filtered = true|false;,3
https://github.com/abhinav1592/PruneCluster,#### Set the clustering size,"  You can specify a number indicating the area of the cluster. Higher number means more markers ""merged"". (Example) pruneCluster.Cluster.Size = 87;",3
https://github.com/abhinav1592/PruneCluster,#### Apply the changes,  Must be called when ANY changes are made. pruneCluster.ProcessView();,3
https://github.com/abhinav1592/PruneCluster,#### Add custom data to marker object,"  Each marker has a data object where you can specify your data. marker.data.name = 'Roger';
marker.data.ID = '76ez';",3
https://github.com/abhinav1592/PruneCluster,#### Setting up a Leaflet icon or a Leaflet popup,"  You can attach to the markers an icon object and a popup content marker.data.icon = L.icon(...);  // See http://leafletjs.com/reference.html#icon
marker.data.popup = 'Popup content';",3
https://github.com/abhinav1592/PruneCluster,#### Faster leaflet icons,"  If you have a lot of markers, you can create the icons and popups on the fly in order to improve their performance. function createIcon(data, category) {
    return L.icon(...);
}

...

marker.data.icon = createIcon; You can also override the PreapareLeafletMarker method. You can apply listeners to the markers here. pruneCluster.PrepareLeafletMarker = function(leafletMarker, data) {
    leafletMarker.setIcon(/*... */); // See http://leafletjs.com/reference.html#icon
    //listeners can be applied to markers in this function
    leafletMarker.on('click', function(){
    //do click event logic here
    });
    // A popup can already be attached to the marker
    // bindPopup can override it, but it's faster to update the content instead
    if (leafletMarker.getPopup()) {
        leafletMarker.setPopupContent(data.name);
    } else {
        leafletMarker.bindPopup(data.name);
    }
};",3
https://github.com/abhinav1592/PruneCluster,#### Setting up a custom cluster icon,"  pruneCluster.BuildLeafletClusterIcon = function(cluster) {
    var population = cluster.population, // the number of markers inside the cluster
        stats = cluster.stats; // if you have categories on your markers

    // If you want list of markers inside the cluster
    // (you must enable the option using PruneCluster.Cluster.ENABLE_MARKERS_LIST = true)
    var markers = cluster.GetClusterMarkers() 
        
    ...
    
    return icon; // L.Icon object (See http://leafletjs.com/reference.html#icon);
};",3
https://github.com/abhinav1592/PruneCluster,#### Listening to events on a cluster,"  To listen to events on the cluster, you will need to override the BuildLeafletCluster method. A click event is already specified on m, but you can add other events like mouseover, mouseout, etc. Any events that a Leaflet marker supports, the cluster also supports, since it is just a modified marker. A full list of events can be found here. Below is an example of how to implement mouseover and mousedown for the cluster, but any events can be used in place of those. pruneCluster.BuildLeafletCluster = function(cluster, position) {
      var m = new L.Marker(position, {
        icon: pruneCluster.BuildLeafletClusterIcon(cluster)
      });

      m.on('click', function() {
        // Compute the  cluster bounds (it's slow : O(n))
        var markersArea = pruneCluster.Cluster.FindMarkersInArea(cluster.bounds);
        var b = pruneCluster.Cluster.ComputeBounds(markersArea);

        if (b) {
          var bounds = new L.LatLngBounds(
            new L.LatLng(b.minLat, b.maxLng),
            new L.LatLng(b.maxLat, b.minLng));

          var zoomLevelBefore = pruneCluster._map.getZoom();
          var zoomLevelAfter = pruneCluster._map.getBoundsZoom(bounds, false, new L.Point(20, 20, null));

          // If the zoom level doesn't change
          if (zoomLevelAfter === zoomLevelBefore) {
            // Send an event for the LeafletSpiderfier
            pruneCluster._map.fire('overlappingmarkers', {
              cluster: pruneCluster,
              markers: markersArea,
              center: m.getLatLng(),
              marker: m
            });

            pruneCluster._map.setView(position, zoomLevelAfter);
          }
          else {
            pruneCluster._map.fitBounds(bounds);
          }
        }
      });
      m.on('mouseover', function() {
        //do mouseover stuff here
      });
      m.on('mouseout', function() {
        //do mouseout stuff here
      });

      return m;
    };
};",3
https://github.com/abhinav1592/PruneCluster,#### Redraw the icons,"  Marker icon redrawing with a flag: marker.data.forceIconRedraw = true;

...

pruneCluster.ProcessView(); Redraw all the icons: pruneCluster.RedrawIcons();",3
https://github.com/abhinav1592/PruneCluster,### Acknowledgements,  This library was developed in context of the BRIDGE project. It is now supported by the community and we thank the contributors.,5
https://github.com/abhinav1592/PruneCluster,### Licence,  The source code of this library is licensed under the MIT License.,5
https://github.com/barchetta/hackathon-2016-12,# hackathon-2016-12,,1
https://github.com/barchetta/hackathon-2016-12,## Running, ,3
https://github.com/barchetta/hackathon-2016-12,#### Locally,"  
To run: service/bin/www
http://localhost:3000/hotels
You must set API_KEY environment variable to your Google API key.
It should pick up proxy settings from http_proxy
",3
https://github.com/barchetta/hackathon-2016-12,#### In GCC,"  
Latest version not running there yet
A stub is running here: http://104.198.132.115:8080/
",3
https://github.com/barchetta/hackathon-2016-12,## Docker Notes,"  
scripts/buildit: Builds the docker image
docker images: list images
docker rmi <image id>: remove image
docker run -p 3030:3000 -d <image id>: Run image mapping private port 3000 to public (external) port 3030
docker ps -a: show all running containers
",3
https://github.com/barchetta/hackathon-2016-12,#### Reference Docs,"  
Dockerizing a Node.js web app
",6
https://github.com/barchetta/hackathon-2016-12,## Google Cloud SDK Notes,"  
google-cloud-sdk/bin/gcloud init: initialize SDK
",36
https://github.com/barchetta/hackathon-2016-12,#### Reference Docs,"  
Google Cloud SDK Documentation
",6
https://github.com/barchetta/hackathon-2016-12,## Kubernetes Notes,"  

scripts/pushit: Tags and pushes the docker image to my docker registry in GC. If it hangs and can't ping the repo server then likely it's a proxy configuration issue with docker (on the Mac I had to set proxies using Docker preferences).


To deploy, go to your Kubernetes Console, click on Conainer Clusters, the click ""Connect"" for your cluster and follow the instructions to start a local admin dashboard for your cluster


Then you can go to http://localhost:8001/ui
Click Pods then Create (in the upper right). To get your image URL you will need to go to the Container Engine Console click on the image in your Registry and click ""Show pull command"". It will look something like:  us.gcr.io/ecstatic-magpie-152317/server.js:v2. And don't forget to mark the service as external and map your incomming port (Port) to the port the container's port (Target Port)
After provisioning click on Services and you should see an External endpoints

",36
https://github.com/barchetta/hackathon-2016-12,####  Reference Docs,"  
Pushing to Container Registry 
Creating Single-Container Pods
",6
https://github.com/barchetta/hackathon-2016-12,## Google Places API,"  

Get a key you can do so using your projects API Console


Put key in request. Request looks like:
https://maps.googleapis.com/maps/api/place/nearbysearch/json?location=-33.8670522,151.1957362&type=lodging&rankby=distance&key=YOUR_API_KEY

",36
https://github.com/barchetta/hackathon-2016-12,####  Reference Docs,"  
Places Web Service Documentation
google-maps-services-js : Github repo for Node.js client

We're not using this due to proxy issues


Docs for Node.js google map client
",6
https://github.com/rivabe/aci-fabric-deploy,# Introduction," Fabric-Deploy is a tool to automate the deployment of physical configuration
(access ports, port channels and VPCs) to an ACI fabric. The tool reads port
allocations from an Excel spreadsheet and automatically pushes all relevant
configuration to the fabric to configure such ports. Supported types include
regular access ports, port channels, and VPCs. The tool also instances
default interface policies for CDP, LLDP, LACP, MCP, STP, etc.",1
https://github.com/rivabe/aci-fabric-deploy,# Requirements,"  
Python3.3 or above.
The ""acifabriclib"" library

Download it from the following URL and install it using ""python3 setup.py install""

https://github.com/datacenter/acifabriclib




The ""requests"" library.
",3
https://github.com/rivabe/aci-fabric-deploy,# Usage,"  $ python3 aci-fabric-deploy.py --input <spreadhseet> 

Optional arguments:
  -u URL, --url URL                 APIC IP address.
  -l LOGIN, --login LOGIN           APIC login ID.
  -p PASSWORD, --password PASSWORD  APIC login password.
  -i INPUT, --input INPUT           Input file
  -d DEBUG, --debug DEBUG           Enable debug mode
 The application also takes the regular parameters for APIC address, username and
password, as well as parses any existing credentials.py file stored in the
same directory. In that case, the content of the credentials.py file must
follow this format: URL=""https://192.168.0.90""
LOGIN=""admin""
PASSWORD=""Ap1cPass123""
 If the credentials.py does not exist and the credentials are not supplied from
the command line, the application will ask for them interactively.",3
https://github.com/rivabe/aci-fabric-deploy,# Usage Examples,"  $ python3 aci-fabric-deploy.py --input Sample_PortMapping.xlsx
$ python3 aci-fabric-deploy.py --input Sample_PortMapping.xlsx --debug yes
$ python3 aci-fabric-deploy.py --input Sample_PortMapping.xlsx -l admin -p ""Ap1cPass123"" -u ""https://192.168.0.90""
",3
https://github.com/rivabe/aci-fabric-deploy,# Output Examples,"  $ python3 aci-fabric-deploy.py --input Sample_PortMapping.xlsx

   _____     _          _           ____             _
  |  ___|_ _| |__  _ __(_) ___     |  _ \  ___ _ __ | | ___  _   _
  | |_ / _` | '_ \| '__| |/ __|____| | | |/ _ \ '_ \| |/ _ \| | | |
  |  _| (_| | |_) | |  | | (_|_____| |_| |  __/ |_) | | (_) | |_| |
  |_|  \__,_|_.__/|_|  |_|\___|    |____/ \___| .__/|_|\___/ \__, |
                                              |_|            |___/

  == A tool to deploy physical configuration on an ACI fabric ==

[+] Creating standard interface policies
[+] Creating interface 'Access_DC001_ESX1_452'
[+] Creating interface 'Access_DC001_ESX1_454'
[+] Creating interface 'VPC_DC001_ESX7_583'
[+] Creating interface 'VPC_DC001_ESX7_584'
[+] Creating interface 'VPC_DC001_ESX7_585'
[+] Creating interface 'VPC_DC001_ESX7_586'
[+] Creating interface 'VPC_DC001_ESX1_690'
[+] Creating interface 'VPC_DC001_ESX1_703'
[+] Creating interface 'PC_DC001_ESX7_284'
",3
https://github.com/GitBoat/openshift3mlbparks,# Sample application for OpenShift 3, This sample application will create and deploy a JBoss EAP application server as well as a MongoDB database.  The sample application will display a map and perform geospatial queries to populate the map with all Major League Baseball stadiums in the United States.,1
https://github.com/GitBoat/openshift3mlbparks,## Quick instructions to just get this working on an OpenShift 3 deployment as a normal user,"  $ oc login https://yourOpenShiftServer
$ oc new-project mlbparks
$ oc create -f https://raw.githubusercontent.com/gshipley/openshift3mlbparks/master/mlbparks-template.json
$ oc new-app mlbparks
 Once the application is deployed and running, you can also scale the number of EAP pods to 3 with the following commands: $ oc scale --replicas=3 rc mlbparks-1
",3
https://github.com/GitBoat/openshift3mlbparks,## Install template as cluster-admin for everyone to use,"  Load the template with cluster-admin user: # oc create -f https://raw.githubusercontent.com/gshipley/openshift3mlbparks/master/mlbparks-template.json -n openshift
",3
https://github.com/GitBoat/openshift3mlbparks,# oc create -f https://raw.githubusercontent.com/gshipley/openshift3mlbparks/master/mlbparks-template.json -n openshift,,-
https://github.com/mnacos/coffee-react-quickstart,# Coffee React Quickstart," Quickstart for creating React.js web applications. It has a number of nice goodies baked in including: 
Live reloading for both CSS and Javascript! This really speeds up development. Live reloading is powered by the Webpack module bundler and react-hot-loader projects.
Write your JSX in Coffeescript thanks to coffee-react-transform.
Amazing URL-driven-development (UDD) with the react-router project.
Uses Gulp for building CSS and Javascript. Run gulp watch for rebuilding css/js on the fly while developing and gulp build to create minified versions for deploying to production.
Includes sensible element stylings and several useful Sass plugins:

Susy: best-of-breed grid system.
modular-scale: easily create pleasing modular type scales.
Sassy Buttons: flexible button styling.
Breakpoint: Super simple media queries.


",12
https://github.com/mnacos/coffee-react-quickstart,## Install dependencies,  Clone this repo and then after entering the new directory run npm install and bundle install. This will install the respective NPM and Ruby Gem dependencies. You'll also need to have gulp installed globally to run the coffeescript gulpfile: npm install -g gulp,3
https://github.com/mnacos/coffee-react-quickstart,## Development,  Run in the root of your directory: npm run watch This will watch the src directories and build on changes and placed the built css and js files in the public directory. It'll serve everything in the /public directory at localhost:8080 Then try editing src/scripts/hello_world.cjsx and see your changes magically show up in your browser with no page reload!,3
https://github.com/mnacos/coffee-react-quickstart,# Production build,"  To build for production, simply run gulp build",3
https://github.com/mnacos/coffee-react-quickstart,# Demo,  Try out the example app included with this quickstart: http://kyleamathews.github.io/coffee-react-quickstart/,3
https://github.com/kcufId/pupy,# Pupy," Pupy is an opensource, cross-platform (Windows, Linux, OSX, Android), multi function RAT (Remote Administration Tool) and post-exploitation tool mainly written in python. It features a all-in-memory execution guideline and leaves very low footprint. Pupy can communicate using various transports, migrate into processes (reflective injection), load remote python code, python packages and python C-extensions from memory.
Pupy modules can transparently access remote python objects using rpyc to perform various interactive tasks.
Pupy can generate payloads in multiple formats like PE executables, reflective DLLs, pure python files, powershell, apk, ...
When you package a payload, you can choose a launcher (connect, bind, ...), a transport (ssl, http, rsa, obfs3, scramblesuit, ...) and a number of ""scriptlets"". Scriptlets are python scripts meant to be embedded to perform various tasks offline (without requiring a session), like starting a background script, adding persistence, starting a keylogger, detecting a sandbox, ...",1
https://github.com/kcufId/pupy,## Features,"  
Multi-platform (tested on windows xp, 7, 8, 10, kali linux, ubuntu, osx, android)
On windows, the Pupy payload can be compiled as a reflective DLL and the whole python interpreter is loaded from memory. Pupy does not touch the disk :)
pupy can also be packed into a single .py file and run without any dependencies other that the python standard library on all OS

pycrypto gets replaced by pure python aes && rsa implementations when unavailable


Pupy can reflectively migrate into other processes
Pupy can remotely import, from memory, pure python packages (.py, .pyc) and compiled python C extensions (.pyd, .so). The imported python modules do not touch the disk.
Pupy is easily extensible, modules are quite simple to write, sorted by os and category.
A lot of awesome modules are already implemented!
Pupy uses rpyc and a module can directly access python objects on the remote client

We can also access remote objects interactively from the pupy shell and you even get auto-completion of remote attributes!


Communication transports are modular, stackable and awesome. You could exfiltrate data using HTTP over HTTP over AES over XOR. Or any combination of the available transports !
Pupy can communicate using obfsproxy pluggable transports
All the non interactive modules can be dispatched to multiple hosts in one command
Commands and scripts running on remote hosts are interruptible
Auto-completion for commands and arguments
Custom config can be defined: command aliases, modules automatically run at connection, ...
Interactive python shells with auto-completion on the all in memory remote python interpreter can be opened
Interactive shells (cmd.exe, /bin/bash, ...) can be opened remotely. Remote shells on Unix & windows clients have a real tty with all keyboard signals working fine just like a ssh shell
Pupy can execute PE exe remotely and from memory (cf. ex with mimikatz)
Pupy can generate payloads in various formats : apk,lin_x86,lin_x64,so_x86,so_x64,exe_x86,exe_x64,dll_x86,dll_x64,py,pyinst,py_oneliner,ps1,ps1_oneliner,rubber_ducky
Pupy can be deployed in memory, from a single command line using pupygen.py's python or powershell one-liners.
""scriptlets"" can be embeded in generated payloads to perform some tasks ""offline"" without needing network connectivity (ex: start keylogger, add persistence, execute custom python script, check_vm ...)
tons of other features, check out the implemented modules
",1
https://github.com/kcufId/pupy,## Implemented Transports,"  All transports in pupy are stackable. This mean that by creating a custom transport conf (pupy/network/transport/<transport_name>/conf.py), you can make you pupy session looks like anything. For example you could stack HTTP over HTTP over base64 over HTTP over AES over obfs3 :o) 
rsa

A layer with authentication & encryption using RSA and AES256, often stacked with other layers


aes

layer using a static AES256 key


ssl (the default one)

TCP transport wrapped with SSL


ssl_rsa

same as ssl but stacked with a rsa layer


http

layer making the traffic look like HTTP traffic. HTTP is stacked with a rsa layer


obfs3

A protocol to keep a third party from telling what protocol is in use based on message contents
obfs3 is stacked with a rsa layer for a better security


scramblesuit

A Polymorphic Network Protocol to Circumvent Censorship
scramblesuit is stacked with a rsa layer for a better security


udp

rsa layer but over UDP (could be buggy, it doesn't handle packet loss yet)


other

Other layers doesn't really have any interest and are given for code examples : (dummy, base64, XOR, ...)


",1
https://github.com/kcufId/pupy,"## Implemented Launchers (not up to date, cf. ./pupygen.py -h)","  Launchers allow pupy to run custom actions before starting the reverse connection 
connect

Just connect back


bind

Bind payload instead of reverse


auto_proxy

Retrieve a list of possible SOCKS/HTTP proxies and try each one of them. Proxy retrieval methods are: registry, WPAD requests, gnome settings, HTTP_PROXY env variable


",1
https://github.com/kcufId/pupy,## Implemented Modules (not up to date), ,1
https://github.com/kcufId/pupy,### All platforms:,"  
command execution
download
upload
interactive python shell with auto-completion
interactive shell (cmd.exe, powershell.exe, /bin/sh, /bin/bash, ...)

tty allocation is well supported on both windows and *nix. Just looks like a ssh shell


shellcode exec
persistence
socks5 proxy
local and remote port forwarding
screenshot
keylogger
run the awesome credential gathering tool LaZagne from memory !
sniff tools, netcreds
process migration (windows & linux, not osx yet)
...
a lot of other tools (upnp client, various recon/pivot tools using impacket remotely, ...)
",1
https://github.com/kcufId/pupy,### Windows specific :,"  
migrate

inter process architecture injection also works (x86->x64 and x64->x86)


in memory execution of PE exe both x86 and x64!

works very well with mimitakz :-)


webcam snapshot
microphone recorder
mouselogger:

takes small screenshots around the mouse at each click and send them back to the server


token manipulation
getsystem
creddump
tons of useful powershell scripts
...
",1
https://github.com/kcufId/pupy,### Android specific,"  
Text to speech for Android to say stuff out loud
webcam snapshots (front cam & back cam)
GPS tracker !
 ##Installation
Refer to the wiki
##Documentation
Refer to the wiki",1
https://github.com/kcufId/pupy,##Installation,Refer to the wiki ##Documentation Refer to the wiki,3
https://github.com/kcufId/pupy,##Documentation,  Screenshot section on the wiki,6
https://github.com/kcufId/pupy,### Some screenshots (not up to date),,6
https://github.com/kcufId/pupy,## FAQ,"  
Does the server work on windows?
 Pupy server works best on linux. The server on windows has not been really tested and there is probably a lot of bugs. I try my best to code in a portable way but I don't always find the time to fix everything. If you find the courage to patch non-portable code, I will gladly accept pull requests! :) 
I can't install it, how does it work?
 Have a look at the Installation section in the wiki 
I have the following error when starting pupy.sh: ImportError: No module named creddump.win32.domcachedump
 Follow the Installations steps in the wiki, you missed the git submodules initialisation/updates 
I have the following error when using pupygen : IOError: [Errno 2] No such file or directory: '/full-path/pupy-master/pupy/payload_templates/pupyx86.exe'
 Follow the Installations steps in the wiki, you missed the git submodules initialisation/updates 
I have another error at installation
 Follow the Installations steps in the wiki (yes I know) 
Hey, I love pupy and I was wondering if I could offer you a beer !
 Sure ! thank you !
Via pledgie :
Via BTC: 12BKKN81RodiG9vxJn34Me9ky19ArqNQxC 
hey c4n y0u add a DDOS module plzz?
 No.",6
https://github.com/kcufId/pupy,## Contact,"  by mail: contact@n1nj4.eu
on Twitter: Follow me on twitter If some of you want to participate to pupy development, don't hesitate ! All help is greatly appreciated and I will review every pull request.
This project is a personal development, please respect its philosophy and don't use it for evil purposes! ##special thanks
Special thanks to all contributors that helps me improve pupy and make it an even better tool ! :)",5
https://github.com/kcufId/pupy,##special thanks,,5
https://github.com/59naga/object-parser,# Object-parser [![NPM version][npm-image]][npm] [![Build Status][travis-image]][travis] [![Coverage Status][coveralls-image]][coveralls],"  
Multiple parse/stringify function
",1
https://github.com/59naga/object-parser,## Installation, ,3
https://github.com/59naga/object-parser,### Via npm,"  $ npm install object-parser --save var OP= require('object-parser');
console.log(OP); //object",3
https://github.com/59naga/object-parser,### Via bower,"  $ bower install object-parser --save <script src=""bower_components/object-parser/object-parser.min.js""></script>
<script>
  console.log(OP); //object
</script>",3
https://github.com/59naga/object-parser,# API, ,36
https://github.com/59naga/object-parser,"## `OP.stringify(type,object,replacer,indent)`","  var object= [['foo',{bar:'baz'},['beep','boop']]];

OP.stringify('yaml',object);
// '-\n    - foo\n    - {bar: baz}\n    - [beep, boop]'

OP.stringify('json',object);
// '[[""foo"",{""bar"":""baz""},[""beep"",""boop""]]]'

OP.stringify('json5',object);
// '[[""foo"",{bar:""baz""},[""beep"",""boop""]]]'

OP.stringify('jsonml',object);
// '<foo bar=""baz""><beep>boop</beep></foo>'",6
https://github.com/59naga/object-parser,"## `OP.parse(type,object)`","  OP.parse('yaml','-\n    - foo\n    - {bar: baz}\n    - [beep, boop]\n');
// [
//   [
//     ""foo"",
//     {
//       ""bar"": ""baz""
//     },
//     [
//       ""beep"",
//       ""boop""
//     ]
//   ]
// ]

OP.parse('json','[[""foo"",{""bar"":""baz""},[""beep"",""boop""]]]');
// [
//   [
//     ""foo"",
//     {
//       ""bar"": ""baz""
//     },
//     [
//       ""beep"",
//       ""boop""
//     ]
//   ]
// ]

OP.parse('json5','[[""foo"",{bar:""baz""},[""beep"",""boop""]]]');
// [
//   [
//     ""foo"",
//     {
//       ""bar"": ""baz""
//     },
//     [
//       ""beep"",
//       ""boop""
//     ]
//   ]
// ]

OP.parse('jsonml','<foo bar=""baz""><beep>boop</beep></foo>');
// [
//   [
//     ""foo"",
//     {
//       ""bar"": ""baz""
//     },
//     [
//       ""beep"",
//       ""boop""
//     ]
//   ]
// ]",6
https://github.com/59naga/object-parser,## License,  MIT,5
https://github.com/jbakic/Shielded,# Shielded," Available on NuGet. Shielded is a full-featured implementation of Software Transactional Memory
in .NET. It provides a system (the Shield static class) for running in-memory
transactions, and data structures which are aware of transactions. It can also
generate transaction-aware proxy subclasses based on a POCO class type (only
supported on the .NET Framework, not on .NET Standard). The implementation is
strict, with strong guarantees on safety. It is mostly lock-free, using only
one major lock which is held during the pre-commit check. Here is a small example: var n = new Shielded<int>();
int a = n;
Shield.InTransaction(() =>
    n.Value = n + 5); Shielded fields are thread-safe. You can read them out of transaction, but
changes must be done inside. While inside, the library guarantees a consistent
view of all shielded fields. Another example, the STM version of ""Hello world!"" - parallel addition in an
array. Here, in a dictionary: var dict = new ShieldedDict<int, int>();
ParallelEnumerable.Range(0, 100000)
    .ForAll(i => Shield.InTransaction(() =>
        dict[i % 100] = dict.ContainsKey(i % 100) ? dict[i % 100] + 1 : 1)); Shielded works with value types, and the language automatically does the needed
cloning. For ref types, it only makes the reference itself transactional.
The class should then be immutable, or, if you're targetting the full .NET Framework,
and if you have a class you want to make transactional: public class TestClass {
    public virtual Guid Id { get; set; }
    public virtual string Name { get; set; }
} Then you create instances like this: using Shielded.ProxyGen;
...
var t = Factory.NewShielded<TestClass>(); The Factory creates a proxy sub-class, using CodeDom, which will have transactional
overrides for all virtual properties of the base class that are public or protected.
Due to CodeDom limitations, the getter and setter must have the same accessibility!
The proxy objects are thread-safe (or, at least their virtual properties are), and
can only be changed inside transactions. Since CodeDom is not available on .NET Standard, this feature is currently not
supported if you're not targeting the full .NET Framework. Usage is simple: var id = t.Id;
Shield.InTransaction(() =>
    t.Name = ""Test object""); It is safe to execute any number of concurrent transactions that are reading from
or writing into the same shielded fields - each transaction will complete correctly.
This is accomplished by: 
ensuring that in one transaction you read a consistent state of
all shielded fields
buffering writes into storage which is local for each thread
 Your changes are commited and made visible to other threads only if all
the shielded fields you read or wrote into have not changed since you
started. If any have new changes, your transaction is retried from the
beginning, but this time reading the new data. Though it may seem so,
this cannot create an infinite loop since for any conflict to occur at
least one transaction must successfully commit. Overall, the system must
make progress. This quality would place Shielded in the lock-free class of non-blocking
concurrency mechanisms, according to academic classification. However,
this is not accurate since the commit check gets done under a lock. Hence
the word ""mostly"" in the short description.",123
https://github.com/jbakic/Shielded,## Features,"  

MVCC: Each transaction reads a consistent snapshot of the state without
the need for locking, since updates just create new versions.

Old versions are dropped soon after no one is capable of reading them
any more.



Read-only transactions always complete without any repetitions and
without entering the global lock!


Strictness: If a write is made anywhere, the system will insist that
all touched locations, read or written, still contain the same version
of data that they had when the transaction opened. This means it does not
suffer from the Write Skew issue.


Transactional collections: Included in the library are ShieldedDict<>
(dictionary), ShieldedSeq<> (singly linked list) and ShieldedTree<> (a
red-black tree implementation).

It is possible to use this library with immutable collections from
System.Collections.Immutable.



Transaction-local storage: ShieldedLocal<> allows storing anything
in the transaction context, visible only from within that transaction.


To perform side-effects (IO, and most other operations which are not
shielded) you use the SideEffect method of the Shield class, which takes
optional onCommit and onRollback lambdas, or the SyncSideEffect method which
allows you to execute code during a commit, while the changed fields are still
locked.


Conditional transactions: Method Shield.Conditional allows you
to define something similar to a database AFTER trigger. It receives a test, and
an action to perform, both lambdas. It runs the test, makes a note of
all shielded objects that the test had accessed, and later re-executes
the test when any of those objects is committed into. If test passes, the
action is called.

Implemented transactionally, so can be called from transactions, and
can be triggered by the transaction that created it.
Returns an IDisposable for deactivating the subscription, also
transactionally. It may even deactivate itself, e.g. to guarantee one-time execution.



Pre-commit checks: Shield.PreCommit is very similar to Shield.Conditional,
but executes the test within a transaction that changes one of the fields it is
interested in, just before that transaction will commit.

Can be used to ensure certain invariants are held, or to implement
thread prioritization by allowing only some threads which access a field
to commit into it.



Custom commit operations: You can integrate your own code into the commit process,
to execute while the shielded fields, that are being written, are held locked.

Already mentioned Shield.SyncSideEffect does this on the level of one transaction.
Using Shield.WhenCommitting, you subscribe globally for any commit, or based on
the type of field being written. These subscriptions should never throw!
Shield.RunToCommit runs a transaction just up to commit, and allows you to
commit/rollback later, or from another thread. This is useful for asynchronous
programming.



Commutables: operations which can be performed without conflict, because
they can be reordered in time and have the same net effect, i.e. they are
commutable (name borrowed from Clojure). Incrementing an int is an
example - if you don’t care what the int’s value is, you can increment it
without conflict by simply incrementing whatever value you encounter there
at commit time. Using commutes, when appropriate, reduces conflicts and
improves concurrency. Incrementing an int, conflict-free:
n.Commute((ref int a) => a++);

Commutes are not performed under any lock, but rather in a special
commute subtransaction, which reads the latest data, and tries to
commit with the same stamp as your main transaction. If only the commutes
fail, then only the commutes get retried.
If, in the example above, your main transaction has already (or perhaps
will later) read the n field or written to it (non-commutatively), the
commute “degenerates?- it gets executed in place, in your transaction,
and you can see it’s effect. This means consistency - if you read it, it
will stay as read when you commit. But, it is now a potential conflict.
Shield has various commutable operations defined in it. Appending to a
sequence is commutable - if you do not touch the seq, it never conflicts.
Collection Count fields are comuted over, to avoid unnecessary conflicts.


",1
https://github.com/ctinnell/swift-java-bridge,# swift-java-bridge, Execute Java Code from a Swift Cocoa Application,1
https://github.com/ctinnell/swift-java-bridge,## Overview,"  This project demonstrates using a Cocoa Application to execute queries against a remote database.  This sample Cocoa application will launch a JVM, import DB2 JDBC drivers into the classpath, and communicate through JNI using C to a Java class that connects to a DB2 database and executes queries.  The Cocoa application is written in Swift, but accesses Objective-C methods to connect and execute the queries.",1
https://github.com/ctinnell/swift-java-bridge,## Disclaimer,"  Any project that mixes Cocoa, C, Java, JNI, JDBC, Objectice-C, and Swift has to be fun, right?  This project isn't really meant to be used for anything yet other than to demonstrate how these technologies can be used together to do powerful things.  My frustration with the lack of database connectivity in Cocoa may drive me to package this up in a nice framework some day.",1
https://github.com/ctinnell/swift-java-bridge,## License,"  Copyright (c) 2015 Clay Tinnell. Use of the code provided on this repository is subject to the MIT License. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",5
https://github.com/ashusa303/aw-reporting,# AwReporting (Beta),,1
https://github.com/ashusa303/aw-reporting,## Special Note,"  If you are using this project, please follow the API anouncements and API version Sunsets:
https://developers.google.com/adwords/api/community/aw-announcements
https://developers.google.com/adwords/api/docs/sunset-dates The AdWords API changes version more or less every 4 months, so you would need to upgrade your project around that timeframe. Please let us know if you run into issues in the project's issue tracker (https://github.com/googleads/aw-reporting/issues), this Beta release may not fit your needs if you work with very large accounts but we are working to make the project better, your feedback is very important.",46
https://github.com/ashusa303/aw-reporting,## Overview,"  AwReporting is an open-source Java framework for large scale AdWords API reporting. 

18 common reports are included in the reference implementation. You can easily follow the code examples to implement more.


Reports are stored in your relational database, so you can integrate them with your existing systems.

",1
https://github.com/ashusa303/aw-reporting,## Quick Start, ,3
https://github.com/ashusa303/aw-reporting,### Prerequisites,"  You will need Java, Maven and MySQL installed before configuring the project.",3
https://github.com/ashusa303/aw-reporting,### Build the project using Maven,  $ git clone https://github.com/googleads/aw-reporting $ mvn clean install eclipse:eclipse $ mvn compile dependency:copy-dependencies package,3
https://github.com/ashusa303/aw-reporting,### Configure your MySQL database,  CREATE DATABASE AWReports DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; CREATE USER 'reportuser'@'localhost' IDENTIFIED BY 'SOME_PASSWORD'; GRANT ALL PRIVILEGES ON AWReports.* TO 'reportuser'@'localhost' WITH GRANT OPTION;,3
https://github.com/ashusa303/aw-reporting,### Configure AwReporting,"  Now we'll create a properties file to specify your MCC, developer token, OAuth and database credentials. $ vi aw-reporting/src/main/resources/aw-report-sample.properties Fill in the following fields with your MCC account ID and developer token. 
mccAccountId=
 
developerToken=
 Fill in your OAuth credentials. If you need to create them, visit: https://code.google.com/apis/console#access Note that you don't have to enter RefreshToken as AwReporting takes care of getting a new one when it runs for the first time. 
clientId=
 
clientSecret=
 Fill in the following with the number of rows that will be parsed from the CSV file before persisting to the DB.
The bigger the number, the bigger the memory usage, but also might give an improvement in performance. 
aw.report.processor.rows.size=1000
 Fill in the following to set the number of threads for the CSV processing and DB insertion. 
aw.report.processor.threads=4
 Fill in the following with your database connection. 
aw.report.model.db.sql.url=jdbc:mysql://localhost:3306/AWReports?rewriteBatchedStatements=true
 
aw.report.model.db.sql.username=reportuser
 
aw.report.model.db.sql.password=SOME_PASSWORD
",3
https://github.com/ashusa303/aw-reporting,### Run the project and verify it's working,"  Now, you are ready to run AwReporting with the following command. $ java -Xmx1G -jar aw-reporting/target/aw-reporting.jar -startDate YYYYMMDD -endDate YYYYMMDD \
-file aw-reporting/src/main/resources/aw-report-sample.properties -verbose
 Be sure to specify the properties file you edited above on the command line. It's possible to run the project using either Eclipse or the command line. If using Eclipse, open and run: 
aw-reporting/src/main/java/com/google/api/ads/adwords/awreporting/AwReporting.java
 As it's running, the project will provide status messages about the reports it's downloading on the command line. Check your database when the run finishes to be sure it's been populated with the reporting data, e.g.: 
SELECT * FROM AWReports.AW_ReportAccount limit 1;
",3
https://github.com/ashusa303/aw-reporting,### Command line options,"  Set the following command line options before running the project: 
Note: aw-reporting.jar is in the aw-reporting/aw-reporting/target/ directory.

java -Xmx1G -jar aw-reporting.jar -startDate YYYYMMDD -endDate YYYYMMDD -file <file>


Arguments:

   -accountIdsFile <file>
                              Defines a file that contains all the account IDs, one per line, to be used
                              instead of getting the accounts from the API. The list can contain all the accounts,
                              or just a specific set of accounts

   -csvReportFile
                              Specifies the CSV data file to be used when importing data from a local file. In order to use
                              this feature, you must pass the report type in the ""-onFileReport"" property.

   -dateRange 
                              ReportDefinitionDateRangeType.

   -debug
                              Will display all the debug information. If the option 'verbose' is
                              activated, all the information will be displayed on the console as
                              well

   -endDate <YYYMMDD>
                              End date for CUSTOM_DATE Reports (YYYYMMDD)

   -file <file>
                              aw-report-sample.properties file.

   -help
                              Print this message.

   -onFileReport
                              Especifies a report type (it has to be know by AwReporting model), and it will look for the data
                              in the file passed in the property ""csvReportFile"". If you use this property, it's mandatory
                              to specify a CSV file with ""-csvReportFile"". The CSV file has to follow the same format as the
                              one downloaded from the API: the first line contains the name of the report; second line must
                              contain the column headers; following lines must contain the data.  

   -startDate <YYYYMMDD>
                              Start date for CUSTOM_DATE Reports (YYYYMMDD).

   -verbose
                              The application will print all the tracing on the console


",3
https://github.com/ashusa303/aw-reporting,### Import the project into Eclipse (optional),"  To import the project into Eclipse, first import the model: 
File -> Import -> General -> Existing projects into workspace.
 
aw-reporting/aw-reporting-model
 Next import the database code: 
File -> Import -> General -> Existing projects into workspace.
 
aw-reporting/aw-reporting
",3
https://github.com/ashusa303/aw-reporting,### Generate the database schema using Maven,"  The project is already configured to use the hibernate4 Maven plugin to generate the schema for the configured dialect.
Due to the way the plugin works, to set the database dialect, you need to change a separate file instead of just use the aw-reporting properties file: 
aw-reporting/aw-reporting-model/src/main/resources/hbm2ddl/hibernate.properties
 The configured dialect is MySQL. Make sure to change this to be the same that is being used in the main properties file. To run the schema generation, just go to a command line, cd into aw-reporting-model folder, and run the following: mvn hibernate4:export -Phbm2ddl This will create a ""schema.sql"" in the ""target/"" folder of the project. Important Note: The schema creates the whole database assuming that none of the tables were created before. To update the database you will need to go through the SQL file and delete the unnecessary code.",3
https://github.com/ashusa303/aw-reporting,## Details about the code,"  For better organization and encapsulation, the project groups the reporting workflow into two parts:
Aw-Report-Model for persistence, entities and the CSV mapping to AdWords information and Aw-Reporting for the logic (API services, downloader and processors).",3
https://github.com/ashusa303/aw-reporting,### Aw-Report-Model,"  Provides all the necessary classes to persist data and the entities?mapping to AdWords report data. 

Entities: these POJOs define all the available fields for each report kind as java fields, by using annotations. The Entities contain the information to link the java fields to the report fields definition, the csv display name header fields and the datastore fields.


CSV: The CSV classes use the OpenCSV library to convert CSV files into Java beans using annotations. The package also contains two new annotations to define the Report Definition Type and the mapping between java field, report’s Column Name and Display Name headers. For example:


Annotation @CsvReport at the Report class level, for example for ReportAccount:
@CsvReport(value=
ReportDefinitionReportType.ACCOUNT_PERFORMANCE_REPORT)
public class ReportAccount extends Report {...


Annotation @CsvField at the java field level, for example for avgCpm:
@CsvField (value = ""Avg. CPM"", reportField = ""AverageCpm"")
public BigDecimal avgCpm;



 
Persistence: The persistence layer uses Spring for bean management, injection and in class annotations, this helps to clearly demarcate the application layers.
AuthTokenPersister: is the interface for the authorization token storage, we have implemented it for Mysql and a MongoDB.
ReportEntitiesPersister is the interface for the report entities storage, we have implemented it for Mysql and a MongoDB.
",3
https://github.com/ashusa303/aw-reporting,### Aw-Reporting,"  Provides the logic (API services, downloader and processors) 

Downloader: Based on MultipleClientReportDownloader java example (it uses the Library ReportDownloader) the Downloader is in charge of downloading all the report files using multiple threads.


Processors: The ReportProcessor is the class with the main logic, it is responsible for calling the downloader, use the CSV classes for the parsing and call the Persistence helpers for the storage. This class can be replaced by a custom processor by changing the bean component in the projects xml configuration files.


API Services: Beside the report Downloader calls to AdHoc Reports, the ManagedCustomerDelegate is the only class talking to the AdWords API, it is in charge of getting all the account ids in the MCC tree.


AwReporting main: The AwReporting main class is in charge of printing the help information, of the properties file example and of passing the command line parameters to the processor for execution.

",3
https://github.com/ashusa303/aw-reporting,## Offline Data Import,"  In order to support some report types that are not yet available in the API, but are available in the AdWords Interface, we introduced the feature of importing data to the database directly from CSV files that were downloaded from the interface. The offline data import works just as the online mode (where the data is downloaded from the API), but skips the download step. All the field mappings and report types supported are still the same, but keep in mind that most of the entity IDs are not available in the reports downloaded from the interface. IMPORTANT NOTE: Before importing the CSV with AwReporting, you must edit the file and make sure that it's in the same format as the CSV file downloaded from the API: 
First line must contain the name or description of the report;
Second line must contain the column names/headers;
Following lines must contain the data.
 Usually when you download a report from the interface, the CSV file will contain some additional lines in the beginning of the file. You have to remove those lines before importing it into AwReporting. To use the offline import data, you just need to specify in the command line the report type that you will import, and the local file that you will use as an addition to the other arguments: $ java -Xmx1G -jar aw-reporting/target/aw-reporting.jar -startDate YYYYMMDD -endDate YYYYMMDD \
-file aw-reporting/src/main/resources/aw-report-sample.properties \
-onFileReport CAMPAIGN_PERFORMANCE_REPORT -csvReportFile <CSV FILE LOCATION>
 IMPORTANT NOTE: The dates specified are very import, because they will be used to populate the database following the same format as the data downloaded from the API. Date periods are not supported.",3
https://github.com/ashusa303/aw-reporting,## **Experimental:** Video Campaign Performance report,"  With the offline data import feature available, we added the Video Campaign Performance Report to AwReporting model. This means that it's now possible to download the Video Performance reports from the interface, import it into AwReporting and make the data available in the database. This report still an experiment, and we want to hear more feedback from users in order to further improve this, and make sure that this is in fact a necessity. To import video campaign performance reports in AwReport, just run the following command: $ java -Xmx1G -jar aw-reporting/target/aw-reporting.jar -startDate YYYYMMDD -endDate YYYYMMDD \
-file aw-reporting/src/main/resources/aw-report-sample.properties \
-onFileReport VIDEO_CAMPAIGN_REPORT -csvReportFile <CSV FILE LOCATION>
 IMPORTANT NOTE: The API does not support video campaign reports. This is a work around to import video campaign reports into the database, facilitating the usage of the data in your applications.",3
https://github.com/ashusa303/aw-reporting,### Fine print,"  Pull requests are very much appreciated. Please sign the Google Individual Contributor License Agreement (There is a convenient online form) before submitting. 
AuthorsJulian Toledo (Google Inc.)
Gustavo Menezes (Google Inc.)
CopyrightCopyright © 2013 Google, Inc.
LicenseApache 2.0
LimitationsThis is example software, use with caution under your own risk.
",7
https://github.com/avigad/Spectral,# Spectral Sequences," Formalization project of the CMU HoTT group to formalize the Serre spectral sequence. Update July 16: The construction of the Serre spectral sequence has been completed. The result is serre_convergence in cohomology.serre.
The main algebra part is in algebra.spectral_sequence. This repository also contains the contents of the MRC group on formalizing homology in Lean.",1
https://github.com/avigad/Spectral,#### Participants,"  Jeremy Avigad, Steve Awodey, Ulrik Buchholtz, Floris van Doorn, Clive Newstead, Egbert Rijke, Mike Shulman.",5
https://github.com/avigad/Spectral,## Resources,"  
Mike's blog posts on ncatlab.
The Licata-Finster article about Eilenberg-Mac Lane spaces.
We learned about the Serre spectral sequence from Hatcher's chapter about spectral sequences.
Lang's algebra (revised 3rd edition) contains a chapter on general homology theory, with a section on spectral sequences. Thus, we can use this book at least as an outline for the algebraic part of the project.
Mac Lane's Homology contains a lot of homological algebra and a chapter on spectral sequences, including exact couples.
",6
https://github.com/ThomasGrivaz/Learning-Analytics-Project,# Learning-Analytics-Project,,1
https://github.com/ThomasGrivaz/Learning-Analytics-Project,## Description of the dataset:,"  The dataset we will be working on is a set of events related to a programming MOOC (massive open online course). Users are asked to submit their solution to a programming assignment which are automatically graded. For each user we have at our disposal a number of informations: 
the grade of the related submission
a timestamp of the submission
the time between two submissions
some events associated to a submission (e.g. if the user has watched a video, posted a message on the forum etc.) that illustrate the strategy followed by the user.
",1
https://github.com/ThomasGrivaz/Learning-Analytics-Project,## Overall Goal:,"  
Explore assignment strategies
Predict if the grade would improve after a resubmission to an assignment
Predict grade improvement between the first and last submission to an assignment
",1
https://github.com/ThomasGrivaz/Learning-Analytics-Project,## Data Analysis Pipeline:,"  
Develop an Hypothesis
Extract features
Partition data into train and test set
Train model (on train set)
Evaluate model performance (on test set)
Find the best feature set and model
",1
https://github.com/ThomasGrivaz/Learning-Analytics-Project,## Hypotheses & Features Selection:,"  The MOOC is composed of 3 main components: videos, forum and problems. Each of these components have events associated with.
For example for the video components, we can track if a user has played a video, how long he watched it or if he paused the video. Similarly for the forum we can know if a user has posted comments, watched a thread etc. The goal here is to make relevant hypotheses and extract associated features that reflect a learning behaviour. Three features were already extracted in the Python code supplied: the duration of a video activity, the average time difference between two videos watched and the number of forum threads viewed. Hypotheses related to video events 
the time spent watching videos has a positive effect on the next submission grade
--> count the time spent (DurationOfVideoActivity)
the more frequently a user watches a video, the more chances he has to increase his grade
--> extract the duration between two videos watched and compute the mean (AverageVideoTimeDiffs)
the number of different videos watched has a positive effect on the next submission grade
--> count the number of different videos (NumberVideoWatched)
if the learner seeks to specific points in the video lectures, (s)he is actively engaged with the course material
--> count the number of seek events (NumberOfSeekEvents)
 Hypothese related to forum events 
the number of threads viewed has a positive effect on the next submission grade
--> count the number of thread views (NumberOfThreadViews)
the number of thread created has a positive effect on the next submission grade
--> count the number of thread launched (NumberOfThreadCreated)
the number of comments posted has a positive effect on the next submission grade
--> count the number of comments posted (NumberOfComments)
When a learner upvotes a post or a comment, most likely they found the contet helpful and it helped them solve their problems, this might have a positive effect on the next submission grade.
--> count the number of upvotes for both comments and posts (NumberOfUpvotes)
 Hypothese combining both events (bigrams and trigrams) 
watching a video followed by posting
 Other hypotheses 
the time between two submissions should be indicative of the grade difference. A lot of submissions with relatively small time durations between submissions reflect a ""trial and error"" pattern where the learner typically tests some lines of code and wants to see the result by submitting. This behaviour is prone to errors in the code and as such should have a negative effect on the grade.
*TODO (probably secondary features for regression task)
--> find out if certain sequences of behavior are good predictors of improvement
--> compute more in-depth representations of what happened on the forum (did someone reply to your forum thread? Did you reply to them?)
",1
https://github.com/jlangston/mosh-chrome,# Mosh for Chrome," Main author: Richard Woodbury (rpwoodbu@mybox.org) This is a Mosh client port for the
Chrome web browser using
Native Client. It is
particularly useful with Chrome OS.",15
https://github.com/jlangston/mosh-chrome,## Building,"  You need to build on Linux, and probably Ubuntu Linux. You will also need the
Bazel build system installed. Go
here to get it. There's a Debian
package, so installation is easy; the only caveat is that it requires Java
(sorry). You can build the dev track simply by running: $ ./build.sh dev
 The first time this is run, this will download and build all dependencies
(except Bazel, of course). This can take a while, so be patient. Don't expect
status updates for a minute or two at a time in some cases. Subsequent builds
will be extremely fast; Bazel excels at doing incremental builds. Don't be alarmed if you see a few warnings. In particular, the linker may
complain about duplicated symbols. If successful, Bazel will output something like this: Target //:mosh_chrome up-to-date:
  bazel-genfiles/mosh_chrome_dev.zip
 That .zip file contains the entire app. To load it into Chrome, unzip it into
a directory on your machine, then go to chrome://extensions, enable
""Developer mode"", and click the ""Load unpacked extension button"", directing
it to said directory. Then the app will be launchable from the app screen and
the extensions screen. To distribute the app, build the release track and upload the .zip file to
the Chrome Web Store.",3
https://github.com/gskachkov/phantomjs,# [PhantomJS](http://phantomjs.org) - Scriptable Headless WebKit," PhantomJS (www.phantomjs.org) is a headless WebKit scriptable with JavaScript. It is used by hundreds of developers and dozens of organizations for web-related development workflow. The latest stable release is version 1.9 (codenamed ""Sakura""). Follow the official Twitter stream @PhantomJS to get the frequent development updates. The next major version, PhantomJS 2, is a significant upgrade. It is still in heavy development. There is no timeline for the release yet, please monitor the mailing-list for the progress. Note: Please do not create a GitHub pull request without reading the Contribution Guide first. Failure to do so may result in the rejection of the pull request.",1467
https://github.com/gskachkov/phantomjs,## Use Cases,"  
Headless web testing. Lightning-fast testing without the browser is now possible! Various test frameworks such as Jasmine, Capybara, QUnit, Mocha, WebDriver, YUI Test, BusterJS, FuncUnit, Robot Framework, and many others are supported.
Page automation. Access and manipulate web pages with the standard DOM API, or with usual libraries like jQuery.
Screen capture. Programmatically capture web contents, including CSS, SVG and Canvas. Build server-side web graphics apps, from a screenshot service to a vector chart rasterizer.
Network monitoring. Automate performance analysis, track page loading and export as standard HAR format.
",1
https://github.com/gskachkov/phantomjs,## Features,"  
Multiplatform, available on major operating systems: Windows, Mac OS X, Linux, and other Unices.
Fast and native implementation of web standards: DOM, CSS, JavaScript, Canvas, and SVG. No emulation!
Pure headless (no X11) on Linux, ideal for continuous integration systems. Also runs on Amazon EC2, Heroku, and Iron.io.
Easy to install: Download, unpack, and start having fun in just 5 minutes.
",1
https://github.com/gskachkov/phantomjs,## Ecosystem,"  PhantomJS needs not be used only as a stand-alone tool. Check also some excellent related projects: 
CasperJS enables easy navigation scripting and common high-level testing.
Poltergeist allows running Capybara tests headlessly.
Guard::Jasmine automatically tests Jasmine specs on Rails when files are modified.
GhostDriver complements Selenium tests with a PhantomJS WebDriver implementation.
PhantomRobot runs Robot Framework acceptance tests in the background via PhantomJS.
Mocha-PhantomJS run Mocha tests using PhantomJS.
 and many others related projects.",6
https://github.com/gskachkov/phantomjs,## Questions?,"  
Explore the complete documentation.
Read tons of user articles on using PhantomJS.
Join the mailing-list and discuss with other PhantomJS fans.
 PhantomJS is free software/open source, and is distributed under the BSD license. It contains third-party code, see the included third-party.txt file for the license information on third-party code. PhantomJS is created and maintained by Ariya Hidayat (Twitter: @ariyahidayat), with the help of many contributors.",56
https://github.com/cbogithub/pixelpusher,# pixelpusher," Generative and audio-controlled LED patterns for openpixelcontrol The pixelpusher project is a suite of Python modules to generate
artistic LED patterns. Generated patterns are piped to LED hardware
via zestyping's openpixelcontrol.  All code is pure python. The generative.py module contains subclasses that implement several
iterative algorithms for generating patterns on a 2D grid. Parameters and boundary conditions can be changed in real-time, for example by using OSC (Open Sound Control) GUIs from a smartphone. The audiomunger module uses PyAudio bindings to PortAudio for audio
input, and NumPy FFT to compute the short-term power spectral
density. These can be used to generate a running spectrogram display
or patched in to control other generative patterns. Current status is EXTREMELY ALPHA and while I'm working on it I've checked it in more for backup than for sharing. I will let you know when that changes!",14
https://github.com/thesaadarshad/setup-ipsec-vpn,# IPsec VPN Server Auto Setup Scripts,"Set up your own IPsec VPN server in just a few minutes, with both IPsec/L2TP and Cisco IPsec on Ubuntu, Debian and CentOS. All you need to do is provide your own VPN credentials, and let the scripts handle the rest.

An IPsec VPN encrypts your network traffic, so that nobody between you and the VPN server can eavesdrop on your data as it travels via the Internet. This is especially useful when using unsecured networks, e.g. at coffee shops, airports or hotel rooms.

We will use Libreswan as the IPsec server, and xl2tpd as the L2TP provider.

? Related tutorial: IPsec VPN Server Auto Setup with Libreswan",16
https://github.com/thesaadarshad/setup-ipsec-vpn,#### Table of Contents,"Quick start
Features
Requirements
Installation
Next steps
Important notes
Upgrade Libreswan
Bugs & Questions
Uninstallation
See also
License",6
https://github.com/thesaadarshad/setup-ipsec-vpn,## Quick start,"First, prepare your Linux server* with a fresh install of Ubuntu LTS, Debian 8 or CentOS 7/6.

Use this one-liner to set up an IPsec VPN server:

wget https://git.io/vpnsetup -O vpnsetup.sh && sudo sh vpnsetup.sh
If using CentOS, replace the link above with https://git.io/vpnsetup-centos.

Your VPN login details will be randomly generated, and displayed on the screen when finished.

For other installation options and how to set up VPN clients, read the sections below.

* A dedicated server or Virtual Private Server (VPS). OpenVZ VPS is NOT supported.",3
https://github.com/thesaadarshad/setup-ipsec-vpn,## Features,"New: The faster IPsec/XAuth (""Cisco IPsec"") mode is supported
New: A pre-built Docker image of the VPN server is now available
Fully automated IPsec VPN server setup, no user input needed
Encapsulates all VPN traffic in UDP - does not need ESP protocol
Can be directly used as ""user-data"" for a new Amazon EC2 instance
Includes sysctl.conf optimizations for improved performance
Tested with Ubuntu 16.04/14.04/12.04, Debian 8 and CentOS 7/6",1
https://github.com/thesaadarshad/setup-ipsec-vpn,## Requirements,"A newly created Amazon EC2 instance, from these images (AMI):

Ubuntu 16.04 (Xenial), 14.04 (Trusty) or 12.04 (Precise)
Debian 8 (Jessie) EC2 Images
CentOS 7 (x86_64) with Updates
CentOS 6 (x86_64) with Updates
Please see detailed instructions and EC2 pricing.

-OR-

A dedicated server or Virtual Private Server (VPS), freshly installed with one of the above OS. In addition, Debian 7 (Wheezy) can also be used with this workaround. OpenVZ VPS is NOT supported, users could instead try OpenVPN.

This also includes Linux VMs in public clouds, such as DigitalOcean, Vultr, Linode, Google Compute Engine, Amazon Lightsail, Microsoft Azure, IBM SoftLayer and Rackspace.

Deploy to Azure Install on DigitalOcean Deploy to Linode

? I want to run my own VPN but don't have a server for that

Advanced users can set up the VPN server on a $35 Raspberry Pi 3.

?? DO NOT run these scripts on your PC or Mac! They should only be used on a server!",36
https://github.com/thesaadarshad/setup-ipsec-vpn,## Installation,,3
https://github.com/thesaadarshad/setup-ipsec-vpn,### Ubuntu & Debian,"First, update your system with apt-get update && apt-get dist-upgrade and reboot. This is optional, but recommended.

To install the VPN, please choose one of the following options:

Option 1: Have the script generate random VPN credentials for you (will be displayed when finished):

wget https://git.io/vpnsetup -O vpnsetup.sh && sudo sh vpnsetup.sh
Option 2: Edit the script and provide your own VPN credentials:

wget https://git.io/vpnsetup -O vpnsetup.sh
nano -w vpnsetup.sh
[Replace with your own values: YOUR_IPSEC_PSK, YOUR_USERNAME and YOUR_PASSWORD]
sudo sh vpnsetup.sh
Option 3: Define your VPN credentials as environment variables:

# All values MUST be placed inside 'single quotes'
# DO NOT use these characters within values:  \ "" '
wget https://git.io/vpnsetup -O vpnsetup.sh && sudo \
VPN_IPSEC_PSK='your_ipsec_pre_shared_key' \
VPN_USER='your_vpn_username' \
VPN_PASSWORD='your_vpn_password' sh vpnsetup.sh
Note: If unable to download via wget, you may also open vpnsetup.sh (or vpnsetup_centos.sh) and click the Raw button. Press Ctrl-A to select all, Ctrl-C to copy, then paste into your favorite editor.",3
https://github.com/thesaadarshad/setup-ipsec-vpn,## Bugs & Questions,"Got a question? Please first search other people's comments in this Gist and on my blog.
Ask VPN related questions on the Libreswan or strongSwan mailing list, or read these wikis: [1] [2] [3] [4] [5].
If you found a reproducible bug, open a GitHub Issue to submit a bug report.",56
https://github.com/thesaadarshad/setup-ipsec-vpn,## Uninstallation,Please refer to Uninstall the VPN.,36
https://github.com/thesaadarshad/setup-ipsec-vpn,## See also," IPsec VPN Server on Docker
IKEv2 VPN Server on Docker
Streisand
Algo VPN
SoftEther VPN
Shadowsocks
OpenVPN Install
Setup strongSwan",6
https://github.com/thesaadarshad/setup-ipsec-vpn,## License,"Copyright (C) 2014-2017 Lin Song View my profile on LinkedIn
Based on the work of Thomas Sarlandie (Copyright 2012)

This work is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License
Attribution required: please include my name in any derivative and let me know how you have improved it!
",5
https://github.com/detoxin/ricochet,### Anonymous metadata-resistant instant messaging that just works.," Ricochet is an experimental kind of instant messaging that doesn't trust anyone with your identity, your contact list, or your communications. 
You can chat without exposing your identity (or IP address) to anyone
Nobody can discover who your contacts are or when you talk (metadata-free!)
There are no servers or operators that could be compromised, exposing your information.
It's cross-platform and easy for non-technical users.
",12
https://github.com/detoxin/ricochet,### How it works,"  Ricochet is a peer-to-peer instant messaging system built on the Tor Network hidden services. Your login is your hidden service address, and contacts connect to you (not an intermediate server) through Tor. The rendezvous system makes it extremely hard for anyone to learn your identity from your address. Ricochet is not affiliated with or endorsed by The Tor Project. For more information, you can read about Tor and learn about Ricochet's design or protocol (or the old protocol). Everything is open-source and open to contribution.",16
https://github.com/detoxin/ricochet,### Experimental,"  This software is an experiment. It hasn't been audited or formally reviewed by anyone. Security and anonymity are difficult topics, and you should carefully evaluate your risks and exposure with any software. Do not rely on Ricochet for your safety unless you have more trust in my work than it deserves. That said, I believe it does more to try to protect your privacy than any similar software, and is the best chance you have of witholding your personal information.",1
https://github.com/detoxin/ricochet,### Downloads,"  Ricochet is available for Windows, OS X (10.7 or later), and as a generic Linux binary package. Visit the releases page for the latest version and changelog. All releases and signatures are also available at https://ricochet.im/releases/. Binaries are PGP signed by 9032 CAE4 CBFA 933A 5A21 45D5 FF97 C53F 183C 045D.",3
https://github.com/detoxin/ricochet,### Building from source,"  See BUILDING for Linux, OS X, and Windows build instructions.",3
https://github.com/detoxin/ricochet,### Other,"  Bugs can be reported on the issue tracker. Translations can be contributed on Transifex. You can contact me at ricochet:rs7ce36jsj24ogfw or john.brooks@dereferenced.net. You should support The Tor Project, EFF, and run a Tor relay.",5
https://github.com/zouzias/docker-elk,# Docker ELK stack,"  Run the latest version of the ELK (Elasticseach, Logstash, Kibana) stack with Docker and Docker-compose. It will give you the ability to analyze any data set by using the searching/aggregation capabilities of Elasticseach and the visualization power of Kibana. Based on the official images: 
elasticsearch
logstash
kibana
",16
https://github.com/zouzias/docker-elk,# Requirements, ,3
https://github.com/zouzias/docker-elk,## Setup,"  
Install Docker.
Install Docker-compose.
Clone this repository
",3
https://github.com/zouzias/docker-elk,## SELinux,"  On distributions which have SELinux enabled out-of-the-box you will need to either re-context the files or set SELinux into Permissive mode in order for docker-elk to start properly.
For example on Redhat and CentOS, the following will apply the proper context: .-root@centos ~
-$ chcon -R system_u:object_r:admin_home_t:s0 docker-elk/",3
https://github.com/zouzias/docker-elk,## Windows,"  When cloning this repo on Windows with line ending conversion enabled (git option core.autocrlf set to true), the script kibana/entrypoint.sh will malfunction due to a corrupt shebang header (which must not terminated by CR+LF but LF only): ...
Creating dockerelk_kibana_1
Attaching to dockerelk_elasticsearch_1, dockerelk_logstash_1, dockerelk_kibana_1
: No such file or directory/usr/bin/env: bash So you have to either 
disable line ending conversion before cloning the repository by setting core.autocrlf set to false: git config core.autocrlf false, or
convert the line endings in script kibana/entrypoint.sh from CR+LF to LF (e.g. using Notepad++).
 See issue 36 for details.",36
https://github.com/zouzias/docker-elk,# Usage,"  Start the ELK stack using docker-compose: $ docker-compose up You can also choose to run it in background (detached mode): $ docker-compose up -d Now that the stack is running, you'll want to inject logs in it. The shipped logstash configuration allows you to send content via tcp: $ nc localhost 5000 < /path/to/logfile.log And then access Kibana UI by hitting http://localhost:5601 with a web browser. NOTE: You'll need to inject data into logstash before being able to create a logstash index in Kibana. Then all you should have to do is to
hit the create button. See: https://www.elastic.co/guide/en/kibana/current/setup.html#connect You can also access: 
Sense: http://localhost:5601/app/sense
 NOTE: In order to use Sense, you'll need to query the IP address associated to your network device instead of localhost. By default, the stack exposes the following ports: 
5000: Logstash TCP input.
9200: Elasticsearch HTTP
9300: Elasticsearch TCP transport
5601: Kibana
 WARNING: If you're using boot2docker, you must access it via the boot2docker IP address instead of localhost. WARNING: If you're using Docker Toolbox, you must access it via the docker-machine IP address instead of localhost.",36
https://github.com/zouzias/docker-elk,# Configuration,"  NOTE: Configuration is not dynamically reloaded, you will need to restart the stack after any change in the configuration of a component.",3
https://github.com/zouzias/docker-elk,## How can I tune Kibana configuration?,  The Kibana default configuration is stored in kibana/config/kibana.yml.,3
https://github.com/zouzias/docker-elk,## How can I tune Logstash configuration?,"  The logstash configuration is stored in logstash/config/logstash.conf. The folder logstash/config is mapped onto the container /etc/logstash/conf.d so you
can create more than one file in that folder if you'd like to. However, you must be aware that config files will be read from the directory in alphabetical order.",3
https://github.com/zouzias/docker-elk,## How can I specify the amount of memory used by Logstash?,"  The Logstash container use the LS_HEAP_SIZE environment variable to determine how much memory should be associated to the JVM heap memory (defaults to 500m). If you want to override the default configuration, add the LS_HEAP_SIZE environment variable to the container in the docker-compose.yml: logstash:
  build: logstash/
  command: logstash -f /etc/logstash/conf.d/logstash.conf
  volumes:
    - ./logstash/config:/etc/logstash/conf.d
  ports:
    - ""5000:5000""
  links:
    - elasticsearch
  environment:
    - LS_HEAP_SIZE=2048m",3
https://github.com/zouzias/docker-elk,## How can I add Logstash plugins? ##,"  To add plugins to logstash you have to: 
Add a RUN statement to the logstash/Dockerfile (ex. RUN logstash-plugin install logstash-filter-json)
Add the associated plugin code configuration to the logstash/config/logstash.conf file
",3
https://github.com/zouzias/docker-elk,## How can I enable a remote JMX connection to Logstash?,"  As for the Java heap memory, another environment variable allows to specify JAVA_OPTS used by Logstash. You'll need to specify the appropriate options to enable JMX and map the JMX port on the docker host. Update the container in the docker-compose.yml to add the LS_JAVA_OPTS environment variable with the following content (I've mapped the JMX service on the port 18080, you can change that), do not forget to update the -Djava.rmi.server.hostname option with the IP address of your Docker host (replace DOCKER_HOST_IP): logstash:
  build: logstash/
  command: logstash -f /etc/logstash/conf.d/logstash.conf
  volumes:
    - ./logstash/config:/etc/logstash/conf.d
  ports:
    - ""5000:5000""
    - ""18080:18080""
  links:
    - elasticsearch
  environment:
    - LS_JAVA_OPTS=-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=18080 -Dcom.sun.management.jmxremote.rmi.port=18080 -Djava.rmi.server.hostname=DOCKER_HOST_IP -Dcom.sun.management.jmxremote.local.only=false",3
https://github.com/zouzias/docker-elk,## How can I tune Elasticsearch configuration?,"  The Elasticsearch container is using the shipped configuration and it is not exposed by default. If you want to override the default configuration, create a file elasticsearch/config/elasticsearch.yml and add your configuration in it. Then, you'll need to map your configuration file inside the container in the docker-compose.yml. Update the elasticsearch container declaration to: elasticsearch:
  build: elasticsearch/
  command: elasticsearch -Des.network.host=_non_loopback_
  ports:
    - ""9200:9200""
  volumes:
    - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml You can also specify the options you want to override directly in the command field: elasticsearch:
  build: elasticsearch/
  command: elasticsearch -Des.network.host=_non_loopback_ -Des.cluster.name: my-cluster
  ports:
    - ""9200:9200""",3
https://github.com/zouzias/docker-elk,# Storage, ,3
https://github.com/zouzias/docker-elk,## How can I store Elasticsearch data?,"  The data stored in Elasticsearch will be persisted after container reboot but not after container removal. In order to persist Elasticsearch data even after removing the Elasticsearch container, you'll have to mount a volume on your Docker host. Update the elasticsearch container declaration to: elasticsearch:
  build: elasticsearch/
  command: elasticsearch -Des.network.host=_non_loopback_
  ports:
    - ""9200:9200""
  volumes:
    - /path/to/storage:/usr/share/elasticsearch/data This will store elasticsearch data inside /path/to/storage.",3
https://github.com/BhanuPatnana/tutorials,"# The REST with Spring"" Classes"""," After 5 months of work, here's the Master Class of REST With Spring: 
>> THE REST WITH SPRING MASTER CLASS",16
https://github.com/BhanuPatnana/tutorials,# Spring Tutorials,"  This project is a collection of small and focused tutorials each covering a single and well defined area of development.
Most of the tutorial projects are focused on the Spring Framework (and Spring Security).
In additional to Spring, the following technologies are in focus: core Java, Jackson, HttpClient, Guava.",1
https://github.com/BhanuPatnana/tutorials,# Working with the code in Eclipse,"  Any IDE can be used to work with the projects, but if you're using Eclipse, consider the following. 
import the included formatter in Eclipse:
https://github.com/eugenp/tutorials/tree/master/eclipse
",3
https://github.com/BhanuPatnana/tutorials,# CI - Jenkins,  This tutorials project is being built >> HERE,6
https://github.com/cpunion/react-web,# React Web [中文](https://github.com/taobaofed/react-web/blob/master/README-zh.md) [![npm version](https://badge.fury.io/js/react-web.svg)](http://badge.fury.io/js/react-web),A framework for building web apps with React Native compatible API.,1
https://github.com/cpunion/react-web,## Examples,,3
https://github.com/cpunion/react-web,### Web Examples,"Open with mobile device or emulate mobile in developer tools

UIExplorer
Movies
TicTacToe
Game2048",3
https://github.com/cpunion/react-web,### Example Source,"React Native Web Example
React Native Web Exploding Hearts",3
https://github.com/cpunion/react-web,## Adding web to an existing React Native project," If you already have a React Native project and want to add web support, you need to execute the following commands in your existing project directory:

Install npm install react-web-cli -g
Execute react-web init <ExistedProjectDir> to install stable npm version, or execute react-web init --version git+https://github.com/taobaofed/react-web.git <ExistedProjectDir> to install latest git version. That install react-web and devDependencies to your project and make a web directory with webpack.config.js file under your project
Register your app into a web platform. To do so, add the code from Fix platform differences. 2. Should run application on web platform to your index.ios.js file
Execute react-web start that starts the web dev server
Execute react-web bundle that builds the output",3
https://github.com/cpunion/react-web,## Getting Started,,3
https://github.com/cpunion/react-web,### Install,npm install --save git+https://github.com/taobaofed/react-web.git,3
https://github.com/cpunion/react-web,### Add Webpack configuration,"Inside your webpack configuration, alias the react-native package to the react-web package, then install and add haste-resolver-webpack-plugin plugin.

// webpack.config.js
var HasteResolverPlugin = require('haste-resolver-webpack-plugin');

module.exports = {
  resolve: {
    alias: {
      'react-native': 'react-web'
    }
  },
  plugins: [
    new HasteResolverPlugin({
      platform: 'web',
      nodeModules: ['react-web']
    })
  ]
}
See more detail of the webpack.config.js from React Native Web Example",3
https://github.com/cpunion/react-web,#### What does HasteResolverPlugin do?,"When using components of react-web, just require('ReactActivityIndicator'), and Webpack will build a bundle with ActivityIndicator.web.js for web platform.

HasteResolverPlugin will do the following for you:

Walk over all components and check out the @providesModule info.
When webpack build bundle, it makes your components recognised rather than throwing an error.
It will help webpack build bundle with correct file depending on the tar* platform.
You can find something like @providesModule ReactActivityIndicator on react-web component's comment, yes, it's for HasteResolverPlugin.",3
https://github.com/cpunion/react-web,### Require modules,"The CommonJS way
var React = require('react-native');
var {
  AppRegistry,
  StyleSheet,
  View,
  Platform,
} = React;
This reference method looks like we're in the way of using the native react-native way:

Like the require module in Node.js, and through Destructuring assignment, allows some components to be referenced in the scope of the current file.

But in fact it is quite different in React Web. When require('react-native'), in the construction of the webpack will be renamed, equivalent to require('react-web').

At the same time, this form of writing will put all the components into at one time, including ReactAppRegistry ReactView and so on, even some components the you did not use.

The Haste way
var AppRegistry = require('ReactAppRegistry');
var View = require('ReactView');
var Text = require('ReactText');
var Platform = require('ReactPlatform');
In this way, we load our components on demand, such as ReactAppRegistry or ReactView and so on.

Packaged components so that we no longer need to care about the differences between the platform.

As mentioned above, the HasteResolverPlugin plugin will help webpack to compile and package the code.",3
https://github.com/cpunion/react-web,#### The CommonJS way,,3
https://github.com/cpunion/react-web,#### The Haste way,,3
https://github.com/cpunion/react-web,### Fix platform differences,"Native events without direct pageX/pageY on web platform
if (Platform.OS == 'web') {
  var touch = event.nativeEvent.changedTouches[0];
  pageX = touch.pageX;
  pageY = touch.pageY;
} else {
  startX = event.nativeEvent.pageX;
  startY = event.nativeEvent.pageY;
}
Should run application on web platform
AppRegistry.registerComponent('Game2048', () => Game2048);
if(Platform.OS == 'web'){
  var app = document.createElement('div');
  document.body.appendChild(app);
  AppRegistry.runApplication('Game2048', {
    rootTag: app
  })
}
Should care about fetch domain on web platform
var fetch = Platform.OS === 'web'? require('ReactJsonp'): require('ReactFetch');
Without some APIs like LayoutAnimation on web platform
var LayoutAnimation = require('ReactLayoutAnimation')
if(Platform.OS !== 'web'){
  LayoutAnimation.configureNext(...)
}
Should manually specify the height of ScrollView
<ScrollView style={{height: 235}} horizontal={true} />",3
https://github.com/cpunion/react-web,### React Native compatible,,3
https://github.com/cpunion/react-web,#### Components,"ActivityIndicatorIOS - ReactActivityIndicator
ActivityIndicator - ReactActivityIndicator
DatePickerIOS - ReactDatePicker TODO
DrawerLayoutAndroid - ReactDrawerLayout
Image - ReactImage
ListView - ReactListView
Modal - ReactModal
Navigator - ReactNavigator
PickerIOS ReactPicker
ProgressViewIOS - ReactProgressView
ScrollView - ReactScrollView
SegmentedControlIOS - ReactSegmentedControl
SliderIOS - ReactSlider
Switch - ReactSwitch
SwitchAndroid - ReactSwitch
SwitchIOS - ReactSwitch
RefreshControl - ReactRefreshControl
TabBarIOS - ReactTabBar
Text - ReactText
TextInput - ReactTextInput
ToastAndroid - ReactToast
Touchable - ReactTouchable
TouchableHighlight - ReactTouchableHighlight
TouchableOpacity - ReactTouchableOpacity
TouchableWithoutFeedback - ReactTouchableWithoutFeedback
View - ReactView
ViewPagerAndroid - ReactViewPager",3
https://github.com/cpunion/react-web,#### APIs,"Alert - ReactAlert
AlertIOS - ReactAlert
Animated - ReactAnimated
AppRegistry - ReactAppRegistry
AsyncStorage - ReactAsyncStorage
Dimensions - ReactDimensions
Easing - ReactEasing
InteractionManager - ReactInteractionManager
LayoutAnimation - ReactLayoutAnimation
PanResponder - ReactPanResponder
PixelRatio - ReactPixelRatio
StyleSheet - ReactStyleSheet",36
https://github.com/cpunion/react-web,#### Plugins,"NativeModules - ReactNativeModules
Platform - ReactPlatform
processColor - ReactProcessColor",36
https://github.com/cpunion/react-web,## Scripts,"Linting - npm run lint - Must run it before commit.
Testing - npm test - Run unit testing by jest.
Developing - npm start - This will run a server at localhost:3000 and use Hot Module Reloading.
Demo deployment - npm run demo - Generate demo assets under pages directory.",3
https://github.com/cpunion/react-web,## License,React Web is BSD licensed.,5
https://github.com/alanqian/feedback,# feedback, Feedback tool similar to the Google Feedback based on jQuery and HTML2Canvas.,1
https://github.com/alanqian/feedback,## Usage,"  Load jQuery, the plugin, and its CSS:     <script src=""http://code.jquery.com/jquery-latest.min.js""></script>
	<script src=""feedback.js""></script>
	<link rel=""stylesheet"" href=""feedback.min.css"" /> Init plugin:     <script type=""text/javascript"">
        $.feedback({
            ajaxURL: 'http://test.url.com/feedback',
            html2canvasURL: 'js/html2canvas.js'
        });
    </script>",3
https://github.com/alanqian/feedback,## Requirements,"  
jQuery
html2canvas
",3
https://github.com/alanqian/feedback,## Compatibility,  Pretty much it should be working on any browser with canvas support. Browsers with no canvas support won't display the feedback button.,3
https://github.com/alanqian/feedback,## Demo,"  http://ivoviz.github.io/feedback/ - Click ""Send feedback"" at the bottom right of the page.",3
https://github.com/alanqian/feedback,## Post Data,"  The information from the client will be sent through ajax post request. The information is in JSON format. 
post.browser - Browser information.
post.url - The page URL.
post.note - Description of the feedback.
post.img - The screenshot of the feedback. - base64 encoded data URI!
post.html - The structure of the page.
",3
https://github.com/alanqian/feedback,## Options, ,36
https://github.com/alanqian/feedback,### ajaxURL (String),  The URL where the plugin will post the screenshot and additional informations. (JSON datatype) Default: '',36
https://github.com/alanqian/feedback,### postBrowserInfo (Boolean),"  Whether you want your client to post their browser information (such as useragent, plugins used, etc.) Default: true",36
https://github.com/alanqian/feedback,### postHTML (Boolean),  Whether you want your client to post the page's HTML structure. Default: true,36
https://github.com/alanqian/feedback,### postURL (Boolean),  Whether you want your client to post the URL of the page. Default: true,36
https://github.com/alanqian/feedback,### proxy (String),"  Url to the proxy which is to be used for loading cross-origin images. If left empty, cross-origin images won't be loaded. Default: ''",36
https://github.com/alanqian/feedback,### letterRendering (Boolean),  Whether to render each letter seperately. Necessary if letter-spacing is used. Default: false,36
https://github.com/alanqian/feedback,### initButtonText (String / HTML),  The default button text. Default: Send feedback,36
https://github.com/alanqian/feedback,### strokeStyle (String / HEX color),"  The color of the highlight border. You can use values either like 'black', 'red', etc. or HEX codes like '#adadad'. Default: black",36
https://github.com/alanqian/feedback,### shadowColor (String / HEX color),  The color of the shadow. Default: black,36
https://github.com/alanqian/feedback,### shadowOffsetX / shadowOffsetY (Integer),  Sets the horizontal / vertical distance of the shadow from the shape. Default: 1,36
https://github.com/alanqian/feedback,### shadowBlur (Integer),  The blur level for the shadow. Default: black,36
https://github.com/alanqian/feedback,### lineJoin (String),"  Sets the type of corner created, when two lines meet. Default: bevel",36
https://github.com/alanqian/feedback,### lineWidth (Integer),  Sets border of the highlighted area. Default: 3,36
https://github.com/alanqian/feedback,### html2canvasURL (String),  The URL where the plugin can download html2canvas.js from. Default: html2canvas.js,36
https://github.com/alanqian/feedback,### tpl.description / tpl.highlighter / tpl.overview / tpl.submitSuccess / tpl.submitError (String / HTML),"  The template of the plugin. You could change it any time, but keep in mind to keep the elements' ids and classes so the script won't break. Default: ...",36
https://github.com/alanqian/feedback,### onClose (Function),  Function that runs when you close the plugin. Default: null,36
https://github.com/alanqian/feedback,### screenshotStroke (Boolean),  Changing to false will remove the borders from the highlighted areas when taking the screenshot. Default: true,36
https://github.com/alanqian/feedback,### highlightElement (Boolean),"  By default when you move your cursor over an element the plugin will temporarily highlight it until you move your cursor out of that area.
I'm not exactly sure whether it's a good thing or not, but Google has it, so yeah. Default: true",36
https://github.com/alanqian/feedback,### initialBox (Boolean),  By Setting this true the user will have to describe the bug/idea before being able to highlight the area. Default: false,36
https://github.com/alanqian/feedback,### feedbackButton (String),  Define a custom button instead of the default button that appears on the lower right corner. Default: .feedback-btn,36
https://github.com/alanqian/feedback,### showDescriptionModal (Boolean),  Sets whether the next modal for entering description should appear or not Default: true,36
https://github.com/alanqian/feedback,### onScreenshotTaken (Function),  A callback function to be called when clicking on take screenshot button. The callback function's prototype is function(post) Default: {},36
https://github.com/alanqian/feedback,### isDraggable (Boolean),  Sets whether the user will be able to drag the feedback options modal or not Default: true,36
https://github.com/alanqian/feedback,## License,  feedback is released under the MIT license. (See LICENSE),5
https://github.com/d-vf/plotly,# plotly, An R package for creating interactive web-based graphs via plotly's JavaScript graphing library.,1
https://github.com/d-vf/plotly,## Installation,"  Install from CRAN: install.packages(""plotly"") Or install the latest development version (on GitHub) via devtools: devtools::install_github(""ropensci/plotly"")",3
https://github.com/d-vf/plotly,## Introduction,"  If you use ggplot2, simply call ggplotly() to convert your ggplot to an interactive, web-based version! library(plotly)
set.seed(100)
d <- diamonds[sample(nrow(diamonds), 1000), ]
p <- ggplot(data = d, aes(x = carat, y = price)) + 
  geom_point(aes(text = paste(""Clarity:"", clarity))) +
  geom_smooth(aes(colour = cut, fill = cut)) + facet_wrap(~ cut)
(gg <- ggplotly(p))  Click here to interact with the resulting graph (notice the custom hover text!) plotly also supports certain chart types that ggplot2 doesn't support (such as 3D surface, point, and line plots). You can easily create these (or any other plotly) charts using the high-level interface. plot_ly(z = volcano, type = ""surface"")  The ggplotly() function converts a ggplot object to a plotly object, so if you like, you may 'post-process' your ggplot graphs to add custom plotly features, for example: layout(gg, hovermode = ""closest"")",13
https://github.com/d-vf/plotly,## Learn more,"  
An overview of plotly's R API
Peruse the examples on plotly's R homepage and ggplot2 homepage
",6
https://github.com/d-vf/plotly,## Contributing,"  
We love collaboration! See the wiki and the code of conduct for more information.
",7
https://github.com/d-vf/plotly,## Stay in touch,"  
feedback@plot.ly
@plotlygraphs
  ",5
https://github.com/d-vf/plotly,##,,-
https://github.com/johntron/es2015-bootstrap,# ES2015 base project," This project uses Babel to transpile both back-end and front-end JavaScript on-the-fly, and SystemJS to load transpiled modules in the browser. See HyperDev or demo.",13
https://github.com/johntron/es2015-bootstrap,## Usage,"  Change presets and other Babel options by updating the ""babel"" section of package.json",3
https://github.com/johntron/es2015-bootstrap,## How it works,"  
HyperDev runs the start command which passes server.js through Babel (obeying options in package.json) and then runs the resulting JavaScript.
The server.js defines an Express server and middleware function which passes all requests ending in "".js"" through Babel's transformFile.
User requests the index in their browser.
Back-end serves index.html.
Browser loads SystemJS.
Browser requests app.js.
Back-end transpiles app.js using same options from step 1, but with SystemJS module definitions.
Browser evaluates ES5 code generated by previous step.
",1
https://github.com/carueda/stoqs,## Spatial Temporal Oceanographic Query System," 



 STOQS is a geospatial database and web application designed to give oceanographers
efficient integrated access to in situ measurement and ex situ sample data.
See http://www.stoqs.org.",16
https://github.com/carueda/stoqs,#### Getting started with a STOQS development system,"  First, install Vagrant and and VirtualBox
?there are standard installers for Mac, Windows, and Linux. (You will also need
X Windows System sofware on your computer.) Then create an empty folder off your
home directory such as Vagrants/stoqsvm, open a command prompt window, cd to that folder, and enter these
commands: curl ""https://raw.githubusercontent.com/stoqs/stoqs/master/Vagrantfile"" -o Vagrantfile
curl ""https://raw.githubusercontent.com/stoqs/stoqs/master/provision.sh"" -o provision.sh
vagrant plugin install vagrant-vbguest
vagrant up --provider virtualbox The vagrant up command takes an hour or so to provision and setup a complete CentOS 7
STOQS server that also includes MB-System, InstantReality, and all the Python data science
tools bundled in packages such as Anaconda.  All connections to this virtual machine are
performed from the the directory you installed it in; you must cd to it (e.g. cd ~/Vagrants/stoqsvm) before logging in with the vagrant ssh -- -X command.  After
installation finishes log into your new virtual machine and test it: vagrant ssh -- -X   # Wait for [vagrant@localhost ~]$ prompt
cd ~/dev/stoqsgit && source venv-stoqs/bin/activate
export DATABASE_URL=postgis://stoqsadm:CHANGEME@127.0.0.1:5432/stoqs
./test.sh CHANGEME In another terminal window start the development server (after a cd ~/Vagrants/stoqsvm): vagrant ssh -- -X   # Wait for [vagrant@localhost ~]$ prompt
cd ~/dev/stoqsgit && source venv-stoqs/bin/activate
export DATABASE_URL=postgis://stoqsadm:CHANGEME@127.0.0.1:5432/stoqs
stoqs/manage.py runserver 0.0.0.0:8000 --settings=config.settings.local Visit your server's STOQS User Interface using your host computer's browser: http://localhost:8000
 More instructions are in the doc/instructions directory ?see LOADING
for how to load your own data and CONTRIBUTING for how to share your work.
See example Jupyter Notebooks
that demonstrate specific analyses and
visualizations that cannot be accomplished in the STOQS User Interface.
Visit the STOQS Wiki pages for updates and links to presentations.
The stoqs-discuss list in Google Groups is also
a good place to ask questions and engage in discussion with the STOQS user and developer communities. Supported by the David and Lucile Packard Foundation, STOQS undergoes continual development
to help support the mission of the Monterey Bay Aquarium Research Institue.  If you have your
own server you will occasionally want to get new features with: git pull
./setup.sh If you use STOQS for your research please cite this publication: 
McCann, M.; Schramm, R.; Cline, D.; Michisaki, R.; Harvey, J.; Ryan, J., ""Using STOQS (The spatial
temporal oceanographic query system) to manage, visualize, and understand AUV, glider, and mooring data,""
in Autonomous Underwater Vehicles (AUV), 2014 IEEE/OES, pp.1-10, 6-9 Oct. 2014
doi: 10.1109/AUV.2014.7054414
",36
https://github.com/sebcrozet/nrays,# nrays," nrays is an attempt to make a 3 and 4 dimensional ray tracer in Rust.
It uses the ncollide3d library to cast rays.",16
https://github.com/sebcrozet/nrays,## 3d ray tracing,"  The current implementation handles phong lighting and reflexions. Nothing fancy here. It supports
the same geometries as ncollide3d, that is, plane, box, sphere, cylinder, cone, and Minkowski sum
of any supported convex objects. Triangle meshes are not yet supported. Here is an example of 3d ray
casting on the Minkowski sum of a cylinder and a box:  Several examples are given on the bin folder. Those are .scene files that can be read by the
loader3d executable produced by the command make. Those scenes require some assets
originally available here. The whole set of
asset is packaged here and has to be
extracted on the bin folder. Here is an example of commands you might type the first time: git clone git://github.com/sebcrozet/nrays.git
cd nrays
make
cd bin
wget https://www.dropbox.com/s/hts81ejea7quxes/media.tar.bz2
tar xf media.tar.bz2
../target/release/loader3d crytek_sponza.scene
",13
https://github.com/letup/CoreAR,# CoreAR.framework, ,1
https://github.com/letup/CoreAR,# Introduction and information,"  CoreAR.framework is open source AR framework. You can make an AR application using visual code like ARToolKit using this framework. CoreAR.framework does not depend on the other computer vision library like OpenCV. Considered portability, this framework is written only C or C++. The pixel array of an image is passed to CoreAR.framework and then visual code's identification number, rotation and translation matrix are obtained from the image including a visual code. Image processing speed of this framework is about 15 fps on iPhone4. Take notice that CoreAR.framework depends on Quartz Help Library and Real time image processing framework for iOS. You have to download these libraries and put on them at the path where CoreAR.framework has been installed.",1
https://github.com/letup/CoreAR,# License,  BSD License.,5
https://github.com/letup/CoreAR,# App Store,  You can take a sample application from App Store.,3
https://github.com/letup/CoreAR,# Sample code in C++,"  float codeSize = 1;
int croppingSize = 64;
int threshold = 100;
int width = (int)bufferSize.width;
int height = (int)bufferSize.height;

// do it
if (chaincodeBuff == NULL)
	chaincodeBuff = (unsigned char*)malloc(sizeof(unsigned char) * width * height);

// binarize for chain code
for (int y = 0; y < height; y++)
	for (int x = 0; x < width; x++)
		*(chaincodeBuff + x + y * width) = *(buffer + x + y * width) < threshold ? CRChainCodeFlagUnchecked : CRChainCodeFlagIgnore;

// prepare to parse chain code
CRChainCode *chaincode = new CRChainCode();
chaincode->parsePixel(chaincodeBuff, width, height);

// clear previous buffer
CRCodeList::iterator it = codeListRef->begin();
while(it != codeListRef->end()) {
	SAFE_DELETE(*it);
	++it;
}
codeListRef->clear();

// reload detected codes
if (!chaincode->blobs->empty()) {
	std::list<CRChainCodeBlob*>::iterator blobIterator = chaincode->blobs->begin();
	while(blobIterator != chaincode->blobs->end()) {
		if (!(*blobIterator)->isValid(width, height)) {
			blobIterator++;
			continue;
		}
		CRCode *code = (*blobIterator)->code();	
		if(code) {
			// estimate and optimize pose and position
			code->normalizeCornerForImageCoord(width, height, focalLength, focalLength);
			code->getSimpleHomography(codeSize);
			code->optimizeRTMatrinxWithLevenbergMarquardtMethod();
			
			// cropping code image area
			code->crop(croppingSize, croppingSize, focalLength, focalLength, codeSize, buffer, width, height);
			codeListRef->push_back(code);
		}
		blobIterator++;
	}
}
",3
https://github.com/letup/CoreAR,# Sample code in C (depracted),"  // Copy image buffer from camera into ""pixel"".
int width;
int height;
unsigned char *pixel = (unsigned char*)malloc(sizeof(unsigned char) * width * height);

// codeInfoStorage receives the result of visual code recognition.
CRCodeInfoStorage *codeInfoStorage = CRCreateCodeInfoStorage();

// storage to save visual code templates.
CRCodeImageTemplate *codeImageTemplateStorage = CRCreateCodeImageTemplateStorage();

// make template to recognize visual codes.
int c_width;
int c_height;
unsigned char *c_p = (unsigned char*)malloc(sizeof(unsigned char) * c_width * c_height);

/* read images of visual codes you want to recognize */

CRCodeImageTemplate *template = CRCreateCodeImageTemplate(c_p, c_width, c_height);
template->code = codeNumber;
template->size = codeSize;
CRCodeImageTemplateStorageAddNewTemplate(codeImageTemplateStorage, template);
free(c_p);

// Start extraction
CRChainCodeStorage *storage = CRCreateChainCodeStorageByParsingPixel(pixel, width, height);
CRChainCodeStorageDetectCornerWithLSM(storage);
CRCodeInfoStorageAddCodeInfoByExtractingFromChainCode(codeInfoStorage, storage, valueBuffer, width, height, codeImageTemplateStorage);

// Release
CRReleaseChainCodeStorage(&storage);
CRReleaseCodeInfoStorage(&codeInfoStorage);
free(pixel);
",3
https://github.com/letup/CoreAR,# Frequently Asked Questions,"  

I can't compile CoreAR.framework...

Ans. CoreAR.framework depends on Quartz Help Library and Real time image processing framework for iOS. You have to download these libraries and put on them at the path where CoreAR.framework has been installed.



How do I render a 3D model on the code with CoreAR.framework?

Ans. CoreAR.framework does not support rendering any 3D model files. You have to write a code to render 3D model files with OpenGLES. Sample program does not render a cube and Utah teapot with 3D model files but with OpenGLES code.


",6
https://github.com/letup/CoreAR,# Blog,"  
sonson.jp
Sorry, Japanese only....
",6
https://github.com/letup/CoreAR,# Dependency,"  
Quartz Help Library
Real time image processing framework for iOS
",3
https://github.com/letup/CoreAR,# Acknowledgement,"  
DENSO IT Laboratory, Inc. has supported my work.
There are some public projects supported by DENSO IT Laboratory, Inc. in cvlab.jp.
",5
https://github.com/wthit56/node.unnecessary.js,# Node.Unnecessary.js," My previous (and ongiong) project, Unnecesary.js, focussed on built-in behaviours and methods within JavaScript. The idea was to demonstrate, through easy-to-follow, well-commented code, how things worked behind the scenes. How does the event loop work? How does type coersion work when comparing two values? The group of source .js files were created to educate people on how JavaScript worked from the inside out. But beyond that, they were pretty useless... ""unnecesary"", you might say. With the new project of Node.Unnecesary.js, I take this methodology to the world of node.js. This time, however, the .js files could be of some use to people. The browser doesn't have many of the utility objects and methods available to node users. So I've created the source files with this in mind. You can require(.js) and use the code as per usual in node, or add a reference to the .js file in a web page, and the ""module"" will be added to the window object, allowing you to use its functionality in your browser-based code. There are a few small tweaks to how things work so that the module is more useful when used in a browser, for urls and the like.",12
https://github.com/wthit56/node.unnecessary.js,## Modules,"  There is 1 module completed so far. Here's an up-to-date list of them all: 
Path
",1
https://github.com/wthit56/node.unnecessary.js,## TODO,"  
Add browser-based tests for urls
",4
https://github.com/romerun/XChange,## XChange, A Financial Exchange Library for Java,1
https://github.com/romerun/XChange,## Description,"  XChange is a library providing a simple and consistent API for interacting with a diverse set of financial security exchanges, including support for Bitcoin. A complete list of implemented exchanges, data providers and brokers can be found on our Exchange Support page. Usage is very simple: Create an Exchange instance, get the appropriate service, and request data.",1
https://github.com/romerun/XChange,## Example,"  // Use the factory to get the version 1 MtGox exchange API using default settings
Exchange mtGox = ExchangeFactory.INSTANCE.createExchange(""com.xeiam.xchange.mtgox.v1.MtGoxExchange"");

// Interested in the public polling market data feed (no authentication)
PollingMarketDataService marketDataService = mtGox.getPollingMarketDataService();

// Get the latest ticker data showing BTC to USD
Ticker ticker = marketDataService.getTicker(Currencies.BTC, Currencies.USD);

System.out.println(ticker.toString());
 All exchange implementations expose the same API, but you can also directly access the raw data. Now go ahead and study some more examples, download the thing and provide feedback.",3
https://github.com/romerun/XChange,## Features,"  
MIT license
consistent API across all implemented exchanges
active development
very minimal 3rd party dependencies
modular components
polling and streaming capability
",1
https://github.com/romerun/XChange,## More Info,"  Project Site: http://xeiam.com/xchange.jsp
Example Code: http://xeiam.com/xchange_examplecode.jsp
Change Log: http://xeiam.com/xchange_changelog.jsp
Java Docs: http://xeiam.com/xchange/javadoc/index.html
Sonar Code Quality: http://sonar.xeiam.com/
Jenkins CI: http://ci.xeiam.com/",6
https://github.com/romerun/XChange,## Wiki,"  Home: https://github.com/timmolter/XChange/wiki
Design Notes: https://github.com/timmolter/XChange/wiki/Design-Notes
Milestones: https://github.com/timmolter/XChange/wiki/Milestones
Exchange Support: https://github.com/timmolter/XChange/wiki/Exchange-support
New Implementation Best Practices: https://github.com/timmolter/XChange/wiki/New-Implementation-Best-Practices",6
https://github.com/romerun/XChange,## Getting Started,  XChange is semantically versioned: http://semver.org,3
https://github.com/romerun/XChange,### Non-Maven,  Download XChange Jars: http://xeiam.com/xchange.jsp,3
https://github.com/romerun/XChange,### Maven,"  The XChange release artifacts are hosted on Maven Central. For snapshots, add the following repository to your pom.xml file. <repository>
  <id>sonatype-oss-snapshot</id>
  <snapshots/>
  <url>https://oss.sonatype.org/content/repositories/snapshots</url>
</repository>
 Add the following dependencies in your pom.xml file. You will need at least xchange-core. Add the additional dependencies for the exchange implementations you are interested in. There is example code for all the implementations in xchange-examples. <dependency>
  <groupId>com.xeiam.xchange</groupId>
  <artifactId>xchange-core</artifactId>
  <version>1.4.0</version>
</dependency>
<dependency>
  <groupId>com.xeiam.xchange</groupId>
  <artifactId>xchange-examples</artifactId>
  <version>1.4.0</version>
</dependency>
<dependency>
  <groupId>com.xeiam.xchange</groupId>
  <artifactId>xchange-mtgox</artifactId>
  <version>1.4.0</version>
</dependency>
<dependency>
  <groupId>com.xeiam.xchange</groupId>
  <artifactId>xchange-cavirtex</artifactId>
  <version>1.4.0</version>
</dependency>
<dependency>
  <groupId>com.xeiam.xchange</groupId>
  <artifactId>xchange-openexchangerates</artifactId>
  <version>1.4.0</version>
</dependency>
<dependency>
  <groupId>com.xeiam.xchange</groupId>
  <artifactId>xchange-btce</artifactId>
  <version>1.4.0</version>
</dependency>
<dependency>
  <groupId>com.xeiam.xchange</groupId>
  <artifactId>xchange-bitstamp</artifactId>
  <version>1.4.0</version>
</dependency>
    <dependency>
  <groupId>com.xeiam.xchange</groupId>
  <artifactId>xchange-campbx</artifactId>
  <version>1.4.0</version>
</dependency>
<dependency>
  <groupId>com.xeiam.xchange</groupId>
  <artifactId>xchange-bitcoincharts</artifactId>
  <version>1.4.0</version>
</dependency>
",3
https://github.com/romerun/XChange,## Building,"  mvn clean package
mvn javadoc:aggregate
mvn clean integration-test -P run-integration-tests
mvn dependency:tree",3
https://github.com/romerun/XChange,## Bugs,"  Windows version of Pass (http://www.passwordstore.org/) in the sense that the store (password structure) is and should be exactly the same between the two programs. If you want Pass4Win in your language, that's now quite possible with the help of Crowdin (http://crowdin.com/). Drop me an e-mail and I'll invite you as translator. The available languages are listed at https://github.com/mbos/Pass4Win/wiki/Translation I really liked the idea of a password store I could access on my shell, and even Android devices. But my main PC is a Windows machine.
So I needed a Windows implementation..... Make sure you have GnuPG for windows installed (http://www.gpg4win.org/) and have at least one secret key.
The setup can be downloaded from https://github.com/mbos/Pass4Win/releases I'm using GpgAPI (https://gpgapi.codeplex.com/) for interfacing with GnuPG. And LibGit2Sharp (https://github.com/libgit2/libgit2sharp) for git integration. Feel free to use the add issue button, feedback, bugreports, it's all very welcome!
If you wish to donate feel free, you can do so with bitcoin 184CdvL6i9sDoEpMNST6J71cepjr7nkaHg. If you don't wish to donate feel free  also :-) If you want news about release date's etc. Follow @Pass4Win (https://twitter.com/Pass4Win) on twitter I'll try to keep you all up to date. There's a Gitter page https://gitter.im/mbos/Pass4Win where you can ask questions etc. Regards, Mike",7
https://github.com/romerun/XChange,## Contributing,"  If you'd like to submit a new implementation for another exchange, please take a look at New Implementation Best Practices first, as there are lots of time-saving tips! For more information such as a contributor list and a list of known projects depending on XChange, visit the Main Project Wiki.",7
https://github.com/romerun/XChange,## Donations,  17dQktcAmU4urXz7tGk2sbuiCqykm3WLs6,-
https://github.com/bazmecode/Pass4Win,# Pass4Win,,12356
https://github.com/jinchunguang/yii2-app-learning,# Yii 2 Advanced Project Template,,16
https://github.com/jinchunguang/yii2-app-learning,## DIRECTORY STRUCTURE,,1
https://github.com/hughperkins/clBLAS,## Build Status,,4
https://github.com/hughperkins/clBLAS,# clBLAS,"  This repository houses the code for the OpenCL?BLAS portion of clMath.
The complete set of BLAS level 1, 2 & 3 routines is implemented. Please
see Netlib BLAS for the list of supported routines. In addition to GPU
devices, the library also supports running on CPU devices to facilitate
debugging and multicore programming. APPML 1.10 is the most current
generally available pre-packaged binary version of the library available
for download for both Linux and Windows platforms. The primary goal of clBLAS is to make it easier for developers to
utilize the inherent performance and power efficiency benefits of
heterogeneous computing. clBLAS interfaces do not hide nor wrap OpenCL
interfaces, but rather leaves OpenCL state management to the control of
the user to allow for maximum performance and flexibility. The clBLAS
library does generate and enqueue optimized OpenCL kernels, relieving
the user from the task of writing, optimizing and maintaining kernel
code themselves.",12
https://github.com/hughperkins/clBLAS,## clBLAS update notes 09/2015,"  
Introducing AutoGemm

clBLAS's Gemm implementation has been comprehensively overhauled to use AutoGemm. AutoGemm is a suite of python scripts which generate optimized kernels and kernel selection logic, for all precisions, transposes, tile sizes and so on.
CMake is configured to use AutoGemm for clBLAS so the build and usage experience of Gemm remains unchanged (only performance and maintainability has been improved). Kernel sources are generated at build time (not runtime) and can be configured within CMake to be pre-compiled at build time.
clBLAS users with unique Gemm requirements can customize AutoGemm to their needs (such as non-default tile sizes for very small or very skinny matrices); see AutoGemm documentation for details.


",4
https://github.com/hughperkins/clBLAS,## clBLAS library user documentation,"  Library and API documentation for developers is available online as
a GitHub Pages website",6
https://github.com/hughperkins/clBLAS,## Google Groups,"  Two mailing lists have been created for the clMath projects: 

clmath@googlegroups.com - group whose focus is to answer
questions on using the library or reporting issues


clmath-developers@googlegroups.com - group whose focus is for
developers interested in contributing to the library code itself

",5
https://github.com/hughperkins/clBLAS,## clBLAS Wiki,"  The project wiki contains helpful documentation, including a build
primer",6
https://github.com/hughperkins/clBLAS,## Contributing code,"  Please refer to and read the Contributing document for guidelines on
how to contribute code to this open source project. The code in the
/master branch is considered to be stable, and all pull-requests should
be made against the /develop branch.",7
https://github.com/hughperkins/clBLAS,## License,"  The source for clBLAS is licensed under the Apache License, Version 2.0",5
https://github.com/hughperkins/clBLAS,## Example,"  The simple example below shows how to use clBLAS to compute an OpenCL accelerated SGEMM     #include <sys/types.h>
    #include <stdio.h>

    /* Include the clBLAS header. It includes the appropriate OpenCL headers */
    #include <clBLAS.h>

    /* This example uses predefined matrices and their characteristics for
     * simplicity purpose.
    */

    #define M  4
    #define N  3
    #define K  5

    static const cl_float alpha = 10;

    static const cl_float A[M*K] = {
    11, 12, 13, 14, 15,
    21, 22, 23, 24, 25,
    31, 32, 33, 34, 35,
    41, 42, 43, 44, 45,
    };
    static const size_t lda = K;        /* i.e. lda = K */

    static const cl_float B[K*N] = {
    11, 12, 13,
    21, 22, 23,
    31, 32, 33,
    41, 42, 43,
    51, 52, 53,
    };
    static const size_t ldb = N;        /* i.e. ldb = N */

    static const cl_float beta = 20;

    static cl_float C[M*N] = {
        11, 12, 13,
        21, 22, 23,
        31, 32, 33,
        41, 42, 43,
    };
    static const size_t ldc = N;        /* i.e. ldc = N */

    static cl_float result[M*N];

    int main( void )
    {
    cl_int err;
    cl_platform_id platform = 0;
    cl_device_id device = 0;
    cl_context_properties props[3] = { CL_CONTEXT_PLATFORM, 0, 0 };
    cl_context ctx = 0;
    cl_command_queue queue = 0;
    cl_mem bufA, bufB, bufC;
    cl_event event = NULL;
    int ret = 0;

    /* Setup OpenCL environment. */
    err = clGetPlatformIDs( 1, &platform, NULL );
    err = clGetDeviceIDs( platform, CL_DEVICE_TYPE_GPU, 1, &device, NULL );

    props[1] = (cl_context_properties)platform;
    ctx = clCreateContext( props, 1, &device, NULL, NULL, &err );
    queue = clCreateCommandQueue( ctx, device, 0, &err );

    /* Setup clBLAS */
    err = clblasSetup( );

    /* Prepare OpenCL memory objects and place matrices inside them. */
    bufA = clCreateBuffer( ctx, CL_MEM_READ_ONLY, M * K * sizeof(*A),
                          NULL, &err );
    bufB = clCreateBuffer( ctx, CL_MEM_READ_ONLY, K * N * sizeof(*B),
                          NULL, &err );
    bufC = clCreateBuffer( ctx, CL_MEM_READ_WRITE, M * N * sizeof(*C),
                          NULL, &err );

    err = clEnqueueWriteBuffer( queue, bufA, CL_TRUE, 0,
        M * K * sizeof( *A ), A, 0, NULL, NULL );
    err = clEnqueueWriteBuffer( queue, bufB, CL_TRUE, 0,
        K * N * sizeof( *B ), B, 0, NULL, NULL );
    err = clEnqueueWriteBuffer( queue, bufC, CL_TRUE, 0,
        M * N * sizeof( *C ), C, 0, NULL, NULL );

        /* Call clBLAS extended function. Perform gemm for the lower right sub-matrices */
        err = clblasSgemm( clblasRowMajor, clblasNoTrans, clblasNoTrans,
                                M, N, K,
                                alpha, bufA, 0, lda,
                                bufB, 0, ldb, beta,
                                bufC, 0, ldc,
                                1, &queue, 0, NULL, &event );

    /* Wait for calculations to be finished. */
    err = clWaitForEvents( 1, &event );

    /* Fetch results of calculations from GPU memory. */
    err = clEnqueueReadBuffer( queue, bufC, CL_TRUE, 0,
                                M * N * sizeof(*result),
                                result, 0, NULL, NULL );

    /* Release OpenCL memory objects. */
    clReleaseMemObject( bufC );
    clReleaseMemObject( bufB );
    clReleaseMemObject( bufA );

    /* Finalize work with clBLAS */
    clblasTeardown( );

    /* Release OpenCL working objects. */
    clReleaseCommandQueue( queue );
    clReleaseContext( ctx );

    return ret;
    }",3
https://github.com/hughperkins/clBLAS,## Build dependencies, ,3
https://github.com/hughperkins/clBLAS,### Library for Windows,"  
Windows® 7/8
Visual Studio 2010 SP1, 2012
An OpenCL SDK, such as APP SDK 2.8
Latest CMake
",3
https://github.com/hughperkins/clBLAS,### Library for Linux,"  
GCC 4.6 and onwards
An OpenCL SDK, such as APP SDK 2.9
Latest CMake
",3
https://github.com/hughperkins/clBLAS,### Library for Mac OSX,"  
Recommended to generate Unix makefiles with cmake
",3
https://github.com/hughperkins/clBLAS,### Test infrastructure,"  
Googletest v1.6
ACML on windows/linux; Accelerate on Mac OSX
Latest Boost
",3
https://github.com/hughperkins/clBLAS,### Performance infrastructure,"  
Python
",3
https://github.com/ruoshui/srs,#Simple-RTMP-Server," 
Completely rewrite HLS following m3u8/ts spec, and HLS support h.264+aac/mp3.
High efficient RTMP deliverying support 7k+ concurrency, vhost based, both origin and edge.
Embeded simplified media HTTP server for HLS, api and HTTP flv/ts/mp3/aac streaming.
Variety input: RTMP, pull by ingest file or stream(HTTP/RTMP/RTSP), push by stream caster
RTSP/MPEGTS-over-UDP.
Popular internet delivery: RTMP/HDS for flash, HLS for mobile(IOS/IPad/MAC/Android), HTTP
flv/ts/mp3/aac streaming for user prefered.
Enhanced DVR and hstrs: segment/session/append plan, customer path and HTTP callback.
the hstrs(http stream trigger rtmp source) enable the http-flv stream standby util encoder
start publish, similar to rtmp, which will trigger edge to fetch from origin.
Multiple feature: transcode, forward, ingest, http hooks, dvr, hls, rtsp, http streaming,
http api, refer, log, bandwith test and srs-librtmp.
Best maintainess: simple arch over state-threads(coroutine), single thread, single process
and for linux/osx platform, common server x86-64/i386/arm/mips cpus, rich comments, strictly
follows RTMP/HLS/RTSP spec.
Easy to use: both English and Chinese wiki, typically config files in trunk/conf, traceable
and session based log, linux service script and install script.
MIT license, open source with product management and evolution.
 Enjoy it!",134
https://github.com/ruoshui/srs,## About,"  SRS(Simple RTMP Server) over state-threads created in 2013.10. SRS delivers rtmp/hls/http/hds live on x86/x64/arm/mips linux/osx,
supports origin/edge/vhost and transcode/ingest and dvr/forward
and http-api/http-callback/reload, introduces tracable
session-oriented log, exports client srs-librtmp,
with stream caster to push MPEGTS-over-UDP/RTSP to SRS,
provides EN/CN wiki and the most simple architecture.",14
https://github.com/ruoshui/srs,## AUTHORS,"  There are two types of people that have contributed to the SRS project: 
AUTHORS: Contribute important features. Names of all
PRIMARY response in NetConnection.connect and metadata.
CONTRIBUTORS: Submit patches, report bugs, add translations, help answer
newbie questions, and generally make SRS that much better.
 About all PRIMARY, AUTHORS and CONTRIBUTORS, read AUTHORS.txt. A big THANK YOU goes to: 
All friends of SRS for big supports.
Genes amd Mabbott for creating st(state-threads).
Michael Talyanksy for introducing us to use st.
Roman Arutyunyan for creating nginx-rtmp for SRS to refer to.
Joyent for creating http-parser for http-api for SRS.
Igor Sysoev for creating nginx for SRS to refer to.
FFMPEG and libx264 group for SRS to use to transcode.
Guido van Rossum for creating Python for api-server for SRS.
",5
https://github.com/ruoshui/srs,## Mirrors,"  Github: https://github.com/ossrs/srs, the GIT usage(CN, EN) git clone https://github.com/ossrs/srs.git
 CSDN: https://code.csdn.net/winlinvip/srs-csdn, the GIT usage(CN, EN) git clone https://code.csdn.net/winlinvip/srs-csdn.git
 OSChina: http://git.oschina.net/winlinvip/srs.oschina, the GIT usage(CN, EN) git clone https://git.oschina.net/winlinvip/srs.oschina.git
 Gitlab: https://gitlab.com/winlinvip/srs-gitlab, the GIT usage(CN, EN) git clone https://gitlab.com/winlinvip/srs-gitlab.git
",3
https://github.com/ruoshui/srs,## Usage,"  Step 1: get SRS git clone https://github.com/ossrs/srs &&
cd srs/trunk
 Step 2: build SRS,
Requires Centos6.x/Ubuntu12 32/64bits, others see Build(CN,EN). ./configure && make
 Step 3: start SRS ./objs/srs -c conf/srs.conf
 See also: 
Usage: How to delivery RTMP?(CN, EN)
Usage: How to delivery RTMP Cluster?(CN, EN)
Usage: How to delivery HTTP FLV Live Streaming?(CN, EN)
Usage: How to delivery HTTP FLV Live Streaming Cluster?(CN, EN)
Usage: How to delivery HLS?(CN, EN)
Usage: How to delivery HLS for other codec?(CN, EN)
Usage: How to transode RTMP stream by SRS?(CN, EN)
Usage: How to forward stream to other server?(CN, EN)
Usage: How to deploy low lantency application?(CN, EN)
Usage: How to deploy SRS on ARM?(CN, EN)
Usage: How to ingest file/stream/device to SRS?(CN, EN)
Usage: How to use SRS-HTTP-server to delivery HTTP/HLS stream?(CN, EN)
Usage: How to show the demo of (CN, EN)
Usage: How to publish h.264 raw stream to CN, EN)
Usage: Solution using SRS?(CN, EN)
Usage: Why SRS?(CN, EN)
",36
https://github.com/ruoshui/srs,## Wiki,"  SRS 1.0 wiki Please select your language: 
SRS 1.0 English
SRS 1.0 Chinese
 SRS 2.0 wiki Please select your language: 
SRS 2.0 English
SRS 2.0 Chinese
",6
https://github.com/ruoshui/srs,## Donation,"  Donation:
http://www.ossrs.net/srs.release/donation/index.html Donations:
https://github.com/ossrs/srs/blob/develop/DONATIONS.txt",6
https://github.com/ruoshui/srs,## System Requirements,"  Supported operating systems and hardware: 
All Linux , both 32 and 64 bits
Apple OSX(Darwin), both 32 and 64bits.
All hardware with x86/x86_64/arm/mips cpu.
",3
https://github.com/crann/angular-ckeditor-directive,###Read Me,"An AngularJS directive for the CKEditor, binding the AngularJS controller to the CKEditor's mark-up, plain-text and configuration options.",1
https://github.com/crann/angular-ckeditor-directive,####Getting Started,"Copy over the file dist/ck-editor.min.js or dist/ck-editor.js

Include the path to the direcitve file in index.html

 <script src=""[your path]/directives/ck-editor.js""></script>
Include the directive as a dependency when defining the angular app:

 var exampleApp = angular.module('exampleApp', ['ckeditor']);
Include the required CKEditor options in the controller:

 $scope.ckEditorOptions = {
         toolbar: 'full',
         toolbar_full: [
             {
                 name: 'basicstyles',
                 items: ['Bold', 'Italic', 'Strike', 'Underline']
             },
             {
                 name: 'paragraph',
                 items: ['BulletedList', 'NumberedList', 'Blockquote']
             },
             {
                 name: 'insert',
                 items: ['Table', 'SpecialChar']
             },
             {
                 name: 'forms',
                 items: ['Outdent', 'Indent']
             },
             {
                 name: 'clipboard',
                 items: ['Undo', 'Redo']
             }
         ],
         uiColor: '#FAFAFA',
         height: '400px'
     };
Reference the directive in the HTML page:

 <textarea ck-editor ng-model=""markUp"" plaintext=""plainText"" options=""ckEditorOptions""></textarea>
See the examples folder for a basic implementation of the directive.",3
https://github.com/crann/angular-ckeditor-directive,####Requirements,"AngularJS - v.1.2.25
CKEditor - v.4.4.45",3
https://github.com/crann/angular-ckeditor-directive,#####Credit,"This directive is a combination of the various code snippets provided in the answers to the following StackOverflow question with a few of my tweaks added too:

http://stackoverflow.com/questions/18917262/updating-textarea-value-with-ckeditor-content-in-angular-js",5
https://github.com/troska/homebrew-cask,# Homebrew-Cask,,1
https://github.com/troska/homebrew-cask,"#### Important December update: Homebrew-Cask will now be kept up to date together with Homebrew (see [#15381](https://github.com/caskroom/homebrew-cask/pull/15381) for details). If you haven’t yet, run `brew uninstall --force brew-cask; brew update` to switch to the new system."," Homebrew-Cask will now be kept up to date together with Homebrew (see #15381 for details). If you havent yet, run brew uninstall --force brew-cask; brew update to switch to the new system.",346
https://github.com/troska/homebrew-cask,#### Important: At some point in the future Homebrew-cask will change its behaviour from linking apps to moving them. See [issue #13201](https://github.com/caskroom/homebrew-cask/issues/13201) for details.,At some point in the future Homebrew-cask will change its behaviour from linking apps to moving them. See issue #13201 for details.,46
https://github.com/troska/homebrew-cask,## Let’s try it!,"  To start using Homebrew-Cask, you just need Homebrew installed. $ brew cask install google-chrome
=> Downloading https://dl.google.com/chrome/mac/stable/GGRO/googlechrome.dmg
=> Success! google-chrome installed to /opt/homebrew-cask/Caskroom/google-chrome/stable-channel
=> Linking Google Chrome.app to /Users/phinze/Applications/Google Chrome.app And there we have it. Google Chrome installed with a few quick commands: no clicking, no dragging, no dropping. $ open ~/Applications/""Google Chrome.app""",3
https://github.com/troska/homebrew-cask,## Learn More,"  
Find basic documentation on using homebrew-cask in USAGE.md
Want to contribute a Cask? Awesome! See CONTRIBUTING.md
Want to hack on our code? Also awesome! See hacking.md
More project-related details and discussion are available in FAQ.md and CASK_LANGUAGE_REFERENCE.md
",67
https://github.com/troska/homebrew-cask,## Questions? Wanna chat?,"  We’re really rather friendly! Here are the best places to talk about the project: 
Start an issue on GitHub using one of these templates:

Bug report
Feature request
Cask request


Join us on IRC, we’re at #homebrew-cask on Freenode
",56
https://github.com/troska/homebrew-cask,## Reporting Bugs,"  We still have bugs ?and we are busy fixing them!  If you have a problem, don’t be shy about reporting it on our GitHub issues page. Always search for your issue before posting a new one. When reporting bugs, remember that homebrew-cask is an independent project from Homebrew. Do your best to direct bug reports to the appropriate project. If your command-line started with brew cask, bring the bug to us first! Before reporting a bug, make sure you have the latest versions of homebrew, homebrew-cask, and all Taps by running the following command: $ brew update; brew cleanup; brew cask cleanup In addition, if you haven’t yet, run brew uninstall --force brew-cask; brew update once to switch to the new system. If the issue persists, please run the problematic command with the --verbose flag and post its and brew cask doctor’s outputs in distinct fenced code blocks.",7
https://github.com/troska/homebrew-cask,## License:,  Code is under the BSD 2 Clause (NetBSD) license,5
https://github.com/BuckleTypes/bs-webapi-incubator,# bs-webapi,,1
https://github.com/BuckleTypes/bs-webapi-incubator,## Installation," Experimental bindings to the DOM and other Web APIs. 
 API docs are available at
https://reasonml-community.github.io/bs-webapi-incubator/api/Webapi/ , but
documentation comments are sparse as the code mostly just consists of
external declarations with type signatures. The bindings generally also
correspond very well to the Web APIs they bind to, so using MDN along
with GitHub should go a long way.",3
https://github.com/BuckleTypes/bs-webapi-incubator,## Usage,"  See the examples folder Please only use the modules exposed through the toplevel module Webapi, for example Webapi.Dom.Element. In particular, don't use the 'flat' modules like Webapi__Dom__Element as these are considered private and are not guaranteed to be backwards-compatible.",3
https://github.com/BuckleTypes/bs-webapi-incubator,## Some notes on the DOM API,"  The DOM API is mostly organized into interfaces and relies heavily on inheritance. The ergonomics of the API is also heavily dependent on dynamic typing, which makes it somewhat challenging to implement a thin binding layer that is both safe and ergonomic. To achieve this we employ subtyping and implementation inheritance, concepts which aren't very idiomatic to OCaml (or Reason), but all the more beneficial to understand in order to be able to use these bindings effectively.",3
https://github.com/BuckleTypes/bs-webapi-incubator,### Subtyping,"  The Dom types, and the relationships between them, are actually defined in the Dom module that ships with bs-platform (Source code), where you'll find a bunch of types that look like this: type _element('a);
type element_like('a) = node_like(_element('a));
type element = element_like(_baseClass); This is subtyping implemented with abstract types and phantom arguments. The details of how this works isn't very important (but see #23 for a detailed explanation of how exactly this trickery works) in order to just use them, but there are a few things you should know: 
If you expand the alias of a concrete DOM type, you'll discover it's actually a list of abstract types. e.g. element expands to _baseClass _element _node _eventTarget_like This means element is a subtype of _element, _node and _eventTarget_like.
The _like type are ""open"" (because they have a type variable). This means that a function accepting an 'a element_like will accept any ""supertype"" of element_like. A function accepting just an element will only accept an element (Technically element is actually a ""supertype"" of element_like too).
 This system works exceptionally well, but has one significant flaw: It makes type errors even more complicated than they normally are. If you know what to look for it's not that bad, but unfortunately the formatting of these errors don't make looking for it any easier. We hope to improve that in other ways (see BetterErrors)",3
https://github.com/BuckleTypes/bs-webapi-incubator,### Implementation inheritance,"  If you've looked through the source code a bit, you've likely come across code like this: include Webapi__Dom__EventTarget.Impl({ type nonrec t = t });
include Webapi__Dom__Node.Impl({ type nonrec t = t });
include Webapi__Dom__ParentNode.Impl({ type nonrec t = t });
include Webapi__Dom__NonDocumentTypeChildNode.Impl({ type nonrec t = t });
include Webapi__Dom__ChildNode.Impl({ type nonrec t = t });
include Webapi__Dom__Slotable.Impl({ type nonrec t = t });
include Impl({ type nonrec t = t }); This is the implementation inheritance. Each ""inheritable"" module defines an ""Impl"" module where all its exported functions are defined. include Webapi__Dom__Node.Impl { type nonrec t = t }; means that all the functions in Webapi__Dom__Node.Impl should be included in this module, but with the t type of that module replaced by the t type of this one. And that's it, it now has all the functions. Implementation inheritance is used instead of subtyping to make it easier to understand which functions operate on any given ""subject"". If you have an element and you need to use a function defined in Node, let's say removeChild you cannot just use Node.removeChild. Instead you need to use Element.removeChild, which you can since Element inherits from Node. As a general rule, always use the function in the module corresponding to the type you have. You'll find this makes it very easy to see what types you're dealing with just by reading the code.",3
https://github.com/christopherwoo/data-science-ipython-notebooks,# data-science-ipython-notebooks," This repo is a collection of IPython Notebooks I reference while working with data.  Although I developed and maintain many notebooks, other notebooks I reference were created by various authors, who are credited within their notebook(s) by providing their names and/or a link to their source. For detailed instructions, scripts, and tools to more optimally set up your development environment for data analysis, check out the dev-setup repo. 


",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## Index,"  
spark
mapreduce-python
kaggle-and-business-analyses
deep-learning
scikit-learn
statistical-inference-scipy
pandas
matplotlib
numpy
python-data
amazon web services
command lines
misc
notebook-installation
credits
contributing
contact-info
license
  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## spark,"  IPython Notebook(s) demonstrating spark and HDFS functionality. 


Notebook
Description




spark
In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms.


hdfs
Reliably stores very large files across machines in a large cluster.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## mapreduce-python,"  IPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality. 


Notebook
Description




mapreduce-python
Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and mrjob config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  Disco is another python-based alternative.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## kaggle-and-business-analyses,"  IPython Notebook(s) used in kaggle competitions and business analyses. 


Notebook
Description




titanic
Predicts survival on the Titanic.  Demonstrates data cleaning, exploratory data analysis, and machine learning.


churn-analysis
Predicts customer churn.  Exercises logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Discussion of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## deep-learning,"  IPython Notebook(s) demonstrating deep learning functionality.  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,### tensor-flow-tutorials,"  


Notebook
Description




tsf-basics
Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google.


tsf-linear
Implement linear regression in TensorFlow.


tsf-logistic
Implement logistic regression in TensorFlow.


tsf-nn
Implement nearest neighboars in TensorFlow.


tsf-alex
Implement AlexNet in TensorFlow.


tsf-cnn
Implement convolutional neural networks in TensorFlow.


tsf-mlp
Implement multilayer perceptrons in TensorFlow.


tsf-rnn
Implement recurrent neural networks in TensorFlow.


tsf-gpu
Learn about basic multi-GPU computation in TensorFlow.


tsf-gviz
Learn about graph visualization in TensorFlow.


tsf-lviz
Learn about loss visualization in TensorFlow.


",1
https://github.com/christopherwoo/data-science-ipython-notebooks,### tensor-flow-exercises,"  


Notebook
Description




tsf-not-mnist
Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow.


tsf-fully-connected
Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow.


tsf-regularization
Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow.


tsf-convolutions
Create convolutional neural networks in TensorFlow.


tsf-word2vec
Train a skip-gram model over Text8 data in TensorFlow.


tsf-lstm
Train a LSTM character model over Text8 data in TensorFlow.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,### theano-tutorials,"  


Notebook
Description




theano-intro
Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation.


theano-scan
Learn scans, a mechanism to perform loops in a Theano graph.


theano-logistic
Implement logistic regression in Theano.


theano-rnn
Implement recurrent neural networks in Theano.


theano-mlp
Implement multilayer perceptrons in Theano.


",1
https://github.com/christopherwoo/data-science-ipython-notebooks,### deep-learning-misc,"  


Notebook
Description




deep-dream
Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## scikit-learn,"  IPython Notebook(s) demonstrating scikit-learn functionality. 


Notebook
Description




intro
Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays.


knn
Implement k-nearest neighbors in scikit-learn.


linear-reg
Implement linear regression in scikit-learn.


svm
Implement support vector machine classifiers with and without kernels in scikit-learn.


random-forest
Implement random forest classifiers and regressors in scikit-learn.


k-means
Implement k-means clustering in scikit-learn.


pca
Implement principal component analysis in scikit-learn.


gmm
Implement Gaussian mixture models in scikit-learn.


validation
Implement validation and model selection in scikit-learn.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## statistical-inference-scipy,"  IPython Notebook(s) demonstrating statistical inference with SciPy functionality. 


Notebook
Description




scipy
SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data.


effect-size
Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States.


sampling
Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data.


hypothesis
Explore hypothesis testing by analyzing the difference of first-born babies compared with others.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## pandas,"  IPython Notebook(s) demonstrating pandas functionality. 


Notebook
Description




pandas
Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## matplotlib,"  IPython Notebook(s) demonstrating matplotlib functionality. 


Notebook
Description




matplotlib
Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.


matplotlib-applied
Matplotlib visualizations appied to Kaggle competitions for exploratory data analysis.  Examples of bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## numpy,"  IPython Notebook(s) demonstrating NumPy functionality. 


Notebook
Description




numpy
Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## python-data,"  IPython Notebook(s) demonstrating Python functionality geared towards data analysis. 


Notebook
Description




data structures
Learn Python basics with tuples, lists, dicts, sets.


data structure utilities
Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions.


functions
Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools.


datetime
Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta.


logging
Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler.


pdb
Learn how to debug in Python with the interactive source code debugger.


unit tests
Learn how to test in Python with Nose unit tests.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## aws,"  IPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality. Also check out: 
SAWS: A Supercharged AWS command line interface (CLI).
Awesome AWS: A curated list of libraries, open source repos, guides, blogs, and other resources.
 


Notebook
Description




boto
Official AWS SDK for Python.


s3cmd
Interacts with S3 through the command line.


s3distcp
Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster.


s3-parallel-put
Uploads multiple files to S3 in parallel.


redshift
Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP).


kinesis
Streams data in real time with the ability to process thousands of data streams per second.


lambda
Runs code in response to events, automatically managing compute resources.


  

",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## commands,"  IPython Notebook(s) demonstrating various command lines for Linux, Git, etc. 


Notebook
Description




linux
Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.


anaconda
Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment.


ipython notebook
Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document.


git
Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows.


ruby
Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages.


jekyll
Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server.  Pelican is a python-based alternative.


django
High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include Pyramid, Flask, Tornado, and Bottle.


",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## misc,"  IPython Notebook(s) demonstrating miscellaneous functionality. 


Notebook
Description




regex
Regular expression cheat sheet useful in data wrangling.


",1
https://github.com/christopherwoo/data-science-ipython-notebooks,## notebook-installation, ,3
https://github.com/christopherwoo/data-science-ipython-notebooks,### anaconda,"  Anaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment. Follow instructions to install Anaconda or the more lightweight miniconda.",3
https://github.com/christopherwoo/data-science-ipython-notebooks,### pip-requirements,"  If you prefer to use a more lightweight installation procedure than Anaconda, first clone the repo then run the following pip command on the provided requirements.txt file: $ pip install -r requirements.txt
",3
https://github.com/christopherwoo/data-science-ipython-notebooks,### running-notebooks,"  To view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the ipython notebook.  More information on IPython Notebooks can be found here. $ git clone https://github.com/donnemartin/data-science-ipython-notebooks.git
$ cd data-science-ipython-notebooks
$ ipython notebook
 Notebooks tested with Python 2.7.x.",3
https://github.com/christopherwoo/data-science-ipython-notebooks,## credits,"  
Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinney
PyCon 2015 Scikit-learn Tutorial by Jake VanderPlas
Parallel Machine Learning with scikit-learn and IPython by Olivier Grisel
Statistical Interference Using Computational Methods in Python by Allen Downey
TensorFlow Examples by Aymeric Damien
Summer School 2015 by mila-udem
Kaggle
Yhat Blog
",56
https://github.com/christopherwoo/data-science-ipython-notebooks,## contributing,  Contributions are welcome!  For bug reports or requests please submit an issue.,7
https://github.com/christopherwoo/data-science-ipython-notebooks,## contact-info,"  Feel free to contact me to discuss any issues, questions, or comments. 
Email: donne.martin@gmail.com
Twitter: @donne_martin
GitHub: donnemartin
LinkedIn: donnemartin
Website: donnemartin.com
",5
https://github.com/christopherwoo/data-science-ipython-notebooks,## license,"  This repository contains a variety of content; some developed by Donne Martin, and some from third-parties.  The third-party content is distributed under the license provided by those parties. The content developed by Donne Martin is distributed under the following license: Copyright 2015 Donne Martin

Licensed under the Apache License, Version 2.0 (the ""License"");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an ""AS IS"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
",5
https://github.com/lionfish7699/guides,# Guides," Guides for getting things done, programming well, and programming in style. 
Best Practices
Code Review
How to
Protocol

Communication
Git
iOS
Open Source
Product Review
Rails


Security
Style
 High level guidelines: 
Be consistent.
Don't rewrite existing code to follow this guide.
Don't violate a guideline without a good reason.
A reason is good when you can convince a teammate.
 A note on the language: 
""Avoid"" means don't do it unless you have good reason.
""Don't"" means there's never a good reason.
""Prefer"" indicates a better option and its alternative to watch out for.
""Use"" is a positive instruction.
",1
https://github.com/lionfish7699/guides,## Contributing,"  Please read the contribution guidelines before submitting a pull request. In particular: if you have commit access, please don't merge changes without
waiting a week for everybody to leave feedback.",7
https://github.com/lionfish7699/guides,## Credits,"  Thank you, contributors!  Guides is maintained by thoughtbot, inc.",5
https://github.com/lionfish7699/guides,## License,"  Guides is © 2014 thoughtbot, inc. It is distributed under the Creative Commons
Attribution License. The names and logos for thoughtbot are trademarks of thoughtbot, inc.",5
https://github.com/yaogdu/python-fire,# Python Fire," Python Fire is a library for creating command line interfaces (CLIs) from
absolutely any Python object. 
Python Fire is a simple way to create a CLI in Python. [1]
Python Fire is a helpful tool for developing and debugging Python code. [2]
Python Fire helps with exploring existing code or turning other people's code
into a CLI. [3]
Python Fire makes transitioning between Bash and Python easier. [4]
Python Fire makes using a Python REPL easier by setting up the REPL with the
modules and variables you'll need already imported and created. [5]
",12
https://github.com/yaogdu/python-fire,## Installation,  pip install fire,3
https://github.com/yaogdu/python-fire,## Basic Usage,"  You can call Fire on any Python object:
functions, classes, modules, objects, dictionaries, lists, tuples, etc.
They all work! Here's a simple example. import fire

class Calculator(object):
  """"""A simple calculator class.""""""

  def double(self, number):
    return 2 * number

if __name__ == '__main__':
  fire.Fire(Calculator) Then, from the command line, you can run: python calculator.py double 10  # 20
python calculator.py double --number=15  # 30 To learn how Fire behaves on functions, objects, dicts, lists, etc, and to learn
about Fire's other features, see the Using a Fire CLI page. For additional examples, see The Python Fire Guide.",36
https://github.com/yaogdu/python-fire,## Why is it called Fire?,"  When you call Fire, it fires off (executes) your command.",1
https://github.com/yaogdu/python-fire,## Where can I learn more?,  Please see The Python Fire Guide.,6
https://github.com/yaogdu/python-fire,## Reference,"  


Setup
Command
Notes




install
pip install fire



 


Creating a CLI
Command
Notes




import
import fire



Call
fire.Fire()
Turns the current module into a Fire CLI.


Call
fire.Fire(component)
Turns component into a Fire CLI.


 


Using a CLI
Command
Notes




Help
command -- --help



REPL
command -- --interactive
Enters interactive mode.


Separator
command -- --separator=X
This sets the separator to X. The default separator is -.


Completion
command -- --completion
Generate a completion script for the CLI.


Trace
command -- --trace
Gets a Fire trace for the command.


Verbose
command -- --verbose



Note that flags are separated from the Fire command by an isolated -- arg.




",6
https://github.com/yaogdu/python-fire,## Disclaimer,  This is not an official Google product.,5
https://github.com/monw3c/swiped,# Swiped.js," 
 Demo (use mobile or emulate touches mode on your browser) ",3
https://github.com/monw3c/swiped,## Features,"  
Dependency-free.
Short & long swipe.
Swipe to delete.
Easy to use.
CSS transforms & transitions.
",1
https://github.com/monw3c/swiped,## Installation,"  npm install swiped
bower install swiped
",3
https://github.com/monw3c/swiped,## API, ,36
https://github.com/monw3c/swiped,### Swiped(options),"  
options (object) - Options to configure a new instance of Swiped.
[options.query] (string) - Query selector.
[options.duration] (number) - The time (milliseconds) to open/close the element. Default: 200.
[options.tolerance] (number) - Default: 150.
[options.time] (number) - Time for short swipe. Default: 200.
[options.left] (number) - Distance for swipe from left to right. Default: 0.
[options.right] (number) - Distance for swipe from right to left. Default: 0.
[options.list] (boolean) - Elements depend on each other. Default: false.
[options.onOpen] (function).
[options.onClose] (function).
 var s = Swiped.init(options);

s.open();
s.close();
s.toggle();
s.destroy([isRemoveNode])",36
https://github.com/monw3c/swiped,## Usage,"  Example of the html markup for single element: <div class=""foo"">
    elem1
</div> for multiple: <ul class=""bar"">
    <li>
        elem3
    </li>
    <li>
        elem4
    </li>
    <li>
        elem5
    </li>
</ul> for switch: <div class=""foo""><span></span>element 16</div> initialization for single element: var s1 = Swiped.init({
    query: '.foo',
    right: 300
}); for multiple: var s2 = Swiped.init({
    query: '.bar li',
    list: true,
    left: 200,
    right: 200
}); for switch: var s3 = Swiped.init({
    query: '.foo',
    left: 400
});

document.querySelector('.foo span').addEventListener('touchstart', function() {
    s3.toggle();
});",3
https://github.com/monw3c/swiped,"#### Implementation for swipe to delete""""","  Swiped.init({
    query: '.baz',
    right: 400,
    onOpen: function() {
        this.destroy(true)
    }
});",3
https://github.com/Dauthiwarlord/UniversalMediaServer,# Universal Media Server,"   Universal Media Server is a DLNA-compliant UPnP Media Server.
It is capable of sharing video, audio and images between most modern devices.
It was originally based on PS3 Media Server by shagrath, in order to ensure greater stability and file-compatibility. To see a comparison of popular media servers, click here Universal Media Server supports all major operating systems, with versions for Windows, Linux and Mac OS X.
The program streams or transcodes many different media formats with little or no configuration.
It is powered by MEncoder, FFmpeg, tsMuxeR, AviSynth, MediaInfo, VLC and more, which combine to offer support for a wide range of media formats.",16
https://github.com/Dauthiwarlord/UniversalMediaServer,## Current Project Developers,"  
infidel
Nadahar
SharkHunter
SubJunk
valib
",5
https://github.com/Dauthiwarlord/UniversalMediaServer,## Current Forum Moderators,"  
DeFlanko
Optimus_prime
",5
https://github.com/Dauthiwarlord/UniversalMediaServer,## Links,"  
Website
Forum
Source code
Offical Releases
Issue tracker
FAQ
Wiki
",6
https://github.com/Dauthiwarlord/UniversalMediaServer,## Thanks, ,5
https://github.com/Dauthiwarlord/UniversalMediaServer,##### Thanks for major code contributions:,"  
chocolateboy
ditlew
ExSport
happy.neko
Raptor399
Redlum
renszarv
taconaut
tcox
tomeko
",5
https://github.com/Dauthiwarlord/UniversalMediaServer,##### Thanks for documentation and contributions to the community:,"  
meskibob
otmanix
",5
https://github.com/Dauthiwarlord/UniversalMediaServer,##### Thanks for significant/frequent language translations:,"  
AlfredoRamos
Kirvx
leroy
Tianuchka
",5
https://github.com/Dauthiwarlord/UniversalMediaServer,##### Special Thanks:,"  
boblinds and snoots for the network test cases :)
sarraken, bleuecinephile, bd.azerty, fabounnet for the support and feedback
...And you!
",5
https://github.com/juame/puppet-firewalld,# Module: firewalld,,1
https://github.com/juame/puppet-firewalld,## Description,"  This module manages firewalld, the userland interface that replaces iptables and ships with RHEL7.  The module manages firewalld itself as well as providing types and providers for managing firewalld zones and rich rules.",1
https://github.com/juame/puppet-firewalld,## Usage,  The firewalld module contains types and providers to manage zones and rich rules by interfacing with the firewall-cmd command.  The following types are currently supported.  Note that all zone and rules management is done in --permanent mode.,3
https://github.com/juame/puppet-firewalld,### Firewalld Zones,"  Firewalld zones can be managed with the firewalld_zone resource type. Example:   firewalld_zone { 'restricted':
    ensure => present,
    target => '%%REJECT%%',
    purge_rich_rules => true,
  }",3
https://github.com/juame/puppet-firewalld,#### Parameters,"  
target: Specify the target of the zone
purge_rich_rules: Optional, and defaulted to false.  When true any configured rich rules found in the zone that do not match what is in the Puppet catalog will be purged.
",3
https://github.com/juame/puppet-firewalld,### Firewalld rich rules,"  Firewalld rich rules are managed using the firewalld_rich_rule resource type firewalld_rich_rules will autorequire the firewalld_zone specified in the zone parameter so there is no need to add dependancies for this Example:   firewalld_rich_rule { 'Accept SSH from barny':
    ensure => present,
    zone   => 'restricted',
    source => '192.168.1.2/32',
    service => 'ssh',
    action  => 'accept',
  }",3
https://github.com/juame/puppet-firewalld,#### Parameters,"  

zone: Name of the zone this rich rule belongs to


family: Protocol family, defaults to ipv4


source: Source address information. This can be a hash containing the keys address and invert, or a string containing just the IP address
   source => '192.168.2.1',

   source => { 'address' => '192.168.1.1', 'invert' => true }


dest: Source address information. This can be a hash containing the keys address and invert, or a string containing just the IP address
   dest => '192.168.2.1',

   dest => { 'address' => '192.168.1.1', 'invert' => true }


log: When set to true will enable logging, optionally this can be hash with prefix, level and limit
   log => { 'level' => 'debug', 'prefix' => 'foo' },

   log => true,


audit: When set to true will enable auditing, optionally this can be hash with limit
   audit => { 'limit' => '3/s' },

   audit => true,


action: A string containing the action accept, reject or drop.  For reject it can be optionally supplied as a hash containing type
   action => 'accept'

   action => { 'action' => 'reject', 'type' => 'bad' }

 The following paramters are the element of the rich rule, only one may be used. 

service: Name of the service


port: A hash containing port and protocol values
   port => {
     'port' => 80,
     'protocol' => 'tcp',
   },


icmp_block: Specify an icmp-block for the rule


masquerade: Set to true or false to enable masquerading


forward_port: Set forward-port, this should be a hash containing port,protocol,to_port,to_addr
   forward_port => {
     'port' => '8080',
     'protocol' => 'tcp',
     'to_addr' => '10.2.1.1',
     'to_port' => '8993'
   },

",3
https://github.com/juame/puppet-firewalld,## Limitations / TODO (PR's welcome!),"  
Currently only target is a managable property for a zone
",4
https://github.com/juame/puppet-firewalld,## Author,"  
Written and maintained by Craig Dunn craig@craigdunn.org @crayfisx
Sponsered by Baloise Group http://baloise.github.io
",5
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,# Introduction," MSCollectionViewCalendarLayout was written by Eric Horacek for Monospace Ltd. MSCollectionViewCalendarLayout is a UICollectionViewLayout subclass for displaying chronological data. It divides its cells into columns of days, with the size of each cell corresponding to its length. MSCollectionViewCalendarLayout is very similar to the ""Week"" view in the Apple Calendar/iCal app. See the example screenshots for what this looks like.",15
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,# UICollectionView?,"  UICollectionView is awesome. If you're unfamiliar, read Matt Thompson's excellent article about them on NSHipster. Everyone should use them (yes, even instead of good ol' UITableView). This is especially true now that iOS 6+ adoption is over 90% (As of March, 2013). It's the right thing to do. Because of how awesome UICollectionView is, the UIViewController powering the below example is incredibly thin—only about 175 lines of code, including whitespace.",126
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,# Example,"  The example project queries the SeatGeek API for the next 1000 sport events near Denver, Colorado. It displays these events in a UICollectionView using MSCollectionViewCalendarLayout, mimicking the look and feel of the Apple Calendar iOS App. To run, build and run the Example target in from Example.xcworkspace within the Example directory.",3
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,## Screenshots,   ,3
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,# Usage, ,3
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,## CocoaPods,"  Add the following to your Podfile and run $ pod install. pod 'MSCollectionViewCalendarLayout' If you don't have CocoaPods installed, you can learn how to do so here.",3
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,## Invalidating Layout,"  If you change the content of your MSCollectionViewCalendarLayout, make sure to call the invalidateLayoutCache method. This flushes the internal caches of your MSCollectionViewCalendarLayout, allowing the data to be repopulated correctly.",3
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,## Section Layouts,"  On the iPhone, MSCollectionViewCalendarLayout defaults to tiling its day sections vertically. The day column headers act as they do in a table view, sticking to the top until they're replaced by the next day's as your scroll. On the iPad, the day sections are tiled horizontally. This behavior is controlled by the sectionLayoutType property. Its values can be: 
MSSectionLayoutTypeHorizontalTile ?Day sections tile vertically.
MSSectionLayoutTypeVerticalTile ?Day sections tile horizontally.
",3
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,## Collection View Elements,"  MSCollectionViewCalendarLayout has nine different elements that you should register UICollectionReusableView and UICollectionViewCell classes for. They are: 
Event Cell (UICollectionViewCell) ?Represents your events.
Day Column Header (UICollectionReusableView) ?Contains the day text, top aligned.
Time Row Header (UICollectionReusableView) ?Contains the time text, left aligned.
Day Column Header Background (UICollectionReusableView) ?Background of the day column header.
Time Row Header Background (UICollectionReusableView) ?Background of the time row header.
Current Time Indicator (UICollectionReusableView) ?Displayed over the time row header, aligned at the current time.
Current Time Horizontal Gridline (UICollectionReusableView) ?Displayed under the cells, aligned to the current time.
Horizontal Gridilne (UICollectionReusableView) ?Displayed under the cells, aligns with its corresponding time row header.
Vertical Gridilne (UICollectionReusableView) ?Displayed under the cells, aligns with its corresponding day column header.
 If you think there should be more of these, don't hesitate to add them in a pull request. To see how this is done, check the example.",3
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,## Can I call performBatchUpdates:completion: to make stuff animate?,"  Don't do this. It doesn't work properly, and is a ""bag of hurt"".",3
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,# Requirements,  Requires iOS 6.0+ and ARC.,3
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,# Contributing,"  Forks, patches and other feedback are welcome.",7
https://github.com/tetsuo6666/MSCollectionViewCalendarLayout,# License,"  Copyright (c) 2013 Monospace Ltd. All rights reserved. This code is distributed under the terms and conditions of the MIT license. Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE. ",5
https://github.com/renoguyon/angular-duration-format,# angular-duration-format, AngularJS filter for formatting duration.,1
https://github.com/renoguyon/angular-duration-format,## Usage ##,"  Add angular-duration-format as your app dependency.   angular.module('myModule', [
    angular-duration-format'
  ]);
 In templates you can use   <p>
    Time passed: {{ passed | duration:'hh:mm:ss:sss' }}<br/>
    Preformatted: {{ passedPre }}
  </p>
 In controllers (or directives, services, anywhere)   angular.module('myModule').controller('exampleCtrl', function($scope, $filter) {
    var durationFilter = $filter('duration');
    
    $scope.passed = 123456789;
    $scope.passedPre = durationFilter($scope.passed, 'hh:mm:ss:sss');
  });
 The result should be the same in both cases:   Time passed: 34:17:36:789
  Preformatted: 34:17:36:789
",3
https://github.com/renoguyon/angular-duration-format,## Format options ##,"  Available formatting options: 
(y)ear
(d)ay
(h)our
(m)inute
(s)econd
sss for milliseconds
 Each number will be zero-padded to two places if you double letters (ex. hh, mm). Milliseconds are exception - they are padded to four places and you have to pass four letters (ssss). You can use every separator you want, but be careful. Passing format h hours, m minutes will produce unexpected results 34 34ours, 17 17inutes. To avoid that, wrap every separator containing reserved letters in quotaion marks, like that h 'hours', m 'minutes'. (remember about escaping them in your code!). Now, the result should be nicely formatted 34 hours, 17 minutes.",3
https://github.com/renoguyon/angular-duration-format,## Additional notes ##,"  Note, that you can ommit some unit ""levels"", but it can produce weird results. If in example above you change format to hh:ss, result will be 34:1056, because 17 minutes and 36 seconds it is 1056 seconds.",3
https://github.com/slavame/mitro,# Mitro Password Manager," Mitro saves all your passwords, synchronizes them across all your devices, and lets you share them with others. It has extensions for Chrome, Firefox, and Safari, mobile apps for iOS and Android, and a server to perform the synchronization. If you are a user, install it from the Mitro web site. If you have any questions, you can ask on the mitro-dev@googlegroups.com mailing list, or send @MitroCo a tweet.",156
https://github.com/slavame/mitro,## Quick Start,"  

Install dependencies (see browser-ext/README, mitro-core/README) [node, npm, homebrew, java, ant]


Clone repository: git clone https://github.com/mitro-co/mitro


Install browser extension dependencies:


 cd mitro
cd browser-ext/api
./build.sh
cd - 4. Run the regression tests to ensure your source tree works:

    ```
cd browser-ext/api/js/cli
./runtests.sh FAST && echo ""SUCCESS""
 

Look for ""SUCCESS"" on the last line.


Build the browser extension:


 cd -
cd browser-ext/login
make release 7. To build Firefox, use `make firefox` and to build Safari use `make safari`.

The extensions will be in the `browser-ext/login/build` directory.


### setup and run emailer

To send device verification emails, we use `emailer/emailer2.py`. Requirements: Postgres with the development libraries (Mac OS X: `brew install postgresql`). This script polls a table in the Postgres database to send email.

#### Configuration:

1. `cd emailer`
2. `./build.sh` to set up Python virtualenv with dependencies
3. To run: `build/venv/bin/python emailer2.py --enable_email --mandrill_api_key=api_key`
",3
https://github.com/slavame/mitro,### setup and run emailer,,3
https://github.com/slavame/mitro,#### Configuration:,,3
https://github.com/Chiel92/chugins,# Repository for Officially Supported ChuGins [![Build Status](https://travis-ci.org/ccrma/chugins.svg?branch=master)](https://travis-ci.org/ccrma/chugins),,1
https://github.com/Chiel92/chugins,## Prepackaged Binaries,"  Binaries for most chugins in this repository are automatically included by the ChucK installers for Mac OS X and Windows. If you haven't installed ChucK already, these are available at http://chuck.stanford.edu/release/.",136
https://github.com/Chiel92/chugins,### Linux/Advanced Users,"  To compile and install all chugins: git clone https://github.com/ccrma/chugins.git
cd chugins
make [osx|win32|linux]
sudo make install
",3
https://github.com/Chiel92/chugins,## List of Current Chugins,"  
ABSaturator

soft clip saturating distortion, based on examples from Abel/Berners' Music 424 course at Stanford.


Bitcrusher

sample-width reducer + sample rate decimator, bringing to mind the sounds of your favorite low-fidelity vintage audio equipment.


MagicSine

Efficient means of computing a sine wave with 2 adds and 2 multiples per sample, at the expense of being able to dynamically adjust phase.


KasFilter

by @Kassen
Undersampling-based resonant lowpass filter


FIR

by Perry Cook
Arbitrary order FIR filter


FoldbackSaturator

by Ness Morris
Foldback Saturator for nasty distortion


Pan4 / Pan8 / Pan16

Basic equal-power panners for 4, 8, and 16 channels


PitchTrack

by @jwmatthys
Monophonic autocorrelation pitch tracker, based on [helmholtz~] by Katja, http://www.katjaas.nl/helmholtz/helmholtz.html


GVerb

by @jwmatthys
Good quality stereo reverb with adjustable parameters


Mesh2D

by @jwmatthys
STK instrument that simulates a rectilinear, 2-dimensional digital waveguide mesh structure. Basically sounds like striking a metal plate.


Spectacle

by @jwmatthys
FFT-based spectral delay and EQ


Elliptic

by @jwmatthys
Elliptic filter, capable of very steep slopes or interesting harmonic ripples


PowerADSR

by @ericheep
Power function ADSR envelope.


WinFuncEnv

by @ericheep
Envelope built on window functions.


",1
https://github.com/Chiel92/chugins,## Chugins That We Are Working On,"  
MAUI for chuck
GlucK (OpenGL)
AudioUnit loader
Ambisonics
",4
https://github.com/Chiel92/chugins,## Chugins We would like to see happen,"  
More configurable reverbs, dynamics processors, and distortion units
VST loader
",4
https://github.com/tourze/onepage_scroll,# jQuery One Page Scroll plugin, This plugin is a full refactored fork of Pete R. One Page Scroll plugin with keyboard support from Brook Yang. It's completely rewritten in coffee and uses hammer.js for touch support in all Browsers (even IE Touch Events),16
https://github.com/tourze/onepage_scroll,## Compatibility,"  Tested in Chrome (31.0.1650.57), Firefox (25.0.1), Safari (7.0), IE (9, 10 with Touch Support)",3
https://github.com/tourze/onepage_scroll,## Basic Usage,"  To use the plugin you have to the hammer.js jQuery library. Add onepage-scroll.css to your head and jquery (1.10.2 or later), hammer.js and jquery.onepage-scroll.js at the end of your body. You can use require.js to load the dependencies as needed. Your document should be structured in a way like this: <body>
	...
	<div class=""main"">
		<section>...</section>
		<section>...</section>
		...
	</div>
	...
</body> The .main container must be one level below the body tag in order to make it work full page. You can now call the function to activate as follows: $("".main"").onepage_scroll({
	sectionContainer: ""section"", // sectionContainer accepts any kind of selector in case you don't want to use section
	easing: ""ease"", // Easing options accepts the CSS3 easing animation such ""ease"", ""linear"", ""ease-in"", ""ease-out"", ""ease-in-out"", or even cubic bezier value such as ""cubic-bezier(0.175, 0.885, 0.420, 1.310)""
	animationTime: 1000, // AnimationTime let you define how long each section takes to animate
	pagination: true, // You can either show or hide the pagination. Toggle true for show, false for hide.
	keyboard: false, // Should Keyboard navigation be used
	updateURL: false, // Toggle this true if you want the URL to be updated automatically when the user scroll to each page.
	beforeMove: $.noop, // This option accepts a callback function. The function will be called before the page moves.
	afterMove: $.noop, // This option accepts a callback function. The function will be called after the page moves.
	loop: false, // You can have the page loop back to the top/bottom when the user navigates at up/down on the first/last page.
	responsiveFallbackWidth: false, // You can fallback to normal page scroll by defining the width of the browser in which you want the responsive fallback to be triggered. For example, set this to 600 and whenever the browser's width is less than 600, the fallback will kick in.
	responsiveFallbackHeight: false, // You can fallback to normal page scroll by defining the height of the browser in which you want the responsive fallback to be triggered. For example, set this to 600 and whenever the browser's height is less than 600, the fallback will kick in.
	smooth: false, // You can set if a direct move to a slide should iterate over the other slides or not (direct jump)
	beforeCreate: $.noop, // This option accept a callback function. The function will be called before the onepagescroll is created.
	afterCreate: $.noop, // This option accept a callback function. The function will be called after the onepagescroll is created.
	beforeDestroy: $.noop, // This option accept a callback function. The function will be called before the onepagescroll is destroyed.
	afterDestroy: $.noop // This option accept a callback function. The function will be called after the onepagescroll is destroyed.
});",3
https://github.com/tourze/onepage_scroll,## Public Methods,  You can also trigger page move programmatically:,36
https://github.com/tourze/onepage_scroll,### Get onepage_scroll Object by data,"  To get the onepage_scroll object simply call: onepage_scroll = $("".main"").data(""onepage_scroll"") or if just one element (it should be) just call: onepage_scroll = $("".main"").onepage_scroll() You can then chain the needed methods.",36
https://github.com/tourze/onepage_scroll,### .moveUp(),"  This method allows you to move the page up by one. This action is equivalent to scrolling up/swiping down. $("".main"").data(""onepage_scroll"").moveUp();",36
https://github.com/tourze/onepage_scroll,### .moveDown(),"  This method allows you to move the page down by one. This action is equivalent to scrolling down/swiping up. $("".main"").data(""onepage_scroll"").moveDown();",36
https://github.com/tourze/onepage_scroll,### .moveTo(page_index),"  This method allows you to move to the specified page index programatically.
You can use the index of the slide you want to move to or a specific selector of the slide. If you use the selector variant there must only be one element with the given selector, else the plugin won't move. The plugin looks for the data-attribute of the given slide to determine the index it has to scroll to. $("".main"").data(""onepage_scroll"").moveTo(3);
$("".main"").data(""onepage_scroll"").moveTo(""#slide-1"");",36
https://github.com/tourze/onepage_scroll,### .destroy(),"  This method completely removes all bindings, added classes, stylings and elements. $("".main"").data(""onepage_scroll"").destroy();",36
https://github.com/tourze/onepage_scroll,### .create(),"  This method allows you to manually recreate the plugin bindings, classes, stylings and elements after the destroy call. $("".main"").data(""onepage_scroll"").create();",36
https://github.com/tourze/onepage_scroll,### .unbindEvents(),"  This method allows you to manually unbind all events, useful if you use modals where you want to scroll the modal instead of the content. $("".main"").data(""onepage_scroll"").unbindEvents();",36
https://github.com/tourze/onepage_scroll,### .bindEvents(),"  This method allows you to manually rebind all events. $("".main"").data(""onepage_scroll"").bindEvents();",36
https://github.com/tourze/onepage_scroll,## Callbacks,  You can use callbacks to perform actions before or after the page move.,36
https://github.com/tourze/onepage_scroll,### beforeMove(current_page_index),"  This callback gets called before the plugin performs its move. $("".main"").onepage_scroll({
	beforeMove: function(index) {
		...
	}
});",36
https://github.com/tourze/onepage_scroll,### afterMove(next_page_index),"  This callback gets called after the move animation was performed. $("".main"").onepage_scroll({
	afterMove: function(index) {
		...
	}
});",36
https://github.com/tourze/onepage_scroll,### beforeCreate(),"  This callback gets called before the Plugin is created. $("".main"").onepage_scroll({
	beforeCreate: function() {
		...
	}
});",36
https://github.com/tourze/onepage_scroll,### afterCreate(),"  This callback gets called after the Plugin is created. $("".main"").onepage_scroll({
	afterCreate: function() {
		...
	}
});",36
https://github.com/tourze/onepage_scroll,### beforeDestroy(),"  This callback gets called before the Plugin is destroyed. $("".main"").onepage_scroll({
	beforeDestroy: function() {
		...
	}
});",36
https://github.com/tourze/onepage_scroll,### afterDestroy(),"  This callback gets called after the Plugin is destroyed. $("".main"").onepage_scroll({
	afterDestroy: function() {
		...
	}
});",36
https://github.com/tourze/onepage_scroll,## Resources,"  
Pete R. One Page Scroll plugin: Original Plugin
Modernizr: A JavaScript library that detects HTML5 and CSS3 features in the user’s browser
hammer.js: A javascript library for multi-touch gestures.
OnePageScroll.js: Creating an Apple’s iPhone 5S Website
",6
https://github.com/subclub/oauth2,# OAuth2," 



 A Ruby wrapper for the OAuth 2.0 specification.",1
https://github.com/subclub/oauth2,## Installation,"  gem install oauth2
",3
https://github.com/subclub/oauth2,## Resources,"  
View Source on GitHub
Report Issues on GitHub
Read More at the Wiki
",6
https://github.com/subclub/oauth2,## Usage Examples,"  require 'oauth2'
client = OAuth2::Client.new('client_id', 'client_secret', :site => 'https://example.org')

client.auth_code.authorize_url(:redirect_uri => 'http://localhost:8080/oauth2/callback')
# => ""https://example.org/oauth/authorization?response_type=code&client_id=client_id&redirect_uri=http://localhost:8080/oauth2/callback""

token = client.auth_code.get_token('authorization_code_value', :redirect_uri => 'http://localhost:8080/oauth2/callback', :headers => {'Authorization' => 'Basic some_password'})
response = token.get('/api/resource', :params => { 'query_foo' => 'bar' })
response.class.name
# => OAuth2::Response",3
https://github.com/subclub/oauth2,"# => https://example.org/oauth/authorization?response_type=code&client_id=client_id&redirect_uri=http://localhost:8080/oauth2/callback""""",,-
https://github.com/subclub/oauth2,# => OAuth2::Response,"  The AccessToken methods #get, #post, #put and #delete and the generic #request
will return an instance of the #OAuth2::Response class. This instance contains a #parsed method that will parse the response body and
return a Hash if the Content-Type is application/x-www-form-urlencoded or if
the body is a JSON object.  It will return an Array if the body is a JSON
array.  Otherwise, it will return the original body string. The original response body, headers, and status can be accessed via their
respective methods.",-
https://github.com/subclub/oauth2,## OAuth2::Response,,3
https://github.com/subclub/oauth2,## OAuth2::AccessToken,"  If you have an existing Access Token for a user, you can initialize an instance
using various class methods including the standard new, from_hash (if you have
a hash of the values), or from_kvform (if you have an
application/x-www-form-urlencoded encoded string of the values).",3
https://github.com/subclub/oauth2,## OAuth2::Error,"  On 400+ status code responses, an OAuth2::Error will be raised.  If it is a
standard OAuth2 error response, the body will be parsed and #code and #description will contain the values provided from the error and
error_description parameters.  The #response property of OAuth2::Error will
always contain the OAuth2::Response instance. If you do not want an error to be raised, you may use :raise_errors => false
option on initialization of the client.  In this case the OAuth2::Response
instance will be returned as usual and on 400+ status code responses, the
Response instance will contain the OAuth2::Error instance.",3
https://github.com/subclub/oauth2,## Authorization Grants,"  Currently the Authorization Code, Implicit, Resource Owner Password Credentials, Client Credentials, and Assertion
authentication grant types have helper strategy classes that simplify client
use.  They are available via the #auth_code, #implicit, #password, #client_credentials, and #assertion methods respectively. auth_url = client.auth_code.authorize_url(:redirect_uri => 'http://localhost:8080/oauth/callback')
token = client.auth_code.get_token('code_value', :redirect_uri => 'http://localhost:8080/oauth/callback')

auth_url = client.implicit.authorize_url(:redirect_uri => 'http://localhost:8080/oauth/callback')
# get the token params in the callback and
token = OAuth2::AccessToken.from_kvform(client, query_string)

token = client.password.get_token('username', 'password')

token = client.client_credentials.get_token

token = client.assertion.get_token(assertion_params) If you want to specify additional headers to be sent out with the
request, add a 'headers' hash under 'params': token = client.auth_code.get_token('code_value', :redirect_uri => 'http://localhost:8080/oauth/callback', :headers => {'Some' => 'Header'}) You can always use the #request method on the OAuth2::Client instance to make
requests for tokens for any Authentication grant type.",3
https://github.com/subclub/oauth2,# get the token params in the callback and,,-
https://github.com/subclub/oauth2,## Supported Ruby Versions,"  This library aims to support and is tested against the following Ruby
implementations: 
Ruby 1.8.7
Ruby 1.9.3
Ruby 2.0.0
Ruby 2.1.0
JRuby
Rubinius
 If something doesn't work on one of these interpreters, it's a bug. This library may inadvertently work (or seem to work) on other Ruby
implementations, however support will only be provided for the versions listed
above. If you would like this library to support another Ruby version, you may
volunteer to be a maintainer. Being a maintainer entails making sure all tests
run and pass on that implementation. When something breaks on your
implementation, you will be responsible for providing patches in a timely
fashion. If critical issues for a particular implementation exist at the time
of a major release, support for that Ruby version may be dropped.",3
https://github.com/subclub/oauth2,## License,"  Copyright (c) 2011-2013 Michael Bleigh and Intridea, Inc. See LICENSE for
details.",5
https://github.com/dev1234/BeeFramework,## Join us, QQ Group: 314365063,5
https://github.com/dev1234/BeeFramework,## 0.6.0 New Feature - Liveload, ,14
https://github.com/dev1234/BeeFramework,### Have a better life with liveload,"  
Edit the XML file with any editor (Xcode, Sublime Text, even TextEdit etc.).
After editing, just save the file by shortcut (Command+S) or clicking the menu item Save.
Then the corresponding view in smulator will update according to the changes without rebuilding app.
You can get More info from /serivces/bee.service.liveload/.
",3
https://github.com/dev1234/BeeFramework,### Here is a video about the new feature,  📺  BeeFramework 0.6.0 New Feature - Liveload   [YouTube]   [Youku] ,3
https://github.com/dev1234/BeeFramework,## How to install,"  
Download the source code
Drag and drop /framework folder into your project
Drag and drop /services folder into your project
Build and run
",3
https://github.com/dev1234/BeeFramework,## Demo app,"  A demo app for dribbble.com, as fast as native, as flexible as web. See /projects/dribbble demo for more information. 
",3
https://github.com/dev1234/BeeFramework,## Demo app - Wireframe mode,  ,3
https://github.com/dev1234/BeeFramework,## Demo app - Inspector mode,  ,3
https://github.com/dev1234/BeeFramework,## Semi-Hybrid UI,"  Semi-hybrid offers you a new approach to UI development using XML/CSS, you can reuse these templates in any project based on BeeFramework. See /projects/dribbble demo for more information. ",1
https://github.com/dev1234/BeeFramework,## Services,"  Services extend and expand the functionality of your app automatically, drag and drop the services folder into your project. See /services for more information.  For example: bee.services.alipay.config.parnter = @"""";
bee.services.alipay.config.seller = @"""";
bee.services.alipay.config.privateKey = @"""";
bee.services.alipay.config.publicKey = @"""";
bee.services.alipay.config.notifyURL = @""http://"";

bee.services.alipay.order.no = @""SN"";
bee.services.alipay.order.name = @""NAME"";
bee.services.alipay.order.desc = @""DESC"";
bee.services.alipay.order.price = @""PRICE"";

bee.services.alipay.whenSucceed = ^
{
};

bee.services.alipay.PAY();	// or .ON();
",3
https://github.com/dev1234/BeeFramework,## Scaffold,"  Scaffold helps you to generate Model/Controller code and documents, also provide the local test environment. See /tools/scaffold or /projects/scaffold for more information. 
 For example: > ./scaffold schema build ./example/dribbble.json
> ./scaffold schema test ./example/dribbble.json
",3
https://github.com/dev1234/BeeFramework,## Features,"  
CLI
MVC

View

Liveload
Application
Config
Container

Board
Stack
Router
Window


CSS style sheet
XML template
DOM

Animation/Transition
Data binding
Capability
Elements
Elements ext
Signaling
Auto layout
Query (jQuery-like syntax)


View-Model

Once
Paging
Stream


Other

Color
Font
Image
Metrics




Model
Controller

Message
MessageController
Queue
Routine
Extensions

Message + JSON
Message + HTTP
Message + XML
Message + ActiveRecord






System

Cache

File
Memory
Keychain
UserDefaults


Database

SQLite wrapper
ActiveRecord
Driver


Foundation

Assertion
Log
Performance
Runtime
Sandbox
Singleton
System information
Thread
Ticker
UnitTest


Localization
Network

HTTP client
HTTP server
Reachability
Socket


Resource
Service


",1
https://github.com/dev1234/BeeFramework,## Lastest version,"  

Download the lastest release
  https://github.com/gavinkwoe/BeeFramework/archive/master.zip



Clone the repo (CLI)
  git clone git@github.com:gavinkwoe/BeeFramework.git



Clone the repo (HTTP)
  https://github.com/gavinkwoe/BeeFramework.git



Import from CocoaPods ( thanks to stcui )
Add below to Podfile and run pod install
  platform :ios
  pod 'BeeFramework', :head


",3
https://github.com/dev1234/BeeFramework,## Bug tracker,"  
Have a bug or a feature request? Please open a new issue.
Before opening any issue, please read the Issue Guidelines, written by Nicolas Gallagher.
",7
https://github.com/dev1234/BeeFramework,## License,"    ______    ______    ______
/\  __ \  /\  ___\  /\  ___\
\ \  __<  \ \  __\_ \ \  __\_
 \ \_____\ \ \_____\ \ \_____\
  \/_____/  \/_____/  \/_____/


Copyright (c) 2014-2015, Geek Zoo Studio
http://www.bee-framework.com


Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the ""Software""),
to deal in the Software without restriction, including without limitation
the rights to use, copy, modify, merge, publish, distribute, sublicense,
and/or sell copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
IN THE SOFTWARE.
",5
https://github.com/dev1234/BeeFramework,## Change log, ,4
https://github.com/dev1234/BeeFramework,#### 0.6.0,"  
Liveload
",4
https://github.com/dev1234/BeeFramework,#### 0.5.0,"  
New MVVM architecture
New Package technology
New Signal routing technology
New HTTP server technology
New CSS parser, support more CSS syntax
New ScrollView, support complex layout
More jQuery-like syntax
Refactory directory structure
Refactory animation system
Support multi-language
Support manifest.json
New 3D UI inspector plugin
New grid system plugin
New alipay plugin
New location plugin
New push notification plugin
New social share plugin
New splash plugin
Bug fix
",4
https://github.com/dev1234/BeeFramework,#### 0.4.0,"  
Refactory the directory structure, divided into four parts, applicaton, service, system and vendor.
New XML template technology, perfect support for CSS
New QUERY technology, compatible with the jQUERY grammar
New automatic layout algorithm, easy to handle complex UI development task
New Service technology, plug-and-play
New mocking server technology, simulate network requests.
New ActiveObject technology, support any object serialization and deserialization
New In-app debugger, simplify the useless function
Code generator for JSON schema, no longer need to handwritten server docking code
Add BeeUISkeleton, an simple and powerful application entry
Add BeeRoutine, an BeeMessage which can asynchronous and by-self executing
Fix some BUG
",4
https://github.com/dev1234/BeeFramework,#### 0.3.0,"  
Fully support for MacOS
Fully support for UI template (xml)
Fully support for UI query syntax, like jQUERY
Fully support for template/viewController signal bridging by ID
Fix some bugs
",4
https://github.com/dev1234/BeeFramework,#### 0.2.3,"  
Refactoring the directory structure, Core and MVC completely separated, and the source files and the extensions completely separated
Refactoring the code structure of BeeDatabase and BeeActiveRecord, more clearly
Support the ActiveRecord inherition and nesting, support HAS/BELONG_TO operations
Support dot(.) opertions for BeeRequest and BeeMessage
Fix some bugs
",4
https://github.com/dev1234/BeeFramework,#### 0.2.0,"  
Add BeeDatabase
Add BeeActiveRecord
Overload graph
Fix some bugs
Move precompile options to 'Bee_Precompile.h'
",4
https://github.com/dev1234/BeeFramework,#### 0.1.0,"  
Draft version
Tutorial
In-app debugger
",4
https://github.com/dev1234/BeeFramework,## Contributors,"  


Name
Type




Gavin.Kwoe
https://github.com/gavinkwoe


QFish
https://github.com/qfish


STCui
https://github.com/stcui


ilikeido
https://github.com/ilikeido


gelosie
https://github.com/gelosie


lancy
https://github.com/lancy


uxyheaven
https://github.com/uxyheaven


Yulong
https://github.com/Yulong


esseak
https://github.com/esseak


inonomori
https://github.com/inonomori


",5
https://github.com/dev1234/BeeFramework,## More Incredible Projects from OpenSourceChina,"  You may want to see more great open source projects brought you by Chinese developers. See more in the Projects repo of OpenSourceChina. Join us, please contact gavinkwoe or onevcat.",6
https://github.com/fitmoo/drupal_store_ftm,# store," Initial Commit I pushed a drupal commerce , kickstart profile. Includes a pretty comprihensive store set up. It migth have somes stuf we might not need, but good way to get familiar with commerce, how prodcuts (skus/variations) and product displays relate.
Similiar model should be created in fitmoo. We should really just import the product variations. I also added stock module to /sites/all/modules/contrib We will have to add more modules, for the API, Drupal Services and etc for API end points. We could keep Kickstart as our base or just start with simple drupal and pick out modules we need. Base db with sample content is in /db/fitmoo_store.sql",1
https://github.com/fitmoo/drupal_store_ftm,# API,"  Create User Drupal needs to have a user account before user can create/add/edit products to their fitmoo store.
We will also need to create an account for a buyer
Request:   - Name
  - email
  - password
  - role -- Store Owner for a user that will be creating and updating products
            people buying prodicts do not need a role, they will have defaul Authenticated user role
 Return:   - uid 
 Example Call:   ======================REGISTRATION==============================
  POST http://fitmoo.plsekwerks.com/fit_store/user
  Content-Type: application/json
  {
    ""name"": ""testuser"",
    ""pass"": ""testuser"",
    ""mail"" : ""sabre+1@tut.by""
    ""role"" : ""Store Owner""       
  }
 
  -- response --
  Set-Cookie:  SESSe889a326a5c093a77c387b336cb83f72=E1juSPMd0fUOg3j_esS2G1MwU1jodrDpBjl0KHfli08; expires=Sat, 15-Mar-2014 17:03:45 GMT; path=/; domain=.fitmoo.plsekwerks.com; HttpOnly
  {""uid"":""4"",""uri"":""http://fitmoo.plsekwerks.com/fit_store/user/4""}
 Login User User needs to be logged in when products are pushed to drupal so products are created as that user.
User needs to be logget in when creating order Example Call:   ==================LOGIN===================
  POST http://fitmoo.plsekwerks.com/fit_store/user/login
  Content-Type: application/json
  {""username"": ""testuser"",""password"": ""testuser""}
  -- response --
  [""The username <em class=\""placeholder\"">testuser</em> has not been activated or is blocked.""]
  
  We will setup drupal to auto activate users on API call create user
  
  ==========LOGIN AFTER MANUALY ACTIVATING=============
  POST http://fitmoo.plsekwerks.com/fit_store/user/login
  Content-Type: application/json
  {""username"": ""testuser"",""password"": ""testuser""}
  -- response --
  Set-Cookie:  SESSe889a326a5c093a77c387b336cb83f72=pIuj9EEex7MoJ2AEGctHKvFCIFSMcDRTheU2HevpYUM; expires=Sat, 15-Mar-2014 17:09:19 GMT; path=/; domain=.fitmoo.plsekwerks.com; httponly
  {""sessid"":""pIuj9EEex7MoJ2AEGctHKvFCIFSMcDRTheU2HevpYUM"",""session_name"":""SESSe889a326a5c093a77c387b336cb83f72"",""user"":{""uid"":""4"",""name"":""testuser"",""theme"":"""",""signature"":"""",""signature_format"":""filtered_html"",""created"":""1392903024"",""access"":""0"",""login"":1392903359,""status"":""1"",""timezone"":""America/Los_Angeles"",""language"":"""",""picture"":null,""data"":false,""roles"":{""2"":""authenticated user""},""rdf_mapping"":{""rdftype"":[""sioc:UserAccount""],""name"":{""predicates"":[""foaf:name""]},""homepage"":{""predicates"":[""foaf:page""],""type"":""rel""}}}}
  
  ====================GET TOKEN========================
  GET http://fitmoo.plsekwerks.com/services/session/token
  Cookie:  SESSe889a326a5c093a77c387b336cb83f72=pIuj9EEex7MoJ2AEGctHKvFCIFSMcDRTheU2HevpYUM
  -- response --
  frGgOzjJPzrQBHi-5ghxVs43rDtGEVDMxNGjgW717mA
  
  
  Other available USER calls
  
  ===============GET USER LIST==================
  GET http://fitmoo.plsekwerks.com/fit_store/user
  Cookie: SESSe889a326a5c093a77c387b336cb83f72=pIuj9EEex7MoJ2AEGctHKvFCIFSMcDRTheU2HevpYUM
  X-CSRF-Token: frGgOzjJPzrQBHi-5ghxVs43rDtGEVDMxNGjgW717mA
  
   -- response --
  [{""uid"":""4"",""name"":""testuser"",""theme"":"""",""signature"":"""",""signature_format"":""filtered_html"",""created"":""1392903024"",""access"":""1392903648"",""login"":""1392903359"",""status"":""1"",""timezone"":""America/Los_Angeles"",""language"":"""",""picture"":""0"",""data"":""b:0;"",""uri"":""http://fitmoo.plsekwerks.com/fit_store/user/4""},{""uid"":""3"",""name"":""jiri"",""theme"":"""",""signature"":"""",""signature_format"":""filtered_html"",""created"":""1392649287"",""access"":""1392649302"",""login"":""1392649302"",""status"":""1"",""timezone"":""America/Los_Angeles"",""language"":"""",""picture"":""0"",""data"":null,""uri"":""http://fitmoo.plsekwerks.com/fit_store/user/3""},{""uid"":""1"",""name"":""admin"",""theme"":"""",""signature"":"""",""signature_format"":null,""created"":""1391997056"",""access"":""1392903302"",""login"":""1392894035"",""status"":""1"",""timezone"":""America/Los_Angeles"",""language"":"""",""picture"":""0"",""data"":""b:0;"",""uri"":""http://fitmoo.plsekwerks.com/fit_store/user/1""},{""uid"":""0"",""name"":"""",""theme"":"""",""signature"":"""",""signature_format"":null,""created"":""0"",""access"":""0"",""login"":""0"",""status"":""0"",""timezone"":null,""language"":"""",""picture"":""0"",""data"":null,""uri"":""http://fitmoo.plsekwerks.com/fit_store/user/0""}]
  
  ===============GET USER==================
  GET http://fitmoo.plsekwerks.com/fit_store/user/1
  Cookie: SESSe889a326a5c093a77c387b336cb83f72=pIuj9EEex7MoJ2AEGctHKvFCIFSMcDRTheU2HevpYUM
  X-CSRF-Token: frGgOzjJPzrQBHi-5ghxVs43rDtGEVDMxNGjgW717mA
  -- response --
  {""uid"":""1"",""name"":""admin"",""theme"":"""",""signature"":"""",""signature_format"":null,""created"":""1391997056"",""access"":""1392903302"",""login"":""1392894035"",""status"":""1"",""timezone"":""America/Los_Angeles"",""language"":"""",""picture"":null,""data"":false,""roles"":{""2"":""authenticated user"",""3"":""administrator""},""rdf_mapping"":{""rdftype"":[""sioc:UserAccount""],""name"":{""predicates"":[""foaf:name""]},""homepage"":{""predicates"":[""foaf:page""],""type"":""rel""}}}
 Create Product After user creates a product in fitmoo, API call to Drupal to create same product Request: - Product Display name
- description
- uid (store owner)
- type
- products (these are all the variations created by setting sizes and etc
  - sku (we can autogenerate skus in drupal, these have to be unique)
  - size
  - quantity (stock)
  - image url
  - price
 Response: - sku
- productID
 Example API""   ===============CREATE PRODUCT============== //these are the product variations
  POST http://fitmoo.plsekwerks.com/fit_store/product
  Cookie: SESSe889a326a5c093a77c387b336cb83f72=pIuj9EEex7MoJ2AEGctHKvFCIFSMcDRTheU2HevpYUM
  X-CSRF-Token: frGgOzjJPzrQBHi-5ghxVs43rDtGEVDMxNGjgW717mA
  Content-Type: application/json
  {
        ""title"": ""shoes_1"",
        ""sku"": ""shoes_1sku"",
        ""commerce_price_amount"": ""1000"",
        ""commerce_price_currency_code"": ""USD"",
        ""type"": ""shoes"",
        ""field_shoe_size"": ""10""
  }
  
  -- response --
  {""type"":""shoes"",""product_id"":""8"",""sku"":""shoes_1sku"",""revision_id"":""9"",""title"":""shoes_1"",""uid"":"""",""status"":1,""created"":1392904311,""changed"":1392904311,""commerce_price"":{""amount"":""1000"",""currency_code"":""USD"",""data"":{""components"":[]}},""field_shoe_size"":""10"",""revision_timestamp"":1392904311,""revision_uid"":""4"",""log"":"""",""language"":"""",""attribute_fields"":[""field_shoe_size""],""commerce_price_formatted"":""$10.00"",""field_image_url"":null,""commerce_stock"":null}
  
  ===============GET PRODUCT==============
  GET http://fitmoo.plsekwerks.com/fit_store/product?sku=shoes_1sku
  Cookie: SESSe889a326a5c093a77c387b336cb83f72=pIuj9EEex7MoJ2AEGctHKvFCIFSMcDRTheU2HevpYUM
  X-CSRF-Token: frGgOzjJPzrQBHi-5ghxVs43rDtGEVDMxNGjgW717mA
  -- response --
  {""8"":{""revision_id"":""9"",""sku"":""shoes_1sku"",""title"":""shoes_1"",""revision_uid"":""4"",""status"":""1"",""log"":"""",""revision_timestamp"":""1392904311"",""data"":false,""product_id"":""8"",""type"":""shoes"",""language"":"""",""uid"":""0"",""created"":""1392904311"",""changed"":""1392904311"",""commerce_price"":{""amount"":""1000"",""currency_code"":""USD"",""data"":{""components"":[]}},""field_image_url"":null,""field_shoe_size"":""10"",""commerce_stock"":null,""rdf_mapping"":[],""attribute_fields"":[""field_shoe_size""],""commerce_price_formatted"":""$10.00"",""field_shoe_size_entities"":{""10"":{""tid"":""10"",""vid"":""3"",""name"":""6"",""description"":"""",""format"":""filtered_html"",""weight"":""0"",""vocabulary_machine_name"":""shoe_size"",""rdf_mapping"":{""rdftype"":[""skos:Concept""],""name"":{""predicates"":[""rdfs:label"",""skos:prefLabel""]},""description"":{""predicates"":[""skos:definition""]},""vid"":{""predicates"":[""skos:inScheme""],""type"":""rel""},""parent"":{""predicates"":[""skos:broader""],""type"":""rel""}}}}}}
  
  ===============CREATE NODE PRODUCT==========  node product is the main container that holds all variations
  ids = prodct ids from call aboce CREATE product
  
  POST http://fitmoo.plsekwerks.com/fit_store/product
  Cookie: SESSe889a326a5c093a77c387b336cb83f72=pIuj9EEex7MoJ2AEGctHKvFCIFSMcDRTheU2HevpYUM
  X-CSRF-Token: frGgOzjJPzrQBHi-5ghxVs43rDtGEVDMxNGjgW717mA
  Content-Type: application/json
  {
        ""title"": ""title21"",
        ""sku"": ""sku21"",
        ""node"": ""true"",  (!!!!!!!!!!STRING!!!!!!!!!! don't need ""false"" you create simple commerce_product) 
        ""description"": ""description"", 
        ""type"": ""shoes"",
        ""ids"": [
              {
               ""0"": ""10"",
              ""1"": ""11""
              }
        ]
  }
  
   -- response --
  {""type"":""shoes"",""title"":""title21"",""uid"":""4"",""status"":1,""language"":""und"",""body"":{""und"":[{""value"":""description""}]},""field_product"":{""und"":[{""product_id"":""11""}]},""created"":1393331960,""changed"":1393331960,""timestamp"":1393331960,""log"":"""",""nid"":""6"",""comment"":0,""promote"":0,""sticky"":0,""tnid"":0,""translate"":0,""vid"":""6""}
  
  =================GET NODE PRODUCT============
  GET http://fitmoo.plsekwerks.com/fit_store/node/6
  Cookie: SESSe889a326a5c093a77c387b336cb83f72=pIuj9EEex7MoJ2AEGctHKvFCIFSMcDRTheU2HevpYUM
  X-CSRF-Token: frGgOzjJPzrQBHi-5ghxVs43rDtGEVDMxNGjgW717mA
  -- response --
  {""vid"":""6"",""uid"":""4"",""title"":""title21"",""log"":"""",""status"":""1"",""comment"":""0"",""promote"":""0"",""sticky"":""0"",""nid"":""6"",""type"":""shoes"",""language"":""und"",""created"":""1393331960"",""changed"":""1393331960"",""tnid"":""0"",""translate"":""0"",""revision_timestamp"":""1393331960"",""revision_uid"":""4"",""body"":{""und"":[{""value"":""description"",""summary"":null,""format"":null,""safe_value"":""description"",""safe_summary"":""""}]},""field_gender"":[],""field_brand"":[],""field_product"":{""und"":[{""product_id"":""11""}]},""rdf_mapping"":{""rdftype"":[""sioc:Item"",""foaf:Document""],""title"":{""predicates"":[""dc:title""]},""created"":{""predicates"":[""dc:date"",""dc:created""],""datatype"":""xsd:dateTime"",""callback"":""date_iso8601""},""changed"":{""predicates"":[""dc:modified""],""datatype"":""xsd:dateTime"",""callback"":""date_iso8601""},""body"":{""predicates"":[""content:encoded""]},""uid"":{""predicates"":[""sioc:has_creator""],""type"":""rel""},""name"":{""predicates"":[""foaf:name""]},""comment_count"":{""predicates"":[""sioc:num_replies""],""datatype"":""xsd:integer""},""last_activity"":{""predicates"":[""sioc:last_activity_date""],""datatype"":""xsd:dateTime"",""callback"":""date_iso8601""}},""cid"":0,""last_comment_timestamp"":""1393331960"",""last_comment_name"":"""",""last_comment_uid"":""4"",""comment_count"":0,""name"":""testuser"",""picture"":""0"",""data"":""b:0;"",""path"":""http://fitmoo.plsekwerks.com/node/6""}
 Edit Product Any product updates Request:  - productID
 - price
 - quantity
 - image url
 - size
 - uid
 Responce:  - OK
 - productID
 Delete Product Request:  - productID
 - uid
",36
https://github.com/fitmoo/drupal_store_ftm,# Buy Flow,"  User clicks buy now in Fitmoo. Fitmoo makes a request to Drupal to login the user, on successfull return, fitmoo creates a modal window with iframe to call createOrder menu. Drupal creates order as the loggedin user and displays a checkout form in iframe. User completes the checkout in iframe after confimration page, modal is closed. Confirmation emails go to Buyer and Seller",3
https://github.com/fitmoo/drupal_store_ftm,# API,"  Click Buy - login/register Fitmoo if uid then login user, if no uid register user -- see API above.
After register user is logged in Create Order iframe url request to drupal menu
example: store.fitmoo.com/createorder/productID/quantity Drupal add order to cart -> redirect drupal_goto('checkout') present checkout form (minimal theme)",36
https://github.com/travisjeffery/pat,# pat (formerly pat.go) - A Sinatra style pattern muxer for Go's net/http library, ,1
https://github.com/travisjeffery/pat,## INSTALL,"  $ go get github.com/bmizerany/pat
",3
https://github.com/travisjeffery/pat,## USE,"  package main

import (
	""io""
	""net/http""
	""github.com/bmizerany/pat""
	""log""
)

// hello world, the web server
func HelloServer(w http.ResponseWriter, req *http.Request) {
	io.WriteString(w, ""hello, ""+req.URL.Query().Get("":name"")+""!\n"")
}

func main() {
	m := pat.New()
	m.Get(""/hello/:name"", http.HandlerFunc(HelloServer))

	// Register this pat with the default serve mux so that other packages
	// may also be exported. (i.e. /debug/pprof/*)
	http.Handle(""/"", m)
	err := http.ListenAndServe("":12345"", nil)
	if err != nil {
		log.Fatal(""ListenAndServe: "", err)
	}
} It's that simple. For more information, see:
http://godoc.org/github.com/bmizerany/pat",36
https://github.com/travisjeffery/pat,## CONTRIBUTORS,"  
Alexis Svinartchouk (@zvin)
Blake Mizerany (@bmizerany)
Brian Ketelsen (@bketelsen)
Bryan Matsuo (@bmatsuo)
Caleb Spare (@cespare)
Evan Shaw (@edsrzf)
Gary Burd (@garyburd)
George Rogers (@georgerogers42)
Keith Rarick (@kr)
Matt Williams (@mattyw)
Mike Stipicevic (@wickedchicken)
Nick Saika (@nesv)
Timothy Cyrus (@tcyrus)
binqin (@binku87)
",5
https://github.com/travisjeffery/pat,## LICENSE,"  Copyright (C) 2012 by Keith Rarick, Blake Mizerany Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.",5
https://github.com/zephyrm/d3,# D3: Data-Driven Documents,"  D3 (or D3.js) is a JavaScript library for visualizing data using web standards. D3 helps you bring data to life using SVG, Canvas and HTML. D3 combines powerful visualization and interaction techniques with a data-driven approach to DOM manipulation, giving you the full capabilities of modern browsers and the freedom to design the right visual interface for your data.",12
https://github.com/zephyrm/d3,## Resources,"  
API Reference
Release Notes
Gallery
Examples
Wiki
",6
https://github.com/zephyrm/d3,## Installing,"  If you use npm, npm install d3. Otherwise, download the latest release. The released bundle supports anonymous AMD, CommonJS, and vanilla environments. You can load directly from d3js.org, CDNJS, or unpkg. For example: <script src=""https://d3js.org/d3.v4.js""></script> For the minified version: <script src=""https://d3js.org/d3.v4.min.js""></script> You can also use the standalone D3 microlibraries. For example, d3-selection: <script src=""https://d3js.org/d3-selection.v1.js""></script> D3 is written using ES2015 modules. Create a custom bundle using Rollup, Webpack, or your preferred bundler. To import D3 into an ES2015 application, either import specific symbols from specific D3 modules: import {scaleLinear} from ""d3-scale""; Or import everything into a namespace (here, d3): import * as d3 from ""d3""; In Node: var d3 = require(""d3""); You can also require individual modules and combine them into a d3 object using Object.assign: var d3 = Object.assign({}, require(""d3-format""), require(""d3-geo""), require(""d3-geo-projection""));",3
https://github.com/shilobanerjee/AFiNeS,# README #,,1
https://github.com/shilobanerjee/AFiNeS,### What is this repository for? ###,"  
Coarse-grained model of actomyosin networks
",1
https://github.com/shilobanerjee/AFiNeS,### System Requirements ###,"  Minimally, this system requires gcc+11 and boost C++ library Login to Grace To load gcc, run the command module load Langs/GCC/5.2.0 
 Load boost library module load Libs/Boost/1.59.0
",3
https://github.com/shilobanerjee/AFiNeS,### QUICKSTART GUIDE ###,"  

Download AFiNeS repository
> git clone https://github.com/shilobanerjee/AFiNeS.git



Change to AFiNeS directory
> cd AFiNeS



Create a bin directory with:
> mkdir bin



Link to boost library

Run the command:
> export BOOST_ROOT=/gpfs/apps/hpc/Libs/Boost/1.59.0/lib


Open 'makefile' using a text editor (e.g. emacs). Add -I gpfs/apps/hpc/Libs/Boost/1.59.0/include to the line that begins with INC := in the makefile.



To create an executable, run the command:
> make [clean] network 


[clean] will delete the old executable. This is optional.



You should now have an executable file called bin/afines. NOTE: you only need to recreate this file if you edit the source
code.


Create an output directory for your simulation (not necessarily named ""out/test"") as well as the ""txt_stack"" and ""data""
directories (necessarily named ""txt_stack"" and ""data"") e.g. with the commands:

 > mkdir -p out/test/txt_stack
> mkdir -p out/test/data
 

Run your simulation in the specified output output directory, e.g.,
> bin/afines --dir out/test



See below for other simulation configuration options that you can set from the command line or from a configuration
file


Once your simulation has completed, the following files will have been generated:


out/test/txt_stack/actins.txt //the trajectories of every actin bead


out/test/txt_stack/links.txt //the trajectories of every link


out/test/txt_stack/amotors.txt //the trajectories of all active motors (e.g., myosin) at every time step


out/test/txt_stack/pmotors.txt //the trajectories of all passive motors (e.g., crosslinkers) at every time step


out/test/data/thermo.txt //the energies of actin filaments


out/test/data/output.txt //some metadata about the simulation

 All files are tab delimited 

txt_stack/actins.txt has the format

x y r idx

(x, y)  = bead position,
r  = bead radius
idx = index of filament that the bead is on





txt_stack/links.txt has the format

x y dx dy idx

(x, y) = end position of link closer to the barbed end of filament
(x + dx, y + dy) = end position of link farther from barbed end
idx = index of filament the link is on





txt_stack/amotors.txt and txt_stack/pmotors.txt have the format

x y dx dy fidx0 fidx1 lidx0 lidx1

(x, y) = position of head 0 of motor
(x + dx, y + dy) = position of head 1 of motor
fidx0 = index of filament that head 0 is attached to (-1 if not attached)
fidx1 = index of filament that head 1 is attached to (-1 if not attached)
lidx0 = index of link that head 0 is attached to (-1 if fidx0 = -1)
lidx1 = index of link that head 1 is attached to (-1 if fidx1 = -1)





data/thermo.txt has the format

KE PE TE idx

KE = total v^2 of filament
PE = total potential energy of filament
TE = KE + PE
idx = filament index




 The time associated with the positions/energies is on it's own line before
each list of positions within the file. Thus the structure of actins.txt is:     t = t1
    x1, y1, r1, idx1
    .
    .
    .
    xn, yn, rn, idxn
    t=t2
    x1, y1, r1, idx1,
    .
    .
    .
    t=tn
    .
    .
    .
    xn, yn, rn, idxn
 And similarly for other output files
",3
https://github.com/shilobanerjee/AFiNeS,### Configurable settings ###,"  Currently the following options for simulation parameters (provided in the table) can be set upon execution, either from the command line, or within a
configuration file: For example, to run a 500 second of simulation of 10 rigid actin filaments, an active motor density of 0.5 and a crosslinker density
of 0.05 you would enter the command:
> ./bin/afines --tf 500 --npolymer 10 --a_motor_density 0.5 --p_motor_density 0.05
(this would write to the default output directory)",3
https://github.com/shilobanerjee/AFiNeS,## Simulation Parameters ##,"  


variable name
type
default value
units
description




ENVIRONMENT






xrange
double
50
um
size of cell in horizontal direction


yrange
double
50
um
size of cell in vertical direction


grid_factor
double
1
um^(-2)
number of grid boxes


dt
double
0.0001
s
length of individual timestep


tinit
double
0
s
time that recording of simulation starts


tfinal
double
10
s
length of simulation


nframes
int
100
0
number of frames of actin/link/motor positions printed to file (equally distant in time)


nmsgs
int
1000
0
number of timesteps between printing simulation progress to stdout


viscosity
double
0.001
mg/um*s
Dynamic viscosity


temperature
double
0.004
pN*um
Temp in energy units


bnd_cnd
string
""PERIODIC""

boundary conditions


dir
string
""out/test""

directory for output files


myseed
int
time(NULL)

seed of random number generator


ACTIN






nmonomer
double
11

number of beads per filament


npolymer
double
3

number of polymers in the network


actin_length
double
0.5
um
Length of a single actin monomer


actin_pos_str
string


Starting positions of actin polymers, commas delimit coordinates; semicolons delimit positions


link_length
double
0

Length of links connecting monomers


polymer_bending_modulus
double
0.04
pn*um^2
Bending modulus of a filament


fracture_force
double
1000000
pN
filament breaking poiafines


bending_fracture_force
double
1000000
pN
filament breaking point


link_stretching_stiffness
double
1
pN/um
stiffness of link


MOTORS






a_motor_density
double
0.05
um^(-2)
number of active motors


a_motor_pos_str
string


Starting positions of motors, commas delimit coordinates; semicolons delimit positions


a_m_kon
double
100
s^(-1)
active motor on rate


a_m_koff
double
20
s^(-1)
active motor off rate


a_m_kend
double
20
s^(-1)
active motor off rate at filament end


a_motor_stiffness
double
10
pN/um
active motor spring stiffness


a_motor_length
double
0.4
um
length of motor


a_m_stall
double
10
pN
stall force of motors


a_m_break
double
10
pN
rupture force of motors


a_m_bind
double
0.04
pN*um
binding energy


a_motor_v
double
1
um/s
velocity along filaments towards barbed end when attached


motor_intersect_flag
boolean
false

if true, then motors are placed at filament intersections


a_linkage_prob
double
1

probability that filaments are linked by a motor if motor_intersect_flag = true


dead_head_flag
boolean
false

if true, then head [dead_head] of all motors remains stationary throughout sim


dead_head
int
0

can be 0 or 1; head that remains stationary if dead_head_flag=true


CROSSLINKS






p_motor_density
double
0.05
um^(-2)
number of passive motors


p_motor_pos_str
string


Starting positions of xlinks, commas delimit coordinates; semicolons delimit positions


p_m_kon
double
100
s^(-1)
passive motor on rate


p_m_koff
double
20
s^(-1)
passive motor off rate


p_m_kend
double
20
s^(-1)
passive motor off rate at filament end


p_motor_stiffness
double
50
s^(-1)
xlink spring stiffness (pN/um)


p_motor_length
double
0.4
s^(-1)
length of xlink


p_m_stall
double
0
pN
stall force


p_m_break
double
10
pN
rupture force


p_m_bind
double
0.04
pN*um
binding energy


link_intersect_flag
boolean
false

if true, then crosslinks are placed at filament intersections


p_linkage_prob
double
1

probability that filaments are crosslinked if link_intersect_flag = true


p_dead_head_flag
boolean
false

if true, then head [p_dead_head] of all xlinks remains stationary throughout sim


p_dead_head
int
0

can be 0 or 1; head that remains stationary if p_dead_head_flag=true


static_cl_flag
boolean
false

should be set to true if xlinks start off attached to filaments and never detach


SHEAR






strain_pct
double
0

pre-strain (e.g., 0.5 means a strain of 0.5*xrange)


time_of_strain
double
0

time of pre-strain


d_strain_pct
double
0
s
differential strain (e.g., 0.5 means a strain of 0.5*xrange)


time_of_dstrain
double
10000
s
time when differential strain begins


diff_strain_flag
boolean
false

flag to use if differential strain should be linear (in one direction)


osc_strain_flag
boolean
false

flag to use if differential strain should be oscillatory (like Gardel, Science 2004)


n_bw_shear
int
10^8
s
number of timesteps between subsequent differential strains


d_strain_freq
double
1
Hz
frequency of differential oscillatory strain


",3
https://github.com/shilobanerjee/AFiNeS,### Configuration file Example ###,"  Below is an example of a configuration file named example.cfg
To run a simulation using this configuration, enter the command
   >./bin/afines -c example.cfg",3
https://github.com/shilobanerjee/AFiNeS,#### example.cfg ####,"  npolymer=500
nmonomer=1
dt=0.001
nframes=2000
tfinal=100
actin_length=0.5
a_motor_density=0.05
link_intersect_flag=true
actin_pos_str=0,0,0:1,2,3.141
",3
https://github.com/shilobanerjee/AFiNeS,### Developers ###,  Simon Freedman (University of Chicago) Shiladitya Banerjee (University College London) Glen Hocky (University of Chicago) Aaron Dinner (University of Chicago),5
https://github.com/bambella4316/javascript-arithmetic-lab-bootcamp-prep-000,## JavaScript Arithmetic Lab,,1
https://github.com/bambella4316/javascript-arithmetic-lab-bootcamp-prep-000,## Objectives,"  
Practice doing math with JavaScript
Practice writing functions that do things with numbers
Practice parsing strings as numbers
",12
https://github.com/bambella4316/javascript-arithmetic-lab-bootcamp-prep-000,## Introduction,"  In this lab, we're going to practice writing functions and manipulating numbers in JavaScript. First, though, we need to go over some basic math. In this lab, we're going to learn about various arithmetic operators. What's an operator, you say? It's a symbol that operates on one or more (usually two) objects ?+ is a good example. The + operator says ""add what's to the left of + and what's to the right of + together."" Easy-peasy! As you read through this lesson, you're going to be adding your solutions to index.js. You'll write a total of eight functions; use the results of running learn test in your IDE to guide you towards the right function names and functionality.",1
https://github.com/bambella4316/javascript-arithmetic-lab-bootcamp-prep-000,## Basic Math,"  The most fundamental math operations work as one might expect in JavaScript: + adds two numbers; - subtracts one number from another; * multiplies two numbers; and / divides one number by another. For example (as usual, follow along in console!) 1 + 80 // 81
60 - 40 // 20
2 * 3.4 // 6.8 (there's that floating-point arithmetic again...)
5.0 / 2.5 // 2 At this point, we can fix the first four broken tests: we can define functions add(), subtract(), multiply(), divide() in index.js.",3
https://github.com/bambella4316/javascript-arithmetic-lab-bootcamp-prep-000,## Math + Assignment,"  Additionally, we can increment (++) and decrement (--) a number if it's assigned to a variable: var number = 5

number++ // 5... hmmmm

number // 6 -- the number was incremented after it was evaluated

number-- // 6

number // 5 We can also put the incrementor and decrementor operations before the number: --number // 4

++number // 5 But generally, you will see them placed after the number (and we recommend that that's where you put them). If you're interested in the difference, take a look here And, while we're on the subject, you'll usually only want to use these incrementors and decrementors when the shorthand makes what you're writing easier to read (more on when exactly later). Instead, it's best to use the basic arithmetic operators combined with =. For the examples below, assume that number is equal to 5 (and resets for every example). 
+= modifies the value to the operator's left by adding to it the value to the operator's right:
 number += 3 // 8 
-= modifies the value to the operator's left by subtracting from it the value to the operator's right:
 number -= 2 // 3 
*= modifies the value to the operator's left by multiplying it by the value to the operator's right:
 number *= 10 // 50 
/= modifies the value to the operator's left by dividing it by the value to the operator's right:
 number /= 5 // 1 The thing to remember about these methods is that they modify the variable in place. So if we have two functions that depend on the same external variable, the order in which they're called matters. Follow along in console: var number = 10

function add5() {
  number += 5
}

function divideBy3() {
  number /= 3
}

divideBy3()

console.log(number) // 3.333333333335

add5()

console.log(number) // 8.333333333335

// reset number
number = 10

add5()

console.log(number) // 15

divideBy3()

console.log(number) // 5 Because these methods are more explicit, prefer += to ++ and -= to -- (usually). Okay, now we're ready to write solutions for the next two functions: inc(n) and dec(n).",36
https://github.com/bambella4316/javascript-arithmetic-lab-bootcamp-prep-000,## Parsing Numbers,"  Sometimes, we'll receive a number ?well, we know it's a number, as we've seen many numbers in the past. JavaScript, however, won't know that it's a number because it shows up wrapped in quotes ?JavaScript, then, thinks it's a string. Luckily, JavaScript gives us tools to turn these strings into proper numbers (that is, numbers that JavaScript understands).",3
https://github.com/bambella4316/javascript-arithmetic-lab-bootcamp-prep-000,### `parseInt()`,"  The first such tool is the function parseInt(), which accepts two arguments: the value to parse and the base of the value being parsed. Usually you will want to work with base 10, so a typical call to parseInt() looks like parseInt('2', 10) // 2 What happens if we pass a representation of a non-integer to parseInt()? Let's try it: parseInt('2.2222', 10) If we enter the above in console, we'll see that parseInt() forces the parsed number to be an integer ?which makes sense when we think about it, right? What happens, though, if we pass utter nonsense to parseInt()? Go ahead and try it in the console ?something like parseInt('nonsense!', 10) What did it return? NaN? What is that? NaN stands for ""not a number"" ?pretty handy, right? This is the number (in the JavaScript sense) that JavaScript returns when it can't determine a valid value for a numeric operation.",3
https://github.com/bambella4316/javascript-arithmetic-lab-bootcamp-prep-000,### `parseFloat()`,"  Above, we saw that parseInt() lops off everything after the decimal point and only returns integers. If we want to preserve decimals, we'll need to use parseFloat(). Unlike parseInt(), parseFloat() accepts only a single argument, the thing to be parsed. We can use it like so: parseFloat('80.123999') // 80.123999 You're now ready to solve the final two tests in this lab, makeInt(n) and preserveDecimal(n).",3
https://github.com/bambella4316/javascript-arithmetic-lab-bootcamp-prep-000,## Resources,"  

parseInt(): https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseInt


parseFloat(): https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/parseFloat

 View JavaScript Arithmetic Lab on Learn.co and start learning to code for free.",6
https://github.com/leobcn/takeown,# takeown: delegate file ownership takeover to unprivileged users," Brief usage: takeown [-T] [-r] [-s] PATH
takeown [-T] -a USER PATH...
takeown [-T] -l PATH...
takeown [-T] -d USER PATH...
",1
https://github.com/leobcn/takeown,## INTRO,"  takeown allows administrators to delegate taking ownersip ownership of files
and directories to non-administrators.  It uses the set-uid bit to gain the
necessary privileges to do so. Example: the administrator wants to let the user pablo take over ownership
of files in /var/shared/Incoming.  To that effect, the administrator runs: takeown -a pablo /var/shared/Incoming
 Once he has done so, the user pablo can run the command: takeown /var/shared/Incoming/some-file.txt
 and takeown will change the owner of the file some-file.txt to pablo. Each delegation is recorded in a file .takeown.delegations stored in the
root directory of the volume containing the delegated file / directory. Delegations recorded on a volume only apply to files and directories
stored in the volume.  Delegations do not propagate across mount points.
If a user has been granted a delegation on a directory, he will be
authorized to take ownership of any files contained in that directory,
so long as said files are in the same volume. The flag -r in the takeown command induces takeown to grant ownership to the
invoking user recursively across all files and subdirectories of the specified
paths.  The caveat about not crossing mount points applies -- if another
volume is mounted within the path specified to a takeown -r command, that
volume will be skipped silently. For security reasons, attempts by an authorized user to take ownership of
a volume or ownership of the delegation record file will be silently ignored.",1
https://github.com/leobcn/takeown,## DELEGATING OWNERSHIP TO AN USER,"  To allow a user to take ownership of files under a directory, or specific
files, run: takeown username /path/to/directory/or/file...
 This will delegate the taking of ownership to the user, allowing him to run
takeown to take ownership of any file within the specified paths. WARNING: if you delegate the taking of ownership of a volume to a user,
that user may take ownership of the volume itself, and then remove the
delegation store.  This is not a security issue -- it does not grant the
user any extra privileges -- but it does prevent future uses of takeown
by unprivileged users in that volume.",3
https://github.com/leobcn/takeown,## REVOKING DELEGATIONS,"  To revoke an established delegation, use the following command: takeown -d username /delegated/path
 This removes the specific delegation established for that user name.",3
https://github.com/leobcn/takeown,## LISTING DELEGATIONS,"  Any user may list established delegations with the command: takeown -l [PATH]
 However, only the administrator may list delegations for all users.  Other
users will only get to see the delegations assigned to him.",3
https://github.com/leobcn/takeown,## SIMULATING TAKING OWNERSHIP,"  The action of taking ownership can be simulated with flag -s.  In this mode,
takeown will print what it would do rather than changing the file system.",3
https://github.com/leobcn/takeown,## TRACING,"  If a file /.trace exists in the root directory, the user is allowed to
specify the flag -T, which causes the program to print tracing information,
useful to debug problems with the program.",3
https://github.com/leobcn/takeown,## LICENSE,  This program is published under the GNU GPL version 3 or later.,5
https://github.com/itsky365/vegeta,# Vegeta [![Build Status](https://secure.travis-ci.org/tsenart/vegeta.png)](http://travis-ci.org/tsenart/vegeta) [![Go Report Card](https://goreportcard.com/badge/github.com/tsenart/vegeta)](https://goreportcard.com/report/github.com/tsenart/vegeta) [![GoDoc](https://godoc.org/github.com/tsenart/vegeta?status.svg)](https://godoc.org/github.com/tsenart/vegeta) [![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/tsenart/vegeta?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge) [![Donate](https://img.shields.io/badge/donate-bitcoin-yellow.svg)](#donate)," Vegeta is a versatile HTTP load testing tool built out of a need to drill
HTTP services with a constant request rate.
It can be used both as a command line utility and a library. ",1
https://github.com/itsky365/vegeta,## Install, ,3
https://github.com/itsky365/vegeta,### Pre-compiled executables,  Get them here.,3
https://github.com/itsky365/vegeta,### Homebrew on Mac OS X,  You can install Vegeta using the Homebrew package manager on Mac OS X: $ brew update && brew install vegeta,3
https://github.com/itsky365/vegeta,### Source,"  You need go installed and GOBIN in your PATH. Once that is done, run the
command: $ go get -u github.com/tsenart/vegeta",3
https://github.com/itsky365/vegeta,## Contributing,  See CONTRIBUTING.md.,7
https://github.com/itsky365/vegeta,## Usage manual,"  Usage: vegeta [global flags] <command> [command flags]

global flags:
  -cpus int
      Number of CPUs to use (default 8)
  -profile string
      Enable profiling of [cpu, heap]
  -version
      Print version and exit

attack command:
  -body string
      Requests body file
  -cert string
      TLS client PEM encoded certificate file
  -connections int
      Max open idle connections per target host (default 10000)
  -duration duration
      Duration of the test [0 = forever]
  -header value
      Request header
  -http2
      Send HTTP/2 requests when supported by the server (default true)
  -insecure
      Ignore invalid server TLS certificates
  -keepalive
      Use persistent connections (default true)
  -key string
      TLS client PEM encoded private key file
  -laddr value
      Local IP address (default 0.0.0.0)
  -lazy
      Read targets lazily
  -output string
      Output file (default ""stdout"")
  -rate uint
      Requests per second (default 50)
  -redirects int
      Number of redirects to follow. -1 will not follow but marks as success (default 10)
  -root-certs value
      TLS root certificate files (comma separated list)
  -targets string
      Targets file (default ""stdin"")
  -timeout duration
      Requests timeout (default 30s)
  -workers uint
      Initial number of workers (default 10)

report command:
  -inputs string
      Input files (comma separated) (default ""stdin"")
  -output string
      Output file (default ""stdout"")
  -reporter string
      Reporter [text, json, plot, hist[buckets]] (default ""text"")

dump command:
  -dumper string
      Dumper [json, csv] (default ""json"")
  -inputs string
      Input files (comma separated) (default ""stdin"")
  -output string
      Output file (default ""stdout"")

examples:
  echo ""GET http://localhost/"" | vegeta attack -duration=5s | tee results.bin | vegeta report
  vegeta attack -targets=targets.txt > results.bin
  vegeta report -inputs=results.bin -reporter=json > metrics.json
  cat results.bin | vegeta report -reporter=plot > plot.html
  cat results.bin | vegeta report -reporter=""hist[0,100ms,200ms,300ms]""",3
https://github.com/itsky365/vegeta,#### `-cpus`,"  Specifies the number of CPUs to be used internally.
It defaults to the amount of CPUs available in the system.",3
https://github.com/itsky365/vegeta,#### `-profile`,"  Specifies which profiler to enable during execution. Both cpu and
heap profiles are supported. It defaults to none.",3
https://github.com/itsky365/vegeta,#### `-version`,  Prints the version and exits.,3
https://github.com/itsky365/vegeta,### `attack`,"  $ vegeta attack -h
Usage of vegeta attack:
  -body string
      Requests body file
  -cert string
      TLS client PEM encoded certificate file
  -connections int
      Max open idle connections per target host (default 10000)
  -duration duration
      Duration of the test [0 = forever]
  -header value
      Request header
  -http2
      Send HTTP/2 requests when supported by the server (default true)
  -insecure
      Ignore invalid server TLS certificates
  -keepalive
      Use persistent connections (default true)
  -key string
      TLS client PEM encoded private key file
  -laddr value
      Local IP address (default 0.0.0.0)
  -lazy
      Read targets lazily
  -output string
      Output file (default ""stdout"")
  -rate uint
      Requests per second (default 50)
  -redirects int
      Number of redirects to follow. -1 will not follow but marks as success (default 10)
  -root-certs value
      TLS root certificate files (comma separated list)
  -targets string
      Targets file (default ""stdin"")
  -timeout duration
      Requests timeout (default 30s)
  -workers uint
      Initial number of workers (default 10)",3
https://github.com/itsky365/vegeta,#### `-body`,"  Specifies the file whose content will be set as the body of every
request unless overridden per attack target, see -targets.",3
https://github.com/itsky365/vegeta,#### `-cert`,"  Specifies the PEM encoded TLS client certificate file to be used with HTTPS requests.
If -key isn't specified, it will be set to the value of this flag.",3
https://github.com/itsky365/vegeta,#### `-connections`,  Specifies the maximum number of idle open connections per target host.,3
https://github.com/itsky365/vegeta,#### `-duration`,"  Specifies the amount of time to issue request to the targets.
The internal concurrency structure's setup has this value as a variable.
The actual run time of the test can be longer than specified due to the
responses delay. Use 0 for an infinite attack.",3
https://github.com/itsky365/vegeta,#### `-header`,"  Specifies a request header to be used in all targets defined, see -targets.
You can specify as many as needed by repeating the flag.",3
https://github.com/itsky365/vegeta,#### `-http2`,  Specifies whether to enable HTTP/2 requests to servers which support it.,3
https://github.com/itsky365/vegeta,#### `-insecure`,  Specifies whether to ignore invalid server TLS certificates.,3
https://github.com/itsky365/vegeta,#### `-keepalive`,  Specifies whether to reuse TCP connections between HTTP requests.,3
https://github.com/itsky365/vegeta,#### `-key`,"  Specifies the PEM encoded TLS client certificate private key file to be
used with HTTPS requests.",3
https://github.com/itsky365/vegeta,#### `-laddr`,  Specifies the local IP address to be used.,3
https://github.com/itsky365/vegeta,#### `-lazy`,"  Specifies whether to read the input targets lazily instead of eagerly.
This allows streaming targets into the attack command and reduces memory
footprint.
The trade-off is one of added latency in each hit against the targets.",3
https://github.com/itsky365/vegeta,#### `-output`,"  Specifies the output file to which the binary results will be written
to. Made to be piped to the report command input. Defaults to stdout.",3
https://github.com/itsky365/vegeta,####  `-rate`,"  Specifies the requests per second rate to issue against
the targets. The actual request rate can vary slightly due to things like
garbage collection, but overall it should stay very close to the specified.",3
https://github.com/itsky365/vegeta,#### `-redirects`,"  Specifies the max number of redirects followed on each request. The
default is 10. When the value is -1, redirects are not followed but
the response is marked as successful.",3
https://github.com/itsky365/vegeta,#### `-root-certs`,"  Specifies the trusted TLS root CAs certificate files as a comma separated
list. If unspecified, the default system CAs certificates will be used.",3
https://github.com/itsky365/vegeta,#### `-targets`,"  Specifies the attack targets in a line separated file, defaulting to stdin.
The format should be as follows, combining any or all of the following: Simple targets GET http://goku:9090/path/to/dragon?item=balls
GET http://user:password@goku:9090/path/to
HEAD http://goku:9090/path/to/success
 Targets with custom headers GET http://user:password@goku:9090/path/to
X-Account-ID: 8675309

DELETE http://goku:9090/path/to/remove
Confirmation-Token: 90215
Authorization: Token DEADBEEF
 Targets with custom bodies POST http://goku:9090/things
@/path/to/newthing.json

PATCH http://goku:9090/thing/71988591
@/path/to/thing-71988591.json
 Targets with custom bodies and headers POST http://goku:9090/things
X-Account-ID: 99
@/path/to/newthing.json
",3
https://github.com/itsky365/vegeta,#### `-timeout`,"  Specifies the timeout for each request. The default is 0 which disables
timeouts.",3
https://github.com/itsky365/vegeta,#### `-workers`,"  Specifies the initial number of workers used in the attack. The actual
number of workers will increase if necessary in order to sustain the
requested rate.",3
https://github.com/itsky365/vegeta,### report,"  $ vegeta report -h
Usage of vegeta report:
  -inputs string
      Input files (comma separated) (default ""stdin"")
  -output string
      Output file (default ""stdout"")
  -reporter string
      Reporter [text, json, plot, hist[buckets]] (default ""text"")",3
https://github.com/itsky365/vegeta,#### `-inputs`,"  Specifies the input files to generate the report of, defaulting to stdin.
These are the output of vegeta attack. You can specify more than one (comma
separated) and they will be merged and sorted before being used by the
reports.",3
https://github.com/itsky365/vegeta,#### `-output`,  Specifies the output file to which the report will be written to.,3
https://github.com/itsky365/vegeta,#### `-reporter`,  Specifies the kind of report to be generated. It defaults to text.,3
https://github.com/itsky365/vegeta,##### `text`,"  Requests      [total, rate]             1200, 120.00
Duration      [total, attack, wait]     10.094965987s, 9.949883921s, 145.082066ms
Latencies     [mean, 50, 95, 99, max]   113.172398ms, 108.272568ms, 140.18235ms, 247.771566ms, 264.815246ms
Bytes In      [total, mean]             3714690, 3095.57
Bytes Out     [total, mean]             0, 0.00
Success       [ratio]                   55.42%
Status Codes  [code:count]              0:535  200:665
Error Set:
Get http://localhost:6060: dial tcp 127.0.0.1:6060: connection refused
Get http://localhost:6060: read tcp 127.0.0.1:6060: connection reset by peer
Get http://localhost:6060: dial tcp 127.0.0.1:6060: connection reset by peer
Get http://localhost:6060: write tcp 127.0.0.1:6060: broken pipe
Get http://localhost:6060: net/http: transport closed before response was received
Get http://localhost:6060: http: can't write HTTP request on broken connection",3
https://github.com/itsky365/vegeta,##### `json`,"  {
  ""latencies"": {
    ""total"": 237119463,
    ""mean"": 2371194,
    ""50th"": 2854306,
    ""95th"": 3478629,
    ""99th"": 3530000,
    ""max"": 3660505
  },
  ""bytes_in"": {
    ""total"": 606700,
    ""mean"": 6067
  },
  ""bytes_out"": {
    ""total"": 0,
    ""mean"": 0
  },
  ""earliest"": ""2015-09-19T14:45:50.645818631+02:00"",
  ""latest"": ""2015-09-19T14:45:51.635818575+02:00"",
  ""end"": ""2015-09-19T14:45:51.639325797+02:00"",
  ""duration"": 989999944,
  ""wait"": 3507222,
  ""requests"": 100,
  ""rate"": 101.01010672380401,
  ""success"": 1,
  ""status_codes"": {
    ""200"": 100
  },
  ""errors"": []
}",3
https://github.com/itsky365/vegeta,##### `plot`,"  Generates an HTML5 page with an interactive plot based on
Dygraphs.
Click and drag to select a region to zoom into. Double click to zoom
out.
Input a different number on the bottom left corner input field
to change the moving average window size (in data points). Each point on the plot shows a request, the X axis represents the time
at the start of the request and the Y axis represents the time taken
to complete that request. ",3
https://github.com/itsky365/vegeta,##### `hist`,"  Computes and prints a text based histogram for the given buckets.
Each bucket upper bound is non-inclusive. cat results.bin | vegeta report -reporter='hist[0,2ms,4ms,6ms]'
Bucket         #     %       Histogram
[0,     2ms]   6007  32.65%  ########################
[2ms,   4ms]   5505  29.92%  ######################
[4ms,   6ms]   2117  11.51%  ########
[6ms,   +Inf]  4771  25.93%  ###################",3
https://github.com/itsky365/vegeta,### `dump`,"  $ vegeta dump -h
Usage of vegeta dump:
  -dumper string
      Dumper [json, csv] (default ""json"")
  -inputs string
      Input files (comma separated) (default ""stdin"")
  -output string
      Output file (default ""stdout"")",3
https://github.com/itsky365/vegeta,#### `-inputs`,  Specifies the input files containing attack results to be dumped. You can specify more than one (comma separated).,3
https://github.com/itsky365/vegeta,#### `-output`,  Specifies the output file to which the dump will be written to.,3
https://github.com/itsky365/vegeta,#### `-dumper`,  Specifies the dump format.,3
https://github.com/itsky365/vegeta,##### `json`,  Dumps attack results as JSON objects.,3
https://github.com/itsky365/vegeta,##### `csv`,"  Dumps attack results as CSV records with six columns.
The columns are: unix timestamp in ns since epoch, http status code,
request latency in ns, bytes out, bytes in, and lastly the error.",3
https://github.com/itsky365/vegeta,## Usage: Distributed attacks,"  Whenever your load test can't be conducted due to Vegeta hitting machine limits
such as open files, memory, CPU or network bandwidth, it's a good idea to use Vegeta in a distributed manner. In a hypothetical scenario where the desired attack rate is 60k requests per second,
let's assume we have 3 machines with vegeta installed. Make sure open file descriptor and process limits are set to a high number for your user on each machine
using the ulimit command. We're ready to start the attack. All we need to do is to divide the intended rate by the number of machines,
and use that number on each attack. Here we'll use pdsh for orchestration. $ pdsh -b -w '10.0.1.1,10.0.2.1,10.0.3.1' \
    'echo ""GET http://target/"" | vegeta attack -rate=20000 -duration=60s > result.bin' After the previous command finishes, we can gather the result files to use on our report. $ for machine in ""10.0.1.1 10.0.2.1 10.0.3.1""; do
    scp $machine:~/result.bin $machine.bin &
  done The report command accepts multiple result files in a comma separated list.
It'll read and sort them by timestamp before generating reports. $ vegeta report -inputs=""10.0.1.1.bin,10.0.2.1.bin,10.0.3.1.bin""
Requests      [total, rate]         3600000, 60000.00
Latencies     [mean, 95, 99, max]   223.340085ms, 326.913687ms, 416.537743ms, 7.788103259s
Bytes In      [total, mean]         3714690, 3095.57
Bytes Out     [total, mean]         0, 0.00
Success       [ratio]               100.0%
Status Codes  [code:count]          200:3600000
Error Set:",3
https://github.com/itsky365/vegeta,## Usage (Library),"  package main

import (
  ""fmt""
  ""time""

  vegeta ""github.com/tsenart/vegeta/lib""
)

func main() {
  rate := uint64(100) // per second
  duration := 4 * time.Second
  targeter := vegeta.NewStaticTargeter(vegeta.Target{
    Method: ""GET"",
    URL:    ""http://localhost:9100/"",
  })
  attacker := vegeta.NewAttacker()

  var metrics vegeta.Metrics
  for res := range attacker.Attack(targeter, rate, duration) {
    metrics.Add(res)
  }
  metrics.Close()

  fmt.Printf(""99th percentile: %s\n"", metrics.Latencies.P99)
}",3
https://github.com/itsky365/vegeta,#### Limitations,"  There will be an upper bound of the supported rate which varies on the
machine being used.
You could be CPU bound (unlikely), memory bound (more likely) or
have system resource limits being reached which ought to be tuned for
the process execution. The important limits for us are file descriptors
and processes. On a UNIX system you can get and set the current
soft-limit values for a user. $ ulimit -n # file descriptors
2560
$ ulimit -u # processes / threads
709 Just pass a new number as the argument to change it.",3
https://github.com/itsky365/vegeta,## License,  See LICENSE.,5
https://github.com/itsky365/vegeta,## Donate,"  If you use and love Vegeta, please consider sending some Satoshi to
1MDmKC51ve7Upxt75KoNM6x1qdXHFK6iW2. In case you want to be mentioned as a
sponsor, let me know! ",3
https://github.com/dxas90/ionic-cli,# Ionic-Cli," The Ionic Framework command line utility makes it easy to start, build, run, and emulate Ionic apps. In addition, it comes with (optional!) integration with the Ionic Cloud, a set of mobile backend services perfect for Ionic apps. Use the ionic --help command for more detailed task information.",13
https://github.com/dxas90/ionic-cli,## Installing,"  $ npm install -g ionic Note: For a global install of -g ionic, OSX/Linux users may need to prefix the command with sudo or can setup proper file permissions on OSX for npm to install without sudo. Minimal node requirements: 
NodeLTS or greater
NPM 3x
",3
https://github.com/dxas90/ionic-cli,## Starting an Ionic App,"  To start a Ionic 1x app, run: $ ionic start myapp [template] To start a Ionic 2 app, run: $ ionic start myapp [template] --v2 Starter templates can either come from a named template, a Github repo, a Codepen, or a local directory. A starter template is what becomes the www directory for a V1 project, and a src directory for a V2 project Named V1 template starters: 
tabs (Default)
sidemenu
maps
salesforce
blank
 Named V2 template starters: 
tabs (Default)
sidemenu
blank
 Github Repo starters: 
Any Github repo url, ex: https://github.com/driftyco/ionic-starter-tabs
Named templates are simply aliases to Ionic starter repos
 Codepen URL starters: 
Any Codepen url, ex: http://codepen.io/ionic/pen/odqCz
Ionic Codepen Demos
 Plunker URL starters: 
Any Plunker url, ex: http://embed.plnkr.co/dFvL8n/preview
 Local directory starters: 
Relative or absolute path to a local directory
 Command-line flags/options: [--appname|-a]  .......  Human readable name for the app
                         (Use quotes around the name)
[--id|-i]  ............  Package name set in the <widget id> config
                         ex: com.mycompany.myapp
[--no-cordova|-w]  ....  Do not create an app targeted for Cordova
[--sass|-s] ...........  Setup the project to use Sass CSS precompiling (V1 only)
[--list|-l]  ..........  List starter templates available

[--io-app-id] .........  The Ionic.io app ID to use
",3
https://github.com/dxas90/ionic-cli,## Adding a platform target,  $ ionic platform ios android,3
https://github.com/dxas90/ionic-cli,## Testing in a Browser,"  Use ionic serve to start a local development server for app dev and testing. Additionally, this command starts LiveReload which is used to monitor changes in the file system. As soon as you save a file the browser is refreshed automatically. View Using Sass if you would also like to have ionic serve watch the project's Sass files. $ ionic serve [options]",3
https://github.com/dxas90/ionic-cli,## Building your app,  $ ionic build ios,3
https://github.com/dxas90/ionic-cli,## Emulating your app,  Deploys the Ionic app on specified platform emulator. This is simply an alias for run --emulator. $ ionic emulate ios [options],3
https://github.com/dxas90/ionic-cli,## Running your app,  Deploys the Ionic app on specified platform devices. If a device is not found it'll then deploy to an emulator/simulator. $ ionic run ios [options],3
https://github.com/dxas90/ionic-cli,## Icon and Splash Screen Image Generation,"  Automatically generate icons and splash screens from source images to create each size needed for each platform, in addition to copying each resized and cropped image into each platform's resources directory. Source images can either be a png, psd Photoshop or ai Illustrator file. Images are generated using Ionic's image resizing and cropping server, instead of requiring special libraries and plugins to be installed locally. Since each platform has different image requirements, it's best to make a source image for the largest size needed, and let the CLI do all the resizing, cropping and copying for you. Newly generated images will be placed in the resources directory at the root of the Cordova project. Additionally, the CLI will update and add the correct <platform> configs to the project's config.xml file. During the build process, Cordova (v3.6 or later) will look through the project's config.xml file and copy the newly created resource images to the platform's specific resource folder. For example, Android's resource folder can be found in platforms/android/res, and iOS uses platforms/ios/APP_NAME/Resources.",3
https://github.com/dxas90/ionic-cli,### Icon Source Image,"  Save an icon.png, icon.psd or icon.ai file within the resources directory at the root of the Cordova project. The icon image's minimum dimensions should be 192x192 px, and should have no rounded corners. Note that each platform will apply it's own mask and effects to the icons. For example, iOS will automatically apply it's custom rounded corners, so the source file should not already come with rounded corners. This Photoshop icon template provides the recommended size and guidelines of the artwork's safe zone. $ ionic resources --icon 
Photoshop Icon Template
",3
https://github.com/dxas90/ionic-cli,### Splash Screen Source Image,"  Save a splash.png, splash.psd or splash.ai file within the resources directory at the root of the Cordova project. Splash screen dimensions vary for each platform, device and orientation, so a square source image is required the generate each of various sizes. The source image's minimum dimensions should be 2208x2208 px, and its artwork should be centered within the square, knowning that each generated image will be center cropped into landscape and portait images. The splash screen's artwork should roughly fit within a center square (1200x1200 px). This Photoshop splash screen template provides the recommended size and guidelines of the artwork's safe zone. Additionally, when the Orientation preference config is set to either landscape or portrait mode, then only the necessary images will be generated. $ ionic resources --splash 
Photoshop Splash Screen Template
",3
https://github.com/dxas90/ionic-cli,### Generating Icons and Splash Screens,"  To generate both icons and splash screens, follow the instructions above and run: $ ionic resources",3
https://github.com/dxas90/ionic-cli,### Platform Specific Resource Images,"  One source image can be used to generate images for each platform by placing the file within the resources directory, such as resources/icon.png. To use different source images for individual platforms, place the source image in the respective platform's directory. For example, to use a different icon for Android, it should follow this path: resources/android/icon.png, and a different image for iOS would use this path: resources/ios/icon.png.",3
https://github.com/dxas90/ionic-cli,### Generating Exact Platform Resources,"  By default the ionic resources command will automatically figure out which platforms it should generate according to what platforms have been added to your project. However, you can also explicitly state which resources should be built by providing a platform name in the command. The example below would generate only ios resources (even if the platform hasn't been added to the project). $ ionic resources ios",3
https://github.com/dxas90/ionic-cli,### Default Ionic Resources,"  Ionic provides you some default icons and splash screens to give you a better idea of how to size your icons and splashscreen, as well as how to modify your config.xml file for your own icons. $ ionic resources --default If you already have a resources directory, the command above will not over write your files. If you wish to force an over write, use ionic resources --default --force. When starting a new app and adding a platform ionic platform add ios - the default icons and splashscreens will be downloaded and your config.xml will be modified to set up the default resources. This should help you identify your Ionic apps easier as well as help you get the file structure and configuration correct.",3
https://github.com/dxas90/ionic-cli,## Crosswalk for Android,  To install Crosswalk for Android run: ionic plugin add cordova-plugin-crosswalk-webview --save All that is left is to run the project as normal - ionic run android.,3
https://github.com/dxas90/ionic-cli,## Advanced serve options,"  LiveReload By default, for Ionic 1 projects, LiveReload will watch for changes in your www/ directory,
excluding www/lib/.  To change this, you can specify a watchPatterns
property in the ionic.config.json file located in your project root to watch
(or not watch) for specific changes. {
  ""name"": ""myApp"",
  ""app_id"": """",
  ""watchPatterns"": [
    ""www/js/*"",
    ""!www/css/**/*""
  ]
} For a reference on glob pattern syntax, check out
globbing patterns on
the Grunt website. Gulp Integration When running ionic serve, you can have Ionic run any Gulp tasks you specify by putting them into a gulp task called serve:before: gulp.task('serve:before', ['sass', 'watch']); Now, when you run ionic serve, it will run the watch task while starting the Ionic server. If you would like to disable gulp from running during serve, pass the --nogulp option. Your gulpfile must be named gulpfile.js or Gulpfile.js, there is currently no support for typescript, babel or coffeescript gulp files in the 2.0 CLI NOTE For V1: $ ionic setup sass will add a watchPatterns propery with the default values to your ionic.config.json
file that you can then edit, in addition to the serve:before gulp task
described in the Using Sass section. Service Proxies: The serve command can add some proxies to the http server. These proxies are useful if you are developing in the browser and you need to make calls to an external API. With this feature you can proxy request to the external api through the ionic http server preventing the No 'Access-Control-Allow-Origin' header is present on the requested resource error. In the ionic.config.json file you can add a property with an array of proxies you want to add. The proxies are object with the following properties: 
path: string that will be matched against the beginning of the incoming request URL.
proxyUrl: a string with the url of where the proxied request should go.
proxyNoAgent: (optional) true/false, if true opts out of connection pooling, see HttpAgent
 {
  ""name"": ""appname"",
  ""email"": """",
  ""app_id"": """",
  ""proxies"": [
    {
      ""path"": ""/v1"",
      ""proxyUrl"": ""https://api.instagram.com/v1""
    }
  ]
}
 Using the above configuration, you can now make requests to your local server at http://localhost:8100/v1 to have it proxy out requests to https://api.instagram.com/v1 For example: angular.module('starter.controllers', [])
.constant('InstagramApiUrl', '')
// .contant('InstagramApiUrl','https://api.instagram.com')
//In production, make this the real URL

.controller('FeedCtrl', function($scope, $http, InstagramApiUrl) {

  $scope.feed = null;

  $http.get(InstagramApiUrl + '/v1/media/search?client_id=1&lat=48&lng=2.294351').then(function(data) {
    console.log('data ' , data)
    $scope.feed = data;
  })

}) See also this gist for more help. Command-line flags/options: [--consolelogs|-c] ......  Print app console logs to Ionic CLI
[--serverlogs|-s] .......  Print dev server logs to Ionic CLI
[--port|-p] .............  Dev server HTTP port (8100 default)
[--livereload-port|-i] ..  Live Reload port (35729 default)
[--nobrowser|-b] ........  Disable launching a browser
[--nolivereload|-r] .....  Do not start live reload
[--noproxy|-x] ..........  Do not add proxies
[--address] .............  Serves in the browser at the specified address
[--lab] .................  Serves both iOS and Android in the browser
[--nogulp] ..............  Serve without running gulp tasks
[--platform|-t] .........  Serve the platform specific styles in the browser (ios/android)
",3
https://github.com/dxas90/ionic-cli,## Using Ionic Labs,"  We've extended the serve command to open the new Lab UI that features iOS, Android, and Windows side-by-side. $ ionic serve --lab If you've used the serve command before, you'll feel right at home with this one. Just like serve, it opens your app in a browser, but now it shows you what your app will look like on a phone, with both iOS, Android, Windows side by side. And of course, it supports Live Reload and all the other goodies we've added over the last couple of months. NOTE: This does not emulate cordova or cordova plugins. So while the UI may feel like a native app, you'll still want to deploy to a device to test plugins.",3
https://github.com/dxas90/ionic-cli,## Serving an alternate document root,"  If you'd like to test your app in the browser and you use a folder other than the default of www, you can specify this folder in your ionic.config.json file. You might also want to have the document root be created if you use some sort of build system, we suggest using createDocumentRoot for that so that ionic serve will create that folder for you. It is also advised you specify the watch patterns for this document root as well, as follows: {
  ""name"": ""SmoothRiders"",
  ""documentRoot"": ""app"",
  ""createDocumentRoot"": ""app"",
  ""watchPatterns"": [
    ""app/js/*"",
    ""!app/css/**/*""
  ]
}
",3
https://github.com/dxas90/ionic-cli,## Packaging an app (beta),"  Using Ionic's service, you can compile and package your project into an app-store ready app without
requiring native SDKs on your machine. $ ionic package debug android The third argument can be either debug or release, and the last argument can be either android or ios.",3
https://github.com/dxas90/ionic-cli,## Cordova Commands,"  Ionic uses Cordova underneath, so you can also substitute Cordova commands to prepare/build/emulate/run, or to add additional plugins. Note: we occasionally send anonymous usage statistics to the Ionic team to make the tool better.",3
https://github.com/dxas90/ionic-cli,## Working around proxies,"  If you have a proxy you need to get around, you can pass that proxy with the default http_proxy node environment variable or an environment variable proxy. A few ways to set up and use the environment variable: export http_proxy=internal.proxy.com
# Or
export PROXY=internal.proxy.com

ionic start my_app

# Additionally, pass in line
PROXY=internal.proxy.com ionic start my_app",3
https://github.com/dxas90/ionic-cli,# Or,,-
https://github.com/dxas90/ionic-cli,"# Additionally, pass in line",,-
https://github.com/dxas90/ionic-cli,## Using Sass (V1 Only),"  By default, V1 starter projects are hooked up to Ionic's precompiled CSS file, which is found in the project's www/lib/ionic/css directory, and is linked to the app in the head of the root index.html file. However, projects can also be customized using Sass, which gives developers and designers ""superpowers"" in terms of creating and maintaining CSS. Below are two ways to setup Sass for your Ionic project (the ionic setup sass command simply does the manual steps for you). Once Sass has been setup for your Ionic project, then the ionic serve command will also watch for Sass changes. For V2 projects, there's nothing you need to do! Ionic 2 projects by default are setup with sass and come with all the build process enabled.",3
https://github.com/dxas90/ionic-cli,#### Setup Sass Automatically (V1),"  ionic setup sass
",3
https://github.com/dxas90/ionic-cli,#### Setup Sass Manually (V1),"  
Run npm install from the working directory of an Ionic project. This will install gulp.js and a few handy tasks, such as gulp-sass and gulp-minify-css.
Remove <link href=""lib/ionic/css/ionic.css"" rel=""stylesheet""> from the <head> of the root index.html file.
Remove <link href=""css/style.css"" rel=""stylesheet""> from the <head> of the root index.html file.
Add <link href=""css/ionic.app.css"" rel=""stylesheet""> to the <head> of the root index.html file.
In your serve:before gulp task, add the sass task gulp.task('serve:before', ['sass', 'watch']); (this can also be customized to whatever gulp tasks you'd like).
",3
https://github.com/dxas90/ionic-cli,# Ionic Cloud services,"  The CLI integrates with Ionic Cloud, a set of backend services that integrate perfectly with Ionic apps. To get started, visit the Ionic Cloud homepage and sign up. There are a few things you can utilize the CLI for to support ease of development.",36
https://github.com/dxas90/ionic-cli,## Login,  Type ionic login to get logged in the CLI.,3
https://github.com/dxas90/ionic-cli,### Login without prompt,  You can pass the email and password to login without being prompted for email and password. ionic login --email user@ionic.io --password somepass,3
https://github.com/dxas90/ionic-cli,### Login with environment variables,  The CLI also supports settings environment variables to read off the email and password for the user. Set IONIC_EMAIL and IONIC_PASSWORD as variables to have the CLI read these instead of being prompted for them.,3
https://github.com/dxas90/ionic-cli,## Upload your Ionic app,"  Use the ionic upload command to take your current application you are developing and upload it to the Ionic.io servers. Now you can use the ionic view app to view that application or have others view the application. After uploading the application, you will see a message: Uploading app....

Successfully uploaded (f23j9fjs)
 This indicates you uploaded the application correctly, and the App ID is set to f23j9fjs. You can then view that App ID from the View app or the application listing on your Ionic Cloud dashboard.",3
https://github.com/dxas90/ionic-cli,### Adding a note with your upload,"  To add a note to your build, pass the --note option as follows: ionic upload --note ""This version of the application fixes the menu selections"".",3
https://github.com/dxas90/ionic-cli,## Set your Ionic Project App ID manually,  Use the ionic link <appId> command to set your Ionic App ID to continue working with the same app with the Ionic platform across development enviroments.,3
https://github.com/dxas90/ionic-cli,## Share the application with another user,  Use the ionic share <email> command to have an email sent to another person to have them view the Ionic application you are using. Note: You must have an Ionic Cloud account as well as the user you are sharing with.,3
https://github.com/dxas90/ionic-cli,# Ionic Hooks (V1),"  Ionic provides some default hooks for you to use in your Cordova application. In versions prior to 1.3.18, these hooks were automatically installed via the ionic platform command. In 1.3.18, the hooks were automatically removed due to some errors users were having with Crosswalk and other plugins with variables. If you were a user who would still like to use those hooks, you can re-install these hooks with the ionic hooks add command. If you would like to remove these hooks yourself, use ionic hooks remove to get rid of them.",3
https://github.com/dxas90/ionic-cli,# Ionic CLI 2.0, ,3
https://github.com/dxas90/ionic-cli,## Ionic Generators,"  First class support has come to the Ionic CLI to scaffold and generate Ionic and Angular 2 components. From your app directory, use the generate command (alias: g). Usage: 
ionic generate page About - Generate a page named About with HTML, JavaScript, and Sass named about.
ionic g tabs MyTabPage - Generate a page named MyTabPage, queries for the amount of tabs, and creates pages for those tabs.
 List: View all generators: ionic g --list.",3
https://github.com/ccloes/aws-codedeploy-agent,# AWS CodeDeploy Agent,,1
https://github.com/ccloes/aws-codedeploy-agent,## Build Steps,"  git clone https://github.com/aws/aws-codedeploy-agent.git
gem install bundler
cd aws-codedeploy-agent
bundle install
rake clean && rake",3
https://github.com/ccloes/aws-codedeploy-agent,## Integration Test,"  Please do the build steps mentioned above before running the integration test. The integration test creates the following 
An IAM role ""codedeploy-agent-integ-test-deployment-role"" if it doesn't exist
An IAM role ""codedeploy-agent-integ-test-instance-role"" if it doesn't exist
A CodeDeploy application
A CodeDeploy deployment group
An EC2 key pair ""codedeploy-agent-integ-test-key"" if it doesn't exist
An EC2 security group ""codedeploy-agent-integ-test-sg"" if it doesn't exist
An EC2 instance tagged with key ""codedeploy-agent-integ-test-instance""
A CodeDeploy deployment on that ec2 instance.
 It terminates the test ec2 instance and deletes the CodeDeploy application at the end of each test run.
It also terminates any test ec2 instances before starting up the test. Update the features/AwsCredentials.yml file with AWS access key and secret key. The access key should have permission to create the above mentioned resources. You can also change the default region and ami id if you want. To run the integration test execute rake test-integration
",3
https://github.com/jacknjzhou/raet,# RAET (Reliable Asynchronous Event Transport) Protocol,,1
https://github.com/jacknjzhou/raet,## Motivation,"  Modern large scale distributed application architectures, wherein components are
distributed across the internet on multiple hosts and multiple CPU cores, are often
based on a messaging or event bus that allows the various distributed components
to communicate asynchronously with each other. Typically the messaging bus is
some form of messaging queue service such as AMQP or ZeroMQ. The message bus supports
what is commonly referred to as a publish/subscribe methodology for information
exchange. While there are many advantages to a full featured message queuing service,
one of the disadvantagesis the inability to manage performance at scale. A message queuing service performs two distinct but complementary functions. 
The first is asynchronous transport of messages over the internet.
The second is message queue management, that is, the identification, tracking,
storage, and distribution of messages between publishers and subscribers via queues.
 One of the advantages of a message queuing service for many applications is that
the service hides behind an API, the complexities of queue management from the clients.
The disadvantage is that at scale, where the volume of messages, the
timing of messages, and the associated demands on memory, network, and cpu capacity
become critical, the client has little ability to tune the service for performance.
Often MQ services become bottlenecks for the distributed application.
The more complicated MQ services, like AMQP, tend to be unreliable under load. Separating the function of network transport of asynchrounous event from the
function of message queue management allows independant tuning at scale of each function. Most if not all of the MQ services are based on TCP/IP for transport.
TCP/IP adds significant latency to the network communications and is therefore
not well suited for the asynchronous nature of distibuted event driven application
communications. This is primarily due to the way TCP/IP handles connection setup
and teardown as well as failed connections in order to support streams. Fundamentally
TCP/IP is optomized for sending large contiguous data streams not many small
aynchronous events or messages. While not a problem for small scale systems,
the differences in the associated traffic characteristics can become problematic
at scale. Because UDP/IP has lower latency and is connectionless, it is much better suited
to many small asynchronous messages and scales better. The drawback of bare UDP/IP
is that it is not reliable. What is needed, therefore, is a tuned transport
protocol that adds reliability to UDP/IP without sacrificing latency and scalability.
A transactioned protocol, is much more appropriate for providing reliablity to
asynchronous event transport than a streaming protocol. Morover, because most MQ services are based on TCP/IP they tend to also use
HTTP and therefore TLS/SSL for secure communications. While using HTTP provides
easy integration with web based systems, it can become problematic for high performant systems
Furthermore, TLS is also problematic as a security system both from performance
and vulnerabilty aspects. Elliptic Curve Cryptography, on the other hand, provides increases in security
with lower performance requirements relative to over other approaches.
LibSodium provides an open source Elliptic Curve Cryptographic library with support
for both authentication and encryption. The CurveCP protocol is based on LibSodium
and provides a handshake protocol for bootstrapping secure network exchanges of information. Finally, one of the best ways to manage and fine tune processor resources
(cpu, memory, network) in distributed concurrent event driven applications is to use
something called micro-threads. A microthread is typically an in-language feature
that allows logical concurrency with no more overhead than a function call.
Micro threading uses cooperative multi-tasking instead of threads and/or processes
and avoids many of the complexities of resource contention, context switching,
and interprocess communications while providing much higher total performance. Because all the cooperative micro-threads run in one process, a simple micro-threaded
application is limited to one CPU core. To enable full utilization of all CPU
cores, the application needs to be able to run at least one process per CPU core.
This requires same host inter-process communications. But unlike the conventional
approach to multi-processing  where there is of one process per logical concurrent
function, a micro-threaded multi-process application has instead one micro-thread
per logical concurrent function and the total number of micro-threads
is distributed amoungst a minimal number of processes, no more than the number of
cpu cores. This optimizes the use of the cpu power while minimizes the overhead of
process context switching. An example of a framework that uses this type of micro-threaded but multi-process
architecture is Erlang. Indeed, the success of the Erlang model provided
support for the viability of the RAET approach.
Indeed, one might ask, why not use Erlang? Unfortunately, the Erlang ecosystem is
somewhat limited in comparison to Python's and the language itself uses what one
might describe as a very unfortunate syntax.
One of the design objectives behine RAET was to leverage existing Python expertise
and the richness of the Python ecosystem but still be able to develop distributed
applications using a micro-threaded multi-process architectural model. The goal was
to combine the best of both worlds. RAET is designed to provide secure reliable scalable asynchronous message/event
transport over the internet in a micro-threaded multi-process application framework
that uses UDP for interhost communication and LibSodium for authentication, encryption
and the CurveCP handshake for secure bootstrap. The queue management and micro-threaded application support is provided by Ioflo.
RAET is a complementary project to Ioflo in that RAET enables multiple Ioflo
applications to work together over a network as part of a distributed application. The primary use case and motivating problem that resulted in the development of RAET
was the need to enable SaltStack to scale better. SaltStack is a remote execution
and configuration management platform written in Python. SaltStack uses ZeroMQ (0MQ)
as its message bus or message queuing service. ZeroMQ is based on TCP/IP so suffers from
the aforementioned latency and non-asynchronicity issues of TCP/IP based architectures.
Moreover because ZeroMQ integrates queue management and transport in a monolithic way
with special ""sockets"", tuning the performance of the queuing independent of the transport
at scale becomes problematic. Tracing down bugs can also be problematic.",12
https://github.com/jacknjzhou/raet,## Installation,"  Current raet is provided as a PyPi package. To install on a unix based system
use pip. $ pip install raet

 on OS X $ sudo pip install raet
",3
https://github.com/jacknjzhou/raet,## Introduction,"Currently RAET supports two types of communication.

Host to host communication over UDP/IP sockets
Same host interprocess communication over Unix Domain (UXD) Sockets
The architecture of a RAET based application is shown in the figure below:",1
https://github.com/jacknjzhou/raet,##Naming Metaphor for Components,The following naming metaphor is designed to consistent but not conflicting with Ioflo,3
https://github.com/jacknjzhou/raet,"### Road, Estates, Main Estate","  
The UDP channel is  a “Road""
The members of a Road are “Estates? (as in real estate lots that front the road)
Each Estate has a unique UDP Host Port address “ha?, a unique  string “name?and unique numerical ID “eid"".
One Estate on the Road is the “Main?Estate
The Main Estate is responsible for allowing other estates to join the Road
via the Join (Key Exchange)  and Allow (CurveCP) transactions
The Main Estate is also responsible for routing messages between other Estates
",3
https://github.com/jacknjzhou/raet,"### Lane, Yards, Main Yard","  
Within each Estate may be a “Lane?  This is a UXD channel.
The members of a Lane are “Yards? (as in subdivision plots within the Estate)
Each Yard on a Lane has a unique UXD file name host address “ha? and a unique string “name?
There is also a numerical Yard ID “yid"" that the class uses to generate yard
names but it is not an attribute of the Yard instance.
The Lane name is also used with the Yard Name to form a unique Filename that
is the ha of the UXD
One Yard on a Lane is  the “Main?Yard
The Main Yard is responsible for forming the Lane and permitting other Yards
to be on the lane. There is yet no formal process for this.
Currently there is a flag that will drop packets from any Yard that is not
already in the list of Yards maintained by the Main yard.
Also file permissions can be used to prevent spurious Yards from communicating
with the Main Yard.
The Main Yard is responsible for routing messages between other yards on the Lane
",3
https://github.com/jacknjzhou/raet,## IoFlo Execution,"  
Each Estate UDP interface is run via a RoadStack (UDP sockets)
which is run within the context of an IoFlo House
(so think of the House that runs the UDP Stack as the Manor House of the Estate)
Each Yard UXD interface is run via a LaneStack (Unix domain socket)
which is run within the context of an IoFlo House
(so think of Houses that run UXD stacks as accessory Houses (Tents, Shacks) on the Estate)
The ""Manor"" House is special in that it runs both the UDP stack for the Estate
and also runs the UXD Stack for the Main Yard
The House that runs the Main Estate UDP Stack can be thought of as Mayor’s House
Within the context of a House is a Data Store. Shares in the Store are Addressed
by the unique Share Name which is a dotted path
",3
https://github.com/jacknjzhou/raet,## Routing,"  Given the Ioflo execution architecture described above, routing is performed as follows: 
In order to address a specific Estate, the Estate Name is required
In order to address a specific Yard within an Estate, the Yard Name is required
In order to address a specific Queue within a House, the Share Name is required
 The UDP stack maps Estate Name to UDP HA and Estate ID
The UXD stack maps Yard Name to UXD HA
The Store of any IoFlo behavior maps Share Name to Share reference Therefore Routing
from: a source identified by
a queue in a source Share,
in a source Yard,
in a source Estate
to: a destination identified by
a queue, in a destination Share,
in a destination Yard,
in a destination Estate requires two Triples, one for Source and one for Destination Source
(Estate Name, Yard Name, Share Name) Destination
(Estate Name, Yard Name, Share Name) If any element of the Triple is None or Empty then a Default is used. Below is an example of a Message Body that has the Routing information it it.     estate = 'minion1'
    stack0 = stacking.StackUxd(name='lord', lanename='cherry', yid=0)
    stack1 = stacking.StackUxd(name='serf', lanename='cherry', yid=1)
    yard = yarding.Yard( name=stack0.yard.name, prefix='cherry')
    stack1.addRemoteYard(yard)

    src = (estate, stack1.yard.name, None)
    dst = (estate, stack0.yard.name, None)
    route = odict(src=src, dst=dst)
    msg = odict(route=route, stuff=""Serf to my lord. Feed me!"")
    stack1.transmit(msg=msg)

    timer = Timer(duration=0.5)
    timer.restart()
    while not timer.expired:
        stack0.serviceAll()
        stack1.serviceAll()


    lord Received Message
    {
        'route':
        {
            'src': ['minion1', 'yard1', None],
            'dst': ['minion1', 'yard0', None]
        },
        'stuff': 'Serf to my lord. Feed me!'
    }",3
https://github.com/jacknjzhou/raet,## Details of UDP/IP Raet Protocol,"  The UDP Raet protocol is based on a coding metaphor naming convention, that is, of
estates attached to a road. The core objects are provided in the following package:
raet.road",3
https://github.com/jacknjzhou/raet,### Road Raet Production UDP/IP Ports,"  Manor Estate 4505
Other Estates 4510",3
https://github.com/jacknjzhou/raet,### Packet Data Format,"  The data used to initialize a packet is an ordered dict with several fields
most of the fields are shared with the header data format below so only the
unique fields are shown here.",3
https://github.com/jacknjzhou/raet,### Unique Packet data fields,"  sh: source host ip address (ipv4)
sp: source ip port
dh: destination host ip address (ipv4)
dp: destination host ip port
",3
https://github.com/jacknjzhou/raet,### Header Data Format.,"  The .data in the packet header is an ordered dict  which is used to either
create a packet to transmit
or holds the field from a received packet.
What fields are included in a header is dependent on the header kind.",3
https://github.com/jacknjzhou/raet,### Header encoding,"  There are three header encoding formats currently supported. 

RAET Native. This is an minimized ascii test format that optimizes the tradeoff between
easy readability and size. This is the default.


JSON. This is the most verbose format but has the advantage of compatibility.


Binary. This is not yet implemented. Once the protocol reaches a more mature state
and its not likely that there will be any header changes (or very infrequent) then
a binary format that minimizes size will be provided.

 When the head kind is json = 0, then certain optimizations are used to minimize
the header length. 
The header field keys are two bytes long
If a header field value is the default then the field is not included
Lengths are encoded as hex strings
The flags are encoded as a double char hex string in field 'fg'
",3
https://github.com/jacknjzhou/raet,### Header Data Fields,"  ri: raet id Default 'RAET'
vn: Version (Version) Default 0
pk: Packet Kind (PcktKind)
pl: Packet Length (PcktLen)
hk: Header kind   (HeadKind) Default 0
hl: Header length (HeadLen) Default 0

se: Source Estate ID (SEID)
de: Destination Estate ID (DEID)
cf: Correspondent Flag (CrdtFlag) Default 0
bf: BroadCast Flag (BcstFlag)  Default 0

si: Session ID (SID) Default 0
ti: Transaction ID (TID) Default 0
tk: Transaction Kind (TrnsKind)

dt: Datetime Stamp  (Datetime) Default 0
oi: Order index (OrdrIndx)   Default 0

wf: Waiting Ack Flag    (WaitFlag) Default 0
    Next segment or ordered packet is waiting for ack to this packet
ml: Message Length (MsgLen)  Default 0
    Length of message only (unsegmented)
sn: Segment Number (SgmtNum) Default 0
sc: Segment Count  (SgmtCnt) Default 1
sf: Segment Flag  (SgmtFlag) Default 0
    This packet is part of a segmented message
af: All Flag (AllFlag) Default 0
    Resend all segments not just one

bk: Body kind   (BodyKind) Default 0
ck: Coat kind   (CoatKind) Default 0
fk: Footer kind   (FootKind) Default 0
fl: Footer length (FootLen) Default 0

fg: flags  packed (Flags) Default '00' hs
     2 char Hex string with bits (0, 0, af, sf, 0, wf, bf, cf)
     Zeros are TBD flags
",3
https://github.com/jacknjzhou/raet,### Body Data Format,  The Body .data is a Mapping that is serialized using either JSON or MSGPACK,3
https://github.com/jacknjzhou/raet,### Packet Parts,"  Each packet has 4 parts some of which may be empty. These are: 
Head
Body
Coat
Tail
 The Head is manditory and provides the header fields that are needed to process the
packet. The Tail provides the authentication signature that is used to verify the source of
the packet and that its contents have not been tampered with. The Body is the contents of the packet. Some packets such as Acks and Nacks don't
need a body. The Body is a serialized Python dictionary typically and ordered dictionary
so that parsing and debugging has a consistent view of the ordering of the fields
in the body. The Coat is the encrypted version of the body. The encryption type is CurveCP based.
If the Coat is provided then the Body is encapsulated within the Coat Part.",3
https://github.com/jacknjzhou/raet,### Header Details, ,3
https://github.com/jacknjzhou/raet,#### JSON Encoding,"  Header is the ASCII Safe JSON encoding of a Python ordered dictionary.
Header termination is an empty line given by double pair of carriage-return linefeed
characters. /r/n/r/n
10 13 10 13
ADAD
1010 1101 1010 1101 Carriage-return and newline characters cannot appear in a JSON encoded
string unless they are escaped with backslash, so the 4 byte combination is illegal
in valid JSON that does not have multi-byte unicode characters so it makes it a
uniquely identifiable header termination. These means the header must be ascii safe  so no multibyte utf-8 strings are
allowed in the header.",3
https://github.com/jacknjzhou/raet,#### Native Encoding,"  The header consists of newline delimited lines. Each header line consists
of a two character field identifier followed by a space followed by the value
of the field as ascii hex encoded binary followed by newline.
The Header end is indicated by a blank line, that is, a double newline character.
Example",3
https://github.com/jacknjzhou/raet,#### Binary Encoding,  The header consists of defined set of fixed length fields,3
https://github.com/jacknjzhou/raet,### Session,"  Session is important for security. Want one session opened and then multiple
transactions within session. Session ID
SID
sid
si",3
https://github.com/jacknjzhou/raet,### Session Bootstrap, ,3
https://github.com/jacknjzhou/raet,## Layering:,"  OSI Layers 7: Application: Format: Data (Stack to Application interface buffering etc)
6: Presentation: Format: Data (Encrypt-Decrypt convert to machine independent format)
5: Session: Format: Data (Interhost communications. Authentication. Groups)
4: Transport: Format: Segments (Reliable delivery of Message, Transactions, Segmentation, Error checking)
3: Network: Format: Packets/Datagrams (Addressing Routing)
2: Link: Format: Frames ( Reliable per frame communications connection, Media access controller )
1: Physical: Bits (Transciever communication connection not reliable) 

Link is hidden from Raet


Network is IP host address and UDP Port


Transport is Raet transaction and packet authentication vis tail signature that
provide reliable transport.


Session is session id key exchange for signing. Grouping is Road


Presentation is Encrypt-Decrypt Body and Serialize-Deserialize Body


Application is Body data dictionary

 Packet signing could technically be in either the Transport or Session layers.",3
https://github.com/jacknjzhou/raet,## UXD Message,"  RAET UXD Messages are limited in size to the same maximum (pre segmented)
RAET UDP message size (about 16 Mb) UXD Messages have the following Format
Header followed by serialized message body dict
currently only JSON has been implemented. 

JSON Header:
“RAET\njson\n\n?Followed by a jsonified  message body dict


msgpack Header:
“RAET\npack\n\n?Followed by a msgpackified   message body dict

",3
https://github.com/npouvesle/echo,# [Echo](http://echo.labstack.com) [![GoDoc](http://img.shields.io/badge/go-documentation-blue.svg?style=flat-square)](http://godoc.org/github.com/labstack/echo) [![Build Status](http://img.shields.io/travis/labstack/echo.svg?style=flat-square)](https://travis-ci.org/labstack/echo) [![Coverage Status](http://img.shields.io/coveralls/labstack/echo.svg?style=flat-square)](https://coveralls.io/r/labstack/echo) [![Join the chat at https://gitter.im/labstack/echo](https://img.shields.io/badge/gitter-join%20chat-brightgreen.svg?style=flat-square)](https://gitter.im/labstack/echo),,1
https://github.com/npouvesle/echo,## Features, A fast and unfancy micro web framework for Golang.,1
https://github.com/npouvesle/echo,## Performance,"  
Fast HTTP router which smartly prioritize routes.
Extensible middleware, supports:

echo.MiddlewareFunc
func(echo.HandlerFunc) echo.HandlerFunc
echo.HandlerFunc
func(*echo.Context) error
func(http.Handler) http.Handler
http.Handler
http.HandlerFunc
func(http.ResponseWriter, *http.Request)


Extensible handler, supports:

echo.HandlerFunc
func(*echo.Context) error
http.Handler
http.HandlerFunc
func(http.ResponseWriter, *http.Request)


Sub-router/Groups
Handy functions to send variety of HTTP response:

HTML
HTML via templates
JSON
String
NoContent
Redirect
Error


Build-in support for:

Favicon
Index file
Static files
WebSocket


Centralized HTTP error handling.
Customizable HTTP request binding function.
Customizable HTTP response rendering function, allowing you to use any HTML template engine.
",6
https://github.com/npouvesle/echo,##### [GitHub API](http://developer.github.com/v3),"  Based on [vishr/go-http-routing-benchmark] (https://github.com/vishr/go-http-routing-benchmark), June 5, 2015.",1
https://github.com/npouvesle/echo,## Installation,"  
Echo: 38662 ns/op, 0 B/op, 0 allocs/op
  BenchmarkAce_GithubAll              20000             93675 ns/op           13792 B/op      167 allocs/op
BenchmarkBear_GithubAll             10000            264194 ns/op           79952 B/op      943 allocs/op
BenchmarkBeego_GithubAll             2000           1109160 ns/op          146272 B/op      2092 allocs/op
BenchmarkBone_GithubAll              1000           2063973 ns/op          648016 B/op     8119 allocs/op
BenchmarkDenco_GithubAll            20000             83114 ns/op           20224 B/op       167 allocs/op
BenchmarkEcho_GithubAll             30000             38662 ns/op               0 B/op        0 allocs/op
BenchmarkGin_GithubAll              30000             43467 ns/op               0 B/op        0 allocs/op
BenchmarkGocraftWeb_GithubAll        5000            386829 ns/op          133280 B/op      1889 allocs/op
BenchmarkGoji_GithubAll              3000            561131 ns/op           56113 B/op      334 allocs/op
BenchmarkGoJsonRest_GithubAll        3000            490789 ns/op          135995 B/op      2940 allocs/op
BenchmarkGoRestful_GithubAll          100          15569513 ns/op          797239 B/op      7725 allocs/op
BenchmarkGorillaMux_GithubAll         200           7431130 ns/op          153137 B/op      1791 allocs/op
BenchmarkHttpRouter_GithubAll       30000             51192 ns/op           13792 B/op       167 allocs/op
BenchmarkHttpTreeMux_GithubAll      10000            138164 ns/op           56112 B/op       334 allocs/op
BenchmarkKocha_GithubAll            10000            139625 ns/op           23304 B/op       843 allocs/op
BenchmarkMacaron_GithubAll           2000            709932 ns/op          224960 B/op      2315 allocs/op
BenchmarkMartini_GithubAll            100          10261331 ns/op          237953 B/op      2686 allocs/op
BenchmarkPat_GithubAll                500           3989686 ns/op         1504104 B/op    32222 allocs/op
BenchmarkPossum_GithubAll            5000            259165 ns/op           97441 B/op       812 allocs/op
BenchmarkR2router_GithubAll         10000            240345 ns/op           77328 B/op      1182 allocs/op
BenchmarkRevel_GithubAll             2000           1203336 ns/op          345554 B/op      5918 allocs/op
BenchmarkRivet_GithubAll            10000            247213 ns/op           84272 B/op      1079 allocs/op
BenchmarkTango_GithubAll             5000            379960 ns/op           87081 B/op      2470 allocs/op
BenchmarkTigerTonic_GithubAll        2000            931401 ns/op          241089 B/op      6052 allocs/op
BenchmarkTraffic_GithubAll            200           7292170 ns/op         2664770 B/op     22390 allocs/op
BenchmarkVulcan_GithubAll            5000            271682 ns/op           19894 B/op       609 allocs/op
BenchmarkZeus_GithubAll              2000            748827 ns/op          300688 B/op     2648 allocs/op
",3
https://github.com/npouvesle/echo,## [Recipes](https://github.com/labstack/echo/tree/master/recipes),  $ go get github.com/labstack/echo,6
https://github.com/npouvesle/echo,##[Guide](http://echo.labstack.com/guide),"  
File Upload
Streaming File Upload
Streaming Response
WebSocket
Subdomains
JWT Authentication
Graceful Shutdown
 ##Guide",6
https://github.com/npouvesle/echo,## Echo System,"  Community created packages for Echo 
echo-logrus
go_middleware
permissions2
permissionbolt
",6
https://github.com/npouvesle/echo,## Contribute,"  Use issues for everything 
Report problems
Discuss before sending pull request
Suggest new features
Improve/fix documentation
",7
https://github.com/npouvesle/echo,## Credits,"  
Vishal Rana - Author
Nitin Rana - Consultant
Contributors
",5
https://github.com/npouvesle/echo,## License,  MIT,5
https://github.com/shayhowe/modular-html-css-js-workshop,"# Modular HTML, CSS, &amp; JS Workshop","Presentation Slides
Workshop Files
Youve been tasked with developing a new front end feature. HTML, CSS, and JavaScript are nothing new to you, in fact you even know a few tricks to get this feature out the door. It doesnt take you long and the code works like a charm, yet you have a looming suspicion that some of the code might not be up to par. Youre likely right, and youre definitely better than that.

We often write code without paying attention to the bigger picture, or overall code base. Upon stepping back we notice areas of duplicate code, ripe for refactoring. Its time to build more modular front ends, focusing on the reusability of HTML, CSS, and JavaScript, and to take maintainability to heart.",16
https://github.com/shayhowe/modular-html-css-js-workshop,## Assembling Layout, ,3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 1,"  
Within the playlist, position the album artwork to the left of the song title and artist name
Keep the album artwork vertically centered with the song title and artist name
 HTML <li class=""playlist-song flag"">
  <figure class=""flag-object"">
    <img src=""assets/img/#.jpg"" alt=""Artist Name"">
  </figure>
  <div class=""flag-body"">
    <h3 class=""h-subheadline h-bold"">Song Title</h3>
    <h4 class=""artist h-byline"">Artist Name</h4>
  </div>
</li>
 CSS /* Flag object
================================== */

.flag {
  display: table;
  width: 100%;
}
.flag-object,
.flag-body {
  display: table-cell;
  vertical-align: middle;
}
.flag-object img {
  display: block;
}
.flag-body {
  width: 100%;
}

/* Playlist
================================== */

.playlist-song .flag-object {
  padding: 0 20px;
}
.playlist-song .flag-object img {
  border-radius: 5px;
  height: 66px;
}
.playlist-song .flag-body {
  padding-right: 20px;
}
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 2,"  
Reusing styles from positioning the album artwork, add a Currently loading?section at the top of the file to displayed before the playlist loads
 HTML <div class=""loading flag"">
  <figure class=""flag-object"">
    <img src=""assets/img/loading.gif"" alt=""Currently loading..."">
  </figure>
  <div class=""flag-body"">
    <h3>Currently loading&#8230;</h3>
  </div>
</div>
 CSS /* Loading
================================== */

.loading {
  color: #95959a;
  margin: 0 auto;
  padding: 66px;
  width: 292px;
}
.loading .flag-object {
  padding-right: 10px;
}
.loading .flag-object img {
  height: 22px;
}
",3
https://github.com/shayhowe/modular-html-css-js-workshop,## Accommodating Content, ,3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 1,"  
Add previous, play, and next controls within the player
Make the previous and next controls slightly smaller than the play control
Keep all controls vertically centered
 HTML <header class=""player cover-art controls-container"">
  <menu class=""controls"">
    <li>
      <a class=""control-prev ir"" href=""#"">Previous</a>
    </li>
    <li>
      <a class=""control-play ir"" href=""#"">Play/Pause</a>
    </li>
    <li>
      <a class=""control-next ir"" href=""#"">Next</a>
    </li>
  </menu>
</header>
 CSS /* Controls
================================== */

.controls-container {
  position: relative;
}
.controls {
  background: linear-gradient(rgba(0, 0, 0, 0), rgba(0, 0, 0, .5));
  bottom: 0;
  margin: 0;
  padding: 44px 20px 22px 20px;
  position: absolute;
  text-align: center;
  width: 100%;
}
.controls li {
  display: inline-block;
  vertical-align: middle;
}
.controls a {
  background-image: url(""../img/controls.png"");
  background-image: url(?./img/controls.svg"");
  border: 2px solid #fff;
  border-radius: 50%;
  display: block;
  height: 38px;
  margin: 0 8px;
  width: 38px;
}
.controls a:hover {
  background-color: rgba(0, 0, 0, .5);
}
.controls .control-play {
  height: 44px;
  width: 44px;
}
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 2,"  
Add favorite and share controls within each song in the playlist
Reuse as many styles from the player controls as possible
 HTML <menu class=""controls player-controls"">
  ...
</menu>

...

<div class=""flag-body controls-container"">
  <h3 class=""h-subheadline h-bold"">Song Title</h3>
  <h4 class=""artist h-byline"">Artist Name</h4>
  <menu class=""controls playlist-controls"">
    <li>
      <a class=""control-fav ir"" href=""#"">Favorite</a>
    </li>
    <li>
      <a class=""control-share ir"" href=""#"">Share</a>
    </li>
  </menu>
</div>
 CSS /* Controls
======================================================= */

.controls-container {
  position: relative;
}
.controls {
  margin: 0;
  position: absolute;
  text-align: center;
}
.controls li {
  display: inline-block;
  vertical-align: middle;
}
.controls a {
  background-image: url(""../img/controls.png"");
  background-image: url(""../img/controls.svg"");
  border-radius: 50%;
  border-style: solid;
  border-width: 2px;
  display: block;
}

/* Player
======================================================= */

.player-controls {
  background: linear-gradient(rgba(0, 0, 0, 0), rgba(0, 0, 0, .5));
  bottom: 0;
  padding: 44px 20px 22px 20px;
  width: 100%;
}
.player-controls a {
  border-color: #fff;
  height: 38px;
  margin: 0 8px;
  width: 38px;
}
.player-controls a:hover {
  background-color: rgba(0, 0, 0, .5);
}
.player-controls .control-play {
  height: 44px;
  width: 44px;
}

/* Playlist
======================================================= */

.playlist-controls {
  background: linear-gradient(to right, rgba(255, 255, 255, 0), #fff 35px);
  height: 100%;
  padding: 0 20px 0 40px;
  right: 0;
  top: 0;
}
.playlist-controls li {
  position: relative;
  top: 50%;
  transform: translateY(-50%);
}
.playlist-controls a {
  border-color: #bfbfbf;
  height: 32px;
  width: 32px;
}
.playlist-controls a:hover {
  border-color: #7c7c87;
}
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 3,"  
Animate the player controls to appear from the bottom upon hovering over the player
Animate the song controls to appear from the right upon hovering over a song
Add hardware acceleration to each of the animations
 HTML <menu class=""controls player-controls boost"">
  ...
</menu>
<menu class=""controls playlist-controls boost"">
  ...
</menu>
 CSS /* Controls
================================== */

.controls-container {
  overflow: hidden;
  position: relative;
}
.controls {
  margin: 0;
  position: absolute;
  text-align: center;
  transition: all .2s ease-in-out;
}

/* Player
================================== */

.player-controls {
  background: linear-gradient(rgba(0, 0, 0, 0), rgba(0, 0, 0, .5));
  bottom: 0;
  padding: 44px 20px 22px 20px;
  transform: translateY(100%);
  width: 100%;
}
.player:hover .player-controls {
  transform: translateY(0);
}

/* Playlist (below now playing)
================================== */

.playlist-controls {
  background: linear-gradient(to right, rgba(255, 255, 255, 0), fff 35px);
  height: 100%;
  padding: 0 20px 0 40px;
  right: 0;
  top: 0;
  transform: translateX(100%);
}
.playlist-song:hover .playlist-controls {
  transform: translateX(0);
}
",3
https://github.com/shayhowe/modular-html-css-js-workshop,## Setting Up the JavaScript Application, ,3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 1,"  
Our application will be using a few JavaScript libraries, let’s load these files on the page
We can load jQuery and Handlebars from a CDN:
 <script src=""http://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js""></script>
<script src=""http://cdnjs.cloudflare.com/ajax/libs/handlebars.js/1.3.0/handlebars.min.js""></script>
 
Add local files that allow us to interact with Rdio:
 <script src=""assets/js/vendor/jquery.rdio.js""></script>
<script src=""assets/js/vendor/rdio-service.js""></script>
<script src=""assets/js/player.js""></script>
<script src=""assets/js/settings.js""></script>
 
Load a JSON file with our playlist data (to prevent us from having to constantly hit Rdio during development):
 <script src=""data/playlist.json""></script>
 

Add data-player-loading to the loading flag element


Add data-player-container to the main player container element, and set the display property to none for the .container class


Look at PLAYLIST_DATA.data and use the console to familiarize yourself with the data structure

",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 2,"  
Create an object in app.js called App and load the script on the page:
 <script src=""assets/js/app.js""></script>
 
Give the App object RdioService, Templates, Player, and Playlist properties, and assign all these properties a value of any empty object
Give the object an initialize function ?leave the function body empty for now
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 3,"  
Assign App.RdioService to a new instance of RdioService
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 4,"  
Inside the initialize function, create a new instance of the Player object and pass in a playlistId key with a value of p8056088
Assign that new object to App.Player
Call initialize on document ready so that the application boots when the page loads:
 $(document).ready(function() {
  ...
});
 
Take a look at App.Player.playlistData in the console, the data should look the same as PLAYLIST_DATA.data
",3
https://github.com/shayhowe/modular-html-css-js-workshop,## Building the Playlist Object, ,3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 1,"  
Create a new object called Playlist in a file called playlist.js and load the script on the page:
 <script src=""assets/js/playlist.js""></script>
 
Assign it to a constructor function that takes a parameter of data
Set some instance variables in that function: data, songs, currentSong

Initalize songs with an empty arrays
Initalize currentSong with an empty object
Assign data to the value data parameter passed in to the constructor


",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 2,"  
Create an initialize method on the prototype of the Playlist object ?leave the function body empty for now
Call the initialize method from the constructor function after the instance variables are assigned
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 3,"  
Back in the player.js file, find the getPlaylistData callback (Hint: it’s where the self.playlistData = data assignment happens)
In that callback function, create a new Playlist object and assign it to App.Playlist
Pass the callback data into the new Playlist object
Take a look at App.Playlist.data in the console, the data should look the same as PLAYLIST_DATA.data and App.Player.playlistData
",3
https://github.com/shayhowe/modular-html-css-js-workshop,## Building the Song Object, ,3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 1,"  
Create a new object called Song in a file called song.js and load the script on the page:
 <script src=""assets/js/song.js""></script>
 
Assign it to a constructor function that takes a parameter of data
Set some instance variables in that function:

id and assign it to data.id
title and assign it to data.name
artist and assign it to data.artist
artwork and assign it to data.icon400


",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 2,"  
Test it out the new Song object with the following code:
 data = {
  ""id"": ""t8209409"",
  ""radioKey"": ""sr8209409"",
  ""baseIcon"": ""album/2/b/5/00000000000a85b2/1/square-200.jpg"",
  ""artistUrl"": ""/artist/Architecture_In_Helsinki/"",
  ""duration"": 220,
  ""album"": ""Contact High"",
  ""albumUrl"": ""/artist/Architecture_In_Helsinki/album/Contact_High/"",
  ""shortUrl"": ""http://rd.io/x/QHlRKz4bUw/"",
  ""albumArtist"": ""Architecture In Helsinki"",
  ""canStream"": true,
  ""embedUrl"": ""https://rd.io/e/QHlRKz4bUw/"",
  ""trackNum"": 1,
  ""albumArtistKey"": ""r86460"",
  ""icon"": ""http://rdio1img-a.akamaihd.net/album/2/b/5/00000000000a85b2/1/square-200.jpg"",
  ""name"": ""Contact High"",
  ""artistKey"": ""r86460"",
  ""url"": ""/artist/Architecture_In_Helsinki/album/Contact_High/track/Contact_High/"",
  ""icon400"": ""http://rdio3img-a.akamaihd.net/album/2/b/5/00000000000a85b2/1/square-400.jpg"",
  ""artist"": ""Architecture In Helsinki"",
  ""albumKey"": ""a689586""
}

mySong = new Song(data)
",3
https://github.com/shayhowe/modular-html-css-js-workshop,## Rendering the Song, ,3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 1,"  
Add data attributes to the markup in the places where the song information should be rendered, we’ll use: data-song-title, data-song-artist, data-song-artwork
Be sure to get both places for the artwork attribute
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 2,"  
Create an render method on the prototype of the Song object
Use jQuery to render the song title, artist and artwork to the browser using the data attributes as your selectors
Try rendering you song object from the previous section: mySong.render()
",3
https://github.com/shayhowe/modular-html-css-js-workshop,## Rendering the Playlist, ,3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 1,"  
In the initialize method Playlist object use a forEach loop to create new Song objects from each song entry in the data object
Push those objects into the songs array in the Playlist object
Take a look at App.Playlist.songs in the console, you should see a bunch of Song objects
See if you can render one of them. (Hint: App.Playlist.songs[2].render())
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 2,"  
Now we need to create a Handlebars template so that we can render each song to the player’s playlist
Add a script tag with the type of text/x-handlebars-template and add the data-template-song data attribute (This will be the container for the Handlebars template)
Copy one of the lis from the existing markup and paste it inside the Handlebars container
Add Handlebars variables for each of dynamic pieces of the template (title, artist and artwork) (Variables in Handlebars are defined by double curly braces, i.e. {{myVariable}})
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 3,"  
Add the template to the App.Templates object and give it the name playlistSong
Use the Handlebars.compile function like so: Handlebars.compile($('[data-template-song]').html())
Test the template rendering with the following code:
 data = {
  title: ""Contact High"",
  artist: ""Architecture In Helsinki"",
  artwork: ""http://rdio3img-a.akamaihd.net/album/2/b/5/00000000000a85b2/1/square-400.jpg""
}

App.Templates.playlistSong(data)
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 4,"  
Add a data attribute of data-playlist to the ul tag that wraps all of the list items in the playlist
Remove all the static li elements from the playlist, leaving just the wrapping ul tag
Create a render method in the Playlist prototype to render the playlist
We only want to display the next 5 songs on the playlist, so use the slice function to get the first 5 songs from the songs array
Now, use a forEach loop the render each object in your new array and append it to the data-playlist ul node
Try out your new render method by calling App.Playlist.render() in the console
",3
https://github.com/shayhowe/modular-html-css-js-workshop,### Step 5,"  
At the beginning of the render method, assign the first song in the songs array to currentSong so that we can render that song to the player
Since the first song is now our currentSong, let move that element to the bottom of the array using the following code:
 this.songs = this.songs.concat(this.songs.splice(0, 1));
 
Call render on currentSong at the end of the Playlist render function
In the Playlist initialize function, add a call to render so that the playlist will be rendered when then object is created
",3
https://github.com/shayhowe/modular-html-css-js-workshop,## Final Product,  ,3
https://github.com/TLINDEN/novel-mode,# novel-mode, Emacs Screen Reader,1
https://github.com/TLINDEN/novel-mode,# Demo,  ,3
https://github.com/TLINDEN/novel-mode,# Introduction,"  Novel  mode is  a minor  mode which  converts emacs  into a  screen
reader, or in other words,  it enables distraction free reading. It
is however not  suited for distraction free  editing. Try writeroom
mode if you're looking for this. When turned on, it does the following conversions: 
disable almost all distractions, as menu, toolbar, scrollbar
enlarge font size
switch to variable width font
enable word wrap (without fringe marker)
increase line spacing
add a window margin to the left and right (thereby centering the text)
disable all input keys (rendering the buffer read-only)
disable the cursor
switch to buffer-scrolling (like e.g. in Acroread)
display current reading position in percent
add a couple of convenience one-key commands
 Novel mode provides the following one-key commands, when active: n           scroll one page down
p           scroll one page up
<down>      scroll one line down
<up>        scroll one line up
mousewheel  scroll linewise up or down
SPC         scroll one page down
<left>      increase margins, makes visible text narrower
<right>     decrease margins, makes visible text wider
+           increase font size
-           decrease font size
i           invert video display
q           quit novel mode
?           display key mapping
 Important: while normal  key input (beside the  ones listed above),
is disabled, Control and Meta still work, of course. Please be also
aware that this mode might conflict with god-mode or evil-mode. If you use this  mode quite often, then it might be  a good idea to
use save-place mode,  so that a text file will  be opened where you
left last time (just like any  ebook reader would do). Here's how to
do that: (if (version< emacs-version ""25.0"")
    (progn
      (require 'saveplace)
      (setq-default save-place t))
  (save-place-mode 1))
 The name  novel mode is  not my idea,  there's a function  on Xah's
ergomacs   page  with   a  function   for  this   kind  of   stuff:
http://ergoemacs.org/emacs/emacs_novel_reading_mode.html.  In fact,
this mode is based on this function, I had it in my .emacs file and
enhanced it  all the  time.  At  some point it  made more  sence to
maintain this baby in its own mode - hence novel-mode.",1
https://github.com/TLINDEN/novel-mode,# Install,"  To use, save novel-mode.el to a directory in your load-path. Add something like this to your config: (require 'novel-mode)
(add-hook 'text-mode-hook 'novel-mode)
 or load it manually, when needed: M-x novel-mode
",3
https://github.com/TLINDEN/novel-mode,# Customize,"  You can customize the following variables: To setup a default left and right margin, use this: (setq novel-default-margin 50)
 All available  novel-mode variables  can be  modified interactively
with:  M-x customize-group RET novel-mode RET
 You can also use hooks to novel  mode as a way to modify or enhance
its behavior.  The following hooks are available: novel-mode-pre-start-hook
novel-mode-post-start-hook
novel-mode-pre-stop-hook
novel-mode-post-stop-hook
 Example: (add-hook 'novel-mode-post-start-hook
          (lambda ()
            (set-face-font 'default ""DejaVu Sans"")))
(add-hook 'novel-mode-post-stop-hook
          (lambda ()
            (set-face-font 'default ""Courier"")))
",3
https://github.com/TLINDEN/novel-mode,# Meta,"  Copyright (C) 2016, T.v.Dein tlinden@cpan.org This file is NOT part of Emacs. This  program is  free  software; you  can  redistribute it  and/or
modify it  under the  terms of  the GNU  General Public  License as
published by the Free Software  Foundation; either version 2 of the
License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but
WITHOUT  ANY  WARRANTY;  without   even  the  implied  warranty  of
MERCHANTABILITY or FITNESS  FOR A PARTICULAR PURPOSE.   See the GNU
General Public License for more details. You should have  received a copy of the GNU  General Public License
along  with  this program;  if  not,  write  to the  Free  Software
Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307
USA - Version: 0.01
- Author: T.v.Dein <tlinden@cpan.org>
- Keywords: read books novels
- URL: https://github.com/tlinden/novel-mode
- License: GNU General Public License >= 2
",45
https://github.com/rossgritz/ipython-notebooks,# ipython-notebooks," This repo contains various IPython notebooks I've created to experiment with libraries and work through exercises, and explore subjects that I find interesting.  I've included notebook viewer links below.  Click the link to see a live rendering of the notebook.",1
https://github.com/rossgritz/ipython-notebooks,#### Language,"  These notebooks contain introductory content such as an overview of the language and a review of IPython's functionality. Introduction To Python
IPython Magic Commands",16
https://github.com/rossgritz/ipython-notebooks,#### Libraries,"  Examples using a variety of popular ""data science"" Python libraries. NumPy
SciPy
Matplotlib
Pandas
Statsmodels
Scikit-learn
Seaborn
NetworkX
PyMC
NLTK
DEAP
Gensim",3
https://github.com/rossgritz/ipython-notebooks,#### Machine Learning Exercises,"  Implementations of the exercises presented in Andrew Ng's ""Machine Learning"" class on Coursera. Exercise 1 - Linear Regression
Exercise 2 - Logistic Regression
Exercise 3 - Multi-Class Classification
Exercise 4 - Neural Networks
Exercise 6 - Support Vector Machines
Exercise 7 - K-Means Clustering & PCA
Exercise 8 - Anomaly Detection & Recommendation Systems",36
https://github.com/rossgritz/ipython-notebooks,#### Tensorflow Deep Learning Exercises,"  Implementations of the assignments from Google's Udacity course on deep learning. Assignment 1 - Intro & Data Prep
Assignment 2 - Regression & Neural Nets
Assignment 3 - Regularization
Assignment 4 - Convolutions
Assignment 5 - Word Embeddings
Assignment 6 - Recurrent Nets",36
https://github.com/rossgritz/ipython-notebooks,#### Spark Big Data Labs,"  Lab exercises for the original Spark classes on edX. Lab 0 - Learning Apache Spark
Lab 1 - Building A Word Count Application
Lab 2 - Web Server Log Analysis
Lab 3 - Text Analysis & Entity Resolution
Lab 4 - Introduction To Machine Learning
ML Lab 3 - Linear Regression
ML Lab 4 - Click-Through Rate Prediction
ML Lab 5 - Principal Component Analysis",36
https://github.com/rossgritz/ipython-notebooks,#### Misc,"  Notebooks covering various interesting topics! Comparison Of Various Code Optimization Methods
A Simple Time Series Analysis of the S&P 500 Index
An Intro To Probablistic Programming
Language Exploration Using Vector Space Models
Solving Problems With Dynamic Programming",36
https://github.com/tdeborge/angular-phonecat,# AngularJS Phone Catalog Tutorial Application,,1
https://github.com/tdeborge/angular-phonecat,## Overview,"  This application takes the developer through the process of building a web-application using
AngularJS. The application is loosely based on the Google Phone Gallery, which no longer exists.
Here is a historical reference: Google Phone Gallery on WayBack Each tagged commit is a separate lesson teaching a single aspect of the framework. The full tutorial can be found at https://docs.angularjs.org/tutorial.",1
https://github.com/tdeborge/angular-phonecat,## Prerequisites, ,3
https://github.com/tdeborge/angular-phonecat,### Git,"  
A good place to learn about setting up git is here.
You can find documentation and download git here.
",3
https://github.com/tdeborge/angular-phonecat,### Node.js and Tools,"  
Get Node.js.
Install the tool dependencies: npm install
",3
https://github.com/tdeborge/angular-phonecat,## Workings of the Application,"  
The application filesystem layout structure is based on the angular-seed project.
There is no dynamic backend (no application server) for this application. Instead we fake the
application server by fetching static JSON files.
Read the Development section at the end to familiarize yourself with running and developing
an Angular application.
",3
https://github.com/tdeborge/angular-phonecat,## Commits / Tutorial Outline,"  You can check out any point of the tutorial using: git checkout step-?
 To see the changes made between any two lessons use the git diff command: git diff step-?..step-?
",3
https://github.com/tdeborge/angular-phonecat,### step-0 _Bootstrapping_,"  
Add the 'angular.js' script.
Add the ngApp directive to bootstrap the application.
Add a simple template with an expression.
",3
https://github.com/tdeborge/angular-phonecat,### step-1 _Static Template_,"  
Add a stylesheet file ('app/app.css').
Add a static list with two phones.
",3
https://github.com/tdeborge/angular-phonecat,### step-2 _Angular Templates_,"  
Convert the static phone list to dynamic by:

Creating a PhoneListController controller.
Extracting the data from HTML into the controller as an in-memory dataset.
Converting the static document into a template with the use of the ngRepeat directive.


Add a simple unit test for the PhoneListController controller to show how to write tests and
run them using Karma.
",3
https://github.com/tdeborge/angular-phonecat,### step-3 _Components_,"  
Introduce components.
Combine the controller and the template into a reusable, isolated phoneList component.
Refactor the application and tests to use the phoneList component.
",3
https://github.com/tdeborge/angular-phonecat,### step-4 _Directory and File Organization_,"  
Refactor the layout of files and directories, applying best practices and techniques that will
make the application easier to maintain and expand in the future:

Put each entity in its own file.
Organize code by feature area (instead of by function).
Split code into modules that other modules can depend on.
Use external templates in .html files (instead of inline HTML strings).


",3
https://github.com/tdeborge/angular-phonecat,### step-5 _Filtering Repeaters_,"  
Add a search box to demonstrate:

How the data-binding works on input fields.
How to use the filter filter.
How ngRepeat automatically shrinks and grows the number of phones in the view.


Add an end-to-end test to:

Show how end-to-end tests are written and used.
Prove that the search box and the repeater are correctly wired together.


",3
https://github.com/tdeborge/angular-phonecat,### step-6 _Two-way Data Binding_,"  
Add an age property to the phone model.
Add a drop-down menu to control the phone list order.
Override the default order value in controller.
Add unit and end-to-end tests for this feature.
",3
https://github.com/tdeborge/angular-phonecat,### step-7 _XHR & Dependency Injection_,"  
Replace the in-memory dataset with data loaded from the server (in the form of a static
'phone.json' file to keep the tutorial backend agnostic):

The JSON data is loaded using the $http service.


Demonstrate the use of services and dependency injection (DI):

$http is injected into the controller through DI.
Introduce DI annotation methods: .$inject and inline array


",3
https://github.com/tdeborge/angular-phonecat,### step-8 _Templating Links & Images_,"  
Add a phone image and links to phone pages.
Add an end-to-end test that verifies the phone links.
Tweak the CSS to style the page just a notch.
",3
https://github.com/tdeborge/angular-phonecat,### step-9 _Routing & Multiple Views_,"  
Introduce the $route service, which allows binding URLs to views for routing and deep-linking:

Add the ngRoute module as a dependency.
Configure routes for the application.
Use the ngView directive in 'index.html'.


Create a phone list route (/phones):

Map /phones to the existing phoneList component.


Create a phone detail route (/phones/:phoneId):

Map /phones/:phoneId to a new phoneDetail component.
Create a dummy phoneDetail component, which displays the selected phone ID.
Pass the phoneId parameter to the component's controller via $routeParams.


",3
https://github.com/tdeborge/angular-phonecat,### step-10 _More Templating_,"  
Implement fetching data for the selected phone and rendering to the view:

Use $http in PhoneDetailController to fetch the phone details from a JSON file.
Create the template for the detail view.


Add CSS styles to make the phone detail page look ""pretty-ish"".
",3
https://github.com/tdeborge/angular-phonecat,### step-11 _Custom Filters_,"  
Implement a custom checkmark filter.
Update the phoneDetail template to use the checkmark filter.
Add a unit test for the checkmark filter.
",3
https://github.com/tdeborge/angular-phonecat,### step-12 _Event Handlers_,"  
Make the thumbnail images in the phone detail view clickable:

Introduce a mainImageUrl property on PhoneDetailController.
Implement the setImage() method for changing the main image.
Use ngClick on the thumbnails to register a handler that changes the main image.
Add an end-to-end test for this feature.


",3
https://github.com/tdeborge/angular-phonecat,### step-13 _REST and Custom Services_,"  
Replace $http with $resource.
Create a custom Phone service that represents the RESTful client.
Use a custom Jasmine equality tester in unit tests to ignore irrelevant properties.
",3
https://github.com/tdeborge/angular-phonecat,### step-14 _Animations_,"  
Add animations to the application:

Animate changes to the phone list, adding, removing and reordering phones with ngRepeat.
Animate view transitions with ngView.
Animate changes to the main phone image in the phone detail view.


Showcase three different kinds of animations:

CSS transition animations.
CSS keyframe animations.
JavaScript-based animations.


",3
https://github.com/tdeborge/angular-phonecat,## Development with `angular-phonecat`,  The following docs describe how you can test and develop this application further.,3
https://github.com/tdeborge/angular-phonecat,### Installing Dependencies,"  The application relies upon various Node.js tools, such as Bower, Karma and
Protractor. You can install these by running: npm install
 This will also run Bower, which will download the Angular files needed for the current step of the
tutorial. Most of the scripts described below will run this automatically but it doesn't do any harm to run
it whenever you like.",3
https://github.com/tdeborge/angular-phonecat,### Running the Application during Development,"  
Run npm start.
Navigate your browser to http://localhost:8000/ to see the application
running.
",3
https://github.com/tdeborge/angular-phonecat,### Unit Testing,"  We recommend using Jasmine and Karma for your unit tests/specs, but you are free
to use whatever works for you. 
Start Karma with npm test.
A browser will start and connect to the Karma server. Chrome and Firefox are the default browsers,
others can be captured by loading the same URL or by changing the karma.conf.js file.
Karma will sit and watch your application and test JavaScript files. To run or re-run tests just
change any of your these files.
",3
https://github.com/tdeborge/angular-phonecat,### End-to-End Testing,"  We recommend using Protractor for end-to-end (e2e) testing. It requires a webserver that serves the application. See the
Running the Application during Development section, above. 
Serve the application with: npm start
In a separate terminal/command line window run the e2e tests: npm run protractor.
Protractor will execute the e2e test scripts against the web application itself. The project is
set up to run the tests on Chrome directly. If you want to run against other browsers, you must
modify the configuration at e2e-tests/protractor-conf.js.
",3
https://github.com/tdeborge/angular-phonecat,## Application Directory Layout,"  app/                     --> all the source code of the app (along with unit tests)
  bower_components/...   --> 3rd party JS/CSS libraries, including Angular and jQuery
  core/                  --> all the source code of the core module (stuff used throughout the app)
    checkmark/...        --> files for the `checkmark` filter, including JS source code, specs
    phone/...            --> files for the `core.phone` submodule, including JS source code, specs
    core.module.js       --> the core module
  img/...                --> image files
  phone-detail/...       --> files for the `phoneDetail` module, including JS source code, HTML templates, specs
  phone-list/...         --> files for the `phoneList` module, including JS source code, HTML templates, specs
  phones/...             --> static JSON files with phone data (used to fake a backend API)
  app.animations.css     --> hooks for running CSS animations with `ngAnimate`
  app.animations.js      --> hooks for running JS animations with `ngAnimate`
  app.config.js          --> app-wide configuration of Angular services
  app.css                --> default stylesheet
  app.module.js          --> the main app module
  index.html             --> app layout file (the main HTML template file of the app)

e2e-tests/               --> config and source files for e2e tests
  protractor.conf.js     --> config file for running e2e tests with Protractor
  scenarios.js           --> e2e specs

node_modules/...         --> development tools (fetched using `npm`)

scripts/                 --> handy scripts
  private/...            --> private scripts used by the Angular Team to maintain this repo
  update-repo.sh         --> script for pulling down the latest version of this repo (!!! DELETES ALL CHANGES YOU HAVE MADE !!!)

bower.json               --> Bower specific metadata, including client-side dependencies
karma.conf.js            --> config file for running unit tests with Karma
package.json             --> Node.js specific metadata, including development tools dependencies
",3
https://github.com/tdeborge/angular-phonecat,## Contact,"  For more information on AngularJS, please check out https://angularjs.org/.",5
https://github.com/AlexandraRezk02/first-lab-ruby-learn-cli-ile-intro-to-learn,# Solving your first Lab,,1
https://github.com/AlexandraRezk02/first-lab-ruby-learn-cli-ile-intro-to-learn,## Objectives,"  
Open a lab by clicking ""Open"" on this page on Learn.co
Run the lab's tests with the learn CLI command
Make a change to your copy of this lab
Pass the tests using the learn CLI command
Submit the passing lab with the learn submit CLI command
",1
https://github.com/AlexandraRezk02/first-lab-ruby-learn-cli-ile-intro-to-learn,## Instructions,"  This lab is just about practicing the lab workflow on Learn using the learn CLI. 
Click on the ""Open"" link on the lab toolbar above.
  After you click on this, your Learn IDE will launch. 

You should see all of the files associated with this lab in the Learn IDE's file browser on the left pane.


In the console on the bottom pane, run the test suite by typing learn and hitting enter. You'll see something similar to:

  You can see your test is currently failing, which is fine. We haven't done any work yet, so it makes sense. The failure reads: Make sure you have added a new file or edited edit-me.txt 

To pass this lab, make any change to the content of the edit-me.txt file. You can do this by clicking on the name of the file in the file browser in the left pane; its contents will load in the text editor. Type into the text editor to change the contents of the file, then save your changes.


Once your local tests are passing, you can submit this lab by running learn submit from your terminal.

  You should see this lab pass on Learn.co. Congratulations! You've just solved your first lab. View First Lab on Learn.co and start learning to code for free.",3
https://github.com/jaredkirkley/formBuilder,# formBuilder," 


Branch
Build Status




v2.1.9



master



dev



",14
https://github.com/jaredkirkley/formBuilder,# Documentation,  Checkout the GitHub page docs here!,6
https://github.com/jaredkirkley/formBuilder,# About, ,1
https://github.com/jaredkirkley/formBuilder,## What is formBuilder?,"  FormBuilder is a library that can be used to create forms online. These forms will be able to accept user input and save the data in varying ways depending on what data-types have been chosen for the input fields. There are many different input field data-types and each have different filters, validation methods, and options that dictate what kind of data they can or can not accept, and how the input fields will look and behave. These types have been developed to meet the typical needs of what would be desired from an online form, such as a phone number type, an email type, a regular text input type, and many more. If you would like to see a full list of the input types that are available to you with formBuilder please feel free to look ahead to the Data Types section in the User Guide. It is also possible, if these types do not meet the requirements of what is needed for a form that is being built, to easily design a custom input type by modifying a set of base methods, or developing a regular expression to define what input will be allowed in the new type. A more detailed description of how to do this can be found in the Customization section of the User Guide. If you would like to see an example of a form that is built using formBuilder, and how the data from that form is saved, feel free to look ahead to our Live Demo.",13
https://github.com/jaredkirkley/formBuilder,## How is formBuilder used?,"  FormBuilder is used by creating forms and then initializing them as formBuilder widgets. FormBuilder will construct the form fields automatically. You can then build upon those forms by adding as many different kinds of input as are desired. If you would like to know how to use formBuilder and see examples of each different input types and how they work, please feel free to look ahead to the User Guide. For a more in-depth understanding of how to use and manipulate each different available resource in the formBuilder library, please feel free to look ahead to our API Reference",16
https://github.com/jaredkirkley/formBuilder,## Why should I use formBuilder?,"  FormBuilder allows you to create complicated input fields on forms by using only one or two lines of code in your html file. By implementing one or two attributes on an input field you will be able to apply large changes to how the field will appear and how it will handle data. It is also a quick and easy way to be able to eliminate most human error from any online form that you are trying to build. By using input types that have been designed to only accept certain entries you can help to prevent the chance that forms will be submitted to you incorrectly. FormBuilder is also very easy to understand and implement into your code. The user guide and API reference that have been provided to you are useful tools to be able to understand and see examples of how to build your form using formBuilder. In short, formBuilder is a useful tool that can be used to enhance any online form that you are trying to build.",2
https://github.com/jaredkirkley/formBuilder,## Credits,"  Auto Data Direct, Inc.",5
https://github.com/jaredkirkley/formBuilder,## License,  MIT,5
https://github.com/panshuiqing/ocanvas,# [oCanvas](http://ocanvas.org/) - Object-based canvas drawing," oCanvas makes canvas development easier to understand and do, by creating a bridge between the native pixel drawing approach and objects that are created and added to canvas. It is now possible to very easily create objects, change properties of these objects and add events to them ?and everything just works because oCanvas handles the background stuff for you.",12
https://github.com/panshuiqing/ocanvas,## Building your own oCanvas,"  The git repo contains a build directory with a build script. That will combine all modules specified in the config file and output one file with the full source and one file with the minified source. The script uses Node, so you need to install that first. The minification is done by UglifyJS which is included in the repo. First you need to get your own copy of the source files, by running the following in the terminal:
git clone git://github.com/koggdal/ocanvas.git Then navigate to the build directory by running:
cd ocanvas/build Finally run the build command:
node build.js You will now have two source files in the build/dev/ directory: ocanvas-x.x.x.js and ocanvas-x.x.x.min.js",3
https://github.com/panshuiqing/ocanvas,## Documentation,"  All the documentation can be found at the website, http://ocanvas.org/",6
https://github.com/panshuiqing/ocanvas,## Issue reporting,"  Issues should be reported on GitHub, and every good issue should contain a good description, details about oCanvas version, operating system and browser. A test case of some sorts is also very much appreciated.",7
https://github.com/panshuiqing/ocanvas,## Contributing,"  oCanvas is an open source project created and maintained by me (Johannes Koggdal). It would be great to get some more developers working on it, since I can't possibly make everything on my spare time. If you want to help out—reach out to me, so we can sync up to avoid double work. Then just send a pull request to get it in. I have two main branches, master and develop, where develop is the branch where everything happens. When a new version is about to be released, it gets merged to master, where the version number is updated. So if you want to help out, make sure you're working on top of develop.",7
https://github.com/hobmgcode/you-get,# You-Get," 

 You-Get is a tiny command-line utility to download media contents (videos, audios, images) from the Web, in case there is no other handy way to do it. Here's how you use you-get to download a video from this web page: $ you-get http://www.fsf.org/blogs/rms/20140407-geneva-tedx-talk-free-software-free-society
Site:       fsf.org
Title:      TEDxGE2014_Stallman05_LQ
Type:       WebM video (video/webm)
Size:       27.12 MiB (28435804 Bytes)

Downloading TEDxGE2014_Stallman05_LQ.webm ...
100.0% ( 27.1/27.1 MB) ├████████████████████████████████████████┤[1/1]   12 MB/s And here's why you might want to use it: 
You enjoyed something on the Internet, and just want to download them for your own pleasure.
You watch your favorite videos online from your computer, but you are prohibited from saving them. You feel that you have no control over your own computer. (And it's not how an open Web is supposed to work.)
You want to get rid of any closed-source technology or proprietary JavaScript code, and disallow things like Flash running on your computer.
You are an adherent of hacker culture and free software.
 What you-get can do for you: 
Download videos / audios from popular websites such as YouTube, Youku, Niconico, and a bunch more. (See the full list of supported sites)
Stream an online video in your media player. No web browser, no more ads.
Download images (of interest) by scraping a web page.
Download arbitrary non-HTML contents, i.e., binary files.
 Interested? Install it now and get started by examples. Are you a Python programmer? Then check out the source and fork it! ",123
https://github.com/hobmgcode/you-get,## Installation, ,3
https://github.com/hobmgcode/you-get,### Prerequisites,"  The following dependencies are required and must be installed separately, unless you are using a pre-built package on Windows: 
Python 3
FFmpeg (strongly recommended) or Libav
(Optional) RTMPDump
",3
https://github.com/hobmgcode/you-get,### Option 1: Install via pip,"  The official release of you-get is distributed on PyPI, and can be installed easily from a PyPI mirror via the pip package manager. Note that you must use the Python 3 version of pip: $ pip3 install you-get
",3
https://github.com/hobmgcode/you-get,### Option 2: Install via [Antigen](https://github.com/zsh-users/antigen),"  Add the following line to your .zshrc: antigen bundle soimort/you-get
",3
https://github.com/hobmgcode/you-get,### Option 3: Use a pre-built package (Windows only),  Download the exe (standalone) or 7z (all dependencies included) from: https://github.com/soimort/you-get/releases/latest.,3
https://github.com/hobmgcode/you-get,### Option 4: Download from GitHub,"  You may either download the stable (identical with the latest release on PyPI) or the develop (more hotfixes, unstable features) branch of you-get. Unzip it, and put the directory containing the you-get script into your PATH. Alternatively, run $ make install
 to install you-get to a permanent path.",3
https://github.com/hobmgcode/you-get,### Option 5: Git clone,"  This is the recommended way for all developers, even if you don't often code in Python. $ git clone git://github.com/soimort/you-get.git
 Then put the cloned directory into your PATH, or run make install to install you-get to a permanent path.",3
https://github.com/hobmgcode/you-get,## Upgrading,"  Based on which option you chose to install you-get, you may upgrade it via: $ pip3 install --upgrade you-get
 or download the latest release via: $ you-get https://github.com/soimort/you-get/archive/master.zip
",3
https://github.com/hobmgcode/you-get,## Getting Started, ,3
https://github.com/hobmgcode/you-get,### Download a video,"  When you get a video of interest, you might want to use the --info/-i option to see all available quality and formats: $ you-get -i 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
site:                YouTube
title:               Me at the zoo
streams:             # Available quality and codecs
    [ DEFAULT ] _________________________________
    - itag:          43
      container:     webm
      quality:       medium
      size:          0.5 MiB (564215 bytes)
    # download-with: you-get --itag=43 [URL]

    - itag:          18
      container:     mp4
      quality:       medium
    # download-with: you-get --itag=18 [URL]

    - itag:          5
      container:     flv
      quality:       small
    # download-with: you-get --itag=5 [URL]

    - itag:          36
      container:     3gp
      quality:       small
    # download-with: you-get --itag=36 [URL]

    - itag:          17
      container:     3gp
      quality:       small
    # download-with: you-get --itag=17 [URL]
 The format marked with DEFAULT is the one you will get by default. If that looks cool to you, download it: $ you-get 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
site:                YouTube
title:               Me at the zoo
stream:
    - itag:          43
      container:     webm
      quality:       medium
      size:          0.5 MiB (564215 bytes)
    # download-with: you-get --itag=43 [URL]

Downloading zoo.webm ...
100.0% (  0.5/0.5  MB) ├████████████████████████████████████████┤[1/1]    7 MB/s

Saving Me at the zoo.en.srt ...Done.
 (If a YouTube video has any closed captions, they will be downloaded together with the video file, in SubRip subtitle format.) Or, if you prefer another format (mp4), just use whatever the option you-get shows to you: $ you-get --itag=18 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
 Note: 
At this point, format selection has not been generally implemented for most of our supported sites; in that case, the default format to download is the one with the highest quality.
ffmpeg is a required dependency, for downloading and joining videos streamed in multiple parts (e.g. on some sites like Youku), and for YouTube videos of 1080p or high resolution.
If you don't want you-get to join video parts after downloading them, use the --no-merge/-n option.
",3
https://github.com/hobmgcode/you-get,### Download anything else,"  If you already have the URL of the exact resource you want, you can download it directly with: $ you-get https://stallman.org/rms.jpg
Site:       stallman.org
Title:      rms
Type:       JPEG Image (image/jpeg)
Size:       0.06 MiB (66482 Bytes)

Downloading rms.jpg ...
100.0% (  0.1/0.1  MB) ├████████████████████████████████████████┤[1/1]  127 kB/s
 Otherwise, you-get will scrape the web page and try to figure out if there's anything interesting to you: $ you-get http://kopasas.tumblr.com/post/69361932517
Site:       Tumblr.com
Title:      kopasas
Type:       Unknown type (None)
Size:       0.51 MiB (536583 Bytes)

Site:       Tumblr.com
Title:      tumblr_mxhg13jx4n1sftq6do1_1280
Type:       Portable Network Graphics (image/png)
Size:       0.51 MiB (536583 Bytes)

Downloading tumblr_mxhg13jx4n1sftq6do1_1280.png ...
100.0% (  0.5/0.5  MB) ├████████████████████████████████████████┤[1/1]   22 MB/s
 Note: 
This feature is an experimental one and far from perfect. It works best on scraping large-sized images from popular websites like Tumblr and Blogger, but there is really no universal pattern that can apply to any site on the Internet.
",3
https://github.com/hobmgcode/you-get,### Search on Google Videos and download,"  You can pass literally anything to you-get. If it isn't a valid URL, you-get will do a Google search and download the most relevant video for you. (It might not be exactly the thing you wish to see, but still very likely.) $ you-get ""Richard Stallman eats""
",3
https://github.com/hobmgcode/you-get,### Pause and resume a download,"  You may use Ctrl+C to interrupt a download. A temporary .download file is kept in the output directory. Next time you run you-get with the same arguments, the download progress will resume from the last session. In case the file is completely downloaded (the temporary .download extension is gone), you-get will just skip the download. To enforce re-downloading, use the --force/-f option. (Warning: doing so will overwrite any existing file or temporary file with the same name!)",3
https://github.com/hobmgcode/you-get,### Set the path and name of downloaded file,"  Use the --output-dir/-o option to set the path, and --output-filename/-O to set the name of the downloaded file: $ you-get -o ~/Videos -O zoo.webm 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
 Tips: 
These options are helpful if you encounter problems with the default video titles, which may contain special characters that do not play well with your current shell / operating system / filesystem.
These options are also helpful if you write a script to batch download files and put them into designated folders with designated names.
",3
https://github.com/hobmgcode/you-get,### Proxy settings,"  You may specify an HTTP proxy for you-get to use, via the --http-proxy/-x option: $ you-get -x 127.0.0.1:8087 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
 However, the system proxy setting (i.e. the environment variable http_proxy) is applied by default. To disable any proxy, use the --no-proxy option. Tips: 
If you need to use proxies a lot (in case your network is blocking certain sites), you might want to use you-get with proxychains and set alias you-get=""proxychains -q you-get"" (in Bash).
For some websites (e.g. Youku), if you need access to some videos that are only available in mainland China, there is an option of using a specific proxy to extract video information from the site: --extractor-proxy/-y.
",3
https://github.com/hobmgcode/you-get,### Watch a video,"  Use the --player/-p option to feed the video into your media player of choice, e.g. mplayer or vlc, instead of downloading it: $ you-get -p vlc 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
 Or, if you prefer to watch the video in a browser, just without ads or comment section: $ you-get -p chromium 'https://www.youtube.com/watch?v=jNQXAC9IVRw'
 Tips: 
It is possible to use the -p option to start another download manager, e.g., you-get -p uget-gtk 'https://www.youtube.com/watch?v=jNQXAC9IVRw', though they may not play together very well.
",3
https://github.com/hobmgcode/you-get,### Load cookies,"  Not all videos are publicly available to anyone. If you need to log in your account to access something (e.g., a private video), it would be unavoidable to feed the browser cookies to you-get via the --cookies/-c option. Note: 
As of now, we are supporting two formats of browser cookies: Mozilla cookies.sqlite and Netscape cookies.txt.
",3
https://github.com/hobmgcode/you-get,### Reuse extracted data,"  Use --url/-u to get a list of downloadable resource URLs extracted from the page. Use --json to get an abstract of extracted data in the JSON format. Warning: 
For the time being, this feature has NOT been stabilized and the JSON schema may have breaking changes in the future.
",3
https://github.com/hobmgcode/you-get,## Supported Sites,"  


Site
URL
Videos?
Images?
Audios?




YouTube
https://www.youtube.com/
?



Twitter
https://twitter.com/
??


VK
http://vk.com/
?



Vine
https://vine.co/
?



Vimeo
https://vimeo.com/
?



Vidto
http://vidto.me/
?



Videomega
http://videomega.tv/
?



Veoh
http://www.veoh.com/
?



Tumblr
https://www.tumblr.com/
???

TED
http://www.ted.com/
?



SoundCloud
https://soundcloud.com/


?

Pinterest
https://www.pinterest.com/

?


MusicPlayOn
http://en.musicplayon.com/
?



MTV81
http://www.mtv81.com/
?



Mixcloud
https://www.mixcloud.com/


?

Metacafe
http://www.metacafe.com/
?



Magisto
http://www.magisto.com/
?



Khan Academy
https://www.khanacademy.org/
?



JPopsuki TV
http://www.jpopsuki.tv/
?



Internet Archive
https://archive.org/
?



Instagram
https://instagram.com/
??


Imgur
http://imgur.com/

?


Heavy Music Archive
http://www.heavy-music.ru/


?

Google+
https://plus.google.com/
??


Freesound
http://www.freesound.org/


?

Flickr
https://www.flickr.com/
??


FC2 Video
http://video.fc2.com/
?



Facebook
https://www.facebook.com/
?



eHow
http://www.ehow.com/
?



Dailymotion
http://www.dailymotion.com/
?



CBS
http://www.cbs.com/
?



Bandcamp
http://bandcamp.com/


?

AliveThai
http://alive.in.th/
?



interest.me
http://ch.interest.me/tvn
?



755ナナゴーゴー
http://7gogo.jp/
??


niconicoニコニコ動画
http://www.nicovideo.jp/
?



163网易视频网易云音?http://v.163.com/http://music.163.com/
?
?

56?http://www.56.com/
?



AcFun
http://www.acfun.tv/
?



Baidu百度贴吧
http://tieba.baidu.com/
??


爆米花网
http://www.baomihua.com/
?



bilibili哔哩哔哩
http://www.bilibili.com/
?



Dilidili
http://www.dilidili.com/
?



豆瓣
http://www.douban.com/


?

斗鱼
http://www.douyutv.com/
?



凤凰视频
http://v.ifeng.com/
?



风行?http://www.fun.tv/
?



iQIYI爱奇?http://www.iqiyi.com/
?



激动网
http://www.joy.cn/
?



??http://www.ku6.com/
?



酷狗音乐
http://www.kugou.com/


?

酷我音乐
http://www.kuwo.cn/


?

乐视?http://www.letv.com/
?



荔枝FM
http://www.lizhi.fm/


?

秒拍
http://www.miaopai.com/
?



MioMio弹幕?http://www.miomio.tv/
?



痞客?https://www.pixnet.net/
?



PPTV聚力
http://www.pptv.com/
?



齐鲁?http://v.iqilu.com/
?



QQ腾讯视频
http://v.qq.com/
?



阡陌视频
http://qianmo.com/
?



Sina新浪视频微博秒拍视频
http://video.sina.com.cn/http://video.weibo.com/
?



Sohu搜狐视频
http://tv.sohu.com/
?



天天动听
http://www.dongting.com/


?

Tudou土豆
http://www.tudou.com/
?



虾米
http://www.xiami.com/


?

阳光卫视
http://www.isuntv.com/
?



音悦Tai
http://www.yinyuetai.com/
?



Youku优酷
http://www.youku.com/
?



战旗TV
http://www.zhanqi.tv/lives
?



央视?http://www.cntv.cn/
?



 For all other sites not on the list, the universal extractor will take care of finding and downloading interesting resources from the page.",6
https://github.com/hobmgcode/you-get,### Known bugs,"  If something is broken and you-get can't get you things you want, don't panic. (Yes, this happens all the time!) Check if it's already a known problem on https://github.com/soimort/you-get/wiki/Known-Bugs, and search on the list of open issues. If it has not been reported yet, open a new issue, with detailed command-line output attached.",3
https://github.com/hobmgcode/you-get,## Getting Involved,"  You can reach us on the Gitter channel #soimort/you-get (here's how you set up your IRC client for Gitter). If you have a quick question regarding you-get, ask it there. All kinds of pull requests are welcome. However, there are a few guidelines to follow: 
The develop branch is where your pull request should go.
Remember to rebase.
Document your PR clearly, and if applicable, provide some sample links for reviewers to test with.
Write well-formatted, easy-to-understand commit messages. If you don't know how, look at existing ones.
We will not ask you to sign a CLA, but you must assure that your code can be legally redistributed (under the terms of the MIT license).
",7
https://github.com/hobmgcode/you-get,## Legal Issues,"  This software is distributed under the MIT license. In particular, please be aware that 
THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
 Translated to human words: In case your use of the software forms the basis of copyright infringement, or you use the software for any other illegal purposes, the authors cannot take any responsibility for you. We only ship the code here, and how you are going to use it is left to your own discretion.",5
https://github.com/hobmgcode/you-get,## Authors,"  Made by @soimort, who is in turn powered by ? 🍕 and 🍜. You can find the list of all contributors here.",5
https://github.com/openube/ML-From-Scratch,# Machine Learning From Scratch,"Python implementations of various Machine Learning models and algorithms from scratch.

While some of the matrix operations that are implemented by hand (such as calculation of covariance matrix) are available in numpy I have decided to add these as well to make sure that I understand how the linear algebra is applied.

The purpose of this project is purely self-educational.",1
https://github.com/openube/ML-From-Scratch,##Current implementations:,,1
https://github.com/openube/ML-From-Scratch,####Supervised Learning:,"Adaboost
Decision Tree
K Nearest Neighbors
Linear Discriminant Analysis
Linear Regression
Logistic Regression
Multi-class Linear Discriminant Analysis
Multilayer Perceptron
Naive Bayes
Perceptron
Random Forest
Ridge Regression
Support Vector Machine",1
https://github.com/openube/ML-From-Scratch,####Unsupervised Learning:,"Gaussian Mixture Model
Principal Component Analysis
K-Means",1
https://github.com/paarthenon/DefinitelyTyped,# DefinitelyTyped [![Build Status](https://travis-ci.org/DefinitelyTyped/DefinitelyTyped.png?branch=master)](https://travis-ci.org/DefinitelyTyped/DefinitelyTyped),"  
The repository for high quality TypeScript type definitions.
 For more information see the definitelytyped.org website.",16
https://github.com/paarthenon/DefinitelyTyped,## Usage,"  Include a line like this: /// <reference path=""jquery.d.ts"" />",3
https://github.com/paarthenon/DefinitelyTyped,## Contributions,  DefinitelyTyped only works because of contributions by users like you! Please see the contribution guide on how to contribute to DefinitelyTyped.,7
https://github.com/paarthenon/DefinitelyTyped,## How to get the definitions,"  
Directly from the GitHub repos
NuGet packages
Typings - TypeScript Definition Manager
",6
https://github.com/paarthenon/DefinitelyTyped,## List of definitions,"  
See CONTRIBUTORS.md
",6
https://github.com/paarthenon/DefinitelyTyped,## Requested definitions,  Here are the currently requested definitions.,6
https://github.com/paarthenon/DefinitelyTyped,## License,  This project is licensed under the MIT license. Copyrights on the definition files are respective of each contributor listed at the beginning of each definition file. ,5
https://github.com/mraimi/insight2,##Implementation details,,1
https://github.com/mraimi/insight2,##Calculating the median,,1
https://github.com/appirits/awesome_admin_layout,# AwesomeAdminLayout," 
 AwesomeAdminLayout provides a simple way to add admin panel layout to your application.",1
https://github.com/appirits/awesome_admin_layout,## Installation,  Add this line to your application's Gemfile: gem 'awesome_admin_layout' And then execute: $ bundle Or install it yourself as: $ gem install awesome_admin_layout,3
https://github.com/appirits/awesome_admin_layout,## Usage,"  
Ruby on Rails
Sinatra
",3
https://github.com/appirits/awesome_admin_layout,### a. Ruby on Rails,"  

Install font-awesome-rails and jquery-rails.


Import a style in app/assets/stylesheets/application.scss:

 @import ""awesome_admin_layout""; 
Require a script in app/assets/javascripts/application.coffee:
 #= require awesome_admin_layout 
Create a file into app/navigations.
And writing the definitions as follows:
 #
# NOTE: if you only use this layout in admin controller,
#       you can write like this:
#
#       `AwesomeAdminLayout.define(only: Admin::ApplicationController)`
#
AwesomeAdminLayout.define do |controller|
  navigation do
    brand 'AwesomeAdminLayout' do
      external_link controller.root_path
    end

    item 'Dashboard' do
      link controller.dashboard_path
      icon 'dashboard'
    end

    item 'Orders' do
      link controller.orders_path
      icon 'shopping-cart'
      active true
    end

    item 'Products' do
      nest :products
      icon 'cube'
      badge true
    end

    item 'Users' do
      link controller.users_path
      icon 'user'
    end

    item 'Promotions' do
      link controller.promotions_path
      icon 'bullhorn'
    end

    item 'Analytics' do
      link controller.analytics_path
      icon 'bar-chart'
      badge true
    end

    divider

    item 'Store' do
      nest :store
      icon 'home'
    end

    divider

    item 'Extentions' do
      link controller.extentions_path
      icon 'puzzle-piece'
      badge 10
    end

    item 'Settings' do
      link controller.settings_path
      icon 'cog'
    end

    flex_divider

    item current_user.email do
      nest :profile
      icon 'gift'
    end
  end

  navigation :products do
    brand 'Products'

    item 'Products' do
      link controller.products_path
    end

    item 'Stocks' do
      link controller.stocks_path
    end

    item 'Categories' do
      link controller.categories_path
    end
  end

  navigation :store do
    brand 'Store' do
      external_link '/#external'
    end

    item 'Pages' do
      link controller.pages_path
    end

    item 'Links' do
      link controller.links_path
    end

    item 'Themes' do
      link controller.themes_path
    end
  end

  navigation :profile do
    brand current_user.email

    item 'Edit Profile' do
      link controller.edit_user_path(current_user)
    end

    item 'Logout' do
      link controller.destroy_user_session_path, method: :delete
    end
  end
end 
Use the helper method in your views.
 <%= render_admin_layout do %>
  <%# Put your main contents ... %>
<% end %>",3
https://github.com/appirits/awesome_admin_layout,### b. Sinatra,  pending...,3
https://github.com/appirits/awesome_admin_layout,## Development,"  To set up a dummy application for development, simply do: $ cd test/dummy
$ bundle exec ruby sinatra_app.rb And go to your browser and open http://localhost:4567.",3
https://github.com/appirits/awesome_admin_layout,## Contributing,"  
Fork it ( https://github.com/appirits/awesome_admin_layout/fork )
Create your feature branch (git checkout -b my-new-feature)
Commit your changes (git commit -am 'Add some feature')
Push to the branch (git push origin my-new-feature)
Create a new Pull Request
",7
https://github.com/johabu/simple_rsa,# README for simple\_rsa," Developed by Johabu http://johabu.spheniscida.de; http://github.com/johabu
This file is part of simple_rsa.
simple_rsa is free software; you can modify it or redistribute it
under the terms of the GNU General Public License as published by
the Free Software Foundation http://www.fsf.org, either version 3,
or (at your option) any later version.
See http://www.gnu.org/licenses for the license, if you haven't received a copy of it (GNU_GPL.txt).
simple_rsa is distributed without any warranty! simple_rsa is a very simple implementation of the basic RSA encryption algorithm",15
https://github.com/johabu/simple_rsa,## IMPORTANT NOTE,"  This program does NOT fulfil any safety standards! It should NOT be used for real
encryption, because it does not provide any safety! This program is only written
for teaching purposes. simple_rsa is distributed without any warranty!",1
https://github.com/johabu/simple_rsa,## Platforms,"  simple_rsa should work on most platforms, but has been tested on Linux amd64 system using gcc",3
https://github.com/johabu/simple_rsa,## Installing,"  To install simple_rsa, you have to compile it, for instance with GCC: gcc -W -Wall -o RSA simple_rsa.c -lm
",3
https://github.com/johabu/simple_rsa,## Using,"  simple_rsa is able to create a RSA key pair including public and private key.
While key generation important variables of the generation process are displayed.
(See http://en.wikipedia.org/wiki/RSA_(cryptosystem) for RSA algorithm) To start simple_rsa, just type the following command in a shell RSA
",36
https://github.com/juhniorsantos/laravel-authentication-acl,# laravel-authentication-acl,,1
https://github.com/juhniorsantos/laravel-authentication-acl,####Main features:,,1
https://github.com/juhniorsantos/laravel-authentication-acl,####Interested in some new feature?,,7
https://github.com/DuncanAForbes/quantlib,# Contributing," Contributing is easy. Get a GitHub account if you don't have it
already and clone this repository with the ""Fork"" button in the top
right corner of this page. Check out your clone to your machine, code
away, push your changes to your clone and submit a pull request;
instructions are available at
https://help.github.com/articles/fork-a-repo.
(In case you need them, more detailed instructions for creating pull requests are at
https://help.github.com/articles/using-pull-requests,
and a basic guide to GitHub is at
https://guides.github.com/activities/hello-world/.) It's likely that we won't merge your code right away, and we'll ask
for some changes instead. Don't be discouraged! That's normal; the
library is complex, and thus it might take some time to become
familiar with it and to use it in an idiomatic way. We're looking forward to your contributions.",7
https://github.com/ishitach/gtg,# Getting Things GNOME!,"  Getting Things GNOME! (GTG) is a personal tasks and TODO list items organizer
for the GNOME desktop environment inspired by the Getting Things Done (GTD)
methodology. GTG is designed with flexibility, adaptability, and ease of use
in mind so it can be used as more than just GTD software. GTG is intended to help you track everything you need to do and need to know,
from small tasks to large projects.",1
https://github.com/ishitach/gtg,## Dependencies,"  GTG depends on the following packages: 
Python, version 3.0 or above
PyGTK
python-support
python-xdg
python-dbus
python-liblarch
yelp (to read GTG documentation)
 Please refer to your system documentation for information on how to install
these modules if they're not currently available. To install the all the required packages providing the basic features on
Debian-based systems, execute the following command:
$ sudo apt-get install python-support python-gtk2 python-gnome2 
python-glade2 python-xdg python-dbus python-liblarch yelp There are additional plugins (modules for extending the user interface) and
synchronization services (modules for importing/exporting tasks from/to
external services) which needs additional packages to work correctly.",3
https://github.com/ishitach/gtg,### Dependencies for Plugins,"  ""Bugzilla"" plugin dependencies: 
python-bugz
 ""Export and print"" plugin dependencies: 
python-cheetah
pdflatex
pdftk
pdfjam
 Installable on Debian-based system via
$ sudo apt-get install python-cheetah pdftk pdfjam texlive-latex-base ""Geolocalized tasks"" plugin is not maintained for a long time and needs to be
rewritten from scratch. Dependencies: 
python-geoclue
python-clutter
python-clutter-gtk
python-champlain
python-champlain-gtk
 ""Hamster Time Tracker Integration"" plugin needs a running instance of Hamster. ""Notification area"" plugin has only an optional dependence for systems
which supports indicators: 
python-appindicator
 ""Send task via email"" plugin does not have any external dependencies. ""Closed tasks remover"" plugin does not have any external dependencies. ""Tomboy/Gnote"" plugin needs a running instance of Tomboy or Gnote.
python-dbus ""Urgency Color"" plugin does not have any external dependencies.",3
https://github.com/ishitach/gtg,### Dependencies for Synchronization Services,"  Evolution synchronization service has dependencies: 
python-evolution
python-dateutil
 Because of a bug in PyGTK (see https://bugs.launchpad.net/gtg/+bug/936183),
the synchronization service freezes GTG and the synchronization service can't be used. MantisBT synchronization service has a dependency: 
python-suds
 Launchpad synchronization service has a dependency: 
python-launchpadlib
 Gnote and Tomboy synchronization services has no external dependency. Identica and Twitter synchronization services are shipped with the local
version of Tweety library. Remember the Milk synchronization service is shipped with a library for RTM api. It has an external dependency: 
python-dateutil
 Remember the Milk is not maintained for a long time and might be potentially harmful.",3
https://github.com/ishitach/gtg,## Installing and Running,"  To install GTG, either unpack the tarball: $ tar xzvf gtg.tar.gz
 or check out our bazaar branch for a development version (we try to keep those
unbroken and ready for production use): $ bzr branch lp:gtg
 To run GTG, either execute it directly from the source folder: $ cd gtg/
$ ./gtg
 or install it system-wide (must install as root to install system-wide): $ cd gtg
$ sudo python setup.py install # must be root to install system-wide
$ gtg
",3
https://github.com/ishitach/gtg,### How To Use GTG?,"  Please refer to our documentation to get a thorough explanation on how GTG
works. To do this, you will need the yelp help viewer. On Debian-based systems, you
can install yelp by executing this command: $ sudo apt-get install yelp
 You can then view the documentation either by accessing it through GTG (press
F1 or use the help menu), or by using the command line using the following
command: $ yelp help:gtg
 If you want to read the documentation directly from the source code, use
this command (from the source root dir): $ yelp docs/userdoc/C/index.page
",3
https://github.com/ishitach/gtg,### Using GTG from the command line,"  GTG provides two command line tools that allows to interact with GTG: 
gtcli
gtg_new_task
 gtcli provides many options to display, list or edit tasks. gtg_new_task
provides a GTG command line client that allows to easily add tasks. If you want to know more about how to use these tools, please refer to the
tools man page. If you have installed gtg, you can access those by executing: $ man gtcli
$ man gtg_new_task
",3
https://github.com/ishitach/gtg,## Want to know more?,"  
GTG Website: http://gtgnome.net/
GTG project page on Launchpad: https://launchpad.net/gtg
GTG Wiki: http://live.gnome.org/gtg/
GTG developer's documentation: http://gtg.readthedocs.org/en/latest/index.html
 Feel free to join our user mailing-list to receive news about GTG. You can
register on this mailing-list from this page: https://launchpad.net/~gtg-user Thanks for using GTG!",6
https://github.com/eyolfson/research-2016-ecoop-artifact,# ECOOP 2016 Artifact," Our tool adds a new sanitizer to clang, a const sanitizer. This sanitizer
verifies that instances of const are treated as transitively immutable. Our
tool will display a warning for any write through a const type qualifier,
even if a field is explictly const. The goal of our tool is to investigate
how developers use const in programs.",1
https://github.com/eyolfson/research-2016-ecoop-artifact,## Content,"  
Virtual Machine Package
Virtual Machine Package (VDI)
Included Modified LLVM Sources
Included Modified Clang Sources
Included Modified compiler-rt Sources
",1
https://github.com/eyolfson/research-2016-ecoop-artifact,## Virtual Machine,"  Note that these instructions assume the non-VDI image, running on QEMU. For
Windows users, download the VDI image and use VirtualBox. After the Virtual
Machine is running, the instructions are identical. There is an example
virtual machine already
setup. The username and password to this VM are both ecoop-2016. To run the
VM, with QEMU, do the following: qemu-system-x86_64 -enable-kvm -m 2048 -drive file=ecoop-2016.qcow2,format=qcow2
 The login information you'll always want to use is: Username: ecoop-2016
Password: ecoop-2016
 This VM should have all the requirements needed to run all of the experiments.
If you want to SSH into the VM from your host, use the following: qemu-system-x86_64 -enable-kvm -m 2048 -drive file=ecoop-2016.qcow2,format=qcow2 -net user,hostfwd=tcp::10022-:22 -net nic
 Then from your host machine do: ssh ecoop-2016@localhost -p10022
 Note that the VM needs to be connected to the internet in order for some
packages to build.",3
https://github.com/eyolfson/research-2016-ecoop-artifact,## Building (Optional),"  If you are using the VM image that we've distributed, the clang++ executable on
that VM points to a prebuilt version of our tool. However, we've included the
sources and you can build your own clang++ from scratch as follows. Ensure you have the base-devel group installed and the multilib repository
enabled. Afterwards you can build the package in the standard Arch Linux
fashion: cd ~/abs
makepkg -s
 After building the tool, you can use our set of 16 small test cases
you run to ensure the tool works correctly. Navigate to the test
directory to see these tests: cd ~/abs/src/llvm-csan-0.0.1/projects/compiler-rt/test/csan
 Note: if you haven't built the tool, this directory will not exist, do the
following first: cd ~/abs
makepkg -o
 The expected test results are embedded within the source files themselves. Any
lines with CHECK are expected to occur on stderr when the source file is
compiled and run with our tool enabled. Any lines beginning with CHECK-NOT
should not occur when our tool is used. To run all the tests do the following: cd ~/abs/src/llvm-csan-0.0.1/build
make check-csan
 Note 1: you must have built the tool in order to run make check-csan! Note 2: for the timing results in the paper, ran a debug version of the tool.
To build a debug version, follow these steps: cd ~/abs
makepkg -s -p PKGBUILD-debug
 Then replace the current version of our packages with these debugging ones with: pacman -U *.pkg.tar.xz
",3
https://github.com/eyolfson/research-2016-ecoop-artifact,### Manually Running Tests,"  Instead of automatically running the tests with make check-csan (and not getting much feedback,
due to the LLVM testing framework), you can also manually run the tests. You do need to
cd ~/abs; makepkg -o as described above, though. To manually run them yourself do the following: cd ~
clang++ -fsanitize=const -g ~/abs/src/llvm-csan-0.0.1/projects/compiler-rt/test/csan/const-object.cc -o const-object
./const-object
 You may explore all the other tests by exploring
~/abs/src/llvm-csan-0.0.1/projects/compiler-rt/test/csan and running them in
a similar manner.",3
https://github.com/eyolfson/research-2016-ecoop-artifact,## Usage,"  To use the tool, use clang++ as you normally would, but add the
flags -fsanitize=const -g. You should get more precise results if
you disable optimizations and include the frame pointer with -O0 -fno-omit-frame-pointer. To run the example given in Listing 1 of the
paper, do the following: cd ~/examples
clang++ -std=c++11 -fsanitize=const -g listing-1.cpp
 You can run the resulting executable as ./a.out and you should see a
warning. To write to an external log file, use the log_path option. For
example, to log the results to a file called listing-1.log do the following: CSAN_OPTIONS=log_path=listing-1.log ./a.out
 After running the program again, there should be no extra output on stderr
and there should be a listing-1.log.XXXXX file in the current directory where
XXXXX are random numbers. Feel free to try it out!",3
https://github.com/eyolfson/research-2016-ecoop-artifact,## Implementation,"  Note that to browse the implementation you have to have the sources extracted.
To extract the sources, do the following: cd ~/abs
makepkg -o
 The first part of the implementation is getting Clang to annotate definition
expressions of declaration statements so that ConstSanitizer can ignore them.
The code implementing this is in:
~/abs/src/llvm-csan-0.0.1/tools/clang/lib/CodeGen/CGDebugInfo.cpp and
~/abs/src/llvm-csan-0.0.1/tools/clang/lib/CodeGen/CGDebugInfo.h. The part
of the code generation we instrument is in
~/abs/src/llvm-csan-0.0.1/tools/clang/lib/CodeGen/CGDecl.cpp within the
EmitAutoVarDecl method. The heart of our implementation is located at:
~/abs/src/llvm-csan-0.0.1/lib/Transforms/Instrumentation/ConstSanitizer.cpp.
This file corresponds to the instrumentation of LLVM bit code that implements
our runtime const tracking. The computation of the shadow values is in the
getShadowVal method. The runtime library is located at:
~/abs/src/llvm-csan-0.0.1/projects/compiler-rt/lib/csan/csan.cc. This file
contains the implementation that reports the stack traces at runtime. The modification to get Clang to recongize our new sanitizer option is located
at: ~/abs/src/llvm-csan-0.0.1/tools/clang/lib/CodeGen/BackendUtil.cpp.",3
https://github.com/eyolfson/research-2016-ecoop-artifact,## Experiments,"  All experiments are located in the experiments directory. To instrument a
project, for example Ninja, do the following: cd ~/experiments
python build.py ninja
 The build script stores any build-time violations (for instance, that occur
while running a project's tests as part of the build) in the experiments
directory, in a file named PACKAGE-build.log. Ninja is an example of a project
that runs tests as part of its build. To create groupings for manual inspection, run python group.py ninja. The group.py script collects all results from log files with
the specified project name. The next subsections give examples of how we obtained the results in the paper.",3
https://github.com/eyolfson/research-2016-ecoop-artifact,### Protobuf,"  Similar to the Ninja example above, tests are run as part of the build process.
So you may do the following: cd ~/experiments
python build.py protobuf
python group.py protobuf-build
 These results should be comparable to ~/results/protobuf.txt after
organization. Note that running the tests produces many
protobuf-build.log.XXXXX files. While the group.py script does
combine all build log files, the resulting file still contains a
separate section for each build log file. We manually combined these
sections and report combined results from all build logs. Note that before manual post-processing we found 216 unique warnings with 169736
occurences. There was one archetype, relating to message targets, we could not
determine and did not include in the paper. This archetype had 133 unique
warnings with 14638 occurences and were manually identified. We also had a false
positive due to incorrect debugging information (we believe). This archetype had
7 unique locations with 27454 occurences. Manually removing these results should
exactly match the results in the paper.",3
https://github.com/eyolfson/research-2016-ecoop-artifact,### LevelDB,"  Similar to above, tests are run as part of the build process.",3
https://github.com/eyolfson/research-2016-ecoop-artifact,### Fish,"  We obtained the Fish results by running the shell, following these steps: cd ~/experiments
python build.py fish
CSAN_OPTIONS=log_path=fish.log fish/pkg/fish/usr/bin/fish
 Then press control-D to exit. Afterwards you can do the same as with Ninja: python group.py fish
 These results should correspond to the paper.",3
https://github.com/eyolfson/research-2016-ecoop-artifact,### Mosh,"  cd ~/experiments
python build.py mosh
CSAN_OPTIONS=log_path=mosh.log mosh/pkg/mosh/usr/bin/mosh --client=/home/ecoop-2016/experiments/mosh/pkg/mosh/usr/bin/mosh-client --server=/home/ecoop-2016/experiments/mosh/pkg/mosh/usr/bin/mosh-server localhost
 Answer yes to the certificate (if prompted) and login using the same information
used for the virtual machine (username ecoop-2016, password ecoop-2016). Again, similar to the last case, use the group script: python group.py mosh
 These results should correspond to the paper (there may be more unique locations
than in the paper).",3
https://github.com/eyolfson/research-2016-ecoop-artifact,### LLVM,"  Similar to Ninja, LLVM compiles llvm-tblgen and executes it as part of its
build process. Therefore after running the build script the results should be
accessible with: cd ~/experiments
python group.py llvm-build
",3
https://github.com/eyolfson/research-2016-ecoop-artifact,### Tesseract,"  Similar to Fish, we run the executable. You may need to also include
LD_LIBRARY_PATH like so: cd ~/experiments
python build.py tesseract
CSAN_OPTIONS=log_path=tesseract.log LD_LIBRARY_PATH=tesseract/pkg/tesseract/usr/lib tesseract/pkg/tesseract/usr/bin/tesseract stdin stdout
 You should get an error along the lines of ""error opening data file"", and
tesseract immediately exits. However, there will be some results, as before run: python group.py tesseract
",3
https://github.com/eyolfson/research-2016-ecoop-artifact,### Ninja,"  In this case, as part of the build process, the tests are run. Therefore the
ninja-build.log.XXXXX shows what violations occur as part of the test suite.
If you open this file and observe it, the first non-standard library portion of
the stack trace should be in src/disk_interface_test.cc:226:3 matching the
results of the paper. There should be 4 unique source locations, starting in
the standard library, for all violations. To find these unique source
locations, like for all other experiments, use the group script: cd ~/experiments
python group.py ninja-build
 This will group the raw results into unique locations and also give the
dynamic violation count.",3
https://github.com/eyolfson/research-2016-ecoop-artifact,### Wayland / Weston,"  First build Wayland and install the package: cd ~/experiments
python build.py wayland
sudo pacman -U wayland/wayland-1.9.0-1-x86_64.pkg.tar.xz
 Then you can build weston: python build.py weston
 Again, run the produced executable: CSAN_OPTIONS=log_path=weston.log weston/pkg/weston/usr/bin/weston
",3
https://github.com/eyolfson/research-2016-ecoop-artifact,## Timing,"  To collect the timing results, for example for Protobuf, do the following: cd ~/experiments
python time.py protobuf
 Note that you'll have to clear all the build files between each run. Do that
with the following command (you need to cd into the project directory first). cd ~/experiments/protobuf
rm -rf src pkg *.pkg.tar.xz
 The resulting files will be in /tmp/time-protobuf-build and
/tmp/time-protobuf-check. The last 3 lines of the first file indicate how
long it took to build with the tool enabled. The last 3 lines of the second
file indicate how long it took to run the tests with the tool enabled. After
recording these numbers you can do the same procedure with the tool disabled.
To collect the timing (after cleaning) results do: cd ~/experiments
python time-disable-csan.py protobuf
",3
https://github.com/eyolfson/research-2016-ecoop-artifact,## Results,"  Our results are in the results directory, organized by project name. These
files represent our findings organized by manually categorizing the violations
and putting them all under the same heading. The remaining results show the
number of violations at each source location. These violations are annotated
with source locations.",3
https://github.com/guoyu07/G-Library,# G\ Library,"G\ (spelled G Backslash) is an elegant micro-framework that helps you to quickly build PHP web applications like never before. It applies a very sleek, intuitive and extensible MVC structure for your PHP apps. It does routing, themes, database handling (PDO) and route hooking.

G\ is all about making common core task of any modern PHP application a no brainer and give you all the tools to help you in this. G\ is not about making the actual coding job for you so if you want a framework that creates the database tables for you, handle login, sign-ups, validate forms, etc. G\ is not for you, G\ is for developers who enjoy to code and those developers doesnt need that intrusive help.",12
https://github.com/guoyu07/G-Library,##Documentation,Documentation can be found at G\ documentation and is a work in progress so don't hesitate to ask if you don't understand something.,6
https://github.com/guoyu07/G-Library,##License,G\ is copyrighted by Rodolfo Berros and is released under the MIT License. You can use G\ freely in any project you want no strings attached.,5
https://github.com/guoyu07/G-Library,##Contribute,,7
https://github.com/guoyu07/G-Library,###Help and support,"G\ is a non-profit project backed by Chevereto and Junkstr (both companies of Rodolfo Berros) and we gratefully accept any kind of help that you may want to give me like reporting bugs, fix errors, talk about G\ with your friends, etc. G\ is about making PHP better and for that any help is appreciated.",6
https://github.com/guoyu07/G-Library,###Code,If you want to contribute to G\ feel free to use this very same repo.,7
https://github.com/gouldingm/swd-recorder,# SWD Page Recorder," SWD Page Recorder is a .NET application that makes it easy to create new Selenium Webdriver PageObject classes.
You can use it to test webdriver locators (html id, css selectors, xpath etc.) using Selenium Webdriver on various
browsers and using various modes (Internal Driver and Remote Hub connection). ",12
https://github.com/gouldingm/swd-recorder,"#### ?[SWD Starter C#](https://github.com/dzharii/SWD.Starter) -= SWD Page Recorder =- [SWD Starter Java](https://github.com/dzharii/Swd.StarterJ)  ?,6""",,
https://github.com/gouldingm/swd-recorder,#### :anchor: Articles in English:,"  
SWD Page Recorder ?records WebElements and generates PageObject classes (Announcement)
PageObject Generator Utility for Selenium WebDriver
",6
https://github.com/gouldingm/swd-recorder,#### :anchor: Articles in Russian:,"  
Материалы моего доклада (SWD Page Recorder) на #SeleniumCamp 2014 и ещё несколько фактов
SWD Page Recorder: Записывает PageObject-классы для Selenium WebDriver
SWD.Starter: Быстрый старт автоматизации тестирования UI на C# + Selenium WebDriver + PageObjects
",6
https://github.com/gouldingm/swd-recorder,#### :video_camera: Videos,"  
(English)SWD Page Recorder: Working with Frames and JavaScript popups
(Rus) SWD Page Recorder BETA1 ?записывает PageObject'ы на C#, Java, Ruby, Perl, Python!
За пределами PageObject
",6
https://github.com/gouldingm/swd-recorder,## Why SWD Page Recorder?,"  We both know: you awesome application is the best for solving the business problems in your domain. However, the developers may not have time for writing a comprehensive unit and integration testing suites?On the other hand, the QA Team may not trust the unit tests written by developers. There are so many reasons why the teams across the world choose the User Acceptance / User Interface testing approach. And you will realize that the code produced by such tools as Selenium IDE and Selenium Builder is good in the beginning? However, the test suites created with Record & Playback tools will require so much maintenance time, so you would put more effort on fixing the tests rather than running them. That is the hidden cost of the Record & Playback approach. At this point, you will discover many teams uses PageObjects in order to reduce the maintenance time and boosts the test case creation. Your will make the test code more stable and clean. The only one thing... You still need to spend a lot of time creating your PageObject classes manually. You should not. Let SWD Page Recorder do this for your. SWD Page Recorder enables you to pick the required elements from the Web application UI and generate the code for the new PageObject class. ",2
https://github.com/gouldingm/swd-recorder,## Contributors,"  
@sergueik
@dzharii
 ",7
https://github.com/cushon/retrolambda,# Retrolambda: Use Lambdas on Java 7,"  Just as there was Retroweaver et al. for running Java 5 code with
generics on Java 1.4, Retrolambda lets you run Java 8 code with lambda
expressions, method references and try-with-resources statements
on Java 7, 6 or 5. It does this by transforming your Java 8 compiled
bytecode so that it can run on an older Java runtime. After the
transformation they are just a bunch of normal .class files, without any
additional runtime dependencies.
Read more details. There is also limited support for backporting
default methods and static methods on interfaces. This feature is
disabled by default. Retrolambda supports backporting to Java 7, Java 6 and Java 5 runtimes. And
for adventurous developers there are other backporting
tools that may let
you go from Java 5 down to Java 1.4. Android developers may use Retrolambda to take advantage of the Java 8
features on Android. Serge Zaitsev has written an article about
it and there is a Gradle
plugin which makes it easy. Retrolambda does not backport the new Java 8 APIs, but there are other
projects that have backported some of them: 
streamsupport backports the java.util.stream API
ThreeTen backports the java.time API
",126
https://github.com/cushon/retrolambda,## User Guide,"  Retrolambda can be run as a Maven plugin,
Gradle plugin or
command line application. Also have a look at
some tips for using Retrolambda effectively.",36
https://github.com/cushon/retrolambda,### Maven Plugin,"  To run Retrolambda using Maven, add the following to your pom.xml: <plugin>
    <groupId>net.orfjackal.retrolambda</groupId>
    <artifactId>retrolambda-maven-plugin</artifactId>
    <version>2.1.0</version>
    <executions>
        <execution>
            <goals>
                <goal>process-main</goal>
                <goal>process-test</goal>
            </goals>
        </execution>
    </executions>
</plugin> See the plugin documentation
for all possible parameters. There is also a usage example in end-to-end-tests/pom.xml",36
https://github.com/cushon/retrolambda,### Gradle Plugin,  Gradle Retrolamba Plugin is developed by Evan Tatarka. See its site for usage instructions.,36
https://github.com/cushon/retrolambda,### Command Line Application,"  Download
the latest retrolambda.jar from Maven Central. Use JDK 8 to compile your source code. Run Retrolambda, using Java 8, on the class files produced by JDK 8. Run
java -jar retrolambda.jar without any additional options to see the
instructions (for your convenience they are also shown below). Your class files should now run on Java 7 or older. Usage: java -Dretrolambda.inputDir=? -Dretrolambda.classpath=? [-javaagent:retrolambda.jar] -jar retrolambda.jar

Retrolambda takes Java 8 classes and backports lambda expressions and
some other language features to work on Java 7, 6 or 5.
Web site: https://github.com/orfjackal/retrolambda

Copyright (c) 2013-2015  Esko Luontola <www.orfjackal.net>
This software is released under the Apache License 2.0.
The license text is at http://www.apache.org/licenses/LICENSE-2.0

Configurable system properties:

  retrolambda.bytecodeVersion
      Major version number for the generated bytecode. For a list, see
      offset 7 at http://en.wikipedia.org/wiki/Java_class_file#General_layout
      Default value is 51 (i.e. Java 7)

  retrolambda.defaultMethods
      Whether to backport default methods and static methods on interfaces.
      LIMITATIONS: All backported interfaces and all classes which implement
      them or call their static methods must be backported together,
      with one execution of Retrolambda.
      Disabled by default. Enable by setting to ""true""

  retrolambda.inputDir (required)
      Input directory from where the original class files are read.

  retrolambda.outputDir
      Output directory into where the generated class files are written.
      Defaults to same as retrolambda.inputDir

  retrolambda.classpath (required)
      Classpath containing the original class files and their dependencies.
      Uses ; or : as the path separator, see java.io.File#pathSeparatorChar

  retrolambda.classpathFile (alternative)
      File listing the classpath entries.
      Alternative to retrolambda.classpath for avoiding the command line
      length limit. The file must list one file per line with UTF-8 encoding.

  retrolambda.includedFiles
      List of files to process, instead of processing all files.
      This is useful for a build tool to support incremental compilation.
      Uses ; or : as the path separator, see java.io.File#pathSeparatorChar

  retrolambda.includedFilesFile (alternative)
      File listing the files to process, instead of processing all files.
      Alternative to retrolambda.includedFiles for avoiding the command line
      length limit. The file must list one file per line with UTF-8 encoding.

If the Java agent is used, then Retrolambda will use it to capture the
lambda classes generated by Java. Otherwise Retrolambda will hook into
Java's internal lambda dumping API, which is more susceptible to suddenly
stopping to work between Java releases.
",3
https://github.com/cushon/retrolambda,### Tips,"  Be sure to run comprehensive tests on your target JVM version (e.g. Java
7), in case the code accidentally uses Java 8 APIs or language features
that Retrolambda doesn't backport. During development, inside an IDE, it's the easiest to use Java 8, without
Retrolamba, to compile and run tests. But in your continuous integration
and release builds you should run all tests using the target Java version.
For example, you can configure Maven Surefire Plugin to run tests
using a different JVM. I recommend setting up environment variables JAVA8_HOME, JAVA7_HOME etc. and
referring to those variables in the build configuration, instead of relying on
what happens to be the default Java version in JAVA_HOME. You will need Java 8 for compiling and also for generating Javadocs.
JDK 7's Javadoc tool will fail for some valid Java 8 code.",3
https://github.com/cushon/retrolambda,## Backported Language Features,"  Lambda expressions are backported by converting them to anonymous inner
classes. This includes the optimization of using a singleton instance for
stateless lambda expressions to avoid repeated object allocation. Method references are basically just syntax sugar for lambda
expressions and they are backported in the same way. Try-with-resources statements are backported by removing calls to
Throwable.addSuppressed if the target bytecode version is below Java 7.
If you would like the suppressed exceptions to be logged instead of
swallowed, please create a feature request and we'll make it configurable. Optionally also: Default methods are backported by copying the default methods to a
companion class (interface name + ""$"") as static methods, replacing the
default methods in the interface with abstract methods, and by adding the
necessary method implementations to all classes which implement that
interface. Static methods on interfaces are backported by moving the static
methods to a companion class (interface name + ""$""), and by changing all
methods calls to call the new method location.[1] [1] The static methods are moved to a companion class even with
default method support disabled, because some of them may be lambda
implementation methods, but the method calls to static methods are not
updated. This may cause weird error messages if static methods on
interfaces are accidentally used without enabling default method support.",1
https://github.com/cushon/retrolambda,## Known Limitations,"  Does not backport Java 8 APIs. Backporting default methods and static methods on interfaces requires all
backported interfaces and all classes which implement them or call their
static methods to be backported together, with one execution of
Retrolambda. In other words, you must always do a clean build. Also,
backporting default methods won't work across module or dependency
boundaries. May break if a future JDK 8 build stops generating a new class for each
invokedynamic call. Retrolambda works so that it captures the bytecode
that java.lang.invoke.LambdaMetafactory generates dynamically, so
optimizations to that mechanism may break Retrolambda.",3
https://github.com/cushon/retrolambda,## Version History, ,4
https://github.com/cushon/retrolambda,### Retrolambda 2.1.0 (2015-12-19),"  
Added the -Dretrolambda.classpathFile parameter to avoid
the command line length limit
(Issue #70)
Added the -Dretrolambda.includedFilesFile parameter to avoid
the command line length limit
(Pull request #74)
Made it easier to invoke Retrolambda as a library. Made Config
an interface and fixed an assumption of using the default file system
(Pull request #71)
Don't create a companion class when an interface has just
a static initialization block because of constant fields
(Issue #66)
Improved error messages: report the name of the class or lambda method which
crashed Retrolambda
(Issue #69)
",4
https://github.com/cushon/retrolambda,### Retrolambda 2.0.6 (2015-09-06),"  
Fixed method references to constructors causing VerifyError on Android
(Issue #67)
",4
https://github.com/cushon/retrolambda,### Retrolambda 2.0.5 (2015-07-19),"  
Support for lambdas with marker interfaces
(Issue #62)
",4
https://github.com/cushon/retrolambda,### Retrolambda 2.0.4 (2015-07-08),"  
Fixed a compile error when calling default methods from another module
(Issue #56)
Fixed method references to constructors of the current class
(Issue #60)
Removes bytecode references to java.lang.invoke.MethodHandles.Lookup on
Java 6 and older
(Issue #61)
Copies non-class files from input to output directory
(Issue #54)
",4
https://github.com/cushon/retrolambda,### Retrolambda 2.0.3 (2015-06-07),"  
Fixed Retrolambda generating stack map frames for Java 5 bytecode,
causing some bytecode tools to fail
(Issue #55)
",4
https://github.com/cushon/retrolambda,### Retrolambda 2.0.2 (2015-04-14),"  
Fixed a hack which caused lambdas in interfaces to be backported twice,
possibly producing broken method calls in the bytecode
(Issue #48)
Fixed the handling of non-static lambda implementation methods in
interfaces, i.e. lambdas which capture this
(Issue #48)
Removes generic method signatures from the default method implementation
methods which are placed in the interface's companion class, to avoid
them getting out of sync with their erased method descriptors
(Issue #48)
",4
https://github.com/cushon/retrolambda,### Retrolambda 2.0.1 (2015-04-06),"  
Fixed not backporting lambda expressions in default methods and static
methods on interfaces
(Issue #48)
",4
https://github.com/cushon/retrolambda,### Retrolambda 2.0.0 (2015-03-28),"  
Backports default methods and static methods on interfaces
(Issue #31)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.8.1 (2015-01-06),"  
Backports lambda expressions in an interface's constant initializer
(Issue #42)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.8.0 (2014-11-16),"  
Backports try-with-resources statements to Java 6 and older by removing
calls to Throwable.addSuppressed
(Issue #38)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.7.0 (2014-10-21),"  
Support for serializable lambdas
(Issue #35)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.6.2 (2014-10-03),"  
Fixed a crash when trying to backport Android classes
(Issue #34)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.6.1 (2014-08-25),"  
Fixed a crash when trying backport classes which are nominally the same
as those included in the JRE, but which have different bytecode
(Issue #29)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.6.0 (2014-08-20),"  
Does not anymore require the use of a Java agent
(Issue #27)
Maven plugin: by default run Retrolambda in the same process as Maven,
making it a bit faster. If Maven is not running under Java 8, then will
fall back to forking the process and using the Java agent mechanism
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.5.0 (2014-07-19),"  
Maven plugin: use the JDK from Maven Toolchains
if available. The java8home configuration parameter overrides this
(Issue #24)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.4.0 (2014-07-04),"  
Added an optional -Dretrolambda.includedFiles parameter to support the
incremental compilers of build tools
(Issue #23)
Decides which lambda classes to save based on the current class being
processed, instead of the class loader that loaded the lambda class
(Issue #21)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.3.0 (2014-06-04),"  
Maven plugin: made the input and output directories configurable
(Issue #20)
Maven plugin: by default use the current JRE for running Retrolambda.
For the old behavior, add <java8home>${env.JAVA8_HOME}</java8home>
to the plugin configuration
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.2.3 (2014-05-19),"  
Android: Fixed NoSuchMethodError when calling a private method to which
there is a method reference
(Issue #18)
Fixed the possibility of accidentally overriding private methods to which
there is method reference
(Issue #19)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.2.2 (2014-05-15),"  
Fixed method references to private methods; will now make them
package-private the same way as lambda implementation methods
(Issue #17)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.2.1 (2014-05-04),"  
Fixed the Retrolambda Maven plugin not using the project's classpath
(Issue #16)
Maven plugin: save retrolambda.jar under target/retrolambda/
Suppress false warning about class initializer methods on interfaces
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.2.0 (2014-05-02),"  
Maven plugin for running Retrolambda
(thanks, Dave Moten)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.1.4 (2014-03-29),"  
Removes from interfaces bridge methods which were generated by JDK 8 e.g.
when an interface overrides a method and refines its return type
(Issue #13)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.1.3 (2014-03-25),"  
Fixed incompatibility with the Eclipse JDT compiler, version Kepler SR2
with the Java 8 support patch 1.0.0.v20140317-1959
(Issue #12)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.1.2 (2014-01-08),"  
Updated to work with JDK 8 Early Access Build b121 (2013-12-19)
(Issue #3)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.1.1 (2013-11-27),"  
Show help if the -javaagent parameter is missing
(Issue #2)
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.1.0 (2013-07-25),"  
Create only one instance of lambdas which do not capture arguments; i.e.
the same optimization as what JDK 8 does
Start the sequence number of lambda classes from one (e.g.
com.example.Foo$$Lambda$1) for each enclosing class
",4
https://github.com/cushon/retrolambda,### Retrolambda 1.0.0 (2013-07-23),"  
Backports lambda expressions and method references to Java 7 and older
Tested to work with JDK 8 Early Access Build b99 (2013-07-19)
",4
https://github.com/trZone/NPKC_17_Teensy3.2,# NPKC_17_Teensy3.2," NPKC 17 key numpad key tester driven by Teensy 3.2  NPKC_17_V3.ino This version has two ""layers."" How to change layers: Hold top left button (button 0 in the code), then press slash (button 1) Each layer has a different set of key codes which are sent to the arduino Keybaord library different ways FYI: This code is using analogWrite for the LEDS instead of digitalWrite to obtain brightness control, utilizing PWM pins Layer 0 NUMPAD keys:
This is useful for gaming because games can bind separate commands to numpad_1 and regular 1, for example 
ledPins[0] turns on
sends numpad codes, using Keyboard.set_key and Keyboard.send_now because Keyboard.press was not working
keyHolds array remembers what keys have been pressed /released so that every cycle can send the keys to obtain 6-key rollover
 Layer 1 REGULAR keys:
This is useful for using a number pad-like device on a laptop where you can't turn numlock on, as
numlock on a laptop messes up the letters or other keys 
ledPins[1] turns on
sends regular key codes, using Keyboard.press and Keyboard.release for arduino built-in 6-key rollover
 ",1
https://github.com/trZone/NPKC_17_Teensy3.2,##,,-
https://github.com/trZone/NPKC_17_Teensy3.2,##,,-
https://github.com/SerkanSipahi/jspm-cli,# jspm CLI,"      Registry and format agnostic JavaScript package manager. 
Supports installing any module format from any registry, with GitHub and npm currently provided, via the registry API.
Couples to the SystemJS module loader, which is built on the current draft of the browser ES6 module loader specification.
Carefully resolves version ranges using greedy fork minimization into flat multi-version package folders.
Provides tiered bundling of multi-format module trees using SystemJS builder.
Loads and builds assets through SystemJS plugins.
 See https://jspm.io for a project overview. For support, join the Gitter room or Google Group. Use jspm --help to see the full up-to-date list of commands. If you are interested in contributing to the project, please read the contributors' guide. For a list of community projects and tools, see the Third-Party Resources Wiki.",156
https://github.com/SerkanSipahi/jspm-cli,### Documentation,"  See the SystemJS project page for SystemJS usage documentation. 
Getting Started with jspm
Installing Packages
Plugins
Production Workflows
Publishing Packages
Registries
Linking
NodeJS Usage
The Registry Property
jspm API
Registry API
",6
https://github.com/SerkanSipahi/jspm-cli,### License,  Apache 2.0,5
https://github.com/TNAJanssen/DoctrineEncryptBundle,#DoctrineEncryptBundle," Bundle allows to create doctrine entities with fields that will be protected with
help of some encryption algorithm in database and it will be clearly for developer, because bundle is uses doctrine life cycle events This is an fork from the original bundle created by vmelnik-ukrain (Many thanks to him) which can be found here:
vmelnik-ukraine/DoctrineEncryptBundle I improved several things, i make better use of the doctrine events. and it works with lazy loading (relationships)!
This will be an long term project we will be working on with long-term support and backward compatibility. We are using this bundle in all our own symfony2 project.
More about us can be found on our website. Ambta.com",16
https://github.com/TNAJanssen/DoctrineEncryptBundle,###What does it do exactly,"  It gives you the opportunity to add the @Encrypted annotation above each string property /**
 * @Encrypted
 */
protected $username; The bundle uses doctrine his life cycle events to encrypt the data when inserted into the database and decrypt the data when loaded into your entity manager.
It is only able to encrypt string values at the moment, numbers and other fields will be added later on in development.",1
https://github.com/TNAJanssen/DoctrineEncryptBundle,###Advantages and disadvantaged of an encrypted database, ,2
https://github.com/TNAJanssen/DoctrineEncryptBundle,####Advantages,"  
Information is stored safely
Not worrying about saving backups at other locations
Unreadable for employees managing the database
",2
https://github.com/TNAJanssen/DoctrineEncryptBundle,####Disadvantages,"  
Can't use ORDER BY on encrypted data
In SELECT WHERE statements the where values also have to be encrypted
When you lose your key you lose your data (Make a backup of the key on a safe location)
",1
https://github.com/TNAJanssen/DoctrineEncryptBundle,###Documentation,"  This bundle is responsible for encryption/decryption of the data in your database.
All encryption/decryption work on the server side. The following documents are available: 
Installation
Configuration
Usage
Console commands
Custom encryption class
",6
https://github.com/TNAJanssen/DoctrineEncryptBundle,###License,  This bundle is under the MIT license. See the complete license in the bundle,5
https://github.com/TNAJanssen/DoctrineEncryptBundle,###Versions,  I'm using Semantic Versioning like described here,4
https://github.com/TNAJanssen/DoctrineEncryptBundle,###Todos,"  The following items will be done in order 
Review of complete code + fixes/improvements and inline documentation (2.1.1)
Add support for the other doctrine relationships (manyToMany, ManyToOne) (2.2)
Recreate documentation (2.3)
Create example code (2.3)
Create an function to encrypt unencrypted database and vice versa (console command, migration, changed key, etc.) (2.4)
Look for a posibility of automatic encryption of query parameters (2.5)
Look for a posibility to override findOneBy for automatic encryption of parameters (2.6)
Add support to encrypt data by reference to other property as key (Encrypt data specific to user with user key etc.) (2.7)
Add Format-preserving encryption for all data types Doctrine documentation Types (3.0)
",4
https://github.com/KeithLee208/hyperapp,# [hyperapp](https://hyperapp.gomix.me/),  HyperApp is a 1kb functional JavaScript library for building modern UI applications.,1
https://github.com/KeithLee208/hyperapp,## Install,"  npm i hyperapp
",3
https://github.com/KeithLee208/hyperapp,## Usage,"  CDN <script src=""https://cdn.rawgit.com/hyperapp/hyperapp/0.0.9/dist/app.min.js""></script>
<script src=""https://cdn.rawgit.com/hyperapp/hyperapp/0.0.9/dist/html.min.js""></script> Browserify browserify -g uglifyify index.js | uglifyjs > bundle.js
",3
https://github.com/KeithLee208/hyperapp,## Examples,"  
Hello world
app({
    model: ""Hi."",
    view: model => html`<h1>${model}</h1>`
})
View online
 
Counter
app({
    model: 0,
    update: {
        add: model => model + 1,
        sub: model => model - 1
    },
    view: (model, msg) => html`
        <div>
            <button onclick=${msg.add}>+</button>
            <h1>${model}</h1>
            <button onclick=${msg.sub} disabled=${model <= 0}>-</button>
        </div>`
})
View online
 
Input
app({
    model: """",
    update: {
        text: (_, value) => value
    },
    view: (model, msg) => html`
        <div>
            <h1>Hi${model ? "" "" + model : """"}.</h1>
            <input oninput=${e => msg.text(e.target.value)} />
        </div>`
})
View online
 
Drag & Drop
const model = {
    dragging: false,
    position: {
        x: 0, y: 0, offsetX: 0, offsetY: 0
    }
}

const view = (model, msg) => html`
    <div
        onmousedown=${e => msg.drag({
            position: {
                x: e.pageX, y: e.pageY, offsetX: e.offsetX, offsetY: e.offsetY
            }
        })}
        style=${{
            userSelect: ""none"",
            cursor: ""move"",
            position: ""absolute"",
            padding: ""10px"",
            left: `${model.position.x - model.position.offsetX}px`,
            top: `${model.position.y - model.position.offsetY}px`,
            backgroundColor: model.dragging ? ""gold"" : ""deepskyblue""
        }}
    >Drag Me!
    </div>`

const update = {
    drop: model => ({ dragging: false }),
    drag: (model, { position }) => ({ dragging: true, position }),
    move: (model, { x, y }) => model.dragging
        ? ({ position: { ...model.position, x, y } })
        : model
}

const subs = [
    (_, msg) => addEventListener(""mouseup"", msg.drop),
    (_, msg) => addEventListener(""mousemove"", e =>
        msg.move({ x: e.pageX, y: e.pageY }))
]

app({ model, view, update, subs })
View online
 
Todo
const FilterInfo = { All: 0, Todo: 1, Done: 2 }

const model = {
    todos: [],
    filter: FilterInfo.All,
    input: """",
    placeholder: ""Add new todo!""
}

const view = (model, msg) => {
    return html`
        <div>
            <h1>Todo</h1>
            <p>
                Show: ${
                Object.keys(FilterInfo)
                    .filter(key => FilterInfo[key] !== model.filter)
                    .map(key => html`
                        <span><a href=""#"" onclick=${_ => msg.filter({
                            value: FilterInfo[key]
                        })}>${key}</a> </span>
                    `)}
            </p>

            <p><ul>
                ${model.todos
                    .filter(t =>
                        model.filter === FilterInfo.Done
                            ? t.done :
                        model.filter === FilterInfo.Todo
                            ? !t.done :
                        model.filter === FilterInfo.All)
                    .map(t => html`
                        <li style=${{
                                color: t.done ? ""gray"" : ""black"",
                                textDecoration: t.done ? ""line-through"" : ""none""
                            }}
                            onclick=${e => msg.toggle({
                                value: t.done,
                                id: t.id
                            })}>${t.value}
                        </li>`)}
            </ul></p>

            <p>
                <input
                    type=""text""
                    onkeyup=${e => e.keyCode === 13 ? msg.add() : """"}
                    oninput=${e => msg.input({ value: e.target.value })}
                    value=${model.input}
                    placeholder=${model.placeholder}
                />
                <button onclick=${msg.add}>add</button>
            </p>
        </div>`
}

const update = {
    add: model => ({
        input: """",
        todos: model.todos.concat({
            done: false,
            value: model.input,
            id: model.todos.length + 1
        })
    }),
    toggle: (model, { id, value }) => ({
        todos: model.todos.map(t =>
            id === t.id
                ? Object.assign({}, t, { done: !value })
                : t)
    }),
    input: (model, { value }) => ({ input: value }),
    filter: (model, { value }) => ({ filter: value })
}

app({ model, view, update })
View online
 See more examples",3
https://github.com/KeithLee208/hyperapp,## Documentation,"  
html
app

model
update
view
effects
subs
hooks

onAction
onUpdate
onError


root


Routing

setLocation
href


",6
https://github.com/KeithLee208/hyperapp,## html,"  Use html to compose HTML elements. const hello = html`<h1>Hello World!</h1>` html is a tagged template string. If you are familiar with React, this is like JSX, but without breaking JavaScript.",3
https://github.com/KeithLee208/hyperapp,## app,"  Use app to bootstrap your app. app({
    model, update, view, subs, effects, hooks, root
}) All properties are optional.",3
https://github.com/KeithLee208/hyperapp,### model,"  A value or object that represents the entire state of your app. To update the model, you send actions describing how the model should change. See view.",36
https://github.com/KeithLee208/hyperapp,### update,"  An object composed of functions known as reducers. These are a kind of action you send to update the model. A reducer describes how the model should change by returning a new model or part of a model. const update = {
    increment: model => model + 1,
    decrement: model => model - 1
} If a reducer returns part of a model, that part will be merged with the current model. You call reducers inside a view, effect or subscription. Reducers have a signature (model, data), where 
model is the current model, and
data is the data sent along with the action.
",3
https://github.com/KeithLee208/hyperapp,### view,"  The view is a function that returns HTML using the html function. The view has a signature (model, msg, params), where 
model is the current model,
msg is an object you use to send actions (call reducers or cause effects) and
params are the route parameters.
 Use msg to send actions. msg.action(data) where data is any data you want to pass to the reducer / effect. 
Example
app({
    model: true,
    view: (model, msg) => html`<button onclick=${msg.toggle}>${model+""""}</button>`,
    update: {
        toggle: model => !model
    }
})
View online
 The view object may accommodate multiple views too. See routing. 
Example
app({
    view: {
        ""/"": _ => html`<h1>Home</h1>`,
        ""/about"": _ => html`<h1>About</h1>`
    }
})
View online
",36
https://github.com/KeithLee208/hyperapp,### effects,"  Effects cause side effects and are often asynchronous, like writing to a database, or sending requests to servers. They can dispatch other actions too. Effects have a signature (model, msg, error), where 
model is the current model,
msg is an object you use to call reducers / cause effects (see view), and
error is a function you may call with an error if something goes wrong.
 
Example
const wait = time => new Promise(resolve => setTimeout(_ => resolve(), time))

const model = {
    counter: 0,
    waiting: false
}

const view = (model, msg) =>
    html`
        <button
            onclick=${msg.waitThenAdd}
            disabled=${model.waiting}>${model.counter}
        </button>`


const update = {
    add: model => ({ counter: model.counter + 1 }),
    toggle: model => ({ waiting: !model.waiting})
}

const effects = {
    waitThenAdd: (model, msg) => {
        msg.toggle()
        wait(1000).then(msg.add).then(msg.toggle)
    }
}

app({ model, view, update, effects })
View online
",3
https://github.com/KeithLee208/hyperapp,### subs,"  Subscriptions are functions that run once when the DOM is ready. Use a subscription to register global events, like mouse or keyboard listeners. While reducers and effects are actions you cause, you can't call subscriptions directly. A subscription has a signature (model, msg, error). 
Example
app({
    model: { x: 0, y: 0 },
    update: {
        move: (_, { x, y }) => ({ x, y })
    },
    view: model => html`<h1>${model.x}, ${model.y}</h1>`,
    subs: [
        (_, msg) => addEventListener(""mousemove"", e => msg.move({ x: e.clientX, y: e.clientY }))
    ]
})
View online
",3
https://github.com/KeithLee208/hyperapp,### hooks,"  Hooks are functions called for certain events during the lifetime of the app. You can use hooks to implement middleware, loggers, etc. 
Example
app({
    model: true,
    view: (model, msg) => html`
        <div>
            <button onclick=${msg.doSomething}>Log</button>
            <button onclick=${msg.boom}>Error</button>
        </div>`,
    update: {
        doSomething: model => !model,
    },
    effects: {
        boom: (model, msg, data, err) => setTimeout(_ => err(Error(""BOOM"")), 1000)
    },
    hooks: {
        onError: e =>
            console.log(""[Error] %c%s"", ""color: red"", e),
        onAction: name =>
            console.log(""[Action] %c%s"", ""color: blue"", name),
        onUpdate: (last, model) =>
            console.log(""[Update] %c%s -> %c%s"", ""color: gray"", last, ""color: blue"", model)
    }
})
View online
",3
https://github.com/KeithLee208/hyperapp,#### onUpdate,"  Called when the model changes. Signature (lastModel, newModel, data).",3
https://github.com/KeithLee208/hyperapp,#### onAction,"  Called when an action (reducer or effect) is dispatched. Signature (name, data).",3
https://github.com/KeithLee208/hyperapp,#### onError,"  Called when you use the error function inside a subscription or effect. If you don't use this hook, the default behavior is to throw. Signature (err).",3
https://github.com/KeithLee208/hyperapp,### root,"  The root is the HTML element that will serve as a container for your app. If none is given, a div element is appended to the document.body.",3
https://github.com/KeithLee208/hyperapp,## Routing,"  Instead of a view as a single function, declare an object with multiple views and use the route path as the key. app({
    view: {
        ""*"": (model, msg) => {},
        ""/"": (model, msg) => {},
        ""/:slug"": (model, msg, params) => {}
    }
}) 

/ index route, also used when no other route matches


/:a/:b/:c matches a route with three components using the regular expression [A-Za-z0-9]+ and stores each captured group in the params object, which is passed into the view function.

 The route path syntax is based in the same syntax found in Express. 
Example
const { app, html } = require(""hyperapp"")
const anchor = n => html`<h1><a href=${""/"" + n}>${n}</a></h1>`

app({
    view: {
        ""/"": _ => anchor(Math.floor(Math.random() * 999)),
        ""/:key"": (model, msg, { key }) => html`
            <div>
                <h1>${key}</h1>
                <a href=""/"">Back</a>
            </div>`
    }
})
View online
",3
https://github.com/KeithLee208/hyperapp,### setLocation,"  To update the address bar relative location and render a different view, use msg.setLocation(path). 
Example
app({
    view: {
      ""/"": (model, msg) => html`
        <div>
          <h1>Home</h1>
          <button onclick=${_ => msg.setLocation(""/about"")}>About</button>
        </div>`,
      ""/about"": (model, msg) => html`
        <div>
          <h1>About</h1>
          <button onclick=${_ => msg.setLocation(""/"")}>Home</button>
        </div>`
    }
})
View online
",3
https://github.com/KeithLee208/hyperapp,### href,"  As a bonus, we intercept all <a href=""/path"">...</a> clicks and call msg.setLocation(""/path"") for you. If you want to opt out of this, add the custom attribute data-no-routing to any anchor element that should be handled differently. <a data-no-routing>...</a> 
Example
app({
    view: {
      ""/"": (model, msg) => html`
        <div>
          <h1>Home</h1>
          <a href=""/about"">About</a>
        </div>`,
      ""/about"": (model, msg) => html`
        <div>
          <h1>About</h1>
          <a href=""/"">Home</a>
        </div>`
    }
})
View online
",3
https://github.com/isoscl/seadroid,# Seafile Android Client [![Build Status](https://secure.travis-ci.org/haiwen/seadroid.png?branch=master)](http://travis-ci.org/haiwen/seadroid)," The application has been published onto the market for easy access: 
",1
https://github.com/isoscl/seadroid,## Contributors,  See Contributors Graph,5
https://github.com/isoscl/seadroid,## Build the APK,"  

Make sure you have installed the Android SDK then:


cd into seadroid directory


Create key.properties file or simply rename key.properties.example and change configurations to match yours.


Create keystore file if you don't have one

 keytool -genkey -v -keystore app/debug.keystore -alias AndroidDebugKey -keyalg RSA -keysize 2048 -validity 1 -storepass android -keypass android -dname ""cn=TEST, ou=TEST, o=TEST, c=TE""
 
Build with ./gradlew assembleRelease
 You will get app/build/outputs/apk/seafile-${versionName}.apk after the build finishes.",3
https://github.com/isoscl/seadroid,## Develop in Android Studio, ,3
https://github.com/isoscl/seadroid,### Prerequisites,"  
Android Studio
OpenJDK 7 / OracleJDK 7
",3
https://github.com/isoscl/seadroid,### Import project,"  
Open Android Studio
Import project
Select seadroid directory
Choose import from gradle
Click next until import is completed
",3
https://github.com/isoscl/seadroid,## Develop in IntelliJ/Eclipse,"  For those who are using maven build structures, checkout the project from maven branch.",3
https://github.com/isoscl/seadroid,## Internationalization, ,6
https://github.com/isoscl/seadroid,### Contribute your translation,"  Please submit translations via Transifex: https://www.transifex.com/haiwen/seadroid/ Steps: 
Create a free account on Transifex (https://www.transifex.com/).
Send a request to join the language translation.
After accepted by the project maintainer, then you can upload your file or translate online.
",7
https://github.com/shohag121/wp-github-updater,# wp-github-updater,  Wordpress plugin that enables automatic updates of plugins and themes from github,1
https://github.com/shohag121/wp-github-updater,## Installation,"  Download latest zip archive and decompress into your wordpress plugins folder, then activate.",3
https://github.com/shohag121/wp-github-updater,## Usage,"  
Host your plugin or theme on github
Make sure your plugin php file or your theme style.css file has its Plugin URI or Theme URI entry set to a github repository url (e.g. https://github.com/me/my-wp-plugin-or-theme)
Tag the plugin or theme versions you want to be proposed as updates, ONLY use version numbers as tags (e.g. 1.2.0), an update will show if this version is higher than the one currently instaled (as set in current Version tag in plugin php or theme style.css file)
Make releases from your tags (if done manually, you have to add release notes to your tag on github so it becomes a release)
If needed you can add a github release asset to your release, it will be installed instead of your plugin or theme source code (e.g. your repository has install tasks, dependencies that have to be built by a CI system or manually)
",3
https://github.com/shohag121/wp-github-updater,### For plugins,"  Add the following code to your plugin main php file (this example is for use with a plugin class, adapt for another structure): ...

class myplugin {

...

function __construct() {

...
    add_action( 'admin_init', array( $this, 'handle_github_update' ) );
...

}

...

	/**
	 * Handles github plugin update by using
	 * github updater class from wp-github-updater plugin.
	 */
	function handle_github_update() {
		if ( class_exists( 'GitHubUpdater' ) ) {
		  new GitHubUpdater( 'plugin', __FILE__ );
		}
	}
	
...

}
",3
https://github.com/shohag121/wp-github-updater,### For themes,"  Add the following code to your theme functions php file (make sure the second argument to GitHubUpdater class instantiation points to your theme root, e.g. _DIR_ if your functions.php file is in the root of your theme, adapt if not): ...

add_action( 'admin_init', 'myprefix_handle_github_update' );

...

if ( ! function_exists( 'myprefix_handle_github_update' ) ) {
	/**
	 * Handles github theme update by using
	 * github updater class from wp-github-updater plugin.
	 */
	function myprefix_handle_github_update() {
		if ( class_exists( 'GitHubUpdater' ) ) {
		  new GitHubUpdater( 'theme', __DIR__ );
		}
	}
}
 That's all folks!",3
https://github.com/AlexandreHonorato/wildfly,# WildFly Application Server," http://wildfly.org 
Fast Startup
Small Footprint
Modular Design
Unified Configuration and Management
 And of course Java EE!",12
https://github.com/AlexandreHonorato/wildfly,## Building,"  Ensure you have JDK 8 (or newer) installed 
java -version
 On *nix-like system use the prepared script 
./build.sh
 On Windows use the corresponding batch script 
build.bat
 If you already have Maven 3.2.5 (or newer) installed you can use it directly 
mvn install
",3
https://github.com/AlexandreHonorato/wildfly,## Starting and Stopping WildFly,"  Change to the bin directory after a successful build 
$ cd build/target/wildfly-[version]/bin
 Start the server in domain mode 
$ ./domain.sh
 Start the server in standalone mode 
$ ./standalone.sh
 To stop the server, press Ctrl + C, or use the admin console 
$ ./jboss-cli.sh --connect command=:shutdown
 More information: https://docs.jboss.org/author/display/WFLY10/Getting+Started+Guide",36
https://github.com/AlexandreHonorato/wildfly,## Contributing,  https://developer.jboss.org/wiki/HackingOnWildFly,7
https://github.com/AlexandreHonorato/wildfly,## Running the Testsuite,"  The testsuite module contains several submodules including the following: 
""smoke"" -- core tests that should be run as part of every build of the AS. Failures here will fail the build.
""api"" -- tests of features that involve end user use of the public JBoss AS 8 API. Should be run with no failures before any major commits.
""cluster"" -- tests of the WildFly HA clustering features. Should be run with no failures before any major commits.
""domain"" -- tests of the domain management features. Should be run with no failures before any major commits.
""integration"" -- tests of a WildFly standalone server's internals. Should be run with no failures before any major commits.
""spec"" -- tests of features that only involve end user use of the Java EE 7 spec APIs. Should be run with no failures before any major commits.
 To run the basic testsuite including smoke tests from the root directory, run the build script ""./build.sh"" or ""build.bat"": For basic smoke tests, simply: ""./build.sh test"" To run all the tests 
$ ./build.sh install -DallTests
",3
https://github.com/AlexandreHonorato/wildfly,## Using Eclipse,"  
Install the latest version of eclipse
Make sure Xmx in eclipse.ini is at least 1280M, and it's using Java 8
Launch eclipse and install the m2e plugin, make sure it uses your repo configs
(get it from: http://www.eclipse.org/m2e/
or install ""Maven Integration for Eclipse"" from the Eclipse Marketplace)
In eclipse preferences Java->Compiler->Errors/Warnings->Deprecated and restricted
set forbidden reference to WARNING
In eclipse preferences Java->Code Style, import the cleanup, templates, and
formatter configs in ide-configs/eclipse in the wildfly-core repository.
In eclipse preferences Java->Editor->Save Actions enable ""Additional Actions"",
and deselect all actions except for ""Remove trailing whitespace""
Use import on the root pom, which will pull in all modules
Wait (m2e takes a while on initial import)
",3
https://github.com/AlexandreHonorato/wildfly,## License,"  
GNU Lesser General Public License Version 2.1
",5
https://github.com/c-jheengut/kdev-kernel,# KDevelop Linux Kernel Development Plugin," This plugin offers a ""Linux Kernel"" project type to KDevelop that makes it easy and comfortable to work on the Linux kernel. The raw KDevelop comes with extremely useful cross-reference and code parsing tools, but they do not apply well to the Linux kernel. Problems are: 
The kernel source is huge, and parsing all the source code of all drivers is long and unpractical.
Some implicitly declared macros (like __KERNEL__) are needed for the code to be parsed correctly. Without them lots of functions and data structures will appear as undeclared.
A lot of the code (power management, SMP, etc) is conditionally compiled depending on the kernel configuration which is translated into more C defines. These defines are not seen by KDevelop and a huge part of relevant code is thus not parsed.
All the same, architecture-dependant code cannot be parsed without a proper configuration
",12
https://github.com/c-jheengut/kdev-kernel,## Features,"  
Parses your kernel configuration file to define the right macros and only show the source code that is actually compiled by your configuration.
Limits the parser to the kernel files and drivers that are appropriate for your configuration
",1
https://github.com/c-jheengut/kdev-kernel,## Installing,"  This plugin requires KDevelop 4.7. Just typing cmake . && make && sudo make install should be enough to have the project installed. Then in KDevelop, do ""Project -> Open/Import Project..."" and select the root Makefile of your Linux kernel. When prompted for the type of the project, choose ""Linux Kernel"". Then open the project's configuration and in the ""Linux Kernel"" pane select your kernel configuration file. You will then need to restart KDevelop so the right kernel files are parsed with the right defines.",3
https://github.com/c-jheengut/kdev-kernel,## Limitations,"  
KDevelop's parser is C++-oriented and does not support some of the C features used in the kernel like designated initializers. This needs to be fixed upstream.
",4
https://github.com/c-jheengut/kdev-kernel,## Contribute & Feedback,"  This plugin is written by Alexandre Courbot and is released under the GPLv3. You can report issues, suggest features or contribute fixes on its Github page: https://github.com/Gnurou/kdev-kernel Happy Comfortable Hacking! :)",567
https://github.com/uhlume/neveragaindottech.github.io,# neveragain.tech," The response to this pledge has been much larger than we expected;
thank you for your support and participation! We do our best to verify every signature that appears on the website.
It requires a great deal of human effort to verify thousands of signatures,
so we stopped accepting new signatures for manual verification
at noon PST Dec 21, after accepting signatures for 8 days.
We are still processing a large backlog of submitted signatures,
so the number of signatures on the website will continue to increase,
but we are no longer accepting new signatures. Even though we are no longer accepting new signatures to show on the website,
you can still sign the pledge in many ways.
Remember, the pledge is a personal, individual commitment;
announcing your commitment is an invitation to others
to help you hold yourself accountable.
Here are some ways to do that: 
Tweet ""I, <your name>, hereby commit to the neveragain.tech pledge. Please stand with me and hold me to it. #neveragaintech""
Post ""I, <your name>, hereby commit to the neveragain.tech pledge. Please stand with me and hold me to it."" on your personal website or blog, with a link to http://neveragain.tech/.
Print out the pledge and sign it on paper.  Post it in a visible location to show solidarity and gather signatures from your teammates.  Host a signing party at your workplace.
 We are heartened and grateful for your enthusiasm and support.  If you are passionate about this issue, please get involved!  There is plenty more to be done.",16
https://github.com/weimingtom/PySLGalMaker,# PySLGalMaker,,-
https://github.com/weimingtom/PySLGalMaker,## License,,-
https://github.com/ghamry/jquery.hotkeys,# jQuery.Hotkeys [![Build Status](https://secure.travis-ci.org/jeresig/jquery.hotkeys.png)](http://travis-ci.org/jeresig/jquery.hotkeys),,1
https://github.com/ghamry/jquery.hotkeys,#About," jQuery Hotkeys is a plug-in that lets you easily add and remove handlers for keyboard events anywhere in your code supporting almost any key combination.

This plugin is based off of the plugin by Tzury Bar Yochay: jQuery.hotkeys

The syntax is as follows:

$(expression).bind(types, keys, handler);
$(expression).unbind(types, handler);

$(document).bind('keydown', 'ctrl+a', fn);

// e.g. replace '$' sign with 'EUR'
$('input.foo').bind('keyup', '$', function(){
  this.value = this.value.replace('$', 'EUR');
});
Syntax when wanting to use jQuery's on()/off methods:

$(expression).on(types, null, keys, handler);
$(expression).off(types, handler);

$(document).on('keydown', null, 'ctrl+a', fn);

// e.g. replace '$' sign with 'EUR'
$('input.foo').on('keyup', null, '$', function(){
  this.value = this.value.replace('$', 'EUR');
});     ",13
https://github.com/ghamry/jquery.hotkeys,## Example,  Example,3
https://github.com/ghamry/jquery.hotkeys,## Event Types,"  Supported types are 'keydown', 'keyup' and 'keypress'",3
https://github.com/ghamry/jquery.hotkeys,## jQuery Compatibility,"  Works with jQuery 1.4.2 and newer. It is known to be working with all the major browsers on all available platforms (Win/Mac/Linux) 
IE 6/7/8+
FF 1.5/2/3+
Opera-9+
Safari-3+
Chrome-0.2+
",3
https://github.com/ghamry/jquery.hotkeys,## Browserify Compatibility,"  If you want to include this module in a Browserified project, just add it to node_modules and require it. require('jquery.javascript'); This will work if jQuery is global (ex. served from a CDN). If it's not, you need to shim it: {
  ""browserify-shim"": {
    ""jquery"": ""global:jQuery""
  }
}",3
https://github.com/ghamry/jquery.hotkeys,## Notes,  Modifiers are not case sensitive (Ctrl == ctrl == cTRL) If you want to use more than one modifier (e.g. alt+ctrl+z) you should define them by an alphabetical order e.g. alt+ctrl+shift Hotkeys aren't tracked if you're inside of an input element (unless you explicitly bind the hotkey directly to the input). This helps to avoid conflict with normal user typing. You can use namespacing by adding a suffix to the event type (e.g. keyup.toggle),3
https://github.com/ghamry/jquery.hotkeys,## Hotkeys within inputs,"  Hotkeys aren't tracked if the user is focused within an input element or any element that has contenteditable=""true"" unless you bind the hotkey directly to the element. This helps to avoid conflict with normal user typing.
If you don't want this, you can change the booleans of the following to suit: 
jQuery.hotkeys.options.filterInputAcceptingElements
jQuery.hotkeys.options.filterContentEditable
jQuery.hotkeys.options.filterTextInputs (deprecated, will be removed in a later version)
",3
https://github.com/ghamry/jquery.hotkeys,### Meta and Hyper Keys,  Meta and hyper keys don't register on keyup in any browser tested.,3
https://github.com/ghamry/jquery.hotkeys,#### Chrome 33.0.1750.117,"  Meta key registers on keydown event.
Hyper key registers on keydown event.",3
https://github.com/ghamry/jquery.hotkeys,#### Firefox 27.0.1 and Safari 7.0.1,"  Meta key registers on keydown and keypress events.
Hyper key registers on keydown and keypress events.",3
https://github.com/ghamry/jquery.hotkeys,#### Opera 19.0,"  Meta key doesn't register at all :(
Hyper key registers on keydown and keypress events.",3
https://github.com/ghamry/jquery.hotkeys,#### TL;DR,"  Bind to keydown event for meta and hyper keys, but meta key does not work in Opera ;)",3
https://github.com/ghamry/jquery.hotkeys,### Addendum,"  Firefox is the most liberal one in the manner of letting you capture all short-cuts even those that are built-in in the browser such as Ctrl-t for new tab, or Ctrl-a for selecting all text. You can always bubble them up to the browser by returning true in your handler. Others, (IE) either let you handle built-in short-cuts, but will add their functionality after your code has executed. Or (Opera/Safari) will not pass those events to the DOM at all. So, if you bind Ctrl-Q or Alt-F4 and your Safari/Opera window is closed don't be surprised.",3
https://github.com/plirof/pluck,# pluck,,1
https://github.com/plirof/pluck,## pluck · about pluck,"  Pluck is a small and simple content management system (CMS), written in PHP. With Pluck, you can easily manage your own website. Pluck focuses on simplicity and ease of use. This makes Pluck an excellent choice for every small website. Licensed under the General Public License (GPL), Pluck is completely open source. This allows you to do with the software whatever you want, as long as the software stays open source.",125
https://github.com/plirof/pluck,## Features,"  Pluck is packed with some nice features, from which we've listed the most important ones on this page. To try everything live, take a look at our demo http://pluck-cms.org/?file=demo 
create an unlimited amount of pages
create your own blog
create an album to show images or photos to your visitors
include a contact form in your page(s)
",13
https://github.com/plirof/pluck,## For web designers and developers,"  Pluck has also been developed with web designers and developers in mind. Just a few advantages: 
Your clients will love the easy-to-use interface. No more need to spend hours teaching them how to manage their website!
The simple yet powerful theming system allows you to integrate your HTML-layouts with pluck in a matter of minutes.
The flexible module system enables you to integrate your own functionality with ease.
",2
https://github.com/plirof/pluck,## Want to Help?, ,6
https://github.com/plirof/pluck,### Everybody,"  
Use Pluck
Write blog post
Follow the @PluckCMSTeam on Twitter
",5
https://github.com/plirof/pluck,### Developers - Here are some hints for getting started:,"  
Read Pluck Wiki Page
Check out the Issues list (or add your own issues and ideas)
Beginners Guide to Contributing to a GitHUB Project
",7
https://github.com/alg/carrierwave-base64-storage,# Carrierwave Base64 Storage," This is the storage for Carrierwave that serializes the file and saves it into
the field the uploader was mounted on.",1
https://github.com/alg/carrierwave-base64-storage,## Installation,"  gem 'carrierwave-base64-storage'
",3
https://github.com/alg/carrierwave-base64-storage,## Usage,"  In your uploader specify the storage: class AvatarUploader < CarrierWave::Uploader::Base
  storage :base64
end
 IMPORTANT: When you mount the uploader on a field, it uses field_data attribute
on the model to store the actual data, and so make sure the field exists
in your model and is able to fit long text blobs (TEXT in SQL). Example for the ActiveRecord: class User < ActiveRecord::Base
  mount_uploader :avatar, AvatarUploader
end
 (It will be using avatar_data for the actual data and the content type.)",3
https://github.com/alg/carrierwave-base64-storage,## License,"  Copyright (c) 2008-2012 Aleksey Gureiev Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the
""Software""), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions: The above copyright notice and this permission notice shall be included
in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS
OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",5
https://github.com/IL2liu/msu_ngs2015,# DE analysis of RNA-seq data," For RNA-seq data, the strategy taken is to count the number of reads that fall into annotated genes and to perform statistical analysis on the table of counts to discover quantitative changes in expression levels between experimental groups. Easy, right? Not, exactly. 

We have integer counts and not continous measurements. Data is not normally distributed, so statistical methods we applied to microarray data don't work here.


Replication levels in designed RNA-Seq experiments tend to be modest, often not much more than two or three. As a result, there is a need for statistical methods that perform well in small-sample situations.


There is a dependence of variance on the mean (which changes with increasing number of replicates)

 Solution: Appropriate modelling of the mean-variance relationship in DGE data is important for making inferences about differential expression. Employing methods which assess the mean-variance relationship to help with the problem of estimating biological variability for experiments with small number of replicates. In this module, learners will use R Statistical Software to walk-through activities designed to compare the performance of different tools (edgeR, DESeq2, limma-voom) for differential expression analysis of RNA-Seq data, and how the mean-variance relationship is addressed in datasets with increasing number of replicates. 
Learning Objectives

understanding the relationship between mean and variance and how that changes with the number of replicates
familiarizing yourself with tools for DE analysis in R
understanding the importance of having replicates in a RNA-Seq study

",12
https://github.com/Exia101/dev1-mini-project,# Web Technology Mini-Project,,1
https://github.com/Exia101/dev1-mini-project,##  Javascript Web Development Course,"  Your task is to create your own simple one-page portfolio website using the technologies we have learnt so far. It must be: 
Planned and wireframed - Starting from what content you want on the page, and through a series of wireframes increasing in fidelity.
Built with HTML and CSS - These are the only required technologies for the project. Javascript or jQuery can only be added ONCE THE STATIC VERSION IS COMPLETELY FINISHED (cough Jay).
Compliant with WAI-ARIA standards - Your site must be fully accessible. Use the WAVE toolbar to check this, don't forget to add ARIA roles.
Semantically correct - You must use the correct semantic tags for your particular layout.
Responsive - It must be designed mobile first, and made responsive using carefully selected CSS attributes and media queries.
Visually distinctive - You should select a colour scheme and layout that you like, simple is best! The aim should be to create a professional, slick feel.
Version controlled using git - You must use git to track your project, and it must be submitted to the Github repository I have created in a folder called your Github username. You must make at least 15 git commits! There is a prize for whoever makes the most commits.
 Help each other, google around, and use this as an opportunity to get comfortable with the concepts we have learnt this week. That's more important than the outcome of the project. It's due on Tuesday morning at 9.30am! It must be on github by that time.",1
https://github.com/joshswan/gulp-merge-json,# gulp-merge-json,      A gulp plugin for deep-merging multiple JSON files into one file. Export as JSON or a node module.,1
https://github.com/joshswan/gulp-merge-json,## Usage,"  gulp.src('jsonFiles/**/*.json')
	.pipe(merge(options))
	.pipe(gulp.dest('./dist'));",3
https://github.com/joshswan/gulp-merge-json,### Options,"  


Key
Type
Default
Description




fileName
String
combined.json
Output filename


edit
Function
json => json
Edit function (add/remove/edit keys during merge)


transform
Function
json => json
Transform final merged object (similar to edit but applied at the end)


startObj
Object/Array
{}
Starting object to merge into (useful for providing default values)


endObj
Object/Array

Object to merge after file merging complete (useful for overwriting with special values)


exportModule
Boolean/String
false
Output module.exports = {MERGED_JSON_DATA}; or {exportModule} = {MERGED_JSON_DATA} when string passed


concatArrays
Boolean
false
Whether to concatenate arrays instead of merging


mergeArrays
Boolean
true
Whether to merge arrays or overwrite completely


customizer
Function

Custom merge function for use with mergeWith


jsonReplacer
Function

Custom JSON replacer function passed to stringify


jsonSpace
String
\t
String used for white space by stringify


json5
Boolean
false
Use JSON5 instead of JSON for parse and stringify


",3
https://github.com/joshswan/gulp-merge-json,## Examples,"  var merge = require('gulp-merge-json');

/**
 * Basic functionality
 */
gulp.src('jsonFiles/**/*.json')
	.pipe(merge())
	.pipe(gulp.dest('./dist'));

/**
 * Edit JSON with function
 */
gulp.src('jsonFiles/**/*.json')
	.pipe(merge({
		fileName: 'file.json',
		edit: (parsedJson, file) => {
			if (parsedJson.someValue) {
				delete parsedJson.otherValue;
			}

			return parsedJson;
		},
	}))
	.pipe(gulp.dest('./dist'));

/**
 * Edit final JSON with transformer function
 */
gulp.src('jsonFiles/**/*.json')
	.pipe(merge({
		fileName: 'file.json',
		transform: (mergedJson) => {
			return {
				key: {
					type: 'data',
					...mergedJson,
				};
			};
		},
	}))
	.pipe(gulp.dest('./dist'));

/**
 * Provide a default object (files are merged in order so object values will be overwritten)
 */
gulp.src('jsonFiles/**/*.json')
	.pipe(merge({
		startObj: { someKey: 'defaultValue' },
	}))
	.pipe(gulp.dest('./dist'));

/**
 * Provide an overwriting object (merged at the end)
 */
gulp.src('jsonFiles/**/*.json')
	.pipe(merge({
		endObj: { someKey: 'specialValue' },
	}))
	.pipe(gulp.dest('./dist'));

/**
 * Output module.exports = {JSON_DATA}
 */
gulp.src('jsonFiles/**/*.json')
	.pipe(merge({
		exportModule: true,
	}))
	.pipe(gulp.dest('./dist'));

/**
 * Output a custom variable = {JSON_DATA}
 */
gulp.src('jsonFiles/**/*.json')
	.pipe(merge({
		fileName: 'dataModule.js',
		exportModule: 'const myVar',
	}))
	.pipe(gulp.dest('./dist'));

/**
 * Provide replacer and space options for JSON.stringify
 */
gulp.src('jsonFiles/**/*.json')
    .pipe(merge({
        jsonSpace: '  ',
        jsonReplacer: (key, value) => {/*...*/}
    })
    .pipe(gulp.dest('./dist'));

/**
 * Use a customizer function for custom merging behavior
 */
gulp.src('jsonFiles/**/*.json')
  .pipe(merge({
    customizer: (objA, objB) => {
      // Example: Concat arrays but only keep unique values
      if (Array.isArray(objA) && Array.isArray(objB)) {
        return objA.concat(objB).filter((item, index, array) => (
          array.indexOf(item) === index
        ));
      }

      return undefined;
    },
  }))
  .pipe(gulp.dest('./dist'));

/**
 * JSON5
 */
gulp.src('jsonFiles/**/*.json5')
	.pipe(merge({
		json5: true,
	}))
	.pipe(gulp.dest('./dist'));",3
https://github.com/joshswan/gulp-merge-json,### Example Input,"  /*
	json/defaults.json
 */
{
	""key1"": {
		""data1"": ""value1"",
		""data2"": ""value2""
	},
	""key2"": {
		""dataA"": ""valueA"",
		""dataB"": {
			""a"": ""b"",
			""c"": ""d""
		}
	}
}

/*
	json/development.json
 */
{
	""key1"": {
		""data1"": ""devValue""
	},
	""key2"": {
		""dataB"": {
			""c"": ""DEV MODE!""
		}
	},
	""key3"": {
		""important"": ""value""
	}
}",3
https://github.com/joshswan/gulp-merge-json,### Example Output,"  /*
	dist/combined.json
 */
{
	""key1"": {
		""data1"": ""devValue"",
		""data2"": ""value2""
	},
	""key2"": {
		""dataA"": ""valueA"",
		""dataB"": {
			""dataA"": ""valueA"",
			""dataB"": {
				""a"": ""b"",
				""c"": ""DEV MODE!""
			}
		}
	},
	""key3"": {
		""important"": ""value""
	}
}",3
https://github.com/javillegas/unity3d-store,## unity3d-store,"SOOMLA's Store Module for Unity3d

October 29th: v1.7 Work in editor! When you're in the Unity editor, data will be saved to PlayerPrefs.

September 15th: NonConsumableItem class was removed. To create a non-consumable item in your IStoreAssets implementation, use LifeTimeVG with PurchaseType of PurchaseWithMarket.

October 3rd, 2013: iOS Server Side Verification is now implemented into unity3d-store. The server is a complimentary server provided by SOOMLA to help you get your in-game purchases a bit more secured. This feature is not enabled by default. In order to enable Server Side verification go to the Soomla prefab and set ios Server Side Verification -> true.

More documentation and information in SOOMLA's Knowledge Base
For issues you can use the issues section or SOOMLA's Answers Website
unity3d-store is the Unity3d flavor of SOOMLA's Store Module.",146
https://github.com/javillegas/unity3d-store,## Economy Model,  ,1
https://github.com/javillegas/unity3d-store,## Download,,3
https://github.com/javillegas/unity3d-store,####Pre baked unitypackages:,"  ####Pre baked unitypackages: 
If you're upgrading to v1.7.x make sure you take soomla-unity3d-core again.
 soomla-unity3d-core v1.0.5
unity3d-store v1.7.12",3
https://github.com/javillegas/unity3d-store,## Debugging,"  If you want to see full debug messages from android-store and ios-store you just need to check the box that says ""Debug Messages"" in the SOOMLA Settings.
Unity debug messages will only be printed out if you build the project with Development Build checked.",3
https://github.com/javillegas/unity3d-store,## Cloning,"  There are some necessary files in submodules lined with symbolic links. If you're cloning the project make sure you clone it with the --recursive flag. $ git clone --recursive git@github.com:soomla/unity3d-store.git
",3
https://github.com/javillegas/unity3d-store,## Getting Started,"  

Download the soomla-unity3d-core and unity3d-store unitypackages and double-click on them (first 'Core' then 'Store'). It'll import all the necessary files into your project.


Drag the ""StoreEvents"" and ""CoreEvents"" Prefabs from ../Assets/Soomla/Prefabs into your scene. You should see it listed in the ""Hierarchy"" panel. [This step MUST be done for unity3d-store to work properly]


On the menu bar click ""Window -> Soomla -> Edit Settings"" and change the value for ""Soomla Secret"" (also setup Public Key if you're building for Google Play):

Soomla Secret - is an encryption secret you provide that will be used to secure your data. (If you used versions before v1.5.2 this secret MUST be the same as Custom Secret)
Choose the secret wisely. You can't change them after you launch your game!
Public Key - is the public key given to you from Google. (iOS doesn't have a public key).



Create your own implementation of IStoreAssets in order to describe your specific game's assets (example). Initialize SoomlaStore with the class you just created:
SoomlaStore.Initialize(new YourStoreAssetsImplementation());

Initialize SoomlaStore ONLY ONCE when your application loads.


Initialize SoomlaStore in the ""Start()"" function of a 'MonoBehaviour' and NOT in the ""Awake()"" function. SOOMLA has its own 'MonoBehaviour' and it needs to be ""Awakened"" before you initialize.



You'll need an event handler in order to be notified about in-app purchasing related events. refer to the Event Handling section for more information.

 And that's it ! You have storage and in-app purchasing capabilities... ALL-IN-ONE.",3
https://github.com/javillegas/unity3d-store,### Unity & Android, ,3
https://github.com/javillegas/unity3d-store,#### Starting IAB Service in background,"  If you have your own storefront implemented inside your game, it's recommended that you open the IAB Service in the background when the store opens and close it when the store is closed. // Start Iab Service
SoomlaStore.StartIabServiceInBg();

// Stop Iab Service
SoomlaStore.StopIabServiceInBg(); Don't forget to close the Iab Service when your store is closed. You don't have to do this at all, this is just an optimization.",3
https://github.com/javillegas/unity3d-store,## What's next? In App Purchasing.,"  When we implemented modelV3, we were thinking about ways that people buy things inside apps. We figured out many ways you can let your users purchase stuff in your game and we designed the new modelV3 to support 2 of them: PurchaseWithMarket and PurchaseWithVirtualItem. PurchaseWithMarket is a PurchaseType that allows users to purchase a VirtualItem with Google Play or the App Store.
PurchaseWithVirtualItem is a PurchaseType that lets your users purchase a VirtualItem with a different VirtualItem. For Example: Buying 1 Sword with 100 Gems. In order to define the way your various virtual items (Goods, Coins ...) are purchased, you'll need to create your implementation of IStoreAsset (the same one from step 4 in the ""Getting Started"" above). Here is an example: Lets say you have a VirtualCurrencyPack you call TEN_COINS_PACK and a VirtualCurrency you call COIN_CURRENCY: VirtualCurrencyPack TEN_COINS_PACK = new VirtualCurrencyPack(
	            ""10 Coins"",                    // name
	            ""A pack of 10 coins"",      // description
	            ""10_coins"",                    // item id
				10,								// number of currencies in the pack
	            COIN_CURRENCY_ITEM_ID,         // the currency associated with this pack
	            new PurchaseWithMarket(""com.soomla.ten_coin_pack"", 1.99)
		); Now you can use StoreInventory to buy your new VirtualCurrencyPack: StoreInventory.buyItem(TEN_COINS_PACK.ItemId); And that's it! unity3d-store knows how to contact Google Play or the App Store for you and will redirect your users to their purchasing system to complete the transaction. Don't forget to subscribe to store events in order to get the notified of successful or failed purchases (see Event Handling).",3
https://github.com/javillegas/unity3d-store,## Storage & Meta-Data,"  When you initialize SoomlaStore, it automatically initializes two other classes: StoreInventory and StoreInfo: 
StoreInventory is a convenience class to let you perform operations on VirtualCurrencies and VirtualGoods. Use it to fetch/change the balances of VirtualItems in your game (using their ItemIds!)
StoreInfo is where all meta data information about your specific game can be retrieved. It is initialized with your implementation of IStoreAssets and you can use it to retrieve information about your specific game.
 The on-device storage is encrypted and kept in a SQLite database. SOOMLA is preparing a cloud-based storage service that will allow this SQLite to be synced to a cloud-based repository that you'll define. Example Usages 

Get VirtualCurrency with itemId ""currency_coin"":
VirtualCurrency coin = (VirtualCurrency) StoreInfo.GetItemByItemId(""currency_coin"");


Give the user 10 pieces of a virtual currency with itemId ""currency_coin"":
StoreInventory.GiveItem(""currency_coin"", 10);


Take 10 virtual goods with itemId ""green_hat"":
StoreInventory.TakeItem(""green_hat"", 10);


Get the current balance of green hats (virtual goods with itemId ""green_hat""):
int greenHatsBalance = StoreInventory.GetItemBalance(""green_hat"");

",3
https://github.com/javillegas/unity3d-store,## Event Handling,"  SOOMLA lets you subscribe to store events, get notified and implement your own application specific behavior to those events. 
Your behavior is an addition to the default behavior implemented by SOOMLA. You don't replace SOOMLA's behavior.
 The 'Events' class is where all event go through. To handle various events, just add your specific behavior to the delegates in the Events class. For example, if you want to 'listen' to a MarketPurchase event: StoreEvents.OnMarketPurchase += onMarketPurchase;

public void onMarketPurchase(PurchasableVirtualItem pvi, string payload, Dictionary<string, string> extra) {
    // pvi is the PurchasableVirtualItem that was just purchased
    // payload is a text that you can give when you initiate the purchase operation and you want to receive back upon completion
    // extra will contain platform specific information about the market purchase.
    //      Android: The ""extra"" dictionary will contain ""orderId"" and ""purchaseToken"".
    //      iOS: The ""extra"" dictionary will contain ""receipt"" and ""token"".

    // ... your game specific implementation here ...
} NOTE: One thing you need to notice is that if you want to listen to OnSoomlaStoreInitialized event you have to set up the listener before you initialize SoomlaStore.
So you'll need to do: StoreEvents.OnSoomlaStoreInitialized += onSoomlaStoreInitialized;
 before Soomla.SoomlaStore.Initialize(new Soomla.Example.MuffinRushAssets());
",3
https://github.com/javillegas/unity3d-store,## Contribution,"  SOOMLA appreciates code contributions! You are more than welcome to extend the capabilities of SOOMLA. Fork -> Clone -> Implement -> Add documentation -> Test -> Pull-Request. IMPORTANT: If you would like to contribute, please follow our Documentation Guidelines. Clear, consistent comments will make our code easy to understand.",7
https://github.com/javillegas/unity3d-store,"## SOOMLA, Elsewhere ...","  
Framework Website
Knowledge Base
 ",6
https://github.com/javillegas/unity3d-store,## License,"  Apache License. Copyright (c) 2012-2014 SOOMLA. http://www.soom.la 
http://opensource.org/licenses/Apache-2.0
",5
https://github.com/jbenden/pcbsd,# pcbsd,The official PC-BSD git repository,1
https://github.com/jbenden/pcbsd,## Source Map,"build-files/

Contains iso image configuration files, package settings, dummy port settings, and build settings.


`overlays/`
Files included on our install images, scripts, and role settings for the installer.


`src-qt5/`
C++ Code for pcbsd-utils-qt5 package, which builds into all the various PC-BSD related GUI utilities.

Note: Qt5 build tools are located in /usr/local/lib/qt5/bin/ rather than /usr/local/bin/

Requires Qt5 to build / run

To create the Makefile in src-qt5, make sure devel/qt5 is installed on your system and then run: % cd src-qt5 && /usr/local/lib/qt5/bin/qmake


`pbi-modules/`
Contains PC-BSD's PBI .conf files.


`retired/`
Any PC-BSD utilities or files that are no longer in use.


`src-sh/`
Shell code which builds into pcbsd-utils package. Scripts, backends and various CLI related utilities for TrueOS & PC-BSD.


`src-webui/`
All the code for the AppCafe WEB interface.",1
https://github.com/jbenden/pcbsd,## Contacting Us,,5
https://github.com/jbenden/pcbsd,######IRC (FreeNode),"#pcbsd-dev (Developer questions / talk)

#pcbsd (General user information)",5
https://github.com/jbenden/pcbsd,## ######IRC (FreeNode),,5
https://github.com/jbenden/pcbsd,######Mailing Lists,http://lists.pcbsd.org,5
https://github.com/jbenden/pcbsd,## ######Mailing Lists,,5
https://github.com/jbenden/pcbsd,######Bug Tracker, http://bugs.pcbsd.org,5
https://github.com/jbenden/pcbsd,## ######Bug Tracker,,5
https://github.com/erizhang/fake_inject,#Fake Inject,  Fake inject is a assistant tool for the fake function replacement during unit test. So that it can be easier to replace the dependancy with test double.,1
https://github.com/erizhang/fake_inject,## #Fake Inject,,1
https://github.com/erizhang/fake_inject,## A Fake Function Inject Assistant for C,"  Say you have such production code. //dice.c
#include <stdio.h>
#include ""dice.h""
#include <stdlib.h>

int dice_point()
{
	srand(time(NULL));
	int r = ( rand() % 6 ) + 1;
	return r;
}

int isWon()
{
	int points = dice_point();
	if (points > 3){
		return TRUE;
	}
	return FALSE;
} If you would like to test the function isWon(), but it depends on the function dice_point() which will generate the random number, it's hard to be tested. There is a way to write a fake function of dice_point() which is called dice_point_fake() static int closed_share_point(bool write, int value)
{
    static int saved_value;
    if (write) return saved_value;
    return saved_value = value;
}

void set_points(int points)
{
    closed_share_point(false, points);
}

int dice_point_fake()
{
    return closed_share_pont(true, 0);
} So basic replace the dice_point with dice_point_fake is: ...
#include ""fake_inject.h""
...
TEST(DiceTest, GivenDiceWhenPointBiggerThanThreeShallWin)
{
	set_points(3 + 1);
	SET_FAKE_INJECT(dice_point, dice_point_fake);
	CHECK_EQUAL(1, isWon());
	RESET_FAKE_INJECT(dice_point);
}",1
https://github.com/erizhang/fake_inject,"## Hello, fake inject!",,3
https://github.com/erizhang/fake_inject,#include <stdio.h>,,-
https://github.com/erizhang/fake_inject,"#include dice.h""""",,-
https://github.com/erizhang/fake_inject,#include <stdlib.h>,,-
https://github.com/erizhang/fake_inject,"#include fake_inject.h""""",,-
https://github.com/erizhang/fake_inject,## Cheat Sheet,"Macro	Description	Example
SET_FAKE_INJECT(function_name, fake_name);	Use fake function replace original function.	SET_FAKE_INJECT(dice_point, dice_point_fake);
RESET_FAKE_INJECT(function_name);	Reset the fake function to original real function.	RESET_FAKE_INJECT(dice_point);",3
https://github.com/homingli/fig,# Fig,"  Fast, isolated development environments using Docker. Define your app's environment with Docker so it can be reproduced anywhere: FROM python:2.7
ADD . /code
WORKDIR /code
RUN pip install -r requirements.txt
CMD python app.py
 Define the services that make up your app so they can be run together in an isolated environment: web:
  build: .
  links:
   - db
  ports:
   - ""8000:8000""
   - ""49100:22""
db:
  image: postgres (No more installing Postgres on your laptop!) Then type fig up, and Fig will start and run your entire app:  There are commands to: 
start, stop and rebuild services
view the status of running services
tail running services' log output
run a one-off command on a service
",13
https://github.com/homingli/fig,## Installation and documentation,  Full documentation is available on Fig's website.,6
https://github.com/illuminate3/LogViewer,# LogViewer [![For Laravel 5][badge_laravel]](https://github.com/ARCANEDEV/LogViewer#logviewer) [![Packagist License][badge_license]](https://github.com/ARCANEDEV/LogViewer/blob/master/LICENSE.md)," 




 By ARCANEDEV© This package allows you to manage and keep track of each one of your logs files stored under storage_path('logs'). Minimal configuration required. 
NOTE: You can also use LogViewer as an API.
 Official documentation for LogViewer can be found at the LogViewer Wiki. Feel free to check out the releases, license, and contribution guidelines.",156
https://github.com/illuminate3/LogViewer,## Features,"  
A great Log viewer API.
Ready to use (Views, Routes, controllers ?Out of the box) [Note: No need to publish assets]
View, paginate, filter, download and delete logs.
Generate logs menu/tree (With localized levels).
Grouped logs by dates and levels.
Works great with big logs !!
Well tested (100% code coverage with maximum code quality).
",1
https://github.com/illuminate3/LogViewer,## Table of contents,"  
Requirements
Installation and Setup
Configuration
Usage
Extras
FAQ
",6
https://github.com/illuminate3/LogViewer,### ONGOING,"  
 Log viewer CLI.
 Log viewer Statistics & Charts.
 Complete the documentation + Examples (Wiki).
",4
https://github.com/illuminate3/LogViewer,### TODOS,"  
 Adding more localizations.
",4
https://github.com/illuminate3/LogViewer,### DONE,"  
 Well documented package (IDE Friendly).
 100% Code coverage + Maximum code quality.
 Localized log levels.
 Laravel 5.1 supported.
 Laravel 5.0 supported.
 Log viewer menu/tree.
 Logs and Log entries pagination.
 Download the log file.
 Customized log levels icons (font awesome).
",4
https://github.com/illuminate3/LogViewer,## Contribution,"  Any ideas are welcome. Feel free to submit any issues or pull requests, please check the contribution guidelines.",7
https://github.com/illuminate3/LogViewer,## PREVIEW,"  

",3
https://github.com/willotheblessed/Dragonet,# Dragonet," The universal Minecraft server, supports both Minecraft PC and Minecraft PE clients.",1
https://github.com/willotheblessed/Dragonet,#### [Plugin Compatibility](https://github.com/GlowstoneMC/Glowstone/wiki/Plugin-Compatibility),,3
https://github.com/willotheblessed/Dragonet,##Is this fully working now?,"Yes, mostly! But you may expirence some bugs and issues because this software is still in heavy development stage.",4
https://github.com/willotheblessed/Dragonet,##Where do I grab the GUI version?,"Right now, The Dragonet Team is working on a GUI wrapper for the server, it will be released when we are done with 0.0.2!",4
https://github.com/willotheblessed/Dragonet,##Where is the Dragonet GitHub Wiki?,Here!,6
https://github.com/willotheblessed/Dragonet,##Download,You may download pre-compiled binaries at our website: http://dragonet.org/,3
https://github.com/willotheblessed/Dragonet,###Credits & Licencing,"Dragonet software: A universal Minecraft server that supports both Minecraft for PC and Minecraft: Pocket Edition.
Dragonet's code is under org.dragonet package and they are under LGPL v3.

GlowStone software: A Minecraft server that written from zero and no Mojang code included.
Glowstone's code is under net.glowstone package and they are under MIT Licence.",5
https://github.com/ONSdigital/ras-common,# ras-common," 
 This code is derived from work done as a part of Swagger-Codegen and the API Gateway. It's aim is to
standardise boilerplate code used by RAS Micro-Services and extricate as much infrastructure as possible
from the Micro-Service code bases. It should be possible (as demonstrated below) to implement a Micro-Service
in two lines of code (with a few text based configuration files) that is immediately deployable on Cloud Foundry. This code WAS published on the Python Package Index here;
https://pypi.python.org/pypi/ons-ras-common but this is being obsoleted
in favour of using the GitHub ""requirements"" feature. i.e. the package is pulled in directly from GitHub rather than
via Pypi.",12
https://github.com/ONSdigital/ras-common,#### How to use this code,"  These modules are subject to continual change, but every effort will be made to maintain backwards compatibility
so no future additions should break Micro-Services already using the library. In the event something major does
change that breaks this model, it should be well documented on RAS_Developers. With a view to not being
immediately subject to any breakage, the recommendation is that pip freeze is used to tag Micro-Service
implementations to specific versions of this library. 

ons_cloudfoundry
This code is used to automatically detect the presence of Cloud Foundry and amend available environmnt
variables accordingly. Useful properties include;

detected - True if we're running on Cloud Foundry

This module will also update environment variables db_name and db_connection if there are any
database service credentials available in VCAP_SERVICES.


ons_cryptograpgher
This provides encrypt and decrypt as standard functions, which are intended to be impelented by the
platform recommended encryption routines. If you call these functions in preference to implementing your
own encryption routine, should the platform recommendation change in the future, using the most recent
version of this library should be the only change needed.


ons_database
Currently database access if provided via SQLAlchemy over a generic database driver, so within the bounds
of current testing the driver in use is database agnostic. This code will interact with the local configuration
file and the Cloud Foundry detection module and attempt to automatically connect up your database. There are
some additional configuration options that allow you to automatically drop all tables on startup (useful for
unit testing), and any missing tables are created from your in-code models. Current support includes both
Postgres and SQLite drivers.


ons_decorators
We are building a library of useful decorators, currently the focus of this module is validate_jwt. This
can be added to a micro-service endpoint to ensure the endpoint is protected using the currently implemented
JWT token authorization. There is a flag in the configuration file that can be used to turn this option off
dynamically for testing purposes, and the same flag when applied to the API gateway will cause JWT tokens
to be injected into headers as they pass through the gateway, also good for testing. (so there's no real
excuse for 'not' protecting every endpoint as it's implemented)


ons_environment
The environment model wraps all the others together and provides access to them via a single global variable.
To use the package, follow the following pattern;
from ons_ras_common import ons_env
if __name__ == '__main__':
    ons_env.activate()
There are many properties exposed by ons_env that provide access to the other underlying modules.


ons_jwt
Wraps the current implementation of our token authorization. The main function validate is called by the
validate_jwt wrapper, but the other functions may be useful. This is likely to be extended in the near
future with more functionality.


ons_logger
This is a functioning logging system, but currently a placeholder for the 'next generation' logger which will
log in JSON format for the centralised Splunk logging infrastructure.


ons_registration
In order to become visible to the API gateway for the purposes of endpoint routing, Micro-Services need to
register their endpoints (one way or another) with the gateway. This routine provides a connection, registration
and keep-alive service for just that. The routines are generic and easy to replicate in other languages should
the need arise.


ons_swagger
This is a very basic library for managing the local 'swagger' (or API specification) file. It's useful for
extracting information (such as a list of endpoints) and re-writing parts of the file, for example to re-point
the 'host' component.


ons_rabbit
This is a wrapper for RabbitMQ connections and works with the Cloud Foundry module to detect whether there is a
Rabbit Queue available, and if there is, makes the credentials available as properties. i.e. if you have a queue
installed you should have onv_env.rabbit.{host,port,name,username,password,vhost}. Alternatively you can put
local defaults in your config.ini using rabbit_{host,port,name,username,password,vhost}. See the development
section in this repo's config.ini for an example.

",3
https://github.com/LordWiley/node-taas-client,# node-taas-client," A node.js module to interface with the Things-as-a-service, client-side. This package implements a node.js module for #thethingsystem clients,
talking either directly to the steward or through a TAAS server.",16
https://github.com/LordWiley/node-taas-client,## Install,"  npm install taas-client
",3
https://github.com/LordWiley/node-taas-client,## API, ,36
https://github.com/LordWiley/node-taas-client,### Ready!,"  var ClientAPI = require('taas-client');
",36
https://github.com/LordWiley/node-taas-client,### Set!,"  You can identify the steward by either: 

steward.name:

IP address, e.g., '192.168.1.xxx', or '127.0.0.1'
domain name, e.g., 'zekariah', or 'localhost'
place name, i.e., place1.name such as 'zephyr'



steward.uuid:

place UUID, e.g., 2f402f80-da50-11e1-9b23-0123456789ab


 The place and the UUID are advertised by the steward on the local network.
You should also include a reference to either the location of the steward's certificate file (steward.crtPath)
or the actual certificate itself (steward.crtData). If your steward is registered with a TAAS cloud, then you should also deifne the cloud.service domain
and the location of TAAS certificate (cloud.crtPath) or the actual certificate itself (cloud.CrtData). The state machine is fairly simple: 

There are two channels: 'console' and 'management'.


Each of these channels will emit an 'open' event, letting you know whether login is required.


When a channel is ready for use, it will emit a 'ready' event


In the case of the 'console' channel, the 'data' parameter is an array indicating what privileges are authorized.


In the case of the 'management' channel, the 'data' parameter is a user object.




If either channel detects a remote close or an error, then these events are emitted, respectively.

 The API does not attempt to recover on either a close, or error.
Instead, you may choose to start over or exit, as you see fit. var steward = new ClientAPI.ClientAPI(
{ steward : { name    : 'steward.local'
            , crtPath : 'server.crt'
            }

, cloud   : { service : 'taas.thethingsystem.net'
            , crtPath : 'cloud.crt'
            }
}).on('open', function(channel, loginP) {
  // check to see if login required
  if (!loginP) {
    if (channel === 'management') console.log('steward in developer mode, no need to log in.');
    return;
  }

  steward.login('mrose/7', '889791', function(err, error) {
    if (!!err) return console.log('>>> login error: ' + JSON.stringify(error));

    // logged in!
  });
}).on('ready', function(channel, data) {
  // when the management channel is ready, it's time to get to work!
  if (channel !== 'management') return;

  // ok, let's get to work!
}).on('close', function(channel) {
  // typically, just log and recover/exit
}).on('error', function(err, channel) {
  // typically, just log and recover/exit
});
",36
https://github.com/LordWiley/node-taas-client,### Go!,"  There is one state variable, 'actors', that is an object containing information about all known actors in the system,
e.g., 'place/1', 'device/1', and so on.
As changes are reported by the steward, an 'actor' event is omitted with the identity and classification of the actor: // use this event to filter changes on either a particular device (whoami) or deviceType (whatami)
steward.on('actor', function(whoami, whatami) {

});
 The API provides several methods to communicate with the steward.
Each method takes a callback which may be invoked more than once.
Blocking operations in the steward typically result in two callbacks,
the first is a success or failure indicator;
and, if success is indicated, then a subsequent callback is made.
The 'list*' and 'perform*' operations are not blocking,
hence the callback is made exactly once. // if (!doneP), then only a success/failure indication is present, and a subsequent invocation will occur!
var cb = function(message, doneP) { ... };

// invoked exactly once
var cb1 = function(message) { ... };


steward.createActivity(name, uuid, event, task, armed, comments, cb);

steward.createDevice(name, uuid, whatami, info, comments, cb);

steward.createEvent(name, uuid, actor, observe, parameter, comments, cb);

steward.createGroup(name, uuid, type, operator, members, comments, cb);

steward.createTask(name, uuid, actor, perform, parameter, comments, cb);

steward.createUser(name, uuid, role, clientName, comments, cb);


steward.listActivity(activityID, options, cb1);

steward.listActors(prefix, options, cb1);

steward.listDevice(deviceID, options, cb1);

steward.listEvent(eventID, options, cb1);

steward.listGroup(groupID, options, cb1);

steward.listTask(taskID, options, cb1);

steward.listUser(userID, options, cb1);


steward.modifyActivity(activityID, name, armed, event, task, cb);

steward.modifyGroup(groupID, name, type, operator, members, cb);


steward.performActivity(activityID, cb1);

steward.performActor = function(prefix, perform, parameter, cb1);

steward.performDevice(deviceID, perform, parameter, cb1);

steward.performGroup(groupID, perform, parameter, cb1);

steward.performTask(taskID, cb1);


steward.deleteActivity = function(activityID, cb);

// steward.deleteDevice = function(deviceID, cb);

steward.deleteEvent = function(eventID, cb);

steward.deleteGroup = function(groupID, cb);

steward.deleteTask = function(taskID, cb);
",36
https://github.com/LordWiley/node-taas-client,### Finally!,  Enjoy.,-
https://github.com/LordWiley/node-taas-client,# License,"  MIT license. Freely have you received, freely give. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",5
https://github.com/itomato/brew,# Homebrew," Features, usage and installation instructions are summarised on the homepage.",16
https://github.com/itomato/brew,## Update Bug,  If Homebrew was updated on Aug 10-11th 2016 and brew update always says Already up-to-date. you need to run: cd $(brew --repo); git fetch; git reset --hard origin/master; brew update,34
https://github.com/itomato/brew,## What Packages Are Available?,"  
Type brew search for a list.
Or visit braumeister.org to browse packages online.
Or use brew search --desc <keyword> to browse packages from the command line.
",3
https://github.com/itomato/brew,## More Documentation,"  brew help, man brew or check our documentation.",6
https://github.com/itomato/brew,## Troubleshooting,"  First, please run brew update and brew doctor. Second, read the Troubleshooting Checklist. If you don't read these it will take us far longer to help you with your problem.",36
https://github.com/itomato/brew,## Contributing,"  We'd love you to contribute to Homebrew. First, please read our Contribution Guide and Code of Conduct. We explicitly welcome contributions from people who have never contributed to open-source before: we were all beginners once! We can help build on a partially working pull request with the aim of getting it merged. We are also actively seeking to diversify our contributors and especially welcome contributions from women from all backgrounds and people of colour. A good starting point for contributing is running brew audit (or brew audit --strict) with some of the packages you use (e.g. brew audit wget if you use wget) and then read through the warnings, try to fix them until brew audit shows no results and submit a pull request. If no formulae you use have warnings you can run brew audit without arguments to have it run on all packages and pick one. Good luck!",7
https://github.com/itomato/brew,## Security,"  Please report security issues to security@brew.sh. This is our PGP key which is valid until May 24, 2017. 
Key ID: 0xE33A3D3CCE59E297
Fingerprint: C657 8F76 2E23 441E C879  EC5C E33A 3D3C CE59 E297
Full key: https://keybase.io/homebrew/key.asc
",6
https://github.com/itomato/brew,## Who Are You?,"  Homebrew's current maintainers are Misty De Meo, Andrew Janke, Xu Cheng, Tomasz Pajor, Mike McQuaid, Baptiste Fontaine, Brett Koonce, ilovezfs, Martin Afanasjew, Dominyk Tiller, Tim Smith and Alex Dunn. Former maintainers with significant contributions include Jack Nagel, Adam Vandenberg and Homebrew's creator: Max Howell.",5
https://github.com/itomato/brew,## License,"  Code is under the BSD 2 Clause (NetBSD) license.
Documentation is under the Creative Commons Attribution license.",5
https://github.com/itomato/brew,## Donations,"  Homebrew is a non-profit project run entirely by unpaid volunteers. We need your funds to pay for software, hardware and hosting around continuous integration and future improvements to the project. Every donation will be spent on making Homebrew better for our users. Homebrew is a member of the Software Freedom Conservancy which provides us with an ability to receive tax-deductible, Homebrew earmarked donations (and many other services). Software Freedom Conservancy, Inc. is a 501(c)(3) organization incorporated in New York, and donations made to it are fully tax-deductible to the extent permitted by law. 
Donate with PayPal
Donate by USA $ check from a USA bank:

Make check payable to ""Software Freedom Conservancy, Inc."" and place ""Directed donation: Homebrew"" in the memo field.  Checks should then be mailed to:

Software Freedom Conservancy, Inc.
137 Montague ST  STE 380
BROOKLYN, NY 11201             USA




Donate by wire transfer: contact accounting@sfconservancy.org for wire transfer details.
Donate with Flattr or PayPal Giving Fund: coming soon.
",6
https://github.com/itomato/brew,## Sponsors,  Our CI infrastructure was paid for by our Kickstarter supporters. Our CI infrastructure is hosted by The Positive Internet Company. Our bottles (binary packages) are hosted by Bintray.  Secure password storage and syncing provided by 1Password for Teams by AgileBits  Homebrew is a member of the Software Freedom Conservancy ,56
https://github.com/martinheidegger/nodegit,## NodeGit," 
Node bindings to the libgit2 project.
 


Linux
OS X
Windows
Coverage
Dependencies


















 Stable: 0.11.9",14
https://github.com/martinheidegger/nodegit,## Have a problem? Come chat with us! ##,  ,5
https://github.com/martinheidegger/nodegit,## Maintained by ##,"  Tim Branyen @tbranyen,
John Haley @johnhaley81, and
Max Korp @maxkorp with help from tons of
awesome contributors!",5
https://github.com/martinheidegger/nodegit,### Alumni Maintainers ###,"  Steve Smith @orderedlist,
Michael Robinson @codeofinterest, and
Nick Kallen @nk",5
https://github.com/martinheidegger/nodegit,## API Documentation. ##,  http://www.nodegit.org/,6
https://github.com/martinheidegger/nodegit,## Getting started. ##,"  NodeGit will work on most systems out-of-the-box without any native
dependencies. npm install nodegit If you receive errors about libstdc++, which are commonly experienced when
building on Travis-CI, you can fix this by upgrading to the latest
libstdc++-4.9. In Ubuntu: sudo add-apt-repository ppa:ubuntu-toolchain-r/test
sudo apt-get update
sudo apt-get install libstdc++-4.9-dev In Travis: addons:
  apt:
    sources:
      - ubuntu-toolchain-r-test
    packages:
      - libstdc++-4.9-dev If you are still encountering problems while installing, you should try the
Building from source
instructions.",3
https://github.com/martinheidegger/nodegit,## API examples. ##, ,3
https://github.com/martinheidegger/nodegit,### Cloning a repository and reading a file: ###,"  var Git = require(""nodegit"");

// Clone a given repository into the `./tmp` folder.
Git.Clone(""https://github.com/nodegit/nodegit"", ""./tmp"")
  // Look up this known commit.
  .then(function(repo) {
    // Use a known commit sha from this repository.
    return repo.getCommit(""59b20b8d5c6ff8d09518454d4dd8b7b30f095ab5"");
  })
  // Look up a specific file within that commit.
  .then(function(commit) {
    return commit.getEntry(""README.md"");
  })
  // Get the blob contents from the file.
  .then(function(entry) {
    // Patch the blob to contain a reference to the entry.
    return entry.getBlob().then(function(blob) {
      blob.entry = entry;
      return blob;
    });
  })
  // Display information about the blob.
  .then(function(blob) {
    // Show the path, sha, and filesize in bytes.
    console.log(blob.entry.path() + blob.entry.sha() + blob.rawsize() + ""b"");

    // Show a spacer.
    console.log(Array(72).join(""="") + ""\n\n"");

    // Show the entire file.
    console.log(String(blob));
  })
  .catch(function(err) { console.log(err); });",3
https://github.com/martinheidegger/nodegit,### Emulating git log: ###,"  var Git = require(""nodegit"");

// Open the repository directory.
Git.Repository.open(""tmp"")
  // Open the master branch.
  .then(function(repo) {
    return repo.getMasterCommit();
  })
  // Display information about commits on master.
  .then(function(firstCommitOnMaster) {
    // Create a new history event emitter.
    var history = firstCommitOnMaster.history();

    // Create a counter to only show up to 9 entries.
    var count = 0;

    // Listen for commit events from the history.
    history.on(""commit"", function(commit) {
      // Disregard commits past 9.
      if (++count >= 9) {
        return;
      }

      // Show the commit sha.
      console.log(""commit "" + commit.sha());

      // Store the author object.
      var author = commit.author();

      // Display author information.
      console.log(""Author:\t"" + author.name() + "" <"" + author.email() + "">"");

      // Show the commit date.
      console.log(""Date:\t"" + commit.date());

      // Give some space and show the message.
      console.log(""\n    "" + commit.message());
    });

    // Start emitting events.
    history.start();
  }); For more examples, check the examples/ folder.",3
https://github.com/martinheidegger/nodegit,## Unit tests. ##,  You will need to build locally before running the tests.  See above. npm test,3
https://github.com/the-vk/yamp-js,## Usage," Yamp parser is the combination of other parsers - primitive (like parser for a single char) or more complex. A simplest parser that parse just a single character: //Parse a single char 'a'
var charParser = yamp.Char('a');
var result = yamp.Parse(charParser, 'a');
 More complex parsers can be created with parser combiners functions: //Parse a stream of chars that can contains 0 to unlimited chars 'a'
var charStreamParser = yamp.Many(yamp.Char('a'));
var result = yamp.Parse(charStreamParser, 'aaaaa');
 Yamp has fluent API to help configuring parsers: //Parsers can be configured with method chaining
var charStreamParser = yamp.Char('a').Many();
var result = charStreamParser.Parse('aaaaa');
 Unlike traditional parsers (ANTLR, yacc) yamp doesn`t have separate stages for lexical and syntax parse.
If input string can contains comments, you need to remove them before calling yamp parser - or include comments support into parser (than can really challenging task depending on DLS complexity).",3
https://github.com/the-vk/yamp-js,## API Documentation, ,6
https://github.com/the-vk/yamp-js,"### yamp.Select(parser, selector)",  yamp.Select() creates parser that converts output of parser into something different. Common usage is to convert raw strings into JavaScripts object or with yamp.Then() to concat results.,36
https://github.com/the-vk/yamp-js,#### Parameters,"  parser:
Parser for expected element. selector:
Functor than takes single parameter and returns transformed value.",36
https://github.com/the-vk/yamp-js,#### Example,"  //Parser that matches string 'data' and returns object.
var parser = parse.String('data').Select(function (d) { return {data: d}; });
",36
https://github.com/the-vk/yamp-js,"### yamp.Then(first, second)","  yamp.Then() creates parser that match first element, then second. Parameter 'second' allows to handle output of the first parser and append it to output of the second parser.",36
https://github.com/the-vk/yamp-js,#### Parameters,"  first:
First parser. second:
Functor that concats output of the first parser and returns second parser.",36
https://github.com/the-vk/yamp-js,#### Example,"  //Parser that matches string 'ab' and return string 'a'
var parser = yamp.Char('a').Then(function (f) { return yamp.Char('b').Return(f});
var result = parser.Parse('ab'); //result == 'a'

//Parser that mathes any single letter and then any single digit. Returns letter concated with digit.
var firstParser = yamp.Letter();
var secondParser = yamp.Digit();
var idParser = firstParser.Then(function(letter) {
	return secondParser.Select(function (digit) {
		return letter + digit;
	});
});
var result = idParser.Parse(idParser,  'a1'); //result == a1
",36
https://github.com/Olive4Oyl/js-jquery-stop-propogation-lab-wdf-000,# Stop Propagation Lab,,1
https://github.com/Olive4Oyl/js-jquery-stop-propogation-lab-wdf-000,## Objectives,"  
use stopPropagation() to prevent event handlers from bubbling up
",1
https://github.com/Olive4Oyl/js-jquery-stop-propogation-lab-wdf-000,## Intro,  You've been hired to fix some major issues with a traffic light. Your job is to modify the existing code to make sure that the events firing on the page are only firing when you want them to.,1
https://github.com/Olive4Oyl/js-jquery-stop-propogation-lab-wdf-000,## Instructions,"  Open up index.html in the browser. You should see the outline of 3 traffic lights. When you click on the body of any of the lights, the background of the fixture should turn purple. When you click it again, it should turn white. When you click on one of the lights, like the top light of the first fixture, the light turns red, but the body also turns purple. Click around a bit and take a look at the behavior of the lights. Ideally, we want to be able to click on the lights and only have that specific light change color. Your job is to edit the code in js/script.js to make that happen. Currently, three tests fail. These tests check to see that the click event on the light fixture isn't fired when you click on an individual light. You'll want to make sure to pass all the tests. View Stop Propagation Lab on Learn.co and start learning to code for free.",3
https://github.com/bdurand/whenever,### Installation," $ gem install whenever Or with Bundler in your Gemfile. gem 'whenever', :require => false",3
https://github.com/bdurand/whenever,### Getting started,"  $ cd /apps/my-great-project
$ wheneverize . This will create an initial config/schedule.rb file for you.",3
https://github.com/bdurand/whenever,### The `whenever` command,"  $ cd /apps/my-great-project
$ whenever This will simply show you your schedule.rb file converted to cron syntax. It does not read or write your crontab file; you'll need to do this in order for your jobs to execute: $ whenever --update-crontab You can list installed cron jobs using crontab -l. Run whenever --help for a complete list of options for selecting the schedule to use, setting variables in the schedule, selecting a user as which to install the crontab, etc.",3
https://github.com/bdurand/whenever,### Example schedule.rb file,"  every 3.hours do # 1.minute 1.day 1.week 1.month 1.year is also supported
  runner ""MyModel.some_process""
  rake ""my:rake:task""
  command ""/usr/bin/my_great_command""
end

every 1.day, :at => '4:30 am' do
  runner ""MyModel.task_to_run_at_four_thirty_in_the_morning""
end

every :hour do # Many shortcuts available: :hour, :day, :month, :year, :reboot
  runner ""SomeModel.ladeeda""
end

every :sunday, :at => '12pm' do # Use any day of the week or :weekend, :weekday
  runner ""Task.do_something_great""
end

every '0 0 27-31 * *' do
  command ""echo 'you can use raw cron syntax too'""
end

# run this task only on servers with the :app role in Capistrano
# see Capistrano roles section below
every :day, :at => '12:20am', :roles => [:app] do
  rake ""app_server:task""
end",3
https://github.com/bdurand/whenever,# run this task only on servers with the :app role in Capistrano,"  Whenever ships with three pre-defined job types: command, runner, and rake. You can define your own with job_type. For example: job_type :awesome, '/usr/local/bin/awesome :task :fun_level'

every 2.hours do
  awesome ""party"", :fun_level => ""extreme""
end Would run /usr/local/bin/awesome party extreme every two hours. :task is always replaced with the first argument, and any additional :whatevers are replaced with the options passed in or by variables that have been defined with set. The default job types that ship with Whenever are defined like so: job_type :command, "":task :output""
job_type :rake,    ""cd :path && :environment_variable=:environment bundle exec rake :task --silent :output""
job_type :runner,  ""cd :path && bin/rails runner -e :environment ':task' :output""
job_type :script,  ""cd :path && :environment_variable=:environment bundle exec script/:task :output"" Pre-Rails 3 apps and apps that don't use Bundler will redefine the rake and runner jobs respectively to function correctly. If a :path is not set it will default to the directory in which whenever was executed. :environment_variable will default to 'RAILS_ENV'. :environment will default to 'production'. :output will be replaced with your output redirection settings which you can read more about here: http://github.com/javan/whenever/wiki/Output-redirection-aka-logging-your-cron-jobs All jobs are by default run with bash -l -c 'command...'. Among other things, this allows your cron jobs to play nice with RVM by loading the entire environment instead of cron's somewhat limited environment. Read more: http://blog.scoutapp.com/articles/2010/09/07/rvm-and-cron-in-production You can change this by setting your own :job_template. set :job_template, ""bash -l -c ':job'"" Or set the job_template to nil to have your jobs execute normally. set :job_template, nil",-
https://github.com/bdurand/whenever,# see Capistrano roles section below,"  Use the built-in Capistrano recipe for easy crontab updates with deploys. For Capistrano V3, see the next section. In your ""config/deploy.rb"" file: require ""whenever/capistrano"" Take a look at the recipe for options you can set. https://github.com/javan/whenever/blob/master/lib/whenever/capistrano/v2/recipes.rb
For example, if you're using bundler do this: set :whenever_command, ""bundle exec whenever""
require ""whenever/capistrano"" If you are using different environments (such as staging, production), then you may want to do this: set :whenever_environment, defer { stage }
require ""whenever/capistrano"" The capistrano variable :stage should be the one holding your environment name. This will make the correct :environment available in your schedule.rb. If both your environments are on the same server you'll want to namespace them or they'll overwrite each other when you deploy: set :whenever_environment, defer { stage }
set :whenever_identifier, defer { ""#{application}_#{stage}"" }
require ""whenever/capistrano""",3
https://github.com/bdurand/whenever,### Define your own job types,"  In your ""Capfile"" file: require ""whenever/capistrano"" Take a look at the load:defaults task (bottom of file) for options you can set. For example, to namespace the crontab entries by application and stage do this in your ""config/deploy.rb"" file: set :whenever_identifier, ->{ ""#{fetch(:application)}_#{fetch(:stage)}"" } The Capistrano integration by default expects the :application variable to be set in order to scope jobs in the crontab. If your deploy user is different than your application user, you can specify to set the crontab user with: set :whenever_user, ""appuser""",3
https://github.com/bdurand/whenever,### Capistrano integration,"  The first thing to know about the new roles support is that it is entirely
optional and backwards-compatible. If you don't need different jobs running on
different servers in your capistrano deployment, then you can safely stop reading
now and everything should just work the same way it always has. When you define a job in your schedule.rb file, by default it will be deployed to
all servers in the whenever_roles list (which defaults to [:db]). However, if you want to restrict certain jobs to only run on subset of servers,
you can add a :roles => [...] argument to their definitions. Make sure to add
that role to the whenever_roles list in your deploy.rb. When you run cap deploy, jobs with a :roles list specified will only be added to
the crontabs on servers with one or more of the roles in that list. Jobs with no :roles argument will be deployed to all servers in the whenever_roles
list. This is to maintain backward compatibility with previous releases of whenever. So, for example, with the default whenever_roles of [:db], a job like this would be
deployed to all servers with the :db role: every :day, :at => '12:20am' do
  rake 'foo:bar'
end If we set whenever_roles to [:db, :app] in deploy.rb, and have the following
jobs in schedule.rb: every :day, :at => '1:37pm', :roles => [:app] do
  rake 'app:task' # will only be added to crontabs of :app servers
end

every :hour, :roles => [:db] do
  rake 'db:task' # will only be added to crontabs of :db servers
end

every :day, :at => '12:02am' do
  command ""run_this_everywhere"" # will be deployed to :db and :app servers
end Here are the basic rules: 
If a server's role isn't listed in whenever_roles, it will never have jobs
added to its crontab.
If a server's role is listed in the whenever_roles, then it will have all
jobs added to its crontab that either list that role in their :roles arg or
that don't have a :roles arg.
If a job has a :roles arg but that role isn't in the whenever_roles list,
that job will not be deployed to any server.
",3
https://github.com/bdurand/whenever,### Capistrano V3 Integration,"  If your production environment uses RVM (Ruby Version Manager) you will run into a gotcha that causes your cron jobs to hang.  This is not directly related to Whenever, and can be tricky to debug.  Your .rvmrc files must be trusted or else the cron jobs will hang waiting for the file to be trusted.  A solution is to disable the prompt by adding this line to your user rvm file in ~/.rvmrc rvm_trust_rvmrcs_flag=1 This tells rvm to trust all rvmrc files.",3
https://github.com/bdurand/whenever,### Capistrano roles,"  No. Heroku does not support cron, instead providing Heroku Scheduler. If you deploy to Heroku, you should use that rather than Whenever.",3
https://github.com/bdurand/whenever,### RVM Integration,  whenever-test is an extension to Whenever for testing a Whenever schedule.,3
https://github.com/bdurand/whenever,### Heroku?,  Whenever was created for use at Inkling (http://inklingmarkets.com). Their take on it: http://blog.inklingmarkets.com/2009/02/whenever-easy-way-to-do-cron-jobs-from.html Thanks to all the contributors who have made it even better: http://github.com/javan/whenever/contributors,6
https://github.com/bdurand/whenever,### Testing,"  For general discussion and questions, please use the google group: http://groups.google.com/group/whenever-gem If you've found a genuine bug or issue, please use the Issues section on github: http://github.com/javan/whenever/issues Ryan Bates created a great Railscast about Whenever: http://railscasts.com/episodes/164-cron-in-ruby
It's a little bit dated now, but remains a good introduction.    Copyright © 2016 Javan Makhmali",3
https://github.com/bdurand/whenever,### Credit,,5
https://github.com/bdurand/whenever,### Discussion / Feedback / Issues / Bugs,,6
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
